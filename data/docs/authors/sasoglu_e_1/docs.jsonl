{"id": "0705.3995", "contents": "Title: On Undetected Error Probability of Binary Matrix Ensembles Abstract: In this paper, an analysis of the undetected error probability of ensembles\nof binary matrices is presented. The ensemble called the Bernoulli ensemble\nwhose members are considered as matrices generated from i.i.d. Bernoulli source\nis mainly considered here. The main contributions of this work are (i)\nderivation of the error exponent of the average undetected error probability\nand (ii) closed form expressions for the variance of the undetected error\nprobability. It is shown that the behavior of the exponent for a sparse\nensemble is somewhat different from that for a dense ensemble. Furthermore, as\na byproduct of the proof of the variance formula, simple covariance formula of\nthe weight distribution is derived. \n\n"}
{"id": "0707.1099", "contents": "Title: Worst-Case Interactive Communication and Enhancing Sensor Network\n  Lifetime Abstract: We are concerned with the problem of maximizing the worst-case lifetime of a\ndata-gathering wireless sensor network consisting of a set of sensor nodes\ndirectly communicating with a base-station.We propose to solve this problem by\nmodeling sensor node and base-station communication as the interactive\ncommunication between multiple correlated informants (sensor nodes) and a\nrecipient (base-station). We provide practical and scalable interactive\ncommunication protocols for data gathering in sensor networks and demonstrate\ntheir efficiency compared to traditional approaches.\n  In this paper, we first develop a formalism to address the problem of\nworst-case interactive communication between a set of multiple correlated\ninformants and a recipient. We realize that there can be different objectives\nto achieve in such a communication scenario and compute the optimal number of\nmessages and bits exchanged to realize these objectives. Then, we propose to\nadapt these results in the context of single-hop data-gathering sensor\nnetworks. Finally, based on this proposed formalism, we propose a clustering\nbased communication protocol for large sensor networks and demonstrate its\nsuperiority over a traditional clustering protocol. \n\n"}
{"id": "0708.0271", "contents": "Title: Capacity Region of the Finite-State Multiple Access Channel with and\n  without Feedback Abstract: The capacity region of the Finite-State Multiple Access Channel (FS-MAC) with\nfeedback that may be an arbitrary time-invariant function of the channel output\nsamples is considered. We characterize both an inner and an outer bound for\nthis region, using Masseys's directed information. These bounds are shown to\ncoincide, and hence yield the capacity region, of FS-MACs where the state\nprocess is stationary and ergodic and not affected by the inputs.\n  Though `multi-letter' in general, our results yield explicit conclusions when\napplied to specific scenarios of interest. E.g., our results allow us to:\n  - Identify a large class of FS-MACs, that includes the additive mod-2 noise\nMAC where the noise may have memory, for which feedback does not enlarge the\ncapacity region.\n  - Deduce that, for a general FS-MAC with states that are not affected by the\ninput, if the capacity (region) without feedback is zero, then so is the\ncapacity (region) with feedback.\n  - Deduce that the capacity region of a MAC that can be decomposed into a\n`multiplexer' concatenated by a point-to-point channel (with, without, or with\npartial feedback), the capacity region is given by $\\sum_{m} R_m \\leq C$, where\nC is the capacity of the point to point channel and m indexes the encoders.\nMoreover, we show that for this family of channels source-channel coding\nseparation holds. \n\n"}
{"id": "0708.1859", "contents": "Title: Multiple-Description Coding by Dithered Delta-Sigma Quantization Abstract: We address the connection between the multiple-description (MD) problem and\nDelta-Sigma quantization. The inherent redundancy due to oversampling in\nDelta-Sigma quantization, and the simple linear-additive noise model resulting\nfrom dithered lattice quantization, allow us to construct a symmetric and\ntime-invariant MD coding scheme. We show that the use of a noise shaping filter\nmakes it possible to trade off central distortion for side distortion.\nAsymptotically as the dimension of the lattice vector quantizer and order of\nthe noise shaping filter approach infinity, the entropy rate of the dithered\nDelta-Sigma quantization scheme approaches the symmetric two-channel MD\nrate-distortion function for a memoryless Gaussian source and MSE fidelity\ncriterion, at any side-to-central distortion ratio and any resolution. In the\noptimal scheme, the infinite-order noise shaping filter must be minimum phase\nand have a piece-wise flat power spectrum with a single jump discontinuity. An\nimportant advantage of the proposed design is that it is symmetric in rate and\ndistortion by construction, so the coding rates of the descriptions are\nidentical and there is therefore no need for source splitting. \n\n"}
{"id": "0708.3699", "contents": "Title: Convolutional Entanglement Distillation Abstract: We develop a theory of entanglement distillation that exploits a\nconvolutional coding structure. We provide a method for converting an arbitrary\nclassical binary or quaternary convolutional code into a convolutional\nentanglement distillation protocol. The imported classical convolutional code\ndoes not have to be dual-containing or self-orthogonal. The yield and\nerror-correcting properties of such a protocol depend respectively on the rate\nand error-correcting properties of the imported classical convolutional code. A\nconvolutional entanglement distillation protocol has several other benefits.\nTwo parties sharing noisy ebits can distill noiseless ebits ``online'' as they\nacquire more noisy ebits. Distillation yield is high and decoding complexity is\nsimple for a convolutional entanglement distillation protocol. Our theory of\nconvolutional entanglement distillation reduces the problem of finding a good\nconvolutional entanglement distillation protocol to the well-established\nproblem of finding a good classical convolutional code. \n\n"}
{"id": "0708.4214", "contents": "Title: High Rate Single-Symbol Decodable Precoded DSTBCs for Cooperative\n  Networks Abstract: Distributed Orthogonal Space-Time Block Codes (DOSTBCs) achieving full\ndiversity order and single-symbol ML decodability have been introduced recently\nfor cooperative networks and an upper-bound on the maximal rate of such codes\nalong with code constructions has been presented. In this report, we introduce\na new class of Distributed STBCs called Semi-orthogonal Precoded Distributed\nSingle-Symbol Decodable STBCs (S-PDSSDC) wherein, the source performs\nco-ordinate interleaving of information symbols appropriately before\ntransmitting it to all the relays. It is shown that DOSTBCs are a special case\nof S-PDSSDCs. A special class of S-PDSSDCs having diagonal covariance matrix at\nthe destination is studied and an upper bound on the maximal rate of such codes\nis derived. The bounds obtained are approximately twice larger than that of the\nDOSTBCs. A systematic construction of S-PDSSDCs is presented when the number of\nrelays $K \\geq 4$. The constructed codes are shown to achieve the upper-bound\non the rate when $K$ is of the form 0 modulo 4 or 3 modulo 4. For the rest of\nthe values of $K$, the constructed codes are shown to have rates higher than\nthat of DOSTBCs. It is also shown that S-PDSSDCs cannot be constructed with any\nform of linear processing at the relays when the source doesn't perform\nco-ordinate interleaving of the information symbols. \n\n"}
{"id": "0708.4328", "contents": "Title: Dualities Between Entropy Functions and Network Codes Abstract: This paper provides a new duality between entropy functions and network\ncodes. Given a function $g\\geq 0$ defined on all proper subsets of $N$ random\nvariables, we provide a construction for a network multicast problem which is\nsolvable if and only if $g$ is entropic. The underlying network topology is\nfixed and the multicast problem depends on $g$ only through edge capacities and\nsource rates. Relaxing the requirement that the domain of $g$ be subsets of\nrandom variables, we obtain a similar duality between polymatroids and the\nlinear programming bound. These duality results provide an alternative proof of\nthe insufficiency of linear (and abelian) network codes, and demonstrate the\nutility of non-Shannon inequalities to tighten outer bounds on network coding\ncapacity regions. \n\n"}
{"id": "0709.2833", "contents": "Title: Distributed Space Time Codes with Low Decoding Complexity for\n  Asynchronous Relay Networks Abstract: Recently Li and Xia have proposed a transmission scheme for wireless relay\nnetworks based on the Alamouti space time code and orthogonal frequency\ndivision multiplexing to combat the effect of timing errors at the relay nodes.\nThis transmission scheme is amazingly simple and achieves a diversity order of\ntwo for any number of relays. Motivated by its simplicity, this scheme is\nextended to a more general transmission scheme that can achieve full\ncooperative diversity for any number of relays. The conditions on the\ndistributed space time code (DSTC) structure that admit its application in the\nproposed transmission scheme are identified and it is pointed out that the\nrecently proposed full diversity four group decodable DSTCs from precoded\nco-ordinate interleaved orthogonal designs and extended Clifford algebras\nsatisfy these conditions. It is then shown how differential encoding at the\nsource can be combined with the proposed transmission scheme to arrive at a new\ntransmission scheme that can achieve full cooperative diversity in asynchronous\nwireless relay networks with no channel information and also no timing error\nknowledge at the destination node. Finally, four group decodable distributed\ndifferential space time codes applicable in this new transmission scheme for\npower of two number of relays are also provided. \n\n"}
{"id": "0710.5161", "contents": "Title: Decomposable Subspaces, Linear Sections of Grassmann Varieties, and\n  Higher Weights of Grassmann Codes Abstract: Given a homogeneous component of an exterior algebra, we characterize those\nsubspaces in which every nonzero element is decomposable. In geometric terms,\nthis corresponds to characterizing the projective linear subvarieties of the\nGrassmann variety with its Plucker embedding. When the base field is finite, we\nconsider the more general question of determining the maximum number of points\non sections of Grassmannians by linear subvarieties of a fixed (co)dimension.\nThis corresponds to a known open problem of determining the complete weight\nhierarchy of linear error correcting codes associated to Grassmann varieties.\nWe recover most of the known results as well as prove some new results. In the\nprocess we obtain, and utilize, a simple generalization of the Griesmer-Wei\nbound for arbitrary linear codes. \n\n"}
{"id": "0711.0237", "contents": "Title: Zero-rate feedback can achieve the empirical capacity Abstract: The utility of limited feedback for coding over an individual sequence of\nDMCs is investigated. This study complements recent results showing how limited\nor noisy feedback can boost the reliability of communication. A strategy with\nfixed input distribution $P$ is given that asymptotically achieves rates\narbitrarily close to the mutual information induced by $P$ and the\nstate-averaged channel. When the capacity achieving input distribution is the\nsame over all channel states, this achieves rates at least as large as the\ncapacity of the state averaged channel, sometimes called the empirical\ncapacity. \n\n"}
{"id": "0711.2642", "contents": "Title: Multiuser MIMO Achievable Rates with Downlink Training and Channel State\n  Feedback Abstract: We consider a MIMO fading broadcast channel and compute achievable ergodic\nrates when channel state information is acquired at the receivers via downlink\ntraining and it is provided to the transmitter by channel state feedback.\nUnquantized (analog) and quantized (digital) channel state feedback schemes are\nanalyzed and compared under various assumptions. Digital feedback is shown to\nbe potentially superior when the feedback channel uses per channel state\ncoefficient is larger than 1. Also, we show that by proper design of the\ndigital feedback link, errors in the feedback have a minor effect even if\nsimple uncoded modulation is used on the feedback channel. We discuss first the\ncase of an unfaded AWGN feedback channel with orthogonal access and then the\ncase of fading MIMO multi-access (MIMO-MAC). We show that by exploiting the\nMIMO-MAC nature of the uplink channel, a much better scaling of the feedback\nchannel resource with the number of base station antennas can be achieved.\nFinally, for the case of delayed feedback, we show that in the realistic case\nwhere the fading process has (normalized) maximum Doppler frequency shift 0 < F\n< 1/2, a fraction 1 - 2F of the optimal multiplexing gain is achievable. The\ngeneral conclusion of this work is that very significant downlink throughput is\nachievable with simple and efficient channel state feedback, provided that the\nfeedback link is properly designed. \n\n"}
{"id": "0711.3152", "contents": "Title: Multipath Channels of Bounded Capacity Abstract: The capacity of discrete-time, non-coherent, multipath fading channels is\nconsidered. It is shown that if the delay spread is large in the sense that the\nvariances of the path gains do not decay faster than geometrically, then\ncapacity is bounded in the signal-to-noise ratio. \n\n"}
{"id": "0801.2423", "contents": "Title: Design and Analysis of LDGM-Based Codes for MSE Quantization Abstract: Approaching the 1.5329-dB shaping (granular) gain limit in mean-squared error\n(MSE) quantization of R^n is important in a number of problems, notably\ndirty-paper coding. For this purpose, we start with a binary low-density\ngenerator-matrix (LDGM) code, and construct the quantization codebook by\nperiodically repeating its set of binary codewords, or them mapped to m-ary\nones with Gray mapping. The quantization algorithm is based on belief\npropagation, and it uses a decimation procedure to do the guessing necessary\nfor convergence. Using the results of a true typical decimator (TTD) as\nreference, it is shown that the asymptotic performance of the proposed\nquantizer can be characterized by certain monotonicity conditions on the code's\nfixed point properties, which can be analyzed with density evolution, and\ndegree distribution optimization can be carried out accordingly. When the\nnumber of iterations is finite, the resulting loss is made amenable to analysis\nthrough the introduction of a recovery algorithm from ``bad'' guesses, and the\nresults of such analysis enable further optimization of the pace of decimation\nand the degree distribution. Simulation results show that the proposed\nLDGM-based quantizer can achieve a shaping gain of 1.4906 dB, or 0.0423 dB from\nthe limit, and significantly outperforms trellis-coded quantization (TCQ) at a\nsimilar computational complexity. \n\n"}
{"id": "0803.2262", "contents": "Title: Constant-Rank Codes and Their Connection to Constant-Dimension Codes Abstract: Constant-dimension codes have recently received attention due to their\nsignificance to error control in noncoherent random linear network coding. What\nthe maximal cardinality of any constant-dimension code with finite dimension\nand minimum distance is and how to construct the optimal constant-dimension\ncode (or codes) that achieves the maximal cardinality both remain open research\nproblems. In this paper, we introduce a new approach to solving these two\nproblems. We first establish a connection between constant-rank codes and\nconstant-dimension codes. Via this connection, we show that optimal\nconstant-dimension codes correspond to optimal constant-rank codes over\nmatrices with sufficiently many rows. As such, the two aforementioned problems\nare equivalent to determining the maximum cardinality of constant-rank codes\nand to constructing optimal constant-rank codes, respectively. To this end, we\nthen derive bounds on the maximum cardinality of a constant-rank code with a\ngiven minimum rank distance, propose explicit constructions of optimal or\nasymptotically optimal constant-rank codes, and establish asymptotic bounds on\nthe maximum rate of a constant-rank code. \n\n"}
{"id": "0804.0611", "contents": "Title: Channel State Feedback Schemes for Multiuser MIMO-OFDM Downlink Abstract: Channel state feedback schemes for the MIMO broadcast downlink have been\nwidely studied in the frequency-flat case. This work focuses on the more\nrelevant frequency selective case, where some important new aspects emerge. We\nconsider a MIMO-OFDM broadcast channel and compare achievable ergodic rates\nunder three channel state feedback schemes: analog feedback, direction\nquantized feedback and \"time-domain\" channel quantized feedback. The first two\nschemes are direct extensions of previously proposed schemes. The third scheme\nis novel, and it is directly inspired by rate-distortion theory of Gaussian\ncorrelated sources. For each scheme we derive the conditions under which the\nsystem achieves full multiplexing gain. The key difference with respect to the\nwidely treated frequency-flat case is that in MIMO-OFDM the frequency-domain\nchannel transfer function is a Gaussian correlated source. The new time-domain\nquantization scheme takes advantage of the channel frequency correlation\nstructure and outperforms the other schemes. Furthermore, it is by far simpler\nto implement than complicated spherical vector quantization. In particular, we\nobserve that no structured codebook design and vector quantization is actually\nneeded for efficient channel state information feedback. \n\n"}
{"id": "0804.0980", "contents": "Title: Large MIMO Detection: A Low-Complexity Detector at High Spectral\n  Efficiencies Abstract: We consider large MIMO systems, where by `{\\em large}' we mean number of\ntransmit and receive antennas of the order of tens to hundreds. Such large MIMO\nsystems will be of immense interest because of the very high spectral\nefficiencies possible in such systems. We present a low-complexity detector\nwhich achieves uncoded near-exponential diversity performance for hundreds of\nantennas (i.e., achieves near SISO AWGN performance in a large MIMO fading\nenvironment) with an average per-bit complexity of just $O(N_tN_r)$, where\n$N_t$ and $N_r$ denote the number of transmit and receive antennas,\nrespectively. With an outer turbo code, the proposed detector achieves good\ncoded bit error performance as well. For example, in a 600 transmit and 600\nreceive antennas V-BLAST system with a high spectral efficiency of 200 bps/Hz\n(using BPSK and rate-1/3 turbo code), our simulation results show that the\nproposed detector performs close to within about 4.6 dB from theoretical\ncapacity. We also adopt the proposed detector for the low-complexity decoding\nof high-rate non-orthogonal space-time block codes (STBC) from division\nalgebras (DA). For example, we have decoded the $16\\times 16$ full-rate\nnon-orthogonal STBC from DA using the proposed detector and show that it\nperforms close to within about 5.5 dB of the capacity using 4-QAM and rate-3/4\nturbo code at a spectral efficiency of 24 bps/Hz. The practical feasibility of\nthe proposed high-performance low-complexity detector could potentially trigger\nwide interest in the implementation of large MIMO systems. In large MC-CDMA\nsystems with hundreds of users, the proposed detector is shown to achieve near\nsingle-user performance at an average per-bit complexity linear in number of\nusers, which is quite appealing for its use in practical CDMA systems. \n\n"}
{"id": "0804.3155", "contents": "Title: Leveraging Coherent Distributed Space-Time Codes for Noncoherent\n  Communication in Relay Networks via Training Abstract: For point to point multiple input multiple output systems,\nDayal-Brehler-Varanasi have proved that training codes achieve the same\ndiversity order as that of the underlying coherent space time block code (STBC)\nif a simple minimum mean squared error estimate of the channel formed using the\ntraining part is employed for coherent detection of the underlying STBC. In\nthis letter, a similar strategy involving a combination of training, channel\nestimation and detection in conjunction with existing coherent distributed\nSTBCs is proposed for noncoherent communication in AF relay networks.\nSimulation results show that the proposed simple strategy outperforms\ndistributed differential space-time coding for AF relay networks. Finally, the\nproposed strategy is extended to asynchronous relay networks using orthogonal\nfrequency division multiplexing. \n\n"}
{"id": "0805.1857", "contents": "Title: The Gaussian Many-Help-One Distributed Source Coding Problem Abstract: Jointly Gaussian memoryless sources are observed at N distinct terminals. The\ngoal is to efficiently encode the observations in a distributed fashion so as\nto enable reconstruction of any one of the observations, say the first one, at\nthe decoder subject to a quadratic fidelity criterion. Our main result is a\nprecise characterization of the rate-distortion region when the covariance\nmatrix of the sources satisfies a \"tree-structure\" condition. In this\nsituation, a natural analog-digital separation scheme optimally trades off the\ndistributed quantization rate tuples and the distortion in the reconstruction:\neach encoder consists of a point-to-point Gaussian vector quantizer followed by\na Slepian-Wolf binning encoder. We also provide a partial converse that\nsuggests that the tree structure condition is fundamental. \n\n"}
{"id": "0806.3650", "contents": "Title: Recursive Code Construction for Random Networks Abstract: A modification of Koetter-Kschischang codes for random networks is presented\n(these codes were also studied by Wang et al. in the context of authentication\nproblems). The new codes have higher information rate, while maintaining the\nsame error-correcting capabilities. An efficient error-correcting algorithm is\nproposed for these codes. \n\n"}
{"id": "0806.4200", "contents": "Title: The Secrecy Rate Region of the Broadcast Channel Abstract: In this paper, we consider a scenario where a source node wishes to broadcast\ntwo confidential messages for two respective receivers, while a wire-tapper\nalso receives the transmitted signal. This model is motivated by wireless\ncommunications, where individual secure messages are broadcast over open media\nand can be received by any illegitimate receiver. The secrecy level is measured\nby equivocation rate at the eavesdropper. We first study the general\n(non-degraded) broadcast channel with confidential messages. We present an\ninner bound on the secrecy capacity region for this model. The inner bound\ncoding scheme is based on a combination of random binning and the\nGelfand-Pinsker bining. This scheme matches the Marton's inner bound on the\nbroadcast channel without confidentiality constraint. We further study the\nsituation where the channels are degraded. For the degraded broadcast channel\nwith confidential messages, we present the secrecy capacity region. Our\nachievable coding scheme is based on Cover's superposition scheme and random\nbinning. We refer to this scheme as Secret Superposition Scheme. In this\nscheme, we show that randomization in the first layer increases the secrecy\nrate of the second layer. This capacity region matches the capacity region of\nthe degraded broadcast channel without security constraint. It also matches the\nsecrecy capacity for the conventional wire-tap channel. Our converse proof is\nbased on a combination of the converse proof of the conventional degraded\nbroadcast channel and Csiszar lemma. Finally, we assume that the channels are\nAdditive White Gaussian Noise (AWGN) and show that secret superposition scheme\nwith Gaussian codebook is optimal. The converse proof is based on the\ngeneralized entropy power inequality. \n\n"}
{"id": "0807.3065", "contents": "Title: Sharp Bounds for Optimal Decoding of Low Density Parity Check Codes Abstract: Consider communication over a binary-input memoryless output-symmetric\nchannel with low density parity check (LDPC) codes and maximum a posteriori\n(MAP) decoding. The replica method of spin glass theory allows to conjecture an\nanalytic formula for the average input-output conditional entropy per bit in\nthe infinite block length limit. Montanari proved a lower bound for this\nentropy, in the case of LDPC ensembles with convex check degree polynomial,\nwhich matches the replica formula. Here we extend this lower bound to any\nirregular LDPC ensemble. The new feature of our work is an analysis of the\nsecond derivative of the conditional input-output entropy with respect to\nnoise. A close relation arises between this second derivative and correlation\nor mutual information of codebits. This allows us to extend the realm of the\ninterpolation method, in particular we show how channel symmetry allows to\ncontrol the fluctuations of the overlap parameters. \n\n"}
{"id": "0807.3566", "contents": "Title: Stabilizer Quantum Codes: A Unified View based on Forney-style Factor\n  Graphs Abstract: Quantum error-correction codes (QECCs) are a vital ingredient of quantum\ncomputation and communication systems. In that context it is highly desirable\nto design QECCs that can be represented by graphical models which possess a\nstructure that enables efficient and close-to-optimal iterative decoding. In\nthis paper we focus on stabilizer QECCs, a class of QECCs whose construction is\nrendered non-trivial by the fact that the stabilizer label code, a code that is\nassociated with a stabilizer QECC, has to satisfy a certain self-orthogonality\ncondition. In order to design graphical models of stabilizer label codes that\nsatisfy this condition, we extend a duality result for Forney-style factor\ngraphs (FFGs) to the stabilizer label code framework. This allows us to\nformulate a simple FFG design rule for constructing stabilizer label codes, a\ndesign rule that unifies several earlier stabilizer label code constructions. \n\n"}
{"id": "0808.0548", "contents": "Title: How could the replica method improve accuracy of performance assessment\n  of channel coding? Abstract: We explore the relation between the techniques of statistical mechanics and\ninformation theory for assessing the performance of channel coding. We base our\nstudy on a framework developed by Gallager in {\\em IEEE Trans. Inform. Theory}\n{\\bf 11}, 3 (1965), where the minimum decoding error probability is\nupper-bounded by an average of a generalized Chernoff's bound over a code\nensemble. We show that the resulting bound in the framework can be directly\nassessed by the replica method, which has been developed in statistical\nmechanics of disordered systems, whereas in Gallager's original methodology\nfurther replacement by another bound utilizing Jensen's inequality is\nnecessary. Our approach associates a seemingly {\\em ad hoc} restriction with\nrespect to an adjustable parameter for optimizing the bound with a phase\ntransition between two replica symmetric solutions, and can improve the\naccuracy of performance assessments of general code ensembles including low\ndensity parity check codes, although its mathematical justification is still\nopen. \n\n"}
{"id": "0808.1495", "contents": "Title: The finite harmonic oscillator and its applications to sequences,\n  communication and radar Abstract: A novel system, called the oscillator system, consisting of order of p^3\nfunctions (signals) on the finite field F_p; with p an odd prime, is described\nand studied. The new functions are proved to satisfy good auto-correlation,\ncross-correlation and low peak-to-average power ratio properties. Moreover, the\noscillator system is closed under the operation of discrete Fourier transform.\nApplications of the oscillator system for discrete radar and digital\ncommunication theory are explained. Finally, an explicit algorithm to construct\nthe oscillator system is presented. \n\n"}
{"id": "0809.0099", "contents": "Title: Degrees of Freedom of the $K$ User $M \\times N$ MIMO Interference\n  Channel Abstract: We provide innerbound and outerbound for the total number of degrees of\nfreedom of the $K$ user multiple input multiple output (MIMO) Gaussian\ninterference channel with $M$ antennas at each transmitter and $N$ antennas at\neach receiver if the channel coefficients are time-varying and drawn from a\ncontinuous distribution. The bounds are tight when the ratio\n$\\frac{\\max(M,N)}{\\min(M,N)}=R$ is equal to an integer. For this case, we show\nthat the total number of degrees of freedom is equal to $\\min(M,N)K$ if $K \\leq\nR$ and $\\min(M,N)\\frac{R}{R+1}K$ if $K > R$. Achievability is based on\ninterference alignment. We also provide examples where using interference\nalignment combined with zero forcing can achieve more degrees of freedom than\nmerely zero forcing for some MIMO interference channels with constant channel\ncoefficients. \n\n"}
{"id": "0809.2546", "contents": "Title: Depth as Randomness Deficiency Abstract: Depth of an object concerns a tradeoff between computation time and excess of\nprogram length over the shortest program length required to obtain the object.\nIt gives an unconditional lower bound on the computation time from a given\nprogram in absence of auxiliary information. Variants known as logical depth\nand computational depth are expressed in Kolmogorov complexity theory.\n  We derive quantitative relation between logical depth and computational depth\nand unify the different depth notions by relating them to A. Kolmogorov and L.\nLevin's fruitful notion of randomness deficiency. Subsequently, we revisit the\ncomputational depth of infinite strings, introducing the notion of super deep\nsequences and relate it with other approaches. \n\n"}
{"id": "0809.3731", "contents": "Title: Uncertainty Relations for Shift-Invariant Analog Signals Abstract: The past several years have witnessed a surge of research investigating\nvarious aspects of sparse representations and compressed sensing. Most of this\nwork has focused on the finite-dimensional setting in which the goal is to\ndecompose a finite-length vector into a given finite dictionary. Underlying\nmany of these results is the conceptual notion of an uncertainty principle: a\nsignal cannot be sparsely represented in two different bases. Here, we extend\nthese ideas and results to the analog, infinite-dimensional setting by\nconsidering signals that lie in a finitely-generated shift-invariant (SI)\nspace. This class of signals is rich enough to include many interesting special\ncases such as multiband signals and splines. By adapting the notion of\ncoherence defined for finite dictionaries to infinite SI representations, we\ndevelop an uncertainty principle similar in spirit to its finite counterpart.\nWe demonstrate tightness of our bound by considering a bandlimited lowpass\ntrain that achieves the uncertainty principle. Building upon these results and\nsimilar work in the finite setting, we show how to find a sparse decomposition\nin an overcomplete dictionary by solving a convex optimization problem. The\ndistinguishing feature of our approach is the fact that even though the problem\nis defined over an infinite domain with infinitely many variables and\nconstraints, under certain conditions on the dictionary spectrum our algorithm\ncan find the sparsest representation by solving a finite-dimensional problem. \n\n"}
{"id": "0809.4316", "contents": "Title: A Layered Lattice Coding Scheme for a Class of Three User Gaussian\n  Interference Channels Abstract: The paper studies a class of three user Gaussian interference channels. A new\nlayered lattice coding scheme is introduced as a transmission strategy. The use\nof lattice codes allows for an \"alignment\" of the interference observed at each\nreceiver. The layered lattice coding is shown to achieve more than one degree\nof freedom for a class of interference channels and also achieves rates which\nare better than the rates obtained using the Han-Kobayashi coding scheme. \n\n"}
{"id": "0810.2336", "contents": "Title: A Mordell Inequality for Lattices over Maximal Orders Abstract: In this paper we prove an analogue of Mordell's inequality for lattices in\nfinite-dimensional complex or quaternionic Hermitian space that are modules\nover a maximal order in an imaginary quadratic number field or a totally\ndefinite rational quaternion algebra. This inequality implies that the\n16-dimensional Barnes-Wall lattice has optimal density among all 16-dimensional\nlattices with Hurwitz structures. \n\n"}
{"id": "0810.5203", "contents": "Title: Monotonic Convergence in an Information-Theoretic Law of Small Numbers Abstract: An \"entropy increasing to the maximum\" result analogous to the entropic\ncentral limit theorem (Barron 1986; Artstein et al. 2004) is obtained in the\ndiscrete setting. This involves the thinning operation and a Poisson limit.\nMonotonic convergence in relative entropy is established for general discrete\ndistributions, while monotonic increase of Shannon entropy is proved for the\nspecial class of ultra-log-concave distributions. Overall we extend the\nparallel between the information-theoretic central limit theorem and law of\nsmall numbers explored by Kontoyiannis et al. (2005) and Harremo\\\"es et al.\\\n(2007, 2008). Ingredients in the proofs include convexity, majorization, and\nstochastic orders. \n\n"}
{"id": "0811.0726", "contents": "Title: Improved Capacity Scaling in Wireless Networks With Infrastructure Abstract: This paper analyzes the impact and benefits of infrastructure support in\nimproving the throughput scaling in networks of $n$ randomly located wireless\nnodes. The infrastructure uses multi-antenna base stations (BSs), in which the\nnumber of BSs and the number of antennas at each BS can scale at arbitrary\nrates relative to $n$. Under the model, capacity scaling laws are analyzed for\nboth dense and extended networks. Two BS-based routing schemes are first\nintroduced in this study: an infrastructure-supported single-hop (ISH) routing\nprotocol with multiple-access uplink and broadcast downlink and an\ninfrastructure-supported multi-hop (IMH) routing protocol. Then, their\nachievable throughput scalings are analyzed. These schemes are compared against\ntwo conventional schemes without BSs: the multi-hop (MH) transmission and\nhierarchical cooperation (HC) schemes. It is shown that a linear throughput\nscaling is achieved in dense networks, as in the case without help of BSs. In\ncontrast, the proposed BS-based routing schemes can, under realistic network\nconditions, improve the throughput scaling significantly in extended networks.\nThe gain comes from the following advantages of these BS-based protocols.\nFirst, more nodes can transmit simultaneously in the proposed scheme than in\nthe MH scheme if the number of BSs and the number of antennas are large enough.\nSecond, by improving the long-distance signal-to-noise ratio (SNR), the\nreceived signal power can be larger than that of the HC, enabling a better\nthroughput scaling under extended networks. Furthermore, by deriving the\ncorresponding information-theoretic cut-set upper bounds, it is shown under\nextended networks that a combination of four schemes IMH, ISH, MH, and HC is\norder-optimal in all operating regimes. \n\n"}
{"id": "0812.0972", "contents": "Title: Network Protection Codes: Providing Self-healing in Autonomic Networks\n  Using Network Coding Abstract: Agile recovery from link failures in autonomic communication networks is\nessential to increase robustness, accessibility, and reliability of data\ntransmission. However, this must be done with the least amount of protection\nresources, while using simple management plane functionality. Recently, network\ncoding has been proposed as a solution to provide agile and cost efficient\nnetwork self-healing against link failures, in a manner that does not require\ndata rerouting, packet retransmission, or failure localization, hence leading\nto simple control and management planes. To achieve this, separate paths have\nto be provisioned to carry encoded packets, hence requiring either the addition\nof extra links, or reserving some of the resources for this purpose.\n  In this paper we introduce autonomic self-healing strategies for autonomic\nnetworks in order to protect against link failures. The strategies are based on\nnetwork coding and reduced capacity, which is a technique that we call network\nprotection codes (NPC). In these strategies, an autonomic network is able to\nprovide self-healing from various network failures affecting network operation.\nThe techniques improve service and enhance reliability of autonomic\ncommunication.\n  Network protection codes are extended to provide self-healing from multiple\nlink failures in autonomic networks. We provide implementation aspects of the\nproposed strategies. We present bounds and network protection code\nconstructions. Finally, we study the construction of such codes over the binary\nfield. The paper also develops an Integer Linear Program formulation to\nevaluate the cost of provisioning connections using the proposed strategies. \n\n"}
{"id": "0812.2275", "contents": "Title: Secrecy capacity of a class of orthogonal relay eavesdropper channels Abstract: The secrecy capacity of relay channels with orthogonal components is studied\nin the presence of an additional passive eavesdropper node. The relay and\ndestination receive signals from the source on two orthogonal channels such\nthat the destination also receives transmissions from the relay on its channel.\nThe eavesdropper can overhear either one or both of the orthogonal channels.\nInner and outer bounds on the secrecy capacity are developed for both the\ndiscrete memoryless and the Gaussian channel models. For the discrete\nmemoryless case, the secrecy capacity is shown to be achieved by a partial\ndecode-and-forward (PDF) scheme when the eavesdropper can overhear only one of\nthe two orthogonal channels. Two new outer bounds are presented for the\nGaussian model using recent capacity results for a Gaussian multi-antenna\npoint-to-point channel with a multi-antenna eavesdropper. The outer bounds are\nshown to be tight for two sub-classes of channels. The first sub-class is one\nin which the source and relay are clustered and the and the eavesdropper\nreceives signals only on the channel from the source and the relay to the\ndestination, for which the PDF strategy is optimal. The second is a sub-class\nin which the source does not transmit to the relay, for which a\nnoise-forwarding strategy is optimal. \n\n"}
{"id": "0901.0269", "contents": "Title: Random Linear Network Coding For Time Division Duplexing: Energy\n  Analysis Abstract: We study the energy performance of random linear network coding for time\ndivision duplexing channels. We assume a packet erasure channel with nodes that\ncannot transmit and receive information simultaneously. The sender transmits\ncoded data packets back-to-back before stopping to wait for the receiver to\nacknowledge the number of degrees of freedom, if any, that are required to\ndecode correctly the information. Our analysis shows that, in terms of mean\nenergy consumed, there is an optimal number of coded data packets to send\nbefore stopping to listen. This number depends on the energy needed to transmit\neach coded packet and the acknowledgment (ACK), probabilities of packet and ACK\nerasure, and the number of degrees of freedom that the receiver requires to\ndecode the data. We show that its energy performance is superior to that of a\nfull-duplex system. We also study the performance of our scheme when the number\nof coded packets is chosen to minimize the mean time to complete transmission\nas in [1]. Energy performance under this optimization criterion is found to be\nclose to optimal, thus providing a good trade-off between energy and time\nrequired to complete transmissions. \n\n"}
{"id": "0901.1954", "contents": "Title: Two-Way Relay Channels: Error Exponents and Resource Allocation Abstract: In a two-way relay network, two terminals exchange information over a shared\nwireless half-duplex channel with the help of a relay. Due to its fundamental\nand practical importance, there has been an increasing interest in this\nchannel. However, surprisingly, there has been little work that characterizes\nthe fundamental tradeoff between the communication reliability and transmission\nrate across all signal-to-noise ratios. In this paper, we consider\namplify-and-forward (AF) two-way relaying due to its simplicity. We first\nderive the random coding error exponent for the link in each direction. From\nthe exponent expression, the capacity and cutoff rate for each link are also\ndeduced. We then put forth the notion of the bottleneck error exponent, which\nis the worst exponent decay between the two links, to give us insight into the\nfundamental tradeoff between the rate pair and information-exchange reliability\nof the two terminals. As applications of the error exponent analysis, we\npresent two optimal resource allocations to maximize the bottleneck error\nexponent: i) the optimal rate allocation under a sum-rate constraint and its\nclosed-form quasi-optimal solution that requires only knowledge of the capacity\nand cutoff rate of each link; and ii) the optimal power allocation under a\ntotal power constraint, which is formulated as a quasi-convex optimization\nproblem. Numerical results verify our analysis and the effectiveness of the\noptimal rate and power allocations in maximizing the bottleneck error exponent. \n\n"}
{"id": "0902.2260", "contents": "Title: Network Coding with Two-Way Relaying: Achievable Rate Regions and\n  Diversity-Multiplexing Tradeoffs Abstract: This paper addresses the fundamental characteristics of information exchange\nvia multihop network coding over two-way relaying in a wireless ad hoc network.\nThe end-to-end rate regions achieved by time-division multihop (TDMH),\nMAC-layer network coding (MLNC) and PHY-layer network coding (PLNC) are first\ncharacterized. It is shown that MLNC does not always achieve better rates than\nTDMH, time sharing between TDMH and MLNC is able to achieve a larger rate\nregion, and PLNC dominates the rate regions achieved by TDMH and MLNC. An\nopportunistic scheduling algorithm for MLNC and PLNC is then proposed to\nstabilize the two-way relaying system for Poisson arrivals whenever the rate\npair is within the Shannon rate regions of MLNC and PLNC. To understand the\ntwo-way transmission limits of multihop network coding, the sum-rate\noptimization with or without certain traffic pattern and the end-to-end\ndiversity-multiplexing tradeoffs (DMTs) of two-way transmission over multiple\nrelay nodes are also analyzed. \n\n"}
{"id": "0902.2367", "contents": "Title: Dequantizing Compressed Sensing: When Oversampling and Non-Gaussian\n  Constraints Combine Abstract: In this paper we study the problem of recovering sparse or compressible\nsignals from uniformly quantized measurements. We present a new class of convex\noptimization programs, or decoders, coined Basis Pursuit DeQuantizer of moment\n$p$ (BPDQ$_p$), that model the quantization distortion more faithfully than the\ncommonly used Basis Pursuit DeNoise (BPDN) program. Our decoders proceed by\nminimizing the sparsity of the signal to be reconstructed subject to a\ndata-fidelity constraint expressed in the $\\ell_p$-norm of the residual error\nfor $2\\leq p\\leq \\infty$.\n  We show theoretically that, (i) the reconstruction error of these new\ndecoders is bounded if the sensing matrix satisfies an extended Restricted\nIsometry Property involving the $\\ell_p$ norm, and (ii), for Gaussian random\nmatrices and uniformly quantized measurements, BPDQ$_p$ performance exceeds\nthat of BPDN by dividing the reconstruction error due to quantization by\n$\\sqrt{p+1}$. This last effect happens with high probability when the number of\nmeasurements exceeds a value growing with $p$, i.e. in an oversampled situation\ncompared to what is commonly required by BPDN = BPDQ$_2$. To demonstrate the\ntheoretical power of BPDQ$_p$, we report numerical simulations on signal and\nimage reconstruction problems. \n\n"}
{"id": "0903.3487", "contents": "Title: Sending a Bivariate Gaussian Source over a Gaussian MAC with Feedback Abstract: We study the power-versus-distortion trade-off for the transmission of a\nmemoryless bivariate Gaussian source over a two-to-one Gaussian multiple-access\nchannel with perfect causal feedback. In this problem, each of two separate\ntransmitters observes a different component of a memoryless bivariate Gaussian\nsource as well as the feedback from the channel output of the previous\ntime-instants. Based on the observed source sequence and the feedback, each\ntransmitter then describes its source component to the common receiver via an\naverage-power constrained Gaussian multiple-access channel. From the resulting\nchannel output, the receiver wishes to reconstruct both source components with\nthe least possible expected squared-error distortion. We study the set of\ndistortion pairs that can be achieved by the receiver on the two source\ncomponents.\n  We present sufficient conditions and necessary conditions for the\nachievability of a distortion pair. These conditions are expressed in terms of\nthe source correlation and of the signal-to-noise ratio (SNR) of the channel.\nIn several cases the necessary conditions and sufficient conditions coincide.\nThis allows us to show that if the channel SNR is below a certain threshold,\nthen an uncoded transmission scheme that ignores the feedback is optimal. Thus,\nbelow this SNR-threshold feedback is useless. We also derive the precise\nhigh-SNR asymptotics of optimal schemes. \n\n"}
{"id": "0905.2413", "contents": "Title: Outage Capacity and Optimal Transmission for Dying Channels Abstract: In wireless networks, communication links may be subject to random fatal\nimpacts: for example, sensor networks under sudden power losses or cognitive\nradio networks with unpredictable primary user spectrum occupancy. Under such\ncircumstances, it is critical to quantify how fast and reliably the information\ncan be collected over attacked links. For a single point-to-point channel\nsubject to a random attack, named as a \\emph{dying channel}, we model it as a\nblock-fading (BF) channel with a finite and random delay constraint. First, we\ndefine the outage capacity as the performance measure, followed by studying the\noptimal coding length $K$ such that the outage probability is minimized when\nuniform power allocation is assumed. For a given rate target and a coding\nlength $K$, we then minimize the outage probability over the power allocation\nvector $\\mv{P}_{K}$, and show that this optimization problem can be cast into a\nconvex optimization problem under some conditions. The optimal solutions for\nseveral special cases are discussed.\n  Furthermore, we extend the single point-to-point dying channel result to the\nparallel multi-channel case where each sub-channel is a dying channel, and\ninvestigate the corresponding asymptotic behavior of the overall outage\nprobability with two different attack models: the independent-attack case and\nthe $m$-dependent-attack case. It can be shown that the overall outage\nprobability diminishes to zero for both cases as the number of sub-channels\nincreases if the \\emph{rate per unit cost} is less than a certain threshold.\nThe outage exponents are also studied to reveal how fast the outage probability\nimproves over the number of sub-channels. \n\n"}
{"id": "0905.3587", "contents": "Title: Prediction, Retrodiction, and The Amount of Information Stored in the\n  Present Abstract: We introduce an ambidextrous view of stochastic dynamical systems, comparing\ntheir forward-time and reverse-time representations and then integrating them\ninto a single time-symmetric representation. The perspective is useful\ntheoretically, computationally, and conceptually. Mathematically, we prove that\nthe excess entropy--a familiar measure of organization in complex systems--is\nthe mutual information not only between the past and future, but also between\nthe predictive and retrodictive causal states. Practically, we exploit the\nconnection between prediction and retrodiction to directly calculate the excess\nentropy. Conceptually, these lead one to discover new system invariants for\nstochastic dynamical systems: crypticity (information accessibility) and causal\nirreversibility. Ultimately, we introduce a time-symmetric representation that\nunifies all these quantities, compressing the two directional representations\ninto one. The resulting compression offers a new conception of the amount of\ninformation stored in the present. \n\n"}
{"id": "0905.4091", "contents": "Title: Hybrid ARQ in Multiple-Antenna Slow Fading Channels: Performance Limits\n  and Optimal Linear Dispersion Code Design Abstract: This paper focuses on studying the fundamental performance limits and linear\ndispersion code design for the MIMO-ARQ slow fading channel. Optimal average\nrate of well-known HARQ protocols is analyzed. The optimal design of space-time\ncoding for the MIMO-ARQ channel is discussed. Information-theoretic measures\nare used to optimize the rate assignment and derive the optimum design\ncriterion, which is then used to evaluate the optimality of existing space-time\ncodes. A different design criterion, which is obtained from the error\nprobability analysis of space-time coded MIMO-HARQ, is presented. Examples are\nstudied to reveal the gain of ARQ feedback in space-time coded MIMO systems. \n\n"}
{"id": "0906.1079", "contents": "Title: Modified Frame Reconstruction Algorithm for Compressive Sensing Abstract: Compressive sensing is a technique to sample signals well below the Nyquist\nrate using linear measurement operators. In this paper we present an algorithm\nfor signal reconstruction given such a set of measurements. This algorithm\ngeneralises and extends previous iterative hard thresholding algorithms and we\ngive sufficient conditions for successful reconstruction of the original data\nsignal. In addition we show that by underestimating the sparsity of the data\nsignal we can increase the success rate of the algorithm.\n  We also present a number of modifications to this algorithm: the\nincorporation of a least squares step, polynomial acceleration and an adaptive\nmethod for choosing the step-length. These modified algorithms converge to the\ncorrect solution under similar conditions to the original un-modified\nalgorithm. Empirical evidence show that these modifications dramatically\nincrease both the success rate and the rate of convergence, and can outperform\nother algorithms previously used for signal reconstruction in compressive\nsensing. \n\n"}
{"id": "0906.3234", "contents": "Title: Asymptotic Analysis of MAP Estimation via the Replica Method and\n  Applications to Compressed Sensing Abstract: The replica method is a non-rigorous but well-known technique from\nstatistical physics used in the asymptotic analysis of large, random, nonlinear\nproblems. This paper applies the replica method, under the assumption of\nreplica symmetry, to study estimators that are maximum a posteriori (MAP) under\na postulated prior distribution. It is shown that with random linear\nmeasurements and Gaussian noise, the replica-symmetric prediction of the\nasymptotic behavior of the postulated MAP estimate of an n-dimensional vector\n\"decouples\" as n scalar postulated MAP estimators. The result is based on\napplying a hardening argument to the replica analysis of postulated posterior\nmean estimators of Tanaka and of Guo and Verdu.\n  The replica-symmetric postulated MAP analysis can be readily applied to many\nestimators used in compressed sensing, including basis pursuit, lasso, linear\nestimation with thresholding, and zero norm-regularized estimation. In the case\nof lasso estimation the scalar estimator reduces to a soft-thresholding\noperator, and for zero norm-regularized estimation it reduces to a\nhard-threshold. Among other benefits, the replica method provides a\ncomputationally-tractable method for precisely predicting various performance\nmetrics including mean-squared error and sparsity pattern recovery probability. \n\n"}
{"id": "0906.3736", "contents": "Title: Weight Optimization for Consensus Algorithms with Correlated Switching\n  Topology Abstract: We design the weights in consensus algorithms with spatially correlated\nrandom topologies. These arise with: 1) networks with spatially correlated\nrandom link failures and 2) networks with randomized averaging protocols. We\nshow that the weight optimization problem is convex for both symmetric and\nasymmetric random graphs. With symmetric random networks, we choose the\nconsensus mean squared error (MSE) convergence rate as optimization criterion\nand explicitly express this rate as a function of the link formation\nprobabilities, the link formation spatial correlations, and the consensus\nweights. We prove that the MSE convergence rate is a convex, nonsmooth function\nof the weights, enabling global optimization of the weights for arbitrary link\nformation probabilities and link correlation structures. We extend our results\nto the case of asymmetric random links. We adopt as optimization criterion the\nmean squared deviation (MSdev) of the nodes states from the current average\nstate. We prove that MSdev is a convex function of the weights. Simulations\nshow that significant performance gain is achieved with our weight design\nmethod when compared with methods available in the literature. \n\n"}
{"id": "0907.0944", "contents": "Title: Spread spectrum for imaging techniques in radio interferometry Abstract: We consider the probe of astrophysical signals through radio interferometers\nwith small field of view and baselines with non-negligible and constant\ncomponent in the pointing direction. In this context, the visibilities measured\nessentially identify with a noisy and incomplete Fourier coverage of the\nproduct of the planar signals with a linear chirp modulation. In light of the\nrecent theory of compressed sensing and in the perspective of defining the best\npossible imaging techniques for sparse signals, we analyze the related spread\nspectrum phenomenon and suggest its universality relative to the sparsity\ndictionary. Our results rely both on theoretical considerations related to the\nmutual coherence between the sparsity and sensing dictionaries, as well as on\nnumerical simulations. \n\n"}
{"id": "0907.2391", "contents": "Title: Optimal Diversity-Multiplexing Tradeoff in Selective-Fading MIMO\n  Channels Abstract: We establish the optimal diversity-multiplexing (DM) tradeoff of coherent\ntime, frequency, and time-frequency selective-fading multiple-input\nmultiple-output (MIMO) channels and provide a code design criterion for DM\ntradeoff optimality. Our results are based on the new concept of the \"Jensen\nchannel\" associated to a given selective-fading MIMO channel. While the\noriginal problem seems analytically intractable due to the mutual information\nbetween channel input and output being a sum of correlated random variables,\nthe Jensen channel is equivalent to the original channel in the sense of the DM\ntradeoff and lends itself nicely to analytical treatment. We formulate a\nsystematic procedure for designing DM tradeoff optimal codes for general\nselective-fading MIMO channels by demonstrating that the design problem can be\nseparated into two simpler and independent problems: the design of an inner\ncode, or precoder, adapted to the channel statistics (i.e., the selectivity\ncharacteristics) and an outer code independent of the channel statistics. Our\nresults are supported by appealing geometric intuition, first pointed out for\nthe flat-fading case by Zheng and Tse, IEEE Trans. Inf. Theory, 2003. \n\n"}
{"id": "0908.0051", "contents": "Title: High-Rate, Distributed Training-Embedded Complex Orthogonal Designs for\n  Relay Networks Abstract: Distributed Space-Time Block Codes (DSTBCs) from Complex Orthogonal Designs\n(CODs) (both square and non-square CODs other than the Alamouti design) are\nknown to lose their single-symbol ML decodable (SSD) property when used in\ntwo-hop wireless relay networks using amplify and forward protocol. For such a\nnetwork, in this paper, a new class of high rate, training-embedded (TE) SSD\nDSTBCs are constructed from TE-CODs. The proposed codes include the training\nsymbols in the structure of the code which is shown to be the key point to\nobtain high rate as well as the SSD property. TE-CODs are shown to offer\nfull-diversity for arbitrary complex constellations. Non-square TE-CODs are\nshown to provide higher rates (in symbols per channel use) compared to the\nknown SSD DSTBCs for relay networks with number of relays less than $10.$ \n\n"}
{"id": "0908.1162", "contents": "Title: STBCs with Reduced Sphere Decoding Complexity for Two-User MIMO-MAC Abstract: In this paper, Space-Time Block Codes (STBCs) with reduced Sphere Decoding\nComplexity (SDC) are constructed for two-user Multiple-Input Multiple-Output\n(MIMO) fading multiple access channels. In this set-up, both the users employ\nidentical STBCs and the destination performs sphere decoding for the symbols of\nthe two users. First, we identify the positions of the zeros in the\n$\\textbf{R}$ matrix arising out of the Q-R decomposition of the lattice\ngenerator such that (i) the worst case SDC (WSDC) and (ii) the average SDC\n(ASDC) are reduced. Then, a set of necessary and sufficient conditions on the\nlattice generator is provided such that the $\\textbf{R}$ matrix has zeros at\nthe identified positions. Subsequently, explicit constructions of STBCs which\nresults in the reduced ASDC are presented. The rate (in complex symbols per\nchannel use) of the proposed designs is at most $2/N_{t}$ where $N_{t}$ denotes\nthe number of transmit antennas for each user. We also show that the class of\nSTBCs from complex orthogonal designs (other than the Alamouti design) reduce\nthe WSDC but not the ASDC. \n\n"}
{"id": "0908.1966", "contents": "Title: Spectral Graph Analysis of Quasi-Cyclic Codes Abstract: In this paper we analyze the bound on the additive white Gaussian noise\nchannel (AWGNC) pseudo-weight of a (c,d)-regular linear block code based on the\ntwo largest eigenvalues of H^T H. In particular, we analyze (c,d)-regular\nquasi-cyclic (QC) codes of length rL described by J x L block parity-check\nmatrices with circulant block entries of size r x r. We proceed by showing how\nthe problem of computing the eigenvalues of the rL x rL matrix H^T H can be\nreduced to the problem of computing eigenvalues for r matrices of size L x L.\nWe also give a necessary condition for the bound to be attained for a circulant\nmatrix H and show a few classes of cyclic codes satisfying this criterion. \n\n"}
{"id": "0908.2119", "contents": "Title: Compute-and-Forward: Harnessing Interference through Structured Codes Abstract: Interference is usually viewed as an obstacle to communication in wireless\nnetworks. This paper proposes a new strategy, compute-and-forward, that\nexploits interference to obtain significantly higher rates between users in a\nnetwork. The key idea is that relays should decode linear functions of\ntransmitted messages according to their observed channel coefficients rather\nthan ignoring the interference as noise. After decoding these linear equations,\nthe relays simply send them towards the destinations, which given enough\nequations, can recover their desired messages. The underlying codes are based\non nested lattices whose algebraic structure ensures that integer combinations\nof codewords can be decoded reliably. Encoders map messages from a finite field\nto a lattice and decoders recover equations of lattice points which are then\nmapped back to equations over the finite field. This scheme is applicable even\nif the transmitters lack channel state information. \n\n"}
{"id": "0908.2676", "contents": "Title: Deterministic Construction of Binary, Bipolar and Ternary Compressed\n  Sensing Matrices Abstract: In this paper we establish the connection between the Orthogonal Optical\nCodes (OOC) and binary compressed sensing matrices. We also introduce\ndeterministic bipolar $m\\times n$ RIP fulfilling $\\pm 1$ matrices of order $k$\nsuch that $m\\leq\\mathcal{O}\\big(k (\\log_2 n)^{\\frac{\\log_2 k}{\\ln \\log_2\nk}}\\big)$. The columns of these matrices are binary BCH code vectors where the\nzeros are replaced by -1. Since the RIP is established by means of coherence,\nthe simple greedy algorithms such as Matching Pursuit are able to recover the\nsparse solution from the noiseless samples. Due to the cyclic property of the\nBCH codes, we show that the FFT algorithm can be employed in the reconstruction\nmethods to considerably reduce the computational complexity. In addition, we\ncombine the binary and bipolar matrices to form ternary sensing matrices\n($\\{0,1,-1\\}$ elements) that satisfy the RIP condition. \n\n"}
{"id": "0908.3512", "contents": "Title: The Infinite-message Limit of Two-terminal Interactive Source Coding Abstract: A two-terminal interactive function computation problem with alternating\nmessages is studied within the framework of distributed block source coding\ntheory. For any finite number of messages, a single-letter characterization of\nthe sum-rate-distortion function was established in previous works using\nstandard information-theoretic techniques. This, however, does not provide a\nsatisfactory characterization of the infinite-message limit, which is a new,\nunexplored dimension for asymptotic-analysis in distributed block source coding\ninvolving potentially an infinite number of infinitesimal-rate messages. In\nthis paper, the infinite-message sum-rate-distortion function, viewed as a\nfunctional of the joint source pmf and the distortion levels, is characterized\nas the least element of a partially ordered family of functionals having\ncertain convex-geometric properties. The new characterization does not involve\nevaluating the infinite-message limit of a finite-message sum-rate-distortion\nexpression. This characterization leads to a family of lower bounds for the\ninfinite-message sum-rate-distortion expression and a simple criterion to test\nthe optimality of any achievable infinite-message sum-rate-distortion\nexpression. For computing the amplewise Boolean AND function, the\ninfinite-message minimum sum-rates are characterized in closed analytic form.\nThese sum-rates are shown to be achievable using infinitely many\ninfinitesimal-rate messages. The new convex-geometric characterization is used\nto develop an iterative algorithm for evaluating any finite-message\nsumrate-distortion function. It is also used to construct the first examples\nwhich demonstrate that for lossy source reproduction, two messages can strictly\nimprove the one-message Wyner-Ziv rate-distortion function settling an\nunresolved question from a 1985 paper. \n\n"}
{"id": "0908.3702", "contents": "Title: Bit-Interleaved Coded Multiple Beamforming with Constellation Precoding Abstract: In this paper, we present the diversity order analysis of bit-interleaved\ncoded multiple beamforming (BICMB) combined with the constellation precoding\nscheme. Multiple beamforming is realized by singular value decomposition of the\nchannel matrix which is assumed to be perfectly known to the transmitter as\nwell as the receiver. Previously, BICMB is known to have a diversity order\nbound related with the product of the code rate and the number of parallel\nsubchannels, losing the full diversity order in some cases. In this paper, we\nshow that BICMB combined with the constellation precoder and maximum likelihood\ndetection achieves the full diversity order. We also provide simulation results\nthat match the analysis. \n\n"}
{"id": "0909.1525", "contents": "Title: Training-Embedded, Single-Symbol ML-Decodable, Distributed STBCs for\n  Relay Networks Abstract: Recently, a special class of complex designs called Training-Embedded Complex\nOrthogonal Designs (TE-CODs) has been introduced to construct single-symbol\nMaximum Likelihood (ML) decodable (SSD) distributed space-time block codes\n(DSTBCs) for two-hop wireless relay networks using the amplify and forward\nprotocol. However, to implement DSTBCs from square TE-CODs, the overhead due to\nthe transmission of training symbols becomes prohibitively large as the number\nof relays increase. In this paper, we propose TE-Coordinate Interleaved\nOrthogonal Designs (TE-CIODs) to construct SSD DSTBCs. Exploiting the block\ndiagonal structure of TE-CIODs, we show that, the overhead due to the\ntransmission of training symbols to implement DSTBCs from TE-CIODs is smaller\nthan that for TE-CODs. We also show that DSTBCs from TE-CIODs offer higher rate\nthan those from TE-CODs for identical number of relays while maintaining the\nSSD and full-diversity properties. \n\n"}
{"id": "0909.4573", "contents": "Title: Efficient Linear Precoding in Downlink Cooperative Cellular Networks\n  with Soft Interference Nulling Abstract: A simple line network model is proposed to study the downlink cellular\nnetwork. Without base station cooperation, the system is interference-limited.\nThe interference limitation is overcome when the base stations are allowed to\njointly encode the user signals, but the capacity-achieving dirty paper coding\nscheme can be too complex for practical implementation. A new linear precoding\ntechnique called soft interference nulling (SIN) is proposed, which performs at\nleast as well as zero-forcing (ZF) beamforming under full network coordination.\nUnlike ZF, SIN allows the possibility of but over-penalizes interference. The\nSIN precoder is computed by solving a convex optimization problem, and the\nformulation is extended to multiple-antenna channels. SIN can be applied when\nonly a limited number of base stations cooperate; it is shown that SIN under\npartial network coordination can outperform full network coordination ZF at\nmoderate SNRs. \n\n"}
{"id": "0909.5119", "contents": "Title: Random Access Transport Capacity Abstract: We develop a new metric for quantifying end-to-end throughput in multihop\nwireless networks, which we term random access transport capacity, since the\ninterference model presumes uncoordinated transmissions. The metric quantifies\nthe average maximum rate of successful end-to-end transmissions, multiplied by\nthe communication distance, and normalized by the network area. We show that a\nsimple upper bound on this quantity is computable in closed-form in terms of\nkey network parameters when the number of retransmissions is not restricted and\nthe hops are assumed to be equally spaced on a line between the source and\ndestination. We also derive the optimum number of hops and optimal per hop\nsuccess probability and show that our result follows the well-known square root\nscaling law while providing exact expressions for the preconstants as well.\nNumerical results demonstrate that the upper bound is accurate for the purpose\nof determining the optimal hop count and success (or outage) probability. \n\n"}
{"id": "0910.0827", "contents": "Title: Performance of Statistical Tests for Single Source Detection using\n  Random Matrix Theory Abstract: This paper introduces a unified framework for the detection of a source with\na sensor array in the context where the noise variance and the channel between\nthe source and the sensors are unknown at the receiver. The Generalized Maximum\nLikelihood Test is studied and yields the analysis of the ratio between the\nmaximum eigenvalue of the sampled covariance matrix and its normalized trace.\nUsing recent results of random matrix theory, a practical way to evaluate the\nthreshold and the $p$-value of the test is provided in the asymptotic regime\nwhere the number $K$ of sensors and the number $N$ of observations per sensor\nare large but have the same order of magnitude. The theoretical performance of\nthe test is then analyzed in terms of Receiver Operating Characteristic (ROC)\ncurve. It is in particular proved that both Type I and Type II error\nprobabilities converge to zero exponentially as the dimensions increase at the\nsame rate, and closed-form expressions are provided for the error exponents.\nThese theoretical results rely on a precise description of the large deviations\nof the largest eigenvalue of spiked random matrix models, and establish that\nthe presented test asymptotically outperforms the popular test based on the\ncondition number of the sampled covariance matrix. \n\n"}
{"id": "0910.1511", "contents": "Title: Cooperation with an Untrusted Relay: A Secrecy Perspective Abstract: We consider the communication scenario where a source-destination pair wishes\nto keep the information secret from a relay node despite wanting to enlist its\nhelp. For this scenario, an interesting question is whether the relay node\nshould be deployed at all. That is, whether cooperation with an untrusted relay\nnode can ever be beneficial. We first provide an achievable secrecy rate for\nthe general untrusted relay channel, and proceed to investigate this question\nfor two types of relay networks with orthogonal components. For the first\nmodel, there is an orthogonal link from the source to the relay. For the second\nmodel, there is an orthogonal link from the relay to the destination. For the\nfirst model, we find the equivocation capacity region and show that answer is\nnegative. In contrast, for the second model, we find that the answer is\npositive. Specifically, we show by means of the achievable secrecy rate based\non compress-and-forward, that, by asking the untrusted relay node to relay\ninformation, we can achieve a higher secrecy rate than just treating the relay\nas an eavesdropper. For a special class of the second model, where the relay is\nnot interfering itself, we derive an upper bound for the secrecy rate using an\nargument whose net effect is to separate the eavesdropper from the relay. The\nmerit of the new upper bound is demonstrated on two channels that belong to\nthis special class. The Gaussian case of the second model mentioned above\nbenefits from this approach in that the new upper bound improves the previously\nknown bounds. For the Cover-Kim deterministic relay channel, the new upper\nbound finds the secrecy capacity when the source-destination link is not worse\nthan the source-relay link, by matching with the achievable rate we present. \n\n"}
{"id": "0911.2197", "contents": "Title: On the relation between plausibility logic and the maximum-entropy\n  principle: a numerical study Abstract: What is the relationship between plausibility logic and the principle of\nmaximum entropy? When does the principle give unreasonable or wrong results?\nWhen is it appropriate to use the rule `expectation = average'? Can\nplausibility logic give the same answers as the principle, and better answers\nif those of the principle are unreasonable? To try to answer these questions,\nthis study offers a numerical collection of plausibility distributions given by\nthe maximum-entropy principle and by plausibility logic for a set of fifteen\nsimple problems: throwing dice. \n\n"}
{"id": "0911.3256", "contents": "Title: Enumerative Coding for Grassmannian Space Abstract: The Grassmannian space $\\Gr$ is the set of all $k-$dimensional subspaces of\nthe vector space~\\smash{$\\F_q^n$}. Recently, codes in the Grassmannian have\nfound an application in network coding. The main goal of this paper is to\npresent efficient enumerative encoding and decoding techniques for the\nGrassmannian. These coding techniques are based on two different orders for the\nGrassmannian induced by different representations of $k$-dimensional subspaces\nof $\\F_q^n$. One enumerative coding method is based on a Ferrers diagram\nrepresentation and on an order for $\\Gr$ based on this representation. The\ncomplexity of this enumerative coding is $O(k^{5/2} (n-k)^{5/2})$ digit\noperations. Another order of the Grassmannian is based on a combination of an\nidentifying vector and a reduced row echelon form representation of subspaces.\nThe complexity of the enumerative coding, based on this order, is\n$O(nk(n-k)\\log n\\log\\log n)$ digits operations. A combination of the two\nmethods reduces the complexity on average by a constant factor. \n\n"}
{"id": "0911.4219", "contents": "Title: Message Passing Algorithms for Compressed Sensing: I. Motivation and\n  Construction Abstract: In a recent paper, the authors proposed a new class of low-complexity\niterative thresholding algorithms for reconstructing sparse signals from a\nsmall set of linear measurements \\cite{DMM}. The new algorithms are broadly\nreferred to as AMP, for approximate message passing. This is the first of two\nconference papers describing the derivation of these algorithms, connection\nwith the related literature, extensions of the original framework, and new\nempirical evidence.\n  In particular, the present paper outlines the derivation of AMP from standard\nsum-product belief propagation, and its extension in several directions. We\nalso discuss relations with formal calculations based on statistical mechanics\nmethods. \n\n"}
{"id": "0911.4432", "contents": "Title: The Role of Feedback in Two-way Secure Communications Abstract: Most practical communication links are bi-directional. In these models, since\nthe source node also receives signals, its encoder has the option of computing\nits output based on the signals it received in the past. On the other hand,\nfrom a practical point of view, it would also be desirable to identify the\ncases where such an encoder design may not improve communication rates. This\nquestion is particularly interesting for the case where the transmitted\nmessages and the feedback signals are subject to eavesdropping. In this work,\nwe investigate the question of how much impact the feedback has on the secrecy\ncapacity by studying two fundamental models. First, we consider the Gaussian\ntwo-way wiretap channel and derive an outer bound for its secrecy capacity\nregion. We show that the secrecy rate loss can be unbounded when feedback\nsignals are not utilized except for a special case we identify, and thus\nconclude that utilizing feedback can be highly beneficial in general. Second,\nwe consider a half-duplex Gaussian two-way relay channel where the relay node\nis also an eavesdropper, and find that the impact of feedback is less\npronounced compared to the previous scenario. Specifically, the loss in secrecy\nrate, when ignoring the feedback, is quantified to be less than 0.5 bit per\nchannel use when the relay power goes to infinity. This achievable rate region\nis obtained with simple time sharing along with cooperative jamming, which,\nwith its simplicity and near optimum performance, is a viable alternative to an\nencoder that utilizes feedback signals. \n\n"}
{"id": "0911.4640", "contents": "Title: Near-ML Signal Detection in Large-Dimension Linear Vector Channels Using\n  Reactive Tabu Search Abstract: Low-complexity near-optimal signal detection in large dimensional\ncommunication systems is a challenge. In this paper, we present a reactive tabu\nsearch (RTS) algorithm, a heuristic based combinatorial optimization technique,\nto achieve low-complexity near-maximum likelihood (ML) signal detection in\nlinear vector channels with large dimensions. Two practically important\nlarge-dimension linear vector channels are considered: i) multiple-input\nmultiple-output (MIMO) channels with large number (tens) of transmit and\nreceive antennas, and ii) severely delay-spread MIMO inter-symbol interference\n(ISI) channels with large number (tens to hundreds) of multipath components.\nThese channels are of interest because the former offers the benefit of\nincreased spectral efficiency (several tens of bps/Hz) and the latter offers\nthe benefit of high time-diversity orders. Our simulation results show that,\nwhile algorithms including variants of sphere decoding do not scale well for\nlarge dimensions, the proposed RTS algorithm scales well for signal detection\nin large dimensions while achieving increasingly closer to ML performance for\nincreasing number of dimensions. \n\n"}
{"id": "0911.5508", "contents": "Title: Codes on graphs: Duality and MacWilliams identities Abstract: A conceptual framework involving partition functions of normal factor graphs\nis introduced, paralleling a similar recent development by Al-Bashabsheh and\nMao. The partition functions of dual normal factor graphs are shown to be a\nFourier transform pair, whether or not the graphs have cycles. The original\nnormal graph duality theorem follows as a corollary. Within this framework,\nMacWilliams identities are found for various local and global weight generating\nfunctions of general group or linear codes on graphs; this generalizes and\nprovides a concise proof of the MacWilliams identity for linear time-invariant\nconvolutional codes that was recently found by Gluesing-Luerssen and Schneider.\nFurther MacWilliams identities are developed for terminated convolutional\ncodes, particularly for tail-biting codes, similar to those studied recently by\nBocharova, Hug, Johannesson and Kudryashov. \n\n"}
{"id": "0911.5524", "contents": "Title: LS-CS-residual (LS-CS): Compressive Sensing on Least Squares Residual Abstract: We consider the problem of recursively and causally reconstructing time\nsequences of sparse signals (with unknown and time-varying sparsity patterns)\nfrom a limited number of noisy linear measurements. The sparsity pattern is\nassumed to change slowly with time. The idea of our proposed solution,\nLS-CS-residual (LS-CS), is to replace compressed sensing (CS) on the\nobservation by CS on the least squares (LS) residual computed using the\nprevious estimate of the support. We bound CS-residual error and show that when\nthe number of available measurements is small, the bound is much smaller than\nthat on CS error if the sparsity pattern changes slowly enough. We also obtain\nconditions for \"stability\" of LS-CS over time for a signal model that allows\nsupport additions and removals, and that allows coefficients to gradually\nincrease (decrease) until they reach a constant value (become zero). By\n\"stability\", we mean that the number of misses and extras in the support\nestimate remain bounded by time-invariant values (in turn implying a\ntime-invariant bound on LS-CS error). The concept is meaningful only if the\nbounds are small compared to the support size. Numerical experiments backing\nour claims are shown. \n\n"}
{"id": "0912.1790", "contents": "Title: A Note on the Injection Distance Abstract: Koetter and Kschischang showed in [R. Koetter and F.R. Kschischang, \"Coding\nfor Errors and Erasures in Random Network Coding,\" IEEE Trans. Inform. Theory,\n{54(8), 2008] that the network coding counterpart of Gabidulin codes performs\nasymptotically optimal with respect to the subspace distance. Recently, Silva\nand Kschischang introduced in [D. Silva and F.R. Kschischang, \"On Metrics for\nError Correction in Network Coding,\" To appear in IEEE Trans. Inform. Theory,\nArXiv: 0805.3824v4[cs.IT], 2009] the injection distance to give a detailed\npicture of what happens in noncoherent network coding. We show that the above\ncodes are also asymptotically optimal with respect to this distance. \n\n"}
{"id": "0912.3245", "contents": "Title: Structured Error Recovery for Codeword-Stabilized Quantum Codes Abstract: Codeword stabilized (CWS) codes are, in general, non-additive quantum codes\nthat can correct errors by an exhaustive search of different error patterns,\nsimilar to the way that we decode classical non-linear codes. For an n-qubit\nquantum code correcting errors on up to t qubits, this brute-force approach\nconsecutively tests different errors of weight t or less, and employs a\nseparate n-qubit measurement in each test. In this paper, we suggest an error\ngrouping technique that allows to simultaneously test large groups of errors in\na single measurement. This structured error recovery technique exponentially\nreduces the number of measurements by about 3^t times. While it still leaves\nexponentially many measurements for a generic CWS code, the technique is\nequivalent to syndrome-based recovery for the special case of additive CWS\ncodes. \n\n"}
{"id": "0912.3419", "contents": "Title: Application Driven Joint Uplink-Downlink Optimization in Wireless\n  Communications Abstract: This paper introduces a new mathematical framework, which is used to derive\njoint uplink/downlink achievable rate regions for multi-user spatial\nmultiplexing between one base station and multiple terminals. The framework\nconsists of two models: the first one is a simple transmission model for uplink\nand downlink, which is capable to give a lower bound on the capacity for the\ncase that the transmission is subject to imperfect CSI. A detailed model for\nconcrete channel estimation and feedback schemes provides parameter input to\nthe former model and covers the most important aspects such as pilot design\noptimization, linear channel estimation, feedback delay, and feedback\nquantization. We apply this framework to determine optimal pilot densities and\nCSI feedback quantity, given that a weighted sum of uplink and downlink\nthroughput is to be maximized for a certain user velocity. We show that for low\nspeed, and if downlink throughput is of particular importance, a significant\nportion of the uplink should be invested into CSI feedback. At higher velocity,\nhowever, downlink performance becomes mainly affected by CSI feedback delay,\nand hence CSI feedback brings little gain considering the inherent sacrifice of\nuplink capacity. We further show that for high velocities, it becomes\nbeneficial to use no CSI feedback at all, but apply random beamforming in the\ndownlink and operate in time-division duplex. \n\n"}
{"id": "1001.0001", "contents": "Title: On the structure of non-full-rank perfect codes Abstract: The Krotov combining construction of perfect 1-error-correcting binary codes\nfrom 2000 and a theorem of Heden saying that every non-full-rank perfect\n1-error-correcting binary code can be constructed by this combining\nconstruction is generalized to the $q$-ary case. Simply, every non-full-rank\nperfect code $C$ is the union of a well-defined family of $\\mu$-components\n$K_\\mu$, where $\\mu$ belongs to an \"outer\" perfect code $C^*$, and these\ncomponents are at distance three from each other. Components from distinct\ncodes can thus freely be combined to obtain new perfect codes. The Phelps\ngeneral product construction of perfect binary code from 1984 is generalized to\nobtain $\\mu$-components, and new lower bounds on the number of perfect\n1-error-correcting $q$-ary codes are presented. \n\n"}
{"id": "1001.1021", "contents": "Title: The Capacity of Random Linear Coding Networks as Subspace Channels Abstract: In this paper, we consider noncoherent random linear coding networks (RLCNs)\nas a discrete memoryless channel (DMC) whose input and output alphabets consist\nof subspaces. This contrasts with previous channel models in the literature\nwhich assume matrices as the channel input and output. No particular\nassumptions are made on the network topology or the transfer matrix, except\nthat the latter may be rank-deficient according to some rank deficiency\nprobability distribution. We introduce a random vector basis selection\nprocedure which renders the DMC symmetric. The capacity we derive can be seen\nas a lower bound on the capacity of noncoherent RLCNs, where subspace coding\nsuffices to achieve this bound. \n\n"}
{"id": "1001.1732", "contents": "Title: Trade-off capacities of the quantum Hadamard channels Abstract: Coding theorems in quantum Shannon theory express the ultimate rates at which\na sender can transmit information over a noisy quantum channel. More often than\nnot, the known formulas expressing these transmission rates are intractable,\nrequiring an optimization over an infinite number of uses of the channel.\nResearchers have rarely found quantum channels with a tractable classical or\nquantum capacity, but when such a finding occurs, it demonstrates a complete\nunderstanding of that channel's capabilities for transmitting classical or\nquantum information. Here, we show that the three-dimensional capacity region\nfor entanglement-assisted transmission of classical and quantum information is\ntractable for the Hadamard class of channels. Examples of Hadamard channels\ninclude generalized dephasing channels, cloning channels, and the Unruh\nchannel. The generalized dephasing channels and the cloning channels are\nnatural processes that occur in quantum systems through the loss of quantum\ncoherence or stimulated emission, respectively. The Unruh channel is a noisy\nprocess that occurs in relativistic quantum information theory as a result of\nthe Unruh effect and bears a strong relationship to the cloning channels. We\ngive exact formulas for the entanglement-assisted classical and quantum\ncommunication capacity regions of these channels. The coding strategy for each\nof these examples is superior to a naive time-sharing strategy, and we\nintroduce a measure to determine this improvement. \n\n"}
{"id": "1001.2284", "contents": "Title: An Efficient Approach Toward the Asymptotic Analysis of Node-Based\n  Recovery Algorithms in Compressed Sensing Abstract: In this paper, we propose a general framework for the asymptotic analysis of\nnode-based verification-based algorithms. In our analysis we tend the signal\nlength $n$ to infinity. We also let the number of non-zero elements of the\nsignal $k$ scale linearly with $n$. Using the proposed framework, we study the\nasymptotic behavior of the recovery algorithms over random sparse matrices\n(graphs) in the context of compressive sensing. Our analysis shows that there\nexists a success threshold on the density ratio $k/n$, before which the\nrecovery algorithms are successful, and beyond which they fail. This threshold\nis a function of both the graph and the recovery algorithm. We also demonstrate\nthat there is a good agreement between the asymptotic behavior of recovery\nalgorithms and finite length simulations for moderately large values of $n$. \n\n"}
{"id": "1001.2738", "contents": "Title: Note on sampling without replacing from a finite collection of matrices Abstract: This technical note supplies an affirmative answer to a question raised in a\nrecent pre-print [arXiv:0910.1879] in the context of a \"matrix recovery\"\nproblem. Assume one samples m Hermitian matrices X_1, ..., X_m with replacement\nfrom a finite collection. The deviation of the sum X_1+...+X_m from its\nexpected value in terms of the operator norm can be estimated by an \"operator\nChernoff-bound\" due to Ahlswede and Winter. The question arose whether the\nbounds obtained this way continue to hold if the matrices are sampled without\nreplacement. We remark that a positive answer is implied by a classical\nargument by Hoeffding. Some consequences for the matrix recovery problem are\nsketched. \n\n"}
{"id": "1001.4181", "contents": "Title: Improved Upper Bounds to the Causal Quadratic Rate-Distortion Function\n  for Gaussian Stationary Sources Abstract: We improve the existing achievable rate regions for causal and for zero-delay\nsource coding of stationary Gaussian sources under an average mean squared\nerror (MSE) distortion measure. To begin with, we find a closed-form expression\nfor the information-theoretic causal rate-distortion function (RDF) under such\ndistortion measure, denoted by $R_{c}^{it}(D)$, for first-order Gauss-Markov\nprocesses. Rc^{it}(D) is a lower bound to the optimal performance theoretically\nattainable (OPTA) by any causal source code, namely Rc^{op}(D). We show that,\nfor Gaussian sources, the latter can also be upper bounded as Rc^{op}(D)\\leq\nRc^{it}(D) + 0.5 log_{2}(2\\pi e) bits/sample. In order to analyze\n$R_{c}^{it}(D)$ for arbitrary zero-mean Gaussian stationary sources, we\nintroduce \\bar{Rc^{it}}(D), the information-theoretic causal RDF when the\nreconstruction error is jointly stationary with the source. Based upon\n\\bar{Rc^{it}}(D), we derive three closed-form upper bounds to the additive rate\nloss defined as \\bar{Rc^{it}}(D) - R(D), where R(D) denotes Shannon's RDF. Two\nof these bounds are strictly smaller than 0.5 bits/sample at all rates. These\nbounds differ from one another in their tightness and ease of evaluation; the\ntighter the bound, the more involved its evaluation. We then show that, for any\nsource spectral density and any positive distortion D\\leq \\sigma_{x}^{2},\n\\bar{Rc^{it}}(D) can be realized by an AWGN channel surrounded by a unique set\nof causal pre-, post-, and feedback filters. We show that finding such filters\nconstitutes a convex optimization problem. In order to solve the latter, we\npropose an iterative optimization procedure that yields the optimal filters and\nis guaranteed to converge to \\bar{Rc^{it}}(D). Finally, by establishing a\nconnection to feedback quantization we design a causal and a zero-delay coding\nscheme which, for Gaussian sources, achieves... \n\n"}
{"id": "1002.0123", "contents": "Title: Achievable rate regions and outer bounds for a multi-pair bi-directional\n  relay network Abstract: In a bi-directional relay channel, a pair of nodes wish to exchange\nindependent messages over a shared wireless half-duplex channel with the help\nof relays. Recent work has mostly considered information theoretic limits of\nthe bi-directional relay channel with two terminal nodes (or end users) and one\nrelay. In this work we consider bi-directional relaying with one base station,\nmultiple terminal nodes and one relay, all of which operate in half-duplex\nmodes. We assume that each terminal node communicates with the base-station in\na bi-directional fashion through the relay and do not place any restrictions on\nthe channels between the users, relays and base-stations; that is, each node\nhas a direct link with every other node.\n  Our contributions are three-fold: 1) the introduction of four new temporal\nprotocols which fully exploit the two-way nature of the data and outperform\nsimple routing or multi-hop communication schemes by carefully combining\nnetwork coding, random binning and user cooperation which exploit over-heard\nand own-message side information, 2) derivations of inner and outer bounds on\nthe capacity region of the discrete-memoryless multi-pair two-way network, and\n3) a numerical evaluation of the obtained achievable rate regions and outer\nbounds in Gaussian noise which illustrate the performance of the proposed\nprotocols compared to simpler schemes, to each other, to the outer bounds,\nwhich highlight the relative gains achieved by network coding, random binning\nand compress-and-forward-type cooperation between terminal nodes. \n\n"}
{"id": "1002.4935", "contents": "Title: Multiarray Signal Processing: Tensor decomposition meets compressed\n  sensing Abstract: We discuss how recently discovered techniques and tools from compressed\nsensing can be used in tensor decompositions, with a view towards modeling\nsignals from multiple arrays of multiple sensors. We show that with appropriate\nbounds on a measure of separation between radiating sources called coherence,\none could always guarantee the existence and uniqueness of a best rank-r\napproximation of the tensor representing the signal. We also deduce a\ncomputationally feasible variant of Kruskal's uniqueness condition, where the\ncoherence appears as a proxy for k-rank. Problems of sparsest recovery with an\ninfinite continuous dictionary, lowest-rank tensor representation, and blind\nsource separation are treated in a uniform fashion. The decomposition of the\nmeasurement tensor leads to simultaneous localization and extraction of\nradiating sources, in an entirely deterministic manner. \n\n"}
{"id": "1003.0064", "contents": "Title: Decoding by Sampling: A Randomized Lattice Algorithm for Bounded\n  Distance Decoding Abstract: Despite its reduced complexity, lattice reduction-aided decoding exhibits a\nwidening gap to maximum-likelihood (ML) performance as the dimension increases.\nTo improve its performance, this paper presents randomized lattice decoding\nbased on Klein's sampling technique, which is a randomized version of Babai's\nnearest plane algorithm (i.e., successive interference cancelation (SIC)). To\nfind the closest lattice point, Klein's algorithm is used to sample some\nlattice points and the closest among those samples is chosen. Lattice reduction\nincreases the probability of finding the closest lattice point, and only needs\nto be run once during pre-processing. Further, the sampling can operate very\nefficiently in parallel. The technical contribution of this paper is two-fold:\nwe analyze and optimize the decoding radius of sampling decoding resulting in\nbetter error performance than Klein's original algorithm, and propose a very\nefficient implementation of random rounding. Of particular interest is that a\nfixed gain in the decoding radius compared to Babai's decoding can be achieved\nat polynomial complexity. The proposed decoder is useful for moderate\ndimensions where sphere decoding becomes computationally intensive, while\nlattice reduction-aided decoding starts to suffer considerable loss. Simulation\nresults demonstrate near-ML performance is achieved by a moderate number of\nsamples, even if the dimension is as high as 32. \n\n"}
{"id": "1003.2782", "contents": "Title: Reduced ML-Decoding Complexity, Full-Rate STBCs for $2^a$ Transmit\n  Antenna Systems Abstract: For an $n_t$ transmit, $n_r$ receive antenna system ($n_t \\times n_r$\nsystem), a {\\it{full-rate}} space time block code (STBC) transmits $n_{min} =\nmin(n_t,n_r)$ complex symbols per channel use and in general, has an\nML-decoding complexity of the order of $M^{n_tn_{min}}$ (considering square\ndesigns), where $M$ is the constellation size. In this paper, a scheme to\nobtain a full-rate STBC for $2^a$ transmit antennas and any $n_r$, with reduced\nML-decoding complexity of the order of $M^{n_t(n_{min}-3/4)}$, is presented.\nThe weight matrices of the proposed STBC are obtained from the unitary matrix\nrepresentations of a Clifford Algebra. For any value of $n_r$, the proposed\ndesign offers a reduction from the full ML-decoding complexity by a factor of\n$M^{3n_t/4}}$. The well known Silver code for 2 transmit antennas is a special\ncase of the proposed scheme. Further, it is shown that the codes constructed\nusing the scheme have higher ergodic capacity than the well known punctured\nPerfect codes for $n_r < n_t$. Simulation results of the symbol error rates are\nshown for $8 \\times 2$ systems, where the comparison of the proposed code is\nwith the punctured Perfect code for 8 transmit antennas. The proposed code\nmatches the punctured perfect code in error performance, while having reduced\nML-decoding complexity and higher ergodic capacity. \n\n"}
{"id": "1003.2880", "contents": "Title: Regularized sampling of multiband signals Abstract: This paper presents a regularized sampling method for multiband signals, that\nmakes it possible to approach the Landau limit, while keeping the sensitivity\nto noise at a low level. The method is based on band-limited windowing,\nfollowed by trigonometric approximation in consecutive time intervals. The key\npoint is that the trigonometric approximation \"inherits\" the multiband\nproperty, that is, its coefficients are formed by bursts of non-zero elements\ncorresponding to the multiband components. It is shown that this method can be\nwell combined with the recently proposed synchronous multi-rate sampling (SMRS)\nscheme, given that the resulting linear system is sparse and formed by ones and\nzeroes. The proposed method allows one to trade sampling efficiency for noise\nsensitivity, and is specially well suited for bounded signals with unbounded\nenergy like those in communications, navigation, audio systems, etc. Besides,\nit is also applicable to finite energy signals and periodic band-limited\nsignals (trigonometric polynomials). The paper includes a subspace method for\nblindly estimating the support of the multiband signal as well as its\ncomponents, and the results are validated through several numerical examples. \n\n"}
{"id": "1004.5157", "contents": "Title: Deriving Good LDPC Convolutional Codes from LDPC Block Codes Abstract: Low-density parity-check (LDPC) convolutional codes are capable of achieving\nexcellent performance with low encoding and decoding complexity. In this paper\nwe discuss several graph-cover-based methods for deriving families of\ntime-invariant and time-varying LDPC convolutional codes from LDPC block codes\nand show how earlier proposed LDPC convolutional code constructions can be\npresented within this framework. Some of the constructed convolutional codes\nsignificantly outperform the underlying LDPC block codes. We investigate some\npossible reasons for this \"convolutional gain,\" and we also discuss the ---\nmostly moderate --- decoder cost increase that is incurred by going from LDPC\nblock to LDPC convolutional codes. \n\n"}
{"id": "1005.0624", "contents": "Title: The Gaussian Many-to-1 Interference Channel with Confidential Messages Abstract: The many-to-one interference channel has received interest by virtue of\nembodying the essence of an interference network while being more tractable\nthan the general K-user interference channel. In this paper, we introduce\ninformation theoretic secrecy to this model and consider the many-to-one\ninterference channel with confidential messages, in which each receiver, in\nparticular, the one subject to interference, is also one from which the\ninterfering users' messages need to be kept secret from. We derive the\nachievable secrecy sum rate for this channel using nested lattice codes, as\nwell as an upper bound on the secrecy sum rate for all possible channel gain\nconfigurations. We identify several nontrivial cases where the gap between the\nupper bound and the achieved secrecy sum rate is only a function of the number\nof the users K, and is uniform over all possible channel gain configurations in\neach case. In addition, we identify the secure degree of freedom for this\nchannel and show it to be equivalent to its degree of freedom, i.e., the\nsecrecy in high SNR comes for free. \n\n"}
{"id": "1005.3338", "contents": "Title: Feedback Capacity of the Gaussian Interference Channel to within 2 Bits Abstract: We characterize the capacity region to within 2 bits/s/Hz and the symmetric\ncapacity to within 1 bit/s/Hz for the two-user Gaussian interference channel\n(IC) with feedback. We develop achievable schemes and derive a new outer bound\nto arrive at this conclusion. One consequence of the result is that feedback\nprovides multiplicative gain, i.e., the gain becomes arbitrarily large for\ncertain channel parameters. It is a surprising result because feedback has been\nso far known to provide no gain in memoryless point-to-point channels and only\nbounded additive gain in multiple access channels. The gain comes from using\nfeedback to maximize resource utilization, thereby enabling more efficient\nresource sharing between the interfering users. The result makes use of a\ndeterministic model to provide insights into the Gaussian channel. This\ndeterministic model is a special case of El Gamal-Costa deterministic model and\nas a side-generalization, we establish the exact feedback capacity region of\nthis general class of deterministic ICs. \n\n"}
{"id": "1006.0496", "contents": "Title: The diversity-multiplexing tradeoff of the MIMO Z interference channel Abstract: The fundamental generalized diversity-multiplexing tradeoff (GDMT) of the\nquasi-static fading MIMO Z interference channel (Z-IC) is established for the\ngeneral Z-IC with an arbitrary number of antennas at each node under the\nassumptions of full channel state information at the transmitters (CSIT) and a\nshort-term average power constraint. In the GDMT framework, the direct link\nsignal-to-noise ratios (SNR) and cross-link interference-to-noise ratio (INR)\nare allowed to vary so that their ratios relative to a nominal SNR in the dB\nscale, i.e., the SNR/INR exponents, are fixed. It is shown that a simple\nHan-Kobayashi message-splitting/partial interference decoding scheme that uses\nonly partial CSIT -- in which the second transmitter's signal depends only on\nits cross-link channel matrix and the first user's transmit signal doesn't need\nany CSIT whatsoever -- can achieve the full-CSIT GDMT of the MIMO Z-IC. The\nGDMT of the MIMO Z-IC under the No-CSIT assumption is also obtained for some\nrange of multiplexing gains. The size of this range depends on the numbers of\nantennas at the four nodes and the SNR and INR exponents of the direct and\ncross links, respectively. For certain classes of channels including those in\nwhich the interfered receiver has more antennas than do the other nodes, or\nwhen the INR exponent is greater than a certain threshold, the GDMT of the MIMO\nZ-IC under the No-CSIT assumption is completely characterized. \n\n"}
{"id": "1006.3385", "contents": "Title: A Fixed Precoding Approach to Achieve the Degrees of Freedom in X\n  channel Abstract: This paper aims to provide a fixed precoding scheme to achieve the Degrees of\nFreedom DoF of the generalized ergodic X channel. This is achieved through\nusing the notion of ergodic interference alignment technique. Accordingly, in\nthe proposed method the transmitters do not require to know the full channel\nstate information, while this assumption is the integral part of existing\nmethods. Instead, a finite-rate feed-back channel is adequate to achieve the\nDoF. In other words, it is demonstrated that quantized versions of channel\ngains are adequate to achieve theDOF. To get an insight regarding the\nfunctionality of the proposed method, first we rely on finite field channel\nmodels, and then extend the terminology to more realistic cases, including\ndispersive fading channels in the presence of quantizer. Accordingly, in a\nRayliegh fading environment, it is shown a feedback rate of\n2log(p)+Theta(log(log(p))) can provide the DoF, where $p$ is the total transmit\npower. \n\n"}
{"id": "1006.3959", "contents": "Title: Molecular Communication Using Brownian Motion with Drift Abstract: Inspired by biological communication systems, molecular communication has\nbeen proposed as a viable scheme to communicate between nano-sized devices\nseparated by a very short distance. Here, molecules are released by the\ntransmitter into the medium, which are then sensed by the receiver. This paper\ndevelops a preliminary version of such a communication system focusing on the\nrelease of either one or two molecules into a fluid medium with drift. We\nanalyze the mutual information between transmitter and the receiver when\ninformation is encoded in the time of release of the molecule. Simplifying\nassumptions are required in order to calculate the mutual information, and\ntheoretical results are provided to show that these calculations are upper\nbounds on the true mutual information. Furthermore, optimized degree\ndistributions are provided, which suggest transmission strategies for a variety\nof drift velocities. \n\n"}
{"id": "1006.4255", "contents": "Title: Polar codes for the two-user multiple-access channel Abstract: Arikan's polar coding method is extended to two-user multiple-access\nchannels. It is shown that if the two users of the channel use the Arikan\nconstruction, the resulting channels will polarize to one of five possible\nextremals, on each of which uncoded transmission is optimal. The sum rate\nachieved by this coding technique is the one that correponds to uniform input\ndistributions. The encoding and decoding complexities and the error performance\nof these codes are as in the single-user case: $O(n\\log n)$ for encoding and\ndecoding, and $o(\\exp(-n^{1/2-\\epsilon}))$ for block error probability, where\n$n$ is the block length. \n\n"}
{"id": "1006.4509", "contents": "Title: Receive Diversity and Ergodic Performance of Interference Alignment on\n  the MIMO Gaussian Interference Channel Abstract: We consider interference alignment (IA) over K-user Gaussian MIMO\ninterference channel (MIMO-IC) when the SNR is not asymptotically high. We\nintroduce a generalization of IA which enables receive diversity inside the\ninterference-free subspace. We generalize the existence criterion of an IA\nsolution proposed by Yetis et al. to this case, thereby establishing a\nmulti-user diversity-multiplexing trade-off (DMT) for the interference channel.\nFurthermore, we derive a closed-form tight lower-bound for the ergodic mutual\ninformation achievable using IA over a Gaussian MIMO-IC with Gaussian i.i.d.\nchannel coefficients at arbitrary SNR, when the transmitted signals are white\ninside the subspace defined by IA. Finally, as an application of the previous\nresults, we compare the performance achievable by IA at various operating\npoints allowed by the DMT, to a recently introduced distributed method based on\ngame theory. \n\n"}
{"id": "1007.0496", "contents": "Title: Perturbed Hankel Determinants: Applications to the Information Theory of\n  MIMO Wireless Communications Abstract: In this paper we compute two important information-theoretic quantities which\narise in the application of multiple-input multiple-output (MIMO) antenna\nwireless communication systems: the distribution of the mutual information of\nmulti-antenna Gaussian channels, and the Gallager random coding upper bound on\nthe error probability achievable by finite-length channel codes. It turns out\nthat the mathematical problem underpinning both quantities is the computation\nof certain Hankel determinants generated by deformed versions of classical\nweight functions. For single-user MIMO systems, it is a deformed Laguerre\nweight, whereas for multi-user MIMO systems it is a deformed Jacobi weight. We\napply two different methods to characterize each of these Hankel determinants.\nFirst, we employ the ladder operators of the corresponding monic orthogonal\npolynomials to give an exact characterization of the Hankel determinants in\nterms of Painlev\\'{e} differential equations. This turns out to be a\nPainlev\\'{e} V for the single-user MIMO scenario and a Painlev\\'{e} VI for the\nmulti user scenario. We then employ Coulomb fluid methods to derive new\nclosed-form approximations for the Hankel determinants which, although formally\nvalid for large matrix dimensions, are shown to give accurate results for both\nthe MIMO mutual information distribution and the error exponent even when the\nmatrix dimensions are small. Focusing on the single-user mutual information\ndistribution, we then employ both the exact Painlev\\'{e} representation and the\nCoulomb fluid approximation to yield deeper insights into the scaling behavior\nin terms of the number of antennas and signal-to-noise ratio. Among other\nthings, these results allow us to study the asymptotic Gaussianity of the\ndistribution as the number of antennas increase, and to explicitly compute the\ncorrection terms to the mean, variance, and higher order cumulants. \n\n"}
{"id": "1007.3105", "contents": "Title: A Selection Region Based Routing Protocol for Random Mobile ad hoc\n  Networks Abstract: We propose a selection region based multi-hop routing protocol for random\nmobile ad hoc networks, where the selection region is defined by two\nparameters: a reference distance and a selection angle. At each hop, a relay is\nchosen as the nearest node to the transmitter that is located within the\nselection region. By assuming that the relay nodes are randomly placed, we\nderive an upper bound for the optimum reference distance to maximize the\nexpected density of progress and investigate the relationship between the\noptimum selection angle and the optimum reference distance. We also note that\nthe optimized expected density of progress scales as $\\Theta(\\sqrt{\\lambda})$,\nwhich matches the prior results in the literature. Compared with the\nspatial-reuse multi-hop protocol in \\cite{Baccelli:Aloha} recently proposed by\nBaccelli \\emph{et al.}, in our new protocol the amount of nodes involved and\nthe calculation complexity for each relay selection are reduced significantly,\nwhich is attractive for energy-limited wireless ad hoc networks (e.g., wireless\nsensor networks). \n\n"}
{"id": "1007.3661", "contents": "Title: Non-Binary Polar Codes using Reed-Solomon Codes and Algebraic Geometry\n  Codes Abstract: Polar codes, introduced by Arikan, achieve symmetric capacity of any discrete\nmemoryless channels under low encoding and decoding complexity. Recently,\nnon-binary polar codes have been investigated. In this paper, we calculate\nerror probability of non-binary polar codes constructed on the basis of\nReed-Solomon matrices by numerical simulations. It is confirmed that 4-ary\npolar codes have significantly better performance than binary polar codes on\nbinary-input AWGN channel. We also discuss an interpretation of polar codes in\nterms of algebraic geometry codes, and further show that polar codes using\nHermitian codes have asymptotically good performance. \n\n"}
{"id": "1007.3706", "contents": "Title: Cooperative Convex Optimization in Networked Systems: Augmented\n  Lagrangian Algorithms with Directed Gossip Communication Abstract: We study distributed optimization in networked systems, where nodes cooperate\nto find the optimal quantity of common interest, x=x^\\star. The objective\nfunction of the corresponding optimization problem is the sum of private (known\nonly by a node,) convex, nodes' objectives and each node imposes a private\nconvex constraint on the allowed values of x. We solve this problem for generic\nconnected network topologies with asymmetric random link failures with a novel\ndistributed, decentralized algorithm. We refer to this algorithm as AL-G\n(augmented Lagrangian gossiping,) and to its variants as AL-MG (augmented\nLagrangian multi neighbor gossiping) and AL-BG (augmented Lagrangian broadcast\ngossiping.) The AL-G algorithm is based on the augmented Lagrangian dual\nfunction. Dual variables are updated by the standard method of multipliers, at\na slow time scale. To update the primal variables, we propose a novel,\nGauss-Seidel type, randomized algorithm, at a fast time scale. AL-G uses\nunidirectional gossip communication, only between immediate neighbors in the\nnetwork and is resilient to random link failures. For networks with reliable\ncommunication (i.e., no failures,) the simplified, AL-BG (augmented Lagrangian\nbroadcast gossiping) algorithm reduces communication, computation and data\nstorage cost. We prove convergence for all proposed algorithms and demonstrate\nby simulations the effectiveness on two applications: l_1-regularized logistic\nregression for classification and cooperative spectrum sensing for cognitive\nradio networks. \n\n"}
{"id": "1007.3808", "contents": "Title: Characterization of Graph-cover Pseudocodewords of Codes over $F_3$ Abstract: Linear-programming pseudocodewords play a pivotal role in our understanding\nof the linear-programming decoding algorithms. These pseudocodewords are known\nto be equivalent to the graph-cover pseudocodewords. The latter\npseudocodewords, when viewed as points in the multidimensional Euclidean space,\nlie inside a fundamental cone. This fundamental cone depends on the choice of a\nparity-check matrix of a code, rather than on the choice of the code itself.\nThe cone does not depend on the channel, over which the code is employed. The\nknowledge of the boundaries of the fundamental cone could help in studying\nvarious properties of the pseudocodewords, such as their minimum pseudoweight,\npseudoredundancy of the codes, etc. For the binary codes, the full\ncharacterization of the fundamental cone was derived by Koetter et al. However,\nif the underlying alphabet is large, such characterization becom is more\ninvolved. In this work, a characterization of the fundamental cone for codes\nover $F_3$ is discussed. \n\n"}
{"id": "1008.2147", "contents": "Title: Quantum Tagging: Authenticating Location via Quantum Information and\n  Relativistic Signalling Constraints Abstract: We define the task of {\\it quantum tagging}, that is, authenticating the\nclassical location of a classical tagging device by sending and receiving\nquantum signals from suitably located distant sites, in an environment\ncontrolled by an adversary whose quantum information processing and\ntransmitting power is unbounded. We define simple security models for this task\nand briefly discuss alternatives.\n  We illustrate the pitfalls of naive quantum cryptographic reasoning in this\ncontext by describing several protocols which at first sight appear\nunconditionally secure but which, as we show, can in fact be broken by\nteleportation-based attacks. We also describe some protocols which cannot be\nbroken by these specific attacks, but do not prove they are unconditionally\nsecure.\n  We review the history of quantum tagging protocols, which we first discussed\nin 2002 and described in a 2006 patent (for an insecure protocol). The\npossibility has recently been reconsidered by other authors. All the more\nrecently discussed protocols of which we are aware were either previously\nconsidered by us in 2002-3 or are variants of schemes then considered, and all\nare provably insecure. \n\n"}
{"id": "1008.2857", "contents": "Title: Bidirectional multi-pair network with a MIMO relay: Beamforming\n  strategies and lack of duality Abstract: We address the problem of a multi-user relay network, where multiple\nsingle-antenna node pairs want to exchange information by using a multiple\nantenna relay node. Due to the half-duplex constraint of the relay, the\nexchange of information takes place in two steps. In the first step, the nodes\ntransmit their data to the relay, while in the second step, the relay is\nbroadcasting the data by using linear and non-linear precoding strategies. We\nfocus on the second step in this paper. We first consider the problem of\nmaximizing the overall rate achievable using linear and dirty-paper type\nprecoding strategies at the relay. Then, we consider minimizing the total power\nat the relay subject to individual SINR constraints using the same strategies\nat the relay. We show that the downlink-uplink duality does not hold for the\nsetup considered here, which is a somewhat surprising result. We also show that\nthe beamforming strategy which is optimal in the single-pair case performs very\nwell in the multi-pair case for practically relevant SNR. The results are\nillustrated by numerical simulations. \n\n"}
{"id": "1008.4135", "contents": "Title: Interpreting quantum discord through quantum state merging Abstract: We present an operational interpretation of quantum discord based on the\nquantum state merging protocol. Quantum discord is the markup in the cost of\nquantum communication in the process of quantum state merging, if one discards\nrelevant prior information. Our interpretation has an intuitive explanation\nbased on the strong subadditivity of von Neumann entropy. We use our result to\nprovide operational interpretations of other quantities like the local purity\nand quantum deficit. Finally, we discuss in brief some instances where our\ninterpretation is valid in the single copy scenario. \n\n"}
{"id": "1009.3145", "contents": "Title: Universal Rate-Efficient Scalar Quantization Abstract: Scalar quantization is the most practical and straightforward approach to\nsignal quantization. However, it has been shown that scalar quantization of\noversampled or Compressively Sensed signals can be inefficient in terms of the\nrate-distortion trade-off, especially as the oversampling rate or the sparsity\nof the signal increases. In this paper, we modify the scalar quantizer to have\ndiscontinuous quantization regions. We demonstrate that with this modification\nit is possible to achieve exponential decay of the quantization error as a\nfunction of the oversampling rate instead of the quadratic decay exhibited by\ncurrent approaches. Our approach is universal in the sense that prior knowledge\nof the signal model is not necessary in the quantizer design, only in the\nreconstruction. Thus, we demonstrate that it is possible to reduce the\nquantization error by incorporating side information on the acquired signal,\nsuch as sparse signal models or signal similarity with known signals. In doing\nso, we establish a relationship between quantization performance and the\nKolmogorov entropy of the signal model. \n\n"}
{"id": "1009.4269", "contents": "Title: Distributed Interference Cancellation in Multiple Access Channel with\n  Transmitter Cooperation Abstract: We consider a two-user Gaussian multiple access channel with two independent\nadditive white Gaussian interferences. Each interference is known to exactly\none transmitter non-causally. Transmitters are allowed to cooperate through\nfinite-capacity links. The capacity region is characterized to within 3 and 1.5\nbits for the stronger user and the weaker user respectively, regardless of\nchannel parameters. As a by-product, we characterize the capacity region of the\ncase without cooperation to within 1 and 0.5 bits for the stronger user and the\nweaker user respectively. These results are based on a layered modulo-lattice\ntransmission architecture which realizes distributed interference cancellation. \n\n"}
{"id": "1009.5161", "contents": "Title: Information Physics: The New Frontier Abstract: At this point in time, two major areas of physics, statistical mechanics and\nquantum mechanics, rest on the foundations of probability and entropy. The last\ncentury saw several significant fundamental advances in our understanding of\nthe process of inference, which make it clear that these are inferential\ntheories. That is, rather than being a description of the behavior of the\nuniverse, these theories describe how observers can make optimal predictions\nabout the universe. In such a picture, information plays a critical role. What\nis more is that little clues, such as the fact that black holes have entropy,\ncontinue to suggest that information is fundamental to physics in general.\n  In the last decade, our fundamental understanding of probability theory has\nled to a Bayesian revolution. In addition, we have come to recognize that the\nfoundations go far deeper and that Cox's approach of generalizing a Boolean\nalgebra to a probability calculus is the first specific example of the more\nfundamental idea of assigning valuations to partially-ordered sets. By\nconsidering this as a natural way to introduce quantification to the more\nfundamental notion of ordering, one obtains an entirely new way of deriving\nphysical laws. I will introduce this new way of thinking by demonstrating how\none can quantify partially-ordered sets and, in the process, derive physical\nlaws. The implication is that physical law does not reflect the order in the\nuniverse, instead it is derived from the order imposed by our description of\nthe universe. Information physics, which is based on understanding the ways in\nwhich we both quantify and process information about the world around us, is a\nfundamentally new approach to science. \n\n"}
{"id": "1009.5944", "contents": "Title: Throughput-Optimal Random Access with Order-Optimal Delay Abstract: In this paper, we consider CSMA policies for scheduling of multihop wireless\nnetworks with one-hop traffic. The main contribution of this paper is to\npropose Unlocking CSMA (U-CSMA) policy that enables to obtain high throughput\nwith low (average) packet delay for large wireless networks. In particular, the\ndelay under U-CSMA policy becomes order-optimal. For one-hop traffic, delay is\ndefined to be order-optimal if it is O(1), i.e., it stays bounded, as the\nnetwork-size increases to infinity. Using mean field theory techniques, we\nanalytically show that for torus (grid-like) interference topologies with\none-hop traffic, to achieve a network load of $\\rho$, the delay under U-CSMA\npolicy becomes $O(1/(1-\\rho)^{3})$ as the network-size increases, and hence,\ndelay becomes order optimal. We conduct simulations for general random\ngeometric interference topologies under U-CSMA policy combined with congestion\ncontrol to maximize a network-wide utility. These simulations confirm that\norder optimality holds, and that we can use U-CSMA policy jointly with\ncongestion control to operate close to the optimal utility with a low packet\ndelay in arbitrarily large random geometric topologies. To the best of our\nknowledge, it is for the first time that a simple distributed scheduling policy\nis proposed that in addition to throughput/utility-optimality exhibits delay\norder-optimality. \n\n"}
{"id": "1009.5959", "contents": "Title: On the Optimal Compressions in the Compress-and-Forward Relay Schemes Abstract: ..... joint decoding provides more freedom in choosing the compression at the\nrelay.\n  However, the question remains whether this freedom of selecting the\ncompression necessarily improves the achievable rate of the original message.\nIt has been shown in (El Gamal and Kim, 2010) that the answer is negative in\nthe single-relay case. In this paper, it is further demonstrated that in the\ncase of multiple relays, there is no improvement on the achievable rate by\njoint decoding either. More interestingly, it is discovered that any\ncompressions not supporting successive decoding will actually lead to strictly\nlower achievable rates for the original message. Therefore, to maximize the\nachievable rate for the original message, the compressions should always be\nchosen to support successive decoding. Furthermore, it is shown that any\ncompressions not completely decodable even with joint decoding will not provide\nany contribution to the decoding of the original message.\n  The above phenomenon is also shown to exist under the repetitive encoding\nframework recently proposed by (Lim, Kim, El Gamal, and Chung, 2010), which\nimproved the achievable rate in the case of multiple relays. Here, another\ninteresting discovery is that the improvement is not a result of repetitive\nencoding, but the benefit of delayed decoding after all the blocks have been\nfinished. The same rate is shown to be achievable with the simpler classical\nencoding process of (Cover and El Gamal, 1979) with a block-by-block backward\ndecoding process. \n\n"}
{"id": "1010.0011", "contents": "Title: Deterministic Compressed Sensing Matrices from Additive Character\n  Sequences Abstract: Compressed sensing is a novel technique where one can recover sparse signals\nfrom the undersampled measurements. In this correspondence, a $K \\times N$\nmeasurement matrix for compressed sensing is deterministically constructed via\nadditive character sequences. The Weil bound is then used to show that the\nmatrix has asymptotically optimal coherence for $N=K^2$, and to present a\nsufficient condition on the sparsity level for unique sparse recovery. Also,\nthe restricted isometry property (RIP) is statistically studied for the\ndeterministic matrix. Using additive character sequences with small alphabets,\nthe compressed sensing matrix can be efficiently implemented by linear feedback\nshift registers. Numerical results show that the deterministic compressed\nsensing matrix guarantees reliable matching pursuit recovery performance for\nboth noiseless and noisy measurements. \n\n"}
{"id": "1010.0558", "contents": "Title: Analyzing Network Coding Gossip Made Easy Abstract: We give a new technique to analyze the stopping time of gossip protocols that\nare based on random linear network coding (RLNC). Our analysis drastically\nsimplifies, extends and strengthens previous results. We analyze RLNC gossip in\na general framework for network and communication models that encompasses and\nunifies the models used previously in this context. We show, in most settings\nfor the first time, that it converges with high probability in the\ninformation-theoretically optimal time. Most stopping times are of the form O(k\n+ T) where k is the number of messages to be distributed and T is the time it\ntakes to disseminate one message. This means RLNC gossip achieves \"perfect\npipelining\". Our analysis directly extends to highly dynamic networks in which\nthe topology can change completely at any time. This remains true even if the\nnetwork dynamics are controlled by a fully adaptive adversary that knows the\ncomplete network state. Virtually nothing besides simple O(kT) sequential\nflooding protocols was previously known for such a setting. While RLNC gossip\nworks in this wide variety of networks its analysis remains the same and\nextremely simple. This contrasts with more complex proofs that were put forward\nto give less strong results for various special cases. \n\n"}
{"id": "1010.0694", "contents": "Title: Statistical inference optimized with respect to the observed sample for\n  single or multiple comparisons Abstract: The normalized maximum likelihood (NML) is a recent penalized likelihood that\nhas properties that justify defining the amount of discrimination information\n(DI) in the data supporting an alternative hypothesis over a null hypothesis as\nthe logarithm of an NML ratio, namely, the alternative hypothesis NML divided\nby the null hypothesis NML. The resulting DI, like the Bayes factor but unlike\nthe p-value, measures the strength of evidence for an alternative hypothesis\nover a null hypothesis such that the probability of misleading evidence\nvanishes asymptotically under weak regularity conditions and such that evidence\ncan support a simple null hypothesis. Unlike the Bayes factor, the DI does not\nrequire a prior distribution and is minimax optimal in a sense that does not\ninvolve averaging over outcomes that did not occur. Replacing a (possibly\npseudo-) likelihood function with its weighted counterpart extends the scope of\nthe DI to models for which the unweighted NML is undefined. The likelihood\nweights leverage side information, either in data associated with comparisons\nother than the comparison at hand or in the parameter value of a simple null\nhypothesis. Two case studies, one involving multiple populations and the other\ninvolving multiple biological features, indicate that the DI is robust to the\ntype of side information used when that information is assigned the weight of a\nsingle observation. Such robustness suggests that very little adjustment for\nmultiple comparisons is warranted if the sample size is at least moderate. \n\n"}
{"id": "1010.0933", "contents": "Title: Interference Alignment with Limited Feedback on Two-cell Interfering\n  Two-User MIMO-MAC Abstract: In this paper, we consider a two-cell interfering two-user multiple-input\nmultiple-output multiple access channel (MIMO-MAC) with limited feedback. We\nfirst investigate the multiplexing gain of such channel when users have perfect\nchannel state information at transmitter (CSIT) by exploiting an interference\nalignment scheme. In addition, we propose a feedback framework for the\ninterference alignment in the limited feedback system. On the basis of the\nproposed feedback framework, we analyze the rate gap loss and it is shown that\nin order to keep the same multiplexing gain with the case of perfect CSIT, the\nnumber of feedback bits per receiver scales as $B \\geq\n(M\\!-1\\!)\\!\\log_{2}(\\textsf{SNR})+C$, where $M$ and $C$ denote the number of\ntransmit antennas and a constant, respectively. Throughout the simulation\nresults, it is shown that the sum-rate performance coincides with the derived\nresults. \n\n"}
{"id": "1010.0937", "contents": "Title: Signal Space Alignment for an Encryption Message and Successive Network\n  Code Decoding on the MIMO K-way Relay Channel Abstract: This paper investigates a network information flow problem for a\nmultiple-input multiple-output (MIMO) Gaussian wireless network with $K$-users\nand a single intermediate relay having $M$ antennas. In this network, each user\nintends to convey a multicast message to all other users while receiving $K-1$\nindependent messages from the other users via an intermediate relay. This\nnetwork information flow is termed a MIMO Gaussian $K$-way relay channel. For\nthis channel, we show that $\\frac{K}{2}$ degrees of freedom is achievable if\n$M=K-1$. To demonstrate this, we come up with an encoding and decoding strategy\ninspired from cryptography theory. The proposed encoding and decoding strategy\ninvolves a \\textit{signal space alignment for an encryption message} for the\nmultiple access phase (MAC) and \\textit{zero forcing with successive network\ncode decoding} for the broadcast (BC) phase. The idea of the \\emph{signal space\nalignment for an encryption message} is that all users cooperatively choose the\nprecoding vectors to transmit the message so that the relay can receive a\nproper encryption message with a special structure, \\textit{network code chain\nstructure}. During the BC phase, \\emph{zero forcing combined with successive\nnetwork code decoding} enables all users to decipher the encryption message\nfrom the relay despite the fact that they all have different self-information\nwhich they use as a key. \n\n"}
{"id": "1010.2067", "contents": "Title: Algorithmic Thermodynamics Abstract: Algorithmic entropy can be seen as a special case of entropy as studied in\nstatistical mechanics. This viewpoint allows us to apply many techniques\ndeveloped for use in thermodynamics to the subject of algorithmic information\ntheory. In particular, suppose we fix a universal prefix-free Turing machine\nand let X be the set of programs that halt for this machine. Then we can regard\nX as a set of 'microstates', and treat any function on X as an 'observable'.\nFor any collection of observables, we can study the Gibbs ensemble that\nmaximizes entropy subject to constraints on expected values of these\nobservables. We illustrate this by taking the log runtime, length, and output\nof a program as observables analogous to the energy E, volume V and number of\nmolecules N in a container of gas. The conjugate variables of these observables\nallow us to define quantities which we call the 'algorithmic temperature' T,\n'algorithmic pressure' P and algorithmic potential' mu, since they are\nanalogous to the temperature, pressure and chemical potential. We derive an\nanalogue of the fundamental thermodynamic relation dE = T dS - P d V + mu dN,\nand use it to study thermodynamic cycles analogous to those for heat engines.\nWe also investigate the values of T, P and mu for which the partition function\nconverges. At some points on the boundary of this domain of convergence, the\npartition function becomes uncomputable. Indeed, at these points the partition\nfunction itself has nontrivial algorithmic entropy. \n\n"}
{"id": "1010.2787", "contents": "Title: Interference Alignment with Analog Channel State Feedback Abstract: Interference alignment (IA) is a multiplexing gain optimal transmission\nstrategy for the interference channel. While the achieved sum rate with IA is\nmuch higher than previously thought possible, the improvement often comes at\nthe cost of requiring network channel state information at the transmitters.\nThis can be achieved by explicit feedback, a flexible yet potentially costly\napproach that incurs large overhead. In this paper we propose analog feedback\nas an alternative to limited feedback or reciprocity based alignment. We show\nthat the full multiplexing gain observed with perfect channel knowledge is\npreserved by analog feedback and that the mean loss in sum rate is bounded by a\nconstant when signal-to-noise ratio is comparable in both forward and feedback\nchannels. When signal-to-noise ratios are not quite symmetric, a fraction of\nthe multiplexing gain is achieved. We consider the overhead of training and\nfeedback and use this framework to optimize the system's effective throughput.\nWe present simulation results to demonstrate the performance of IA with analog\nfeedback, verify our theoretical analysis, and extend our conclusions on\noptimal training and feedback length. \n\n"}
{"id": "1010.4751", "contents": "Title: Sparse coding and dictionary learning based on the MDL principle Abstract: The power of sparse signal coding with learned dictionaries has been\ndemonstrated in a variety of applications and fields, from signal processing to\nstatistical inference and machine learning. However, the statistical properties\nof these models, such as underfitting or overfitting given sets of data, are\nstill not well characterized in the literature. This work aims at filling this\ngap by means of the Minimum Description Length (MDL) principle -- a well\nestablished information-theoretic approach to statistical inference. The\nresulting framework derives a family of efficient sparse coding and modeling\n(dictionary learning) algorithms, which by virtue of the MDL principle, are\ncompletely parameter free. Furthermore, such framework allows to incorporate\nadditional prior information in the model, such as Markovian dependencies, in a\nnatural way. We demonstrate the performance of the proposed framework with\nresults for image denoising and classification tasks. \n\n"}
{"id": "1010.5720", "contents": "Title: Information-theoretic inference of common ancestors Abstract: A directed acyclic graph (DAG) partially represents the conditional\nindependence structure among observations of a system if the local Markov\ncondition holds, that is, if every variable is independent of its\nnon-descendants given its parents. In general, there is a whole class of DAGs\nthat represents a given set of conditional independence relations. We are\ninterested in properties of this class that can be derived from observations of\na subsystem only. To this end, we prove an information theoretic inequality\nthat allows for the inference of common ancestors of observed parts in any DAG\nrepresenting some unknown larger system. More explicitly, we show that a large\namount of dependence in terms of mutual information among the observations\nimplies the existence of a common ancestor that distributes this information.\nWithin the causal interpretation of DAGs our result can be seen as a\nquantitative extension of Reichenbach's Principle of Common Cause to more than\ntwo variables. Our conclusions are valid also for non-probabilistic\nobservations such as binary strings, since we state the proof for an\naxiomatized notion of mutual information that includes the stochastic as well\nas the algorithmic version. \n\n"}
{"id": "1011.1503", "contents": "Title: Quantization using Compressive Sensing Abstract: The problem of compressing a real-valued sparse source using compressive\nsensing techniques is studied. The rate distortion optimality of a coding\nscheme in which compressively sensed signals are quantized and then\nreconstructed is established when the reconstruction is also required to be\nsparse. The result holds in general when the distortion constraint is on the\nexpected $p$-norm of error between the source and the reconstruction. A new\nrestricted isometry like property is introduced for this purpose and the\nexistence of matrices that satisfy this property is shown. \n\n"}
{"id": "1011.6326", "contents": "Title: New Null Space Results and Recovery Thresholds for Matrix Rank\n  Minimization Abstract: Nuclear norm minimization (NNM) has recently gained significant attention for\nits use in rank minimization problems. Similar to compressed sensing, using\nnull space characterizations, recovery thresholds for NNM have been studied in\n\\cite{arxiv,Recht_Xu_Hassibi}. However simulations show that the thresholds are\nfar from optimal, especially in the low rank region. In this paper we apply the\nrecent analysis of Stojnic for compressed sensing \\cite{mihailo} to the null\nspace conditions of NNM. The resulting thresholds are significantly better and\nin particular our weak threshold appears to match with simulation results.\nFurther our curves suggest for any rank growing linearly with matrix size $n$\nwe need only three times of oversampling (the model complexity) for weak\nrecovery. Similar to \\cite{arxiv} we analyze the conditions for weak, sectional\nand strong thresholds. Additionally a separate analysis is given for special\ncase of positive semidefinite matrices. We conclude by discussing simulation\nresults and future research directions. \n\n"}
{"id": "1012.0416", "contents": "Title: Compress-and-Forward Scheme for Relay Networks: Backword Decoding and\n  Connection to Bisubmodular Flows Abstract: In this paper, a compress-and-forward scheme with backward decoding is\npresented for the unicast wireless relay network. The encoding at the source\nand relay is a generalization of the noisy network coding scheme (NNC). While\nit achieves the same reliable data rate as noisy network coding scheme, the\nbackward decoding allows for a better decoding complexity as compared to the\njoint decoding of the NNC scheme. Characterizing the layered decoding scheme is\nshown to be equivalent to characterizing an information flow for the wireless\nnetwork. A node-flow for a graph with bisubmodular capacity constraints is\npresented and a max-flow min-cut theorem is proved for it. This generalizes\nmany well-known results of flows over capacity constrained graphs studied in\ncomputer science literature. The results for the unicast relay network are\ngeneralized to the network with multiple sources with independent messages\nintended for a single destination. \n\n"}
{"id": "1012.4161", "contents": "Title: Lattice Code Design for the Rayleigh Fading Wiretap Channel Abstract: It has been shown recently that coding for the Gaussian Wiretap Channel can\nbe done with nested lattices. A fine lattice intended to the legitimate user\nmust be designed as a usual lattice code for the Gaussian Channel, while a\ncoarse lattice is added to introduce confusion at the eavesdropper, whose theta\nseries must be minimized. We present a design criterion for both the fine and\ncoarse lattice to obtain wiretap lattice codes for the Rayleigh fading Wiretap\nChannel. \n\n"}
{"id": "1101.3068", "contents": "Title: Degrees of Freedom Region for an Interference Network with General\n  Message Demands Abstract: We consider a single hop interference network with $K$ transmitters and $J$\nreceivers, all having $M$ antennas. Each transmitter emits an independent\nmessage and each receiver requests an arbitrary subset of the messages. This\ngeneralizes the well-known $K$-user $M$-antenna interference channel, where\neach message is requested by a unique receiver. For our setup, we derive the\ndegrees of freedom (DoF) region. The achievability scheme generalizes the\ninterference alignment schemes proposed by Cadambe and Jafar. In particular, we\nachieve general points in the DoF region by using multiple base vectors and\naligning all interferers at a given receiver to the interferer with the largest\nDoF. As a byproduct, we obtain the DoF region for the original interference\nchannel. We also discuss extensions of our approach where the same region can\nbe achieved by considering a reduced set of interference alignment constraints,\nthus reducing the time-expansion duration needed. The DoF region for the\nconsidered system depends only on a subset of receivers whose demands meet\ncertain characteristics. The geometric shape of the DoF region is also\ndiscussed. \n\n"}
{"id": "1101.3348", "contents": "Title: Structured sublinear compressive sensing via belief propagation Abstract: Compressive sensing (CS) is a sampling technique designed for reducing the\ncomplexity of sparse data acquisition. One of the major obstacles for practical\ndeployment of CS techniques is the signal reconstruction time and the high\nstorage cost of random sensing matrices. We propose a new structured\ncompressive sensing scheme, based on codes of graphs, that allows for a joint\ndesign of structured sensing matrices and logarithmic-complexity reconstruction\nalgorithms. The compressive sensing matrices can be shown to offer\nasymptotically optimal performance when used in combination with Orthogonal\nMatching Pursuit (OMP) methods. For more elaborate greedy reconstruction\nschemes, we propose a new family of list decoding belief propagation\nalgorithms, as well as reinforced- and multiple-basis belief propagation\nalgorithms. Our simulation results indicate that reinforced BP CS schemes offer\nvery good complexity-performance tradeoffs for very sparse signal vectors. \n\n"}
{"id": "1101.5108", "contents": "Title: Causal Dependence Tree Approximations of Joint Distributions for\n  Multiple Random Processes Abstract: We investigate approximating joint distributions of random processes with\ncausal dependence tree distributions. Such distributions are particularly\nuseful in providing parsimonious representation when there exists causal\ndynamics among processes. By extending the results by Chow and Liu on\ndependence tree approximations, we show that the best causal dependence tree\napproximation is the one which maximizes the sum of directed informations on\nits edges, where best is defined in terms of minimizing the KL-divergence\nbetween the original and the approximate distribution. Moreover, we describe a\nlow-complexity algorithm to efficiently pick this approximate distribution. \n\n"}
{"id": "1102.0040", "contents": "Title: On the Zero-Error Capacity Threshold for Deletion Channels Abstract: We consider the zero-error capacity of deletion channels. Specifically, we\nconsider the setting where we choose a codebook ${\\cal C}$ consisting of\nstrings of $n$ bits, and our model of the channel corresponds to an adversary\nwho may delete up to $pn$ of these bits for a constant $p$. Our goal is to\ndecode correctly without error regardless of the actions of the adversary. We\nconsider what values of $p$ allow non-zero capacity in this setting. We suggest\nmultiple approaches, one of which makes use of the natural connection between\nthis problem and the problem of finding the expected length of the longest\ncommon subsequence of two random sequences. \n\n"}
{"id": "1102.0267", "contents": "Title: The Capacity Region of the MIMO Interference Channel and its Reciprocity\n  to Within a Constant Gap Abstract: The capacity region of the 2-user multi-input multi-output (MIMO) Gaussian\ninterference channel (IC) is characterized to within a constant gap that is\nindependent of the channel matrices for the general case of the MIMO IC with an\narbitrary number of antennas at each node. An achievable rate region and an\nouter bound to the capacity region of a class of interference channels were\nobtained in previous work by Telatar and Tse as unions over all possible input\ndistributions. In contrast to that previous work on the MIMO IC, a simple and\nan explicit achievable coding scheme are obtained here and shown to have the\nconstant-gap-to-capacity property and in which the sub-rates of the common and\nprivate messages of each user are explicitly specified for each achievable rate\npair. The constant-gap-to-capacity results are thus proved in this work by\nfirst establishing explicit upper and lower bounds to the capacity region. A\nreciprocity result is also proved which is that the capacity of the reciprocal\nMIMO IC is within a constant gap of the capacity region of the forward MIMO IC. \n\n"}
{"id": "1102.3298", "contents": "Title: A family of fast-decodable MIDO codes from crossed-product algebras over\n  Q Abstract: Multiple Input Double Output (MIDO) asymmetric space-time codes for 4\ntransmit antennas and 2 receive antennas can be employed in the downlink from\nbase stations to portable devices. Previous MIDO code constructions with low\nMaximum Likelihood (ML) decoding complexity, full diversity and the\nnon-vanishing determinant (NVD) property are mostly based on cyclic division\nalgebras. In this paper, a new family of MIDO codes with the NVD property based\non crossed-product algebras over Q is introduced. Fast decodability follows\nnaturally from the structure of the codewords which consist of four generalized\nAlamouti blocks. The associated ML complexity order is the lowest known for\nfull-rate MIDO codes (O(M^{10}) instead of O(M^{16}) with respect to the real\nconstellation size M). Numerical simulations show that these codes have a\nperformance from comparable up to 1dB gain compared to the best known MIDO code\nwith the same complexity. \n\n"}
{"id": "1102.3833", "contents": "Title: Aligned Interference Neutralization and the Degrees of Freedom of the 2\n  User Interference Channel with Instantaneous Relay Abstract: It is well known that the classical 2 user Gaussian interference channel has\nonly 1 degree of freedom (DoF), which can be achieved by orthogonal time\ndivision among the 2 users. It is also known that the use of conventional\nrelays, which introduce a processing delay of at least one symbol duration\nrelative to the direct paths between sources and destinations, does not\nincrease the DoF of the 2 user interference channel. The use of instantaneous\nrelays (relays-without-delay) has been explored for the single user\npoint-to-point setting and it is known that such a relay, even with memoryless\nforwarding at the relay, can achieve a higher capacity than conventional\nrelays. In this work, we show that the 2 user interference channel with an\ninstantaneous relay, achieves 3/2 DoF. Thus, an instantaneous relay increases\nnot only the capacity but also the DoF of the 2 user interference channel. The\nachievable scheme is inspired by the aligned interference neutralization scheme\nrecently proposed for the 2X2X2 interference channel. Remarkably the DoF gain\nis achieved with memoryless relays, i.e., with relays that have no memory of\npast received symbols. \n\n"}
{"id": "1102.3902", "contents": "Title: Polytope of Correct (Linear Programming) Decoding and Low-Weight\n  Pseudo-Codewords Abstract: We analyze Linear Programming (LP) decoding of graphical binary codes\noperating over soft-output, symmetric and log-concave channels. We show that\nthe error-surface, separating domain of the correct decoding from domain of the\nerroneous decoding, is a polytope. We formulate the problem of finding the\nlowest-weight pseudo-codeword as a non-convex optimization (maximization of a\nconvex function) over a polytope, with the cost function defined by the channel\nand the polytope defined by the structure of the code. This formulation\nsuggests new provably convergent heuristics for finding the lowest weight\npseudo-codewords improving in quality upon previously discussed. The algorithm\nperformance is tested on the example of the Tanner [155, 64, 20] code over the\nAdditive White Gaussian Noise (AWGN) channel. \n\n"}
{"id": "1102.4411", "contents": "Title: The AWGN Red Alert Problem Abstract: Consider the following unequal error protection scenario. One special\nmessage, dubbed the \"red alert\" message, is required to have an extremely small\nprobability of missed detection. The remainder of the messages must keep their\naverage probability of error and probability of false alarm below a certain\nthreshold. The goal then is to design a codebook that maximizes the error\nexponent of the red alert message while ensuring that the average probability\nof error and probability of false alarm go to zero as the blocklength goes to\ninfinity. This red alert exponent has previously been characterized for\ndiscrete memoryless channels. This paper completely characterizes the optimal\nred alert exponent for additive white Gaussian noise channels with block power\nconstraints. \n\n"}
{"id": "1103.0795", "contents": "Title: Decimation-Enhanced Finite Alphabet Iterative Decoders for LDPC codes on\n  the BSC Abstract: Finite alphabet iterative decoders (FAID) with multilevel messages that can\nsurpass BP in the error floor region for LDPC codes on the BSC were previously\nproposed. In this paper, we propose decimation-enhanced decoders. The technique\nof decimation which is incorporated into the message update rule, involves\nfixing certain bits of the code to a particular value. Under appropriately\nchosen rules, decimation can significantly reduce the number of iterations\nrequired to correct a fixed number of errors, while maintaining the good\nperformance of the original decoder in the error floor region. At the same\ntime, the algorithm is much more amenable to analysis. We shall provide a\nsimple decimation scheme for a particularly good 7-level FAID for column-weight\nthree codes on the BSC, that helps to correct a fixed number of errors in fewer\niterations, and provide insights into the analysis of the decoder. We shall\nalso examine the conditions under which the decimation-enhanced 7-level FAID\nperforms at least as good as the 7-level FAID. \n\n"}
{"id": "1103.0967", "contents": "Title: Intensionality and Two-steps Interpretations Abstract: In this paper we considered the extension of the First-order Logic (FOL) by\nBealer's intensional abstraction operator. Contemporary use of the term\n'intension' derives from the traditional logical Frege-Russell's doctrine that\nan idea (logic formula) has both an extension and an intension. Although there\nis divergence in formulation, it is accepted that the extension of an idea\nconsists of the subjects to which the idea applies, and the intension consists\nof the attributes implied by the idea. From the Montague's point of view, the\nmeaning of an idea can be considered as particular extensions in different\npossible worlds. In the case of the pure FOL we obtain commutative homomorphic\ndiagram that holds in each given possible world of the intensional FOL, from\nthe free algebra of the FOL syntax, toward its intensional algebra of concepts,\nand, successively, to the new extensional relational algebra (different from\nCylindric algebras). Then we show that it corresponds to the Tarski's\ninterpretation of the standard extensional FOL in this possible world. \n\n"}
{"id": "1103.2469", "contents": "Title: Blind Compressed Sensing Over a Structured Union of Subspaces Abstract: This paper addresses the problem of simultaneous signal recovery and\ndictionary learning based on compressive measurements. Multiple signals are\nanalyzed jointly, with multiple sensing matrices, under the assumption that the\nunknown signals come from a union of a small number of disjoint subspaces. This\nproblem is important, for instance, in image inpainting applications, in which\nthe multiple signals are constituted by (incomplete) image patches taken from\nthe overall image. This work extends standard dictionary learning and\nblock-sparse dictionary optimization, by considering compressive measurements,\ne.g., incomplete data). Previous work on blind compressed sensing is also\ngeneralized by using multiple sensing matrices and relaxing some of the\nrestrictions on the learned dictionary. Drawing on results developed in the\ncontext of matrix completion, it is proven that both the dictionary and signals\ncan be recovered with high probability from compressed measurements. The\nsolution is unique up to block permutations and invertible linear\ntransformations of the dictionary atoms. The recovery is contingent on the\nnumber of measurements per signal and the number of signals being sufficiently\nlarge; bounds are derived for these quantities. In addition, this paper\npresents a computationally practical algorithm that performs dictionary\nlearning and signal recovery, and establishes conditions for its convergence to\na local optimum. Experimental results for image inpainting demonstrate the\ncapabilities of the method. \n\n"}
{"id": "1103.4007", "contents": "Title: Multiple Access Channel with Partial and Controlled Cribbing Encoders Abstract: In this paper we consider a multiple access channel (MAC) with partial\ncribbing encoders. This means that each of two encoders obtains a deterministic\nfunction of the other encoder output with or without delay. The partial\ncribbing scheme is especially motivated by the additive noise Gaussian MAC\nsince perfect cribbing results in the degenerated case of full cooperation\nbetween the encoders and requires an infinite entropy link. We derive a single\nletter characterization of the capacity of the MAC with partial cribbing for\nthe cases of causal and strictly causal partial cribbing. Several numerical\nexamples, such as quantized cribbing, are presented. We further consider and\nderive the capacity region where the cribbing depends on actions that are\nfunctions of the previous cribbed observations. In particular, we consider a\nscenario where the action is \"to crib or not to crib\" and show that a naive\ntime-sharing strategy is not optimal. \n\n"}
{"id": "1103.4401", "contents": "Title: On the gradual deployment of random pairwise key distribution schemes\n  (Extended Version) Abstract: In the context of wireless sensor networks, the pairwise key distribution\nscheme of Chan et al. has several advantages over other key distribution\nschemes including the original scheme of Eschenauer and Gligor. However, this\noffline pairwise key distribution mechanism requires that the network size be\nset in advance, and involves all sensor nodes simultaneously. Here, we address\nthis issue by describing an implementation of the pairwise scheme that supports\nthe gradual deployment of sensor nodes in several consecutive phases. We\ndiscuss the key ring size needed to maintain the secure connectivity throughout\nall the deployment phases. In particular we show that the number of keys at\neach sensor node can be taken to be $O(\\log n)$ in order to achieve secure\nconnectivity (with high probability). \n\n"}
{"id": "1103.4406", "contents": "Title: Interference Alignment with Partially Coordinated Transmit Precoding Abstract: In this paper, we introduce an efficient interference alignment (IA)\nalgorithm exploiting partially coordinated transmit precoding to improve the\nnumber of concurrent interference-free transmissions, i.e., the multiplexing\ngain, in multicell downlink. The proposed coordination model is such that each\nbase-station simultaneously transmits to two users and each user is served by\ntwo base-stations. First, we show in a K-user system operating at the\ninformation theoretic upper bound of degrees of freedom (DOF), the generic IA\nis proper when $K \\leq 3$, whereas the proposed partially coordinated IA is\nproper when $K \\leq 5$. Then, we derive a non-iterative, i.e., one shot, IA\nalgorithm for the proposed scheme when $K \\leq 5$. We show that for a given\nlatency, the backhaul data rate requirement of the proposed method grows\nlinearly with K. Monte-Carlo simulation results show that the proposed one-shot\nalgorithm offers higher system throughput than the iterative IA at practical\nSNR levels. \n\n"}
{"id": "1104.0576", "contents": "Title: Adaptive Single-Trial Error/Erasure Decoding of Reed-Solomon Codes Abstract: Algebraic decoding algorithms are commonly applied for the decoding of\nReed-Solomon codes. Their main advantages are low computational complexity and\npredictable decoding capabilities. Many algorithms can be extended for\ncorrection of both errors and erasures. This enables the decoder to exploit\nbinary quantized reliability information obtained from the transmission\nchannel: Received symbols with high reliability are forwarded to the decoding\nalgorithm while symbols with low reliability are erased. In this paper we\ninvestigate adaptive single-trial error/erasure decoding of Reed-Solomon codes,\ni.e. we derive an adaptive erasing strategy which minimizes the residual\ncodeword error probability after decoding. Our result is applicable to any\nerror/erasure decoding algorithm as long as its decoding capabilities can be\nexpressed by a decoder capability function. Examples are Bounded Minimum\nDistance decoding with the Berlekamp-Massey- or the Sugiyama algorithms and the\nGuruswami-Sudan list decoder. \n\n"}
{"id": "1104.0862", "contents": "Title: Causal Rate Distortion Function and Relations to Filtering Theory Abstract: A causal rate distortion function is defined, its solution is described, and\nits relation to filtering theory is discussed. The relation to filtering is\nobtained via a causal constraint imposed on the reconstruction kernel to be\nrealizable. \n\n"}
{"id": "1104.1057", "contents": "Title: Bounds on the Capacity of the Relay Channel with Noncausal State at\n  Source Abstract: We consider a three-terminal state-dependent relay channel with the channel\nstate available non-causally at only the source. Such a model may be of\ninterest for node cooperation in the framework of cognition, i.e.,\ncollaborative signal transmission involving cognitive and non-cognitive radios.\nWe study the capacity of this communication model. One principal problem is\ncaused by the relay's not knowing the channel state. For the discrete\nmemoryless (DM) model, we establish two lower bounds and an upper bound on\nchannel capacity. The first lower bound is obtained by a coding scheme in which\nthe source describes the state of the channel to the relay and destination,\nwhich then exploit the gained description for a better communication of the\nsource's information message. The coding scheme for the second lower bound\nremedies the relay's not knowing the states of the channel by first computing,\nat the source, the appropriate input that the relay would send had the relay\nknown the states of the channel, and then transmitting this appropriate input\nto the relay. The relay simply guesses the sent input and sends it in the next\nblock. The upper bound is non trivial and it accounts for not knowing the state\nat the relay and destination. For the general Gaussian model, we derive lower\nbounds on the channel capacity by exploiting ideas in the spirit of those we\nuse for the DM model; and we show that these bounds are optimal for small and\nlarge noise at the relay irrespective to the strength of the interference.\nFurthermore, we also consider a special case model in which the source input\nhas two components one of which is independent of the state. We establish a\nbetter upper bound for both DM and Gaussian cases and we also characterize the\ncapacity in a number of special cases. \n\n"}
{"id": "1104.5246", "contents": "Title: How well can we estimate a sparse vector? Abstract: The estimation of a sparse vector in the linear model is a fundamental\nproblem in signal processing, statistics, and compressive sensing. This paper\nestablishes a lower bound on the mean-squared error, which holds regardless of\nthe sensing/design matrix being used and regardless of the estimation\nprocedure. This lower bound very nearly matches the known upper bound one gets\nby taking a random projection of the sparse vector followed by an $\\ell_1$\nestimation procedure such as the Dantzig selector. In this sense, compressive\nsensing techniques cannot essentially be improved. \n\n"}
{"id": "1104.5546", "contents": "Title: Optimal coding for the deletion channel with small deletion probability Abstract: The deletion channel is the simplest point-to-point communication channel\nthat models lack of synchronization. Input bits are deleted independently with\nprobability d, and when they are not deleted, they are not affected by the\nchannel. Despite significant effort, little is known about the capacity of this\nchannel, and even less about optimal coding schemes. In this paper we develop a\nnew systematic approach to this problem, by demonstrating that capacity can be\ncomputed in a series expansion for small deletion probability. We compute three\nleading terms of this expansion, and find an input distribution that achieves\ncapacity up to this order. This constitutes the first optimal coding result for\nthe deletion channel.\n  The key idea employed is the following: We understand perfectly the deletion\nchannel with deletion probability d=0. It has capacity 1 and the optimal input\ndistribution is i.i.d. Bernoulli(1/2). It is natural to expect that the channel\nwith small deletion probabilities has a capacity that varies smoothly with d,\nand that the optimal input distribution is obtained by smoothly perturbing the\ni.i.d. Bernoulli(1/2) process. Our results show that this is indeed the case.\nWe think that this general strategy can be useful in a number of capacity\ncalculations. \n\n"}
{"id": "1105.2017", "contents": "Title: Potential Games for Energy-Efficient Resource Allocation in\n  Multipoint-to-Multipoint CDMA Wireless Data Networks Abstract: The problem of noncooperative resource allocation in a\nmultipoint-to-multipoint cellular network is considered in this paper. The\nconsidered scenario is general enough to represent several key instances of\nmodern wireless networks such as a multicellular network, a peer-to-peer\nnetwork (interference channel), and a wireless network equipped with\nfemtocells. In particular, the problem of joint transmit waveforms adaptation,\nlinear receiver design, and transmit power control is examined. Several utility\nfunctions to be maximized are considered, and, among them, we cite the received\nSINR, and the transmitter energy efficiency, which is measured in bit/Joule,\nand represents the number of successfully delivered bits for each energy unit\nused for transmission. Resorting to the theory of potential games,\nnoncooperative games admitting Nash equilibria in multipoint-to-multipoint\ncellular networks regardless of the channel coefficient realizations are\ndesigned. Computer simulations confirm that the considered games are\nconvergent, and show the huge benefits that resource allocation schemes can\nbring to the performance of wireless data networks. \n\n"}
{"id": "1105.3531", "contents": "Title: On the Tradeoff Between Multiuser Diversity and Training Overhead in\n  Multiple Access Channels Abstract: We consider a single antenna narrowband multiple access channel in which\nusers send training sequences to the base station and scheduling is performed\nbased on minimum mean square error (MMSE) channel estimates. In such a system,\nthere is an inherent tradeoff between training overhead and the amount of\nmultiuser diversity achieved. We analyze a block fading channel with\nindependent Rayleigh distributed channel gains, where the parameters to be\noptimized are the number of users considered for transmission in each block and\nthe corresponding time and power spent on training by each user. We derive\nclosed form expressions for the optimal parameters in terms K and L, where K is\nthe number of users considered for transmission in each block and L is the\nblock length in symbols. Considering the behavior of the system as L grows\nlarge, we optimize K with respect to an approximate expression for the\nachievable rate, and obtain second order expressions for the resulting\nparameters in terms of L. \n\n"}
{"id": "1105.5419", "contents": "Title: Strong Secrecy from Channel Resolvability Abstract: We analyze physical-layer security based on the premise that the coding\nmechanism for secrecy over noisy channels is tied to the notion of channel\nresolvability. Instead of considering capacity-based constructions, which\nassociate to each message a sub-code that operates just below the capacity of\nthe eavesdropper's channel, we consider channel-resolvability-based\nconstructions, which associate to each message a sub-code that operates just\nabove the resolvability of the eavesdropper's channel. Building upon the work\nof Csiszar and Hayashi, we provide further evidence that channel resolvability\nis a powerful and versatile coding mechanism for secrecy by developing results\nthat hold for strong secrecy metrics and arbitrary channels.\n  Specifically, we show that at least for symmetric wiretap channels, random\ncapacity-based constructions fail to achieve the strong secrecy capacity while\nchannel-resolvability-based constructions achieve it. We then leverage channel\nresolvability to establish the secrecy-capacity region of arbitrary broadcast\nchannels with confidential messages and a cost constraint for strong secrecy\nmetrics. Finally, we specialize our results to study the secrecy capacity of\nwireless channels with perfect channel state information, mixed channels and\ncompound channels with receiver Channel State Information (CSI), as well as the\nsecret-key capacity of source models for secret-key agreement. By tying secrecy\nto channel resolvability, we obtain achievable rates for strong secrecy metrics\nwith simple proofs. \n\n"}
{"id": "1106.0061", "contents": "Title: Error Probability Bounds for Binary Relay Trees with Crummy Sensors Abstract: We study the detection error probability associated with balanced binary\nrelay trees, in which sensor nodes fail with some probability. We consider N\nidentical and independent crummy sensors, represented by leaf nodes of the\ntree. The root of the tree represents the fusion center, which makes the final\ndecision between two hypotheses. Every other node is a relay node, which fuses\nat most two binary messages into one binary message and forwards the new\nmessage to its parent node. We derive tight upper and lower bounds for the\ntotal error probability at the fusion center as functions of N and characterize\nhow fast the total error probability converges to 0 with respect to N. We show\nthat the convergence of the total error probability is sub-linear, with the\nsame decay exponent as that in a balanced binary relay tree without sensor\nfailures. We also show that the total error probability converges to 0, even if\nthe individual sensors have total error probabilities that converge to 1/2 and\nthe failure probabilities that converge to 1, provided that the convergence\nrates are sufficiently slow. \n\n"}
{"id": "1106.2428", "contents": "Title: On the classification of Hermitian self-dual additive codes over GF(9) Abstract: Additive codes over GF(9) that are self-dual with respect to the Hermitian\ntrace inner product have a natural application in quantum information theory,\nwhere they correspond to ternary quantum error-correcting codes. However, these\ncodes have so far received far less interest from coding theorists than\nself-dual additive codes over GF(4), which correspond to binary quantum codes.\nSelf-dual additive codes over GF(9) have been classified up to length 8, and in\nthis paper we extend the complete classification to codes of length 9 and 10.\nThe classification is obtained by using a new algorithm that combines two graph\nrepresentations of self-dual additive codes. The search space is first reduced\nby the fact that every code can be mapped to a weighted graph, and a different\ngraph is then introduced that transforms the problem of code equivalence into a\nproblem of graph isomorphism. By an extension technique, we are able to\nclassify all optimal codes of length 11 and 12. There are 56,005,876\n(11,3^11,5) codes and 6493 (12,3^12,6) codes. We also find the smallest codes\nwith trivial automorphism group. \n\n"}
{"id": "1106.5367", "contents": "Title: Partial Interference Alignment for K-user MIMO Interference Channels Abstract: In this paper, we consider a Partial Interference Alignment and Interference\nDetection (PIAID) design for $K$-user quasi-static MIMO interference channels\nwith discrete constellation inputs. Each transmitter has M antennas and\ntransmits L independent data streams to the desired receiver with N receive\nantennas. We focus on the case where not all K-1 interfering transmitters can\nbe aligned at every receiver. As a result, there will be residual interference\nat each receiver that cannot be aligned. Each receiver detects and cancels the\nresidual interference based on the constellation map. However, there is a\nwindow of unfavorable interference profile at the receiver for Interference\nDetection (ID). In this paper, we propose a low complexity Partial Interference\nAlignment scheme in which we dynamically select the user set for IA so as to\ncreate a favorable interference profile for ID at each receiver. We first\nderive the average symbol error rate (SER) by taking into account of the\nnon-Guassian residual interference due to discrete constellation. Using graph\ntheory, we then devise a low complexity user set selection algorithm for the\nPIAID scheme,which minimizes the asymptotically tight bound for the average\nend-to-end SER performance. Moreover, we substantially simplify interference\ndetection at the receiver using Semi-Definite Relaxation (SDR) techniques. It\nis shown that the SER performance of the proposed PIAID scheme has significant\ngain compared with various conventional baseline solutions. \n\n"}
{"id": "1106.5683", "contents": "Title: Distributed Interference Alignment with Low Overhead Abstract: Based on closed-form interference alignment (IA) solutions, a low overhead\ndistributed interference alignment (LOIA) scheme is proposed in this paper for\nthe $K$-user SISO interference channel, and extension to multiple antenna\nscenario is also considered. Compared with the iterative interference alignment\n(IIA) algorithm proposed by Gomadam et al., the overhead is greatly reduced.\nSimulation results show that the IIA algorithm is strictly suboptimal compared\nwith our LOIA algorithm in the overhead-limited scenario. \n\n"}
{"id": "1106.5825", "contents": "Title: Fundamentals of Inter-cell Overhead Signaling in Heterogeneous Cellular\n  Networks Abstract: Heterogeneous base stations (e.g. picocells, microcells, femtocells and\ndistributed antennas) will become increasingly essential for cellular network\ncapacity and coverage. Up until now, little basic research has been done on the\nfundamentals of managing so much infrastructure -- much of it unplanned --\ntogether with the carefully planned macro-cellular network. Inter-cell\ncoordination is in principle an effective way of ensuring different\ninfrastructure components behave in a way that increases, rather than\ndecreases, the key quality of service (QoS) metrics. The success of such\ncoordination depends heavily on how the overhead is shared, and the rate and\ndelay of the overhead sharing. We develop a novel framework to quantify\noverhead signaling for inter-cell coordination, which is usually ignored in\ntraditional 1-tier networks, and assumes even more importance in multi-tier\nheterogeneous cellular networks (HCNs). We derive the overhead quality contour\nfor general K-tier HCNs -- the achievable set of overhead packet rate, size,\ndelay and outage probability -- in closed-form expressions or computable\nintegrals under general assumptions on overhead arrivals and different overhead\nsignaling methods (backhaul and/or wireless). The overhead quality contour is\nfurther simplified for two widely used models of overhead arrivals: Poisson and\ndeterministic arrival process. This framework can be used in the design and\nevaluation of any inter-cell coordination scheme. It also provides design\ninsights on backhaul and wireless overhead channels to handle specific overhead\nsignaling requirements. \n\n"}
{"id": "1106.5930", "contents": "Title: An Algorithm for Classification of Binary Self-Dual Codes Abstract: An efficient algorithm for classification of binary self-dual codes is\npresented. As an application, a complete classification of the self-dual codes\nof length 38 is given. \n\n"}
{"id": "1107.2972", "contents": "Title: An MCMC Approach to Universal Lossy Compression of Analog Sources Abstract: Motivated by the Markov chain Monte Carlo (MCMC) approach to the compression\nof discrete sources developed by Jalali and Weissman, we propose a lossy\ncompression algorithm for analog sources that relies on a finite reproduction\nalphabet, which grows with the input length. The algorithm achieves, in an\nappropriate asymptotic sense, the optimum Shannon theoretic tradeoff between\nrate and distortion, universally for stationary ergodic continuous amplitude\nsources. We further propose an MCMC-based algorithm that resorts to a reduced\nreproduction alphabet when such reduction does not prevent achieving the\nShannon limit. The latter algorithm is advantageous due to its reduced\ncomplexity and improved rates of convergence when employed on sources with a\nfinite and small optimum reproduction alphabet. \n\n"}
{"id": "1107.4623", "contents": "Title: A Unifying Analysis of Projected Gradient Descent for\n  $\\ell_p$-constrained Least Squares Abstract: In this paper we study the performance of the Projected Gradient Descent(PGD)\nalgorithm for $\\ell_{p}$-constrained least squares problems that arise in the\nframework of Compressed Sensing. Relying on the Restricted Isometry Property,\nwe provide convergence guarantees for this algorithm for the entire range of\n$0\\leq p\\leq1$, that include and generalize the existing results for the\nIterative Hard Thresholding algorithm and provide a new accuracy guarantee for\nthe Iterative Soft Thresholding algorithm as special cases. Our results suggest\nthat in this group of algorithms, as $p$ increases from zero to one, conditions\nrequired to guarantee accuracy become stricter and robustness to noise\ndeteriorates. \n\n"}
{"id": "1108.1421", "contents": "Title: On the Secrecy Degrees of Freedom of Multi-Antenna Wiretap Channels with\n  Delayed CSIT Abstract: The secrecy degrees of freedom (SDoF) of the Gaussian multiple-input and\nsingle-output (MISO) wiretap channel is studied under the assumption that\ndelayed channel state information (CSI) is available at the transmitter and\neach receiver knows its own instantaneous channel. We first show that a\nstrictly positive SDoF can be guaranteed whenever the transmitter has delayed\nCSI (either on the legitimate channel or/and the eavesdropper channel). In\nparticular, in the case with delayed CSI on both channels, it is shown that the\noptimal SDoF is 2/3. We then generalize the result to the two-user Gaussian\nMISO broadcast channel with confidential messages and characterize the SDoF\nregion when the transmitter has delayed CSI of both receivers. Interestingly,\nthe artificial noise schemes exploiting several time instances are shown to\nprovide the optimal SDoF region by masking the confidential message to the\nunintended receiver while aligning the interference at each receiver. \n\n"}
{"id": "1108.4940", "contents": "Title: Quantum rate distortion, reverse Shannon theorems, and source-channel\n  separation Abstract: We derive quantum counterparts of two key theorems of classical information\ntheory, namely, the rate distortion theorem and the source-channel separation\ntheorem. The rate-distortion theorem gives the ultimate limits on lossy data\ncompression, and the source-channel separation theorem implies that a two-stage\nprotocol consisting of compression and channel coding is optimal for\ntransmitting a memoryless source over a memoryless channel. In spite of their\nimportance in the classical domain, there has been surprisingly little work in\nthese areas for quantum information theory. In the present paper, we prove that\nthe quantum rate distortion function is given in terms of the regularized\nentanglement of purification. We also determine a single-letter expression for\nthe entanglement-assisted quantum rate distortion function, and we prove that\nit serves as a lower bound on the unassisted quantum rate distortion function.\nThis implies that the unassisted quantum rate distortion function is\nnon-negative and generally not equal to the coherent information between the\nsource and distorted output (in spite of Barnum's conjecture that the coherent\ninformation would be relevant here). Moreover, we prove several quantum\nsource-channel separation theorems. The strongest of these are in the\nentanglement-assisted setting, in which we establish a necessary and sufficient\ncodition for transmitting a memoryless source over a memoryless quantum channel\nup to a given distortion. \n\n"}
{"id": "1109.0351", "contents": "Title: Directed Information, Causal Estimation, and Communication in Continuous\n  Time Abstract: A notion of directed information between two continuous-time processes is\nproposed. A key component in the definition is taking an infimum over all\npossible partitions of the time interval, which plays a role no less\nsignificant than the supremum over \"space\" partitions inherent in the\ndefinition of mutual information. Properties and operational interpretations in\nestimation and communication are then established for the proposed notion of\ndirected information. For the continuous-time additive white Gaussian noise\nchannel, it is shown that Duncan's classical relationship between causal\nestimation and information continues to hold in the presence of feedback upon\nreplacing mutual information by directed information. A parallel result is\nestablished for the Poisson channel. The utility of this relationship is then\ndemonstrated in computing the directed information rate between the input and\noutput processes of a continuous-time Poisson channel with feedback, where the\nchannel input process is constrained to be constant between events at the\nchannel output. Finally, the capacity of a wide class of continuous-time\nchannels with feedback is established via directed information, characterizing\nthe fundamental limit on reliable communication. \n\n"}
{"id": "1109.4074", "contents": "Title: Secure Multiplex Coding Over Interference Channel with Confidential\n  Messages Abstract: In this paper, inner and outer bounds on the capacity region of two-user\ninterference channels with two confidential messages have been proposed. By\nadding secure multiplex coding to the error correction method in [15] which\nachieves the best achievable capacity region for interference channel up to\nnow, we have shown that the improved secure capacity region compared with [2]\nnow is the whole Han-Kobayashi region. In addition, this construction not only\nremoves the rate loss incurred by adding dummy messages to achieve security,\nbut also change the original weak security condition in [2] to strong security.\nThen the equivocation rate for a collection of secret messages has also been\nevaluated, when the length of the message is finite or the information rate is\nhigh, our result provides a good approximation for bounding the worst case\nequivocation rate. Our results can be readily extended to the Gaussian\ninterference channel with little efforts. \n\n"}
{"id": "1109.5396", "contents": "Title: Degrees of Freedom of Interference Channels with CoMP Transmission and\n  Reception Abstract: We study the Degrees of Freedom (DoF) of the K-user interference channel with\ncoordinated multi-point (CoMP) transmission and reception. Each message is\njointly transmitted by M_t successive transmitters, and is jointly received by\nM_r successive receivers. We refer to this channel as the CoMP channel with a\ntransmit cooperation order of M_t and receive cooperation order of M_r. Since\nthe channel has a total of K transmit antennas and K receive antennas, the\nmaximum possible DoF is equal to K. We show that the CoMP channel has K DoF if\nand only if M_t + M_r is greater than or equal to K+1. For the general case, we\nderive an outer bound that states that the DoF is bounded above by the ceiling\nof (K+M_t+M_r-2)/2. For the special case with only CoMP transmission, i.e, M_r\n= 1, we propose a scheme that can achieve (K+M_t-1)/2 DoF for all K < 10, and\nconjecture that the result holds true for all K . The achievability proofs are\nbased on the notion of algebraic independence from algebraic geometry. \n\n"}
{"id": "1109.6390", "contents": "Title: Performance of Orthogonal Matching Pursuit for Multiple Measurement\n  Vectors Abstract: In this paper, we consider orthogonal matching pursuit (OMP) algorithm for\nmultiple measurement vectors (MMV) problem. The robustness of OMPMMV is studied\nunder general perturbations---when the measurement vectors as well as the\nsensing matrix are incorporated with additive noise. The main result shows that\nalthough exact recovery of the sparse solutions is unrealistic in noisy\nscenario, recovery of the support set of the solutions is guaranteed under\nsuitable conditions. Specifically, a sufficient condition is derived that\nguarantees exact recovery of the sparse solutions in noiseless scenario. \n\n"}
{"id": "1110.0378", "contents": "Title: Exact Dynamic Support Tracking with Multiple Measurement Vectors using\n  Compressive MUSIC Abstract: Dynamic tracking of sparse targets has been one of the important topics in\narray signal processing. Recently, compressed sensing (CS) approaches have been\nextensively investigated as a new tool for this problem using partial support\ninformation obtained by exploiting temporal redundancy. However, most of these\napproaches are formulated under single measurement vector compressed sensing\n(SMV-CS) framework, where the performance guarantees are only in a\nprobabilistic manner. The main contribution of this paper is to allow\n\\textit{deterministic} tracking of time varying supports with multiple\nmeasurement vectors (MMV) by exploiting multi-sensor diversity. In particular,\nwe show that a novel compressive MUSIC (CS-MUSIC) algorithm with optimized\npartial support selection not only allows removal of inaccurate portion of\nprevious support estimation but also enables addition of newly emerged part of\nunknown support. Numerical results confirm the theory. \n\n"}
{"id": "1110.6591", "contents": "Title: On some quasigroup cryptographical primitives Abstract: We propose modifications of known quasigroup based stream ciphers. Systems of\northogonal n-ary groupoids are used. \n\n"}
{"id": "1110.6778", "contents": "Title: Towards Optimal CSI Allocation in Multicell MIMO Channels Abstract: In this work, we consider the joint precoding across K transmitters (TXs),\nsharing the knowledge of the user's data symbols to be transmitted towards K\nsingle-antenna receivers (RXs). We consider a distributed channel state\ninformation (DCSI) configuration where each TX has its own local estimate of\nthe overall multiuser MIMO channel. The focus of this work is on the\noptimization of the allocation of the CSI feedback subject to a constraint on\nthe total sharing through the backhaul network. Building upon the Wyner model,\nwe derive a new approach to allocate the CSI feedback while making efficient\nuse of the pathloss structure to reduce the amount of feedback necessary. We\nshow that the proposed CSI allocation achieves good performance with only a\nnumber of CSI bits per TX which does not scale with the number of cooperating\nTXs, thus making the joint transmission from a large number of TXs more\npractical than previously thought. Indeed, the proposed CSI allocation reduces\nthe cooperation to a local scale, which allows also for a reduced allocation of\nthe user's data symbols. We further show that the approach can be extended to a\nmore general class of channel: the exponentially decaying channels, which model\naccuratly the cooperation of TXs located on a one dimensional space. Finally,\nwe verify by simulations that the proposed CSI allocation leads to very little\nperformance losses. \n\n"}
{"id": "1111.1555", "contents": "Title: A scheme to protect against multiple quantum erasures Abstract: We present a scheme able to protect k >= 3 qubits of information against the\noccurrence of multiple erasures, based on the code proposed by Yang et al.\n(2004 JETP Letters 79 236). In this scheme redundant blocks are used and we\nrestrict to the case that each erasure must occur in distinct blocks. We\nexplicitly characterize the encoding operation and the restoring operation\nrequired to implement this scheme. The operators used in these operations can\nbe adjusted to construct different quantum erasure-correcting codes. A special\nfeature of this scheme is that no measurement is required. To illustrate our\nscheme, we present an example in which five-qubits of information are protected\nagainst the occurrence of two erasures. \n\n"}
{"id": "1111.1982", "contents": "Title: On the Concentration of the Crest Factor for OFDM Signals Abstract: This paper applies several concentration inequalities to prove concentration\nresults for the crest factor of OFDM signals. The considered approaches are, to\nthe best of our knowledge, new in the context of establishing concentration for\nOFDM signals. \n\n"}
{"id": "1111.2217", "contents": "Title: Moderate-Deviations of Lossy Source Coding for Discrete and Gaussian\n  Sources Abstract: We study the moderate-deviations (MD) setting for lossy source coding of\nstationary memoryless sources. More specifically, we derive fundamental\ncompression limits of source codes whose rates are $R(D) \\pm \\epsilon_n$, where\n$R(D)$ is the rate-distortion function and $\\epsilon_n$ is a sequence that\ndominates $\\sqrt{1/n}$. This MD setting is complementary to the\nlarge-deviations and central limit settings and was studied by Altug and Wagner\nfor the channel coding setting. We show, for finite alphabet and Gaussian\nsources, that as in the central limit-type results, the so-called dispersion\nfor lossy source coding plays a fundamental role in the MD setting for the\nlossy source coding problem. \n\n"}
{"id": "1111.4555", "contents": "Title: Large Deviations Performance of Consensus+Innovations Distributed\n  Detection with Non-Gaussian Observations Abstract: We establish the large deviations asymptotic performance (error exponent) of\nconsensus+innovations distributed detection over random networks with generic\n(non-Gaussian) sensor observations. At each time instant, sensors 1) combine\ntheirs with the decision variables of their neighbors (consensus) and 2)\nassimilate their new observations (innovations). This paper shows for general\nnon-Gaussian distributions that consensus+innovations distributed detection\nexhibits a phase transition behavior with respect to the network degree of\nconnectivity. Above a threshold, distributed is as good as centralized, with\nthe same optimal asymptotic detection performance, but, below the threshold,\ndistributed detection is suboptimal with respect to centralized detection. We\ndetermine this threshold and quantify the performance loss below threshold.\nFinally, we show the dependence of the threshold and performance on the\ndistribution of the observations: distributed detectors over the same random\nnetwork, but with different observations' distributions, for example, Gaussian,\nLaplace, or quantized, may have different asymptotic performance, even when the\ncorresponding centralized detectors have the same asymptotic performance. \n\n"}
{"id": "1111.4596", "contents": "Title: Grassmannian Differential Limited Feedback for Interference Alignment Abstract: Channel state information (CSI) in the interference channel can be used to\nprecode, align, and reduce the dimension of interference at the receivers, to\nachieve the channel's maximum multiplexing gain, through what is known as\ninterference alignment. Most interference alignment algorithms require\nknowledge of all the interfering channels to compute the alignment precoders.\nCSI, considered available at the receivers, can be shared with the transmitters\nvia limited feedback. When alignment is done by coding over frequency\nextensions in a single antenna system, the required CSI lies on the\nGrassmannian manifold and its structure can be exploited in feedback.\nUnfortunately, the number of channels to be shared grows with the square of the\nnumber of users, creating too much overhead with conventional feedback methods.\nThis paper proposes Grassmannian differential feedback to reduce feedback\noverhead by exploiting both the channel's temporal correlation and Grassmannian\nstructure. The performance of the proposed algorithm is characterized both\nanalytically and numerically as a function of channel length, mobility, and the\nnumber of feedback bits. The main conclusions are that the proposed feedback\nstrategy allows interference alignment to perform well over a wide range of\nDoppler spreads, and to approach perfect CSI performance in slowly varying\nchannels. Numerical results highlight the trade-off between the frequency of\nfeedback and the accuracy of individual feedback updates. \n\n"}
{"id": "1111.5272", "contents": "Title: Efficient High-Dimensional Inference in the Multiple Measurement Vector\n  Problem Abstract: In this work, a Bayesian approximate message passing algorithm is proposed\nfor solving the multiple measurement vector (MMV) problem in compressive\nsensing, in which a collection of sparse signal vectors that share a common\nsupport are recovered from undersampled noisy measurements. The algorithm,\nAMP-MMV, is capable of exploiting temporal correlations in the amplitudes of\nnon-zero coefficients, and provides soft estimates of the signal vectors as\nwell as the underlying support. Central to the proposed approach is an\nextension of recently developed approximate message passing techniques to the\namplitude-correlated MMV setting. Aided by these techniques, AMP-MMV offers a\ncomputational complexity that is linear in all problem dimensions. In order to\nallow for automatic parameter tuning, an expectation-maximization algorithm\nthat complements AMP-MMV is described. Finally, a detailed numerical study\ndemonstrates the power of the proposed approach and its particular suitability\nfor application to high-dimensional problems. \n\n"}
{"id": "1112.2690", "contents": "Title: Multilevel Coding Schemes for Compute-and-Forward with Flexible Decoding Abstract: We consider the design of coding schemes for the wireless two-way relaying\nchannel when there is no channel state information at the transmitter. In the\nspirit of the compute and forward paradigm, we present a multilevel coding\nscheme that permits computation (or, decoding) of a class of functions at the\nrelay. The function to be computed (or, decoded) is then chosen depending on\nthe channel realization. We define such a class of functions which can be\ndecoded at the relay using the proposed coding scheme and derive rates that are\nuniversally achievable over a set of channel gains when this class of functions\nis used at the relay. We develop our framework with general modulation formats\nin mind, but numerical results are presented for the case where each node\ntransmits using the QPSK constellation. Numerical results with QPSK show that\nthe flexibility afforded by our proposed scheme results in substantially higher\nrates than those achievable by always using a fixed function or by adapting the\nfunction at the relay but coding over GF(4). \n\n"}
{"id": "1201.0830", "contents": "Title: Wireless Network-Coded Accumulate-Compute and Forward Two-Way Relaying Abstract: The design of modulation schemes for the physical layer network-coded two way\nwireless relaying scenario is considered. It was observed by Koike-Akino et al.\nfor the two way relaying scenario, that adaptively changing the network coding\nmap used at the relay according to the channel conditions greatly reduces the\nimpact of multiple access interference which occurs at the relay during the MA\nPhase and all these network coding maps should satisfy a requirement called\nexclusive law. We extend this approach to an Accumulate-Compute and Forward\nprotocol which employs two phases: Multiple Access (MA) phase consisting of two\nchannel uses with independent messages in each channel use, and Broadcast (BC)\nphase having one channel use. Assuming that the two users transmit points from\nthe same 4-PSK constellation, every such network coding map that satisfies the\nexclusive law can be represented by a Latin Square with side 16, and\nconversely, this relationship can be used to get the network coding maps\nsatisfying the exclusive law. Two methods of obtaining this network coding map\nto be used at the relay are discussed. Using the structural properties of the\nLatin Squares for a given set of parameters, the problem of finding all the\nrequired maps is reduced to finding a small set of maps. Having obtained all\nthe Latin Squares, the set of all possible channel realizations is quantized,\ndepending on which one of the Latin Squares obtained optimizes the performance.\nThe quantization thus obtained, is shown to be the same as the one obtained in\n[7] for the 2-stage bidirectional relaying. \n\n"}
{"id": "1201.1798", "contents": "Title: Tight p-fusion frames Abstract: Fusion frames enable signal decompositions into weighted linear subspace\ncomponents. For positive integers p, we introduce p-fusion frames, a sharpening\nof the notion of fusion frames. Tight p-fusion frames are closely related to\nthe classical notions of designs and cubature formulas in Grassmann spaces and\nare analyzed with methods from harmonic analysis in the Grassmannians. We\ndefine the p-fusion frame potential, derive bounds for its value, and discuss\nthe connections to tight p-fusion frames. \n\n"}
{"id": "1201.2906", "contents": "Title: Quantum polar codes for arbitrary channels Abstract: We construct a new entanglement-assisted quantum polar coding scheme which\nachieves the symmetric coherent information rate by synthesizing \"amplitude\"\nand \"phase\" channels from a given, arbitrary quantum channel. We first\ndemonstrate the coding scheme for arbitrary quantum channels with qubit inputs,\nand we show that quantum data can be reliably decoded by O(N) rounds of\ncoherent quantum successive cancellation, followed by N controlled-NOT gates\n(where N is the number of channel uses). We also find that the entanglement\nconsumption rate of the code vanishes for degradable quantum channels. Finally,\nwe extend the coding scheme to channels with multiple qubit inputs. This gives\na near-explicit method for realizing one of the most striking phenomena in\nquantum information theory: the superactivation effect, whereby two quantum\nchannels which individually have zero quantum capacity can have a non-zero\nquantum capacity when used together. \n\n"}
{"id": "1201.3016", "contents": "Title: Quasigroup based crypto-algorithms Abstract: Modifications of Markovski quasigroup based crypto-algorithm have been\nproposed. Some of these modifications are based on the systems of orthogonal\nn-ary groupoids. T-quasigroups based stream ciphers have been constructed. \n\n"}
{"id": "1201.3278", "contents": "Title: Capacity Region of Multiple Access Channel with States Known Noncausally\n  at One Encoder and Only Strictly Causally at the Other Encoder Abstract: We consider a two-user state-dependent multiaccess channel in which the\nstates of the channel are known non-causally to one of the encoders and only\nstrictly causally to the other encoder. Both encoders transmit a common message\nand, in addition, the encoder that knows the states non-causally transmits an\nindividual message. We find explicit characterizations of the capacity region\nof this communication model in both discrete memoryless (DM) and memoryless\nGaussian cases. In particular the capacity region analysis demonstrates the\nutility of the knowledge of the states only strictly causally at the encoder\nthat sends only the common message in general. More specifically, in the DM\nsetting we show that such a knowledge is beneficial and increases the capacity\nregion in general. In the Gaussian setting, we show that such a knowledge does\nnot help, and the capacity is same as if the states were completely unknown at\nthe encoder that sends only the common message. The analysis also reveals\noptimal ways of exploiting the knowledge of the state only strictly causally at\nthe encoder that sends only the common message when such a knowledge is\nbeneficial. The encoders collaborate to convey to the decoder a lossy version\nof the state, in addition to transmitting the information messages through a\ngeneralized Gel'fand-Pinsker binning. Particularly important in this problem\nare the questions of 1) optimal ways of performing the state compression and 2)\nwhether or not the compression indices should be decoded uniquely. We show that\nboth compression \\`a-la noisy network coding, i.e., with no binning and\nnon-unique decoding, and compression using Wyner-Ziv binning with backward\ndecoding and non-unique or unique decoding are optimal. \n\n"}
{"id": "1201.5805", "contents": "Title: Interference and X Networks with Noisy Cooperation and Feedback Abstract: The Gaussian $K$-user interference and $M\\times K$ X channels are\ninvestigated with no instantaneous channel state information (CSI) at\ntransmitters. First, it is assumed that the CSI is fed back to all nodes after\na finite delay (delayed CSIT), and furthermore, the transmitters operate in\nfull-duplex mode, i.e., they can transmit and receive simultaneously.\nAchievable results are obtained on the degrees of freedom (DoF) of these\nchannels under the above assumption. It is observed that, in contrast with no\nCSIT and full CSIT models, when CSIT is delayed, the achievable DoFs for both\nchannels with full-duplex transmitter cooperation are greater than the best\navailable achievable results on their DoF without transmitter cooperation. Our\nresults are the first to show that the full-duplex transmitter cooperation can\npotentially improve the channel DoF with delayed CSIT. Then, $K$-user\ninterference and $K\\times K$ X channels are considered with output feedback,\nwherein the channel output of each receiver is causally fed back to its\ncorresponding transmitter. Our achievable results with output feedback\ndemonstrate strict DoF improvements over those with the full-duplex delayed\nCSIT when $K>5$ in the $K$-user interference channel and $K>2$ in the $K\\times\nK$ X channel. Next, the combination of delayed CSIT and output feedback, known\nas Shannon feedback, is studied and strictly higher DoFs compared to the output\nfeedback model are achieved in the $K$-user interference channel when K=5 or\n$K>6$, and in the $K\\times K$ X channel when $K>2$. Although being strictly\ngreater than 1 and increasing with size of the networks, the achievable DoFs in\nall the models studied in this paper approach limiting values not greater than\n2. \n\n"}
{"id": "1202.0015", "contents": "Title: On the equivalence between Stein and de Bruijn identities Abstract: This paper focuses on proving the equivalence between Stein's identity and de\nBruijn's identity. Given some conditions, we prove that Stein's identity is\nequivalent to de Bruijn's identity. In addition, some extensions of de Bruijn's\nidentity are presented. For arbitrary but fixed input and noise distributions,\nthere exist relations between the first derivative of the differential entropy\nand the posterior mean. Moreover, the second derivative of the differential\nentropy is related to the Fisher information for arbitrary input and noise\ndistributions. Several applications are presented to support the usefulness of\nthe developed results in this paper. \n\n"}
{"id": "1202.0366", "contents": "Title: Blind Null-Space Learning for MIMO Underlay Cognitive Radio Networks Abstract: This paper proposes a blind technique for MIMO cognitive radio Secondary\nUsers (SU) to transmit in the same band simultaneously with a Primary User (PU)\nunder a maximum interference constraint. In the proposed technique, the SU is\nable to meet the interference constraint of the PU without explicitly\nestimating the interference channel matrix to the PU and without burdening the\nPU with any interaction with the SU.\n  The only condition required of the PU is that for a short time interval it\nuses a power control scheme such that its transmitted power is a monotonic\nfunction of the interference inflicted by the SU. During this time interval,\nthe SU iteratively modifies the spatial orientation of its transmitted signal\nand measures the effect of this modification on the PU's total transmit power.\nThe entire process is based on energy measurements which is very desirable from\nan implementation point of view. \n\n"}
{"id": "1202.0589", "contents": "Title: Min-max fair coordinated beamforming in cellular systems via large\n  systems analysis Abstract: This paper considers base station (BS) cooperation in the form of coordinated\nbeamforming, focusing on min-max fairness in the power usage subject to target\nSINR constraints. We show that the optimal beamforming strategies have an\ninteresting nested zero-forcing structure. In the asymptotic regime where the\nnumber of antennas at each BS and the number of users in each cell both grow\nlarge with their ratio tending to a finite constant, the dimensionality of the\noptimization is greatly reduced, and only knowledge of statistics is required\nto solve it. The optimal solution is characterized in general, and an algorithm\nis proposed that converges to the optimal transmit parameters, for feasible\nSINR targets. For the two cell case, a simple single parameter characterization\nis obtained. These asymptotic results provide insights into the average\nperformance, as well as simple but efficient beamforming strategies for the\nfinite system case. In particular, the optimal beamforming strategy from the\nlarge systems analysis only requires the base stations to have local\ninstantaneous channel state information; the remaining parameters of the\nbeamformer can be calculated using channel statistics which can easily be\nshared amongst the base stations. \n\n"}
{"id": "1202.0871", "contents": "Title: Channel Capacity under General Nonuniform Sampling Abstract: This paper develops the fundamental capacity limits of a sampled analog\nchannel under a sub-Nyquist sampling rate constraint. In particular, we derive\nthe capacity of sampled analog channels over a general class of time-preserving\nsampling methods including irregular nonuniform sampling. Our results indicate\nthat the optimal sampling structures extract out the set of frequencies that\nexhibits the highest SNR among all spectral sets of support size equal to the\nsampling rate. The capacity under sub-Nyquist sampling can be attained through\nfilter-bank sampling, or through a single branch of modulation and filtering\nfollowed by uniform sampling. The capacity under sub-Nyquist sampling is a\nmonotone function of the sampling rate. These results indicate that the optimal\nsampling schemes suppress aliasing, and that employing irregular nonuniform\nsampling does not provide capacity gain over uniform sampling sets with\nappropriate preprocessing for a large class of channels. \n\n"}
{"id": "1202.1595", "contents": "Title: Signal Recovery on Incoherent Manifolds Abstract: Suppose that we observe noisy linear measurements of an unknown signal that\ncan be modeled as the sum of two component signals, each of which arises from a\nnonlinear sub-manifold of a high dimensional ambient space. We introduce SPIN,\na first order projected gradient method to recover the signal components.\nDespite the nonconvex nature of the recovery problem and the possibility of\nunderdetermined measurements, SPIN provably recovers the signal components,\nprovided that the signal manifolds are incoherent and that the measurement\noperator satisfies a certain restricted isometry property. SPIN significantly\nextends the scope of current recovery models and algorithms for low dimensional\nlinear inverse problems and matches (or exceeds) the current state of the art\nin terms of performance. \n\n"}
{"id": "1202.2525", "contents": "Title: Subsampling at Information Theoretically Optimal Rates Abstract: We study the problem of sampling a random signal with sparse support in\nfrequency domain. Shannon famously considered a scheme that instantaneously\nsamples the signal at equispaced times. He proved that the signal can be\nreconstructed as long as the sampling rate exceeds twice the bandwidth (Nyquist\nrate). Cand\\`es, Romberg, Tao introduced a scheme that acquires instantaneous\nsamples of the signal at random times. They proved that the signal can be\nuniquely and efficiently reconstructed, provided the sampling rate exceeds the\nfrequency support of the signal, times logarithmic factors.\n  In this paper we consider a probabilistic model for the signal, and a\nsampling scheme inspired by the idea of spatial coupling in coding theory.\nNamely, we propose to acquire non-instantaneous samples at random times.\nMathematically, this is implemented by acquiring a small random subset of Gabor\ncoefficients. We show empirically that this scheme achieves correct\nreconstruction as soon as the sampling rate exceeds the frequency support of\nthe signal, thus reaching the information theoretic limit. \n\n"}
{"id": "1202.4044", "contents": "Title: Robust computation of linear models by convex relaxation Abstract: Consider a dataset of vector-valued observations that consists of noisy\ninliers, which are explained well by a low-dimensional subspace, along with\nsome number of outliers. This work describes a convex optimization problem,\ncalled REAPER, that can reliably fit a low-dimensional model to this type of\ndata. This approach parameterizes linear subspaces using orthogonal projectors,\nand it uses a relaxation of the set of orthogonal projectors to reach the\nconvex formulation. The paper provides an efficient algorithm for solving the\nREAPER problem, and it documents numerical experiments which confirm that\nREAPER can dependably find linear structure in synthetic and natural data. In\naddition, when the inliers lie near a low-dimensional subspace, there is a\nrigorous theory that describes when REAPER can approximate this subspace. \n\n"}
{"id": "1202.4098", "contents": "Title: Energy-Efficient Sensing and Communication of Parallel Gaussian Sources Abstract: Energy efficiency is a key requirement in the design of wireless sensor\nnetworks. While most theoretical studies only account for the energy\nrequirements of communication, the sensing process, which includes measurements\nand compression, can also consume comparable energy. In this paper, the problem\nof sensing and communicating parallel sources is studied by accounting for the\ncost of both communication and sensing. In the first formulation of the\nproblem, the sensor has a separate energy budget for sensing and a rate budget\nfor communication, while, in the second, it has a single energy budget for both\ntasks. Assuming that sources with larger variances have lower sensing costs,\nthe optimal allocation of sensing energy and rate that minimizes the overall\ndistortion is derived for the first problem. Moreover, structural results on\nthe solution of the second problem are derived under the assumption that the\nsources with larger variances are transmitted on channels with lower noise.\nClosed-form solutions are also obtained for the case where the energy budget is\nsufficiently large. For an arbitrary order on the variances and costs, the\noptimal solution to the first problem is also obtained numerically and compared\nwith several suboptimal strategies. \n\n"}
{"id": "1203.1892", "contents": "Title: Restricted Isometry Property in Quantized Network Coding of Sparse\n  Messages Abstract: In this paper, we study joint network coding and distributed source coding of\ninter-node dependent messages, with the perspective of compressed sensing.\nSpecifically, the theoretical guarantees for robust $\\ell_1$-min recovery of an\nunder-determined set of linear network coded sparse messages are investigated.\nWe discuss the guarantees for $\\ell_1$-min decoding of quantized network coded\nmessages, using the proposed local network coding coefficients in \\cite{naba},\nbased on Restricted Isometry Property (RIP) of the resulting measurement\nmatrix. Moreover, the relation between tail probability of $\\ell_2$-norms and\nsatisfaction of RIP is derived and used to compare our designed measurement\nmatrix, with i.i.d. Gaussian measurement matrix. Finally, we present our\nnumerical evaluations, which shows that the proposed design of network coding\ncoefficients result in a measurement matrix with an RIP behavior, similar to\nthat of i.i.d. Gaussian matrix. \n\n"}
{"id": "1203.3864", "contents": "Title: Matrix ALPS: Accelerated Low Rank and Sparse Matrix Reconstruction Abstract: We propose Matrix ALPS for recovering a sparse plus low-rank decomposition of\na matrix given its corrupted and incomplete linear measurements. Our approach\nis a first-order projected gradient method over non-convex sets, and it\nexploits a well-known memory-based acceleration technique. We theoretically\ncharacterize the convergence properties of Matrix ALPS using the stable\nembedding properties of the linear measurement operator. We then numerically\nillustrate that our algorithm outperforms the existing convex as well as\nnon-convex state-of-the-art algorithms in computational efficiency without\nsacrificing stability. \n\n"}
{"id": "1203.3879", "contents": "Title: Powerline Communications Channel Modelling Methodology Based on\n  Statistical Features Abstract: This paper proposes a new channel modelling method for powerline\ncommunications networks based on the multipath profile in the time domain. The\nnew channel model is developed to be applied in a range of Powerline\nCommunications (PLC) research topics such as impulse noise modelling,\ndeployment and coverage studies, and communications theory analysis. To develop\nthe methodology, channels are categorised according to their propagation\ndistance and power delay profile. The statistical multipath parameters such as\npath arrival time, magnitude and interval for each category are analyzed to\nbuild the model. Each generated channel based on the proposed statistical model\nrepresents a different realisation of a PLC network. Simulation results in\nsimilar the time and frequency domains show that the proposed statistical\nmodelling method, which integrates the impact of network topology presents the\nPLC channel features as the underlying transmission line theory model.\nFurthermore, two potential application scenarios are described to show the\nchannel model is applicable to capacity analysis and correlated impulse noise\nmodelling for PLC networks. \n\n"}
{"id": "1203.4865", "contents": "Title: Successive Refinement with Decoder Cooperation and its Channel Coding\n  Duals Abstract: We study cooperation in multi terminal source coding models involving\nsuccessive refinement. Specifically, we study the case of a single encoder and\ntwo decoders, where the encoder provides a common description to both the\ndecoders and a private description to only one of the decoders. The decoders\ncooperate via cribbing, i.e., the decoder with access only to the common\ndescription is allowed to observe, in addition, a deterministic function of the\nreconstruction symbols produced by the other. We characterize the fundamental\nperformance limits in the respective settings of non-causal, strictly-causal\nand causal cribbing. We use a new coding scheme, referred to as Forward\nEncoding and Block Markov Decoding, which is a variant of one recently used by\nCuff and Zhao for coordination via implicit communication. Finally, we use the\ninsight gained to introduce and solve some dual channel coding scenarios\ninvolving Multiple Access Channels with cribbing. \n\n"}
{"id": "1203.5602", "contents": "Title: On the Application of Noisy Network Coding to the Relay-Eavesdropper\n  Channel Abstract: In this paper, we consider the design of a new secrecy transmission scheme\nfor a four-node relay-eavesdropper channel. The key idea of the proposed scheme\nis to combine noisy network coding with the interference assisted strategy for\nwiretap channel with a helping interferer. A new achievable secrecy rate is\ncharacterized for both discrete memoryless and Gaussian channels. Such a new\nrate can be viewed as a general framework, where the existing interference\nassisted schemes such as noisy-forwarding and cooperative jamming approaches\ncan be shown as special cases of the proposed scheme. In addition, under some\nchannel condition where the existing schemes can only achieve zero secrecy\nrate, the proposed secrecy scheme can still offer significant performance\ngains. \n\n"}
{"id": "1203.6027", "contents": "Title: Causal State Communication Abstract: The problem of state communication over a discrete memoryless channel with\ndiscrete memoryless state is studied when the state information is available\nstrictly causally at the encoder. It is shown that block Markov encoding, in\nwhich the encoder communicates a description of the state sequence in the\nprevious block by incorporating side information about the state sequence at\nthe decoder, yields the minimum state estimation error. When the same channel\nis used to send additional independent information at the expense of a higher\nchannel state estimation error, the optimal tradeoff between the rate of the\nindependent information and the state estimation error is characterized via the\ncapacity- distortion function. It is shown that any optimal tradeoff pair can\nbe achieved via rate-splitting. These coding theorems are then extended\noptimally to the case of causal channel state information at the encoder using\nthe Shannon strategy. \n\n"}
{"id": "1204.0521", "contents": "Title: Explicit receivers for pure-interference bosonic multiple access\n  channels Abstract: The pure-interference bosonic multiple access channel has two senders and one\nreceiver, such that the senders each communicate with multiple temporal modes\nof a single spatial mode of light. The channel mixes the input modes from the\ntwo users pairwise on a lossless beamsplitter, and the receiver has access to\none of the two output ports. In prior work, Yen and Shapiro found the capacity\nregion of this channel if encodings consist of coherent-state preparations.\nHere, we demonstrate how to achieve the coherent-state Yen-Shapiro region (for\na range of parameters) using a sequential decoding strategy, and we show that\nour strategy outperforms the rate regions achievable using conventional\nreceivers. Our receiver performs binary-outcome quantum measurements for every\ncodeword pair in the senders' codebooks. A crucial component of this scheme is\na non-destructive \"vacuum-or-not\" measurement that projects an n-symbol\nmodulated codeword onto the n-fold vacuum state or its orthogonal complement,\nsuch that the post-measurement state is either the n-fold vacuum or has the\nvacuum removed from the support of the n symbols' joint quantum state. This\nreceiver requires the additional ability to perform multimode optical\nphase-space displacements which are realizable using a beamsplitter and a\nlaser. \n\n"}
{"id": "1204.0867", "contents": "Title: Optimal Index Codes for a Class of Multicast Networks with Receiver Side\n  Information Abstract: This paper studies a special class of multicast index coding problems where a\nsender transmits messages to multiple receivers, each with some side\ninformation. Here, each receiver knows a unique message a priori, and there is\nno restriction on how many messages each receiver requests from the sender. For\nthis class of multicast index coding problems, we obtain the optimal index\ncode, which has the shortest codelength for which the sender needs to send in\norder for all receivers to obtain their (respective) requested messages. This\nis the first class of index coding problems where the optimal index codes are\nfound. In addition, linear index codes are shown to be optimal for this class\nof index coding problems. \n\n"}
{"id": "1204.0992", "contents": "Title: Discrete Sampling and Interpolation: Universal Sampling Sets for\n  Discrete Bandlimited Spaces Abstract: We study the problem of interpolating all values of a discrete signal f of\nlength N when d<N values are known, especially in the case when the Fourier\ntransform of the signal is zero outside some prescribed index set J; these\ncomprise the (generalized) bandlimited spaces B^J. The sampling pattern for f\nis specified by an index set I, and is said to be a universal sampling set if\nsamples in the locations I can be used to interpolate signals from B^J for any\nJ. When N is a prime power we give several characterizations of universal\nsampling sets, some structure theorems for such sets, an algorithm for their\nconstruction, and a formula that counts them. There are also natural\napplications to additive uncertainty principles. \n\n"}
{"id": "1204.1091", "contents": "Title: Load-Aware Modeling and Analysis of Heterogeneous Cellular Networks Abstract: Random spatial models are attractive for modeling heterogeneous cellular\nnetworks (HCNs) due to their realism, tractability, and scalability. A major\nlimitation of such models to date in the context of HCNs is the neglect of\nnetwork traffic and load: all base stations (BSs) have typically been assumed\nto always be transmitting. Small cells in particular will have a lighter load\nthan macrocells, and so their contribution to the network interference may be\nsignificantly overstated in a fully loaded model. This paper incorporates a\nflexible notion of BS load by introducing a new idea of conditionally thinning\nthe interference field. For a K-tier HCN where BSs across tiers differ in terms\nof transmit power, supported data rate, deployment density, and now load, we\nderive the coverage probability for a typical mobile, which connects to the\nstrongest BS signal. Conditioned on this connection, the interfering BSs of the\n$i^{th}$ tier are assumed to transmit independently with probability $p_i$,\nwhich models the load. Assuming - reasonably - that smaller cells are more\nlightly loaded than macrocells, the analysis shows that adding such access\npoints to the network always increases the coverage probability. We also\nobserve that fully loaded models are quite pessimistic in terms of coverage. \n\n"}
{"id": "1204.3069", "contents": "Title: An Outer Bound for the Memoryless Two-user Interference Channel with\n  General Cooperation Abstract: The interference channel models a wireless network where several\nsource-destination pairs compete for the same resources. When nodes transmit\nsimultaneously the destinations experience interference. This paper considers a\n4-node network, where two nodes are sources and the other two are destinations.\nAll nodes are full-duplex and cooperate to mitigate interference. A sum-rate\nouter bound is derived, which is shown to unify a number of previously derived\nouter bounds for special cases of cooperation. The approach is shown to extend\nto cooperative interference networks with more than two source-destination\npairs and for any partial sum-rate. How the derived bound relates to similar\nbounds for channel models including cognitive nodes, i.e., nodes that have\nnon-causal knowledge of the messages of some other node, is also discussed.\nFinally, the bound is evaluated for the Gaussian noise channel and used to\ncompare different modes of cooperation. \n\n"}
{"id": "1204.3097", "contents": "Title: Technical Report: Observability of a Linear System under Sparsity\n  Constraints Abstract: Consider an n-dimensional linear system where it is known that there are at\nmost k<n non-zero components in the initial state. The observability problem,\nthat is the recovery of the initial state, for such a system is considered. We\nobtain sufficient conditions on the number of the available observations to be\nable to recover the initial state exactly for such a system. Both deterministic\nand stochastic setups are considered for system dynamics. In the former\nsetting, the system matrices are known deterministically, whereas in the latter\nsetting, all of the matrices are picked from a randomized class of matrices.\nThe main message is that, one does not need to obtain full n observations to be\nable to uniquely identify the initial state of the linear system, even when the\nobservations are picked randomly, when the initial condition is known to be\nsparse. \n\n"}
{"id": "1204.5663", "contents": "Title: Cognitive Interference Channels with Confidential Messages under\n  Randomness Constraint Abstract: The cognitive interference channel with confidential messages (CICC) proposed\nby Liang et. al. is investigated. When the security is considered in coding\nsystems, it is well known that the sender needs to use a stochastic encoding to\navoid the information about the transmitted confidential message to be leaked\nto an eavesdropper. For the CICC, the trade-off between the rate of the random\nnumber to realize the stochastic encoding and the communication rates is\ninvestigated, and the optimal trade-off is completely characterized. \n\n"}
{"id": "1204.5710", "contents": "Title: Information Masking and Amplification: The Source Coding Setting Abstract: The complementary problems of masking and amplifying channel state\ninformation in the Gel'fand-Pinsker channel have recently been solved by Merhav\nand Shamai, and Kim et al., respectively. In this paper, we study a related\nsource coding problem. Specifically, we consider the two-encoder source coding\nsetting where one source is to be amplified, while the other source is to be\nmasked. In general, there is a tension between these two objectives which is\ncharacterized by the amplification-masking tradeoff. In this paper, we give a\nsingle-letter description of this tradeoff.\n  We apply this result, together with a recent theorem by Courtade and Weissman\non multiterminal source coding, to solve a fundamental entropy characterization\nproblem. \n\n"}
{"id": "1204.6098", "contents": "Title: On Locality in Distributed Storage Systems Abstract: This paper studies the design of codes for distributed storage systems (DSS)\nthat enable local repair in the event of node failure. This paper presents\nlocally repairable codes based on low degree multivariate polynomials. Its code\nconstruction mechanism extends work on Noisy Interpolating Set by Dvir et al.\n\\cite{dvir2011}. The paper presents two classes of codes that allow node repair\nto be performed by contacting 2 and 3 surviving nodes respectively. It further\nshows that both classes are good in terms of their rate and minimum distance,\nand allow their rate to be bartered for greater flexibility in the repair\nprocess. \n\n"}
{"id": "1205.4080", "contents": "Title: Dynamic Compressive Sensing of Time-Varying Signals via Approximate\n  Message Passing Abstract: In this work the dynamic compressive sensing (CS) problem of recovering\nsparse, correlated, time-varying signals from sub-Nyquist, non-adaptive, linear\nmeasurements is explored from a Bayesian perspective. While there has been a\nhandful of previously proposed Bayesian dynamic CS algorithms in the\nliterature, the ability to perform inference on high-dimensional problems in a\ncomputationally efficient manner remains elusive. In response, we propose a\nprobabilistic dynamic CS signal model that captures both amplitude and support\ncorrelation structure, and describe an approximate message passing algorithm\nthat performs soft signal estimation and support detection with a computational\ncomplexity that is linear in all problem dimensions. The algorithm, DCS-AMP,\ncan perform either causal filtering or non-causal smoothing, and is capable of\nlearning model parameters adaptively from the data through an\nexpectation-maximization learning procedure. We provide numerical evidence that\nDCS-AMP performs within 3 dB of oracle bounds on synthetic data under a variety\nof operating conditions. We further describe the result of applying DCS-AMP to\ntwo real dynamic CS datasets, as well as a frequency estimation task, to\nbolster our claim that DCS-AMP is capable of offering state-of-the-art\nperformance and speed on real-world high-dimensional problems. \n\n"}
{"id": "1205.4673", "contents": "Title: Minimum Complexity Pursuit: Stability Analysis Abstract: A host of problems involve the recovery of structured signals from a\ndimensionality reduced representation such as a random projection; examples\ninclude sparse signals (compressive sensing) and low-rank matrices (matrix\ncompletion). Given the wide range of different recovery algorithms developed to\ndate, it is natural to ask whether there exist \"universal\" algorithms for\nrecovering \"structured\" signals from their linear projections. We recently\nanswered this question in the affirmative in the noise-free setting. In this\npaper, we extend our results to the case of noisy measurements. \n\n"}
{"id": "1205.4876", "contents": "Title: Selective Coding Strategy for Unicast Composite Networks Abstract: Consider a composite unicast relay network where the channel statistic is\nrandomly drawn from a set of conditional distributions indexed by a random\nvariable, which is assumed to be unknown at the source, fully known at the\ndestination and only partly known at the relays. Commonly, the coding strategy\nat each relay is fixed regardless of its channel measurement. A novel coding\nfor unicast composite networks with multiple relays is introduced. This enables\nthe relays to select dynamically --based on its channel measurement-- the best\ncoding scheme between compress-and-forward (CF) and decode-and-forward (DF). As\na part of the main result, a generalization of Noisy Network Coding is shown\nfor the case of unicast general networks where the relays are divided between\nthose using DF and CF coding. Furthermore, the relays using DF scheme can\nexploit the help of those based on CF scheme via offset coding. It is\ndemonstrated via numerical results that this novel coding, referred to as\nSelective Coding Strategy (SCS), outperforms conventional coding schemes. \n\n"}
{"id": "1205.5062", "contents": "Title: The Classification of Complementary Information Set Codes of Lengths 14\n  and 16 Abstract: In the paper \"A new class of codes for Boolean masking of cryptographic\ncomputations,\" Carlet, Gaborit, Kim, and Sol\\'{e} defined a new class of rate\none-half binary codes called \\emph{complementary information set} (or CIS)\ncodes. The authors then classified all CIS codes of length less than or equal\nto 12. CIS codes have relations to classical Coding Theory as they are a\ngeneralization of self-dual codes. As stated in the paper, CIS codes also have\nimportant practical applications as they may improve the cost of masking\ncryptographic algorithms against side channel attacks. In this paper, we give a\ncomplete classification result for length 14 CIS codes using an equivalence\nrelation on $GL(n,\\FF_2)$. We also give a new classification for all binary\n$[16,8,3]$ and $[16,8,4]$ codes. We then complete the classification for length\n16 CIS codes and give additional classifications for optimal CIS codes of\nlengths 20 and 26. \n\n"}
{"id": "1205.5603", "contents": "Title: The Finite Field Multi-Way Relay Channel with Correlated Sources: Beyond\n  Three Users Abstract: The multi-way relay channel (MWRC) models cooperative communication networks\nin which many users exchange messages via a relay. In this paper, we consider\nthe finite field MWRC with correlated messages. The problem is to find all\nachievable rates, defined as the number of channel uses required per reliable\nexchange of message tuple. For the case of three users, we have previously\nestablished that for a special class of source distributions, the set of all\nachievable rates can be found [Ong et al., ISIT 2010]. The class is specified\nby an almost balanced conditional mutual information (ABCMI) condition. In this\npaper, we first generalize the ABCMI condition to the case of more than three\nusers. We then show that if the sources satisfy the ABCMI condition, then the\nset of all achievable rates is found and can be attained using a separate\nsource-channel coding architecture. \n\n"}
{"id": "1205.6852", "contents": "Title: Multiaccess Channel with Partially Cooperating Encoders and Security\n  Constraints Abstract: We study a special case of Willems's two-user multi-access channel with\npartially cooperating encoders from a security perspective. This model differs\nfrom Willems's setup in that only one encoder, Encoder 1, is allowed to\nconference; Encoder 2 does not transmit any message, and there is an additional\npassive eavesdropper from whom the communication should be kept secret. For the\ndiscrete memoryless (DM) case, we establish inner and outer bounds on the\ncapacity-equivocation region. The inner bound is based on a combination of\nWillems's coding scheme, noise injection and additional binning that provides\nrandomization for security. For the memoryless Gaussian model, we establish\nlower and upper bounds on the secrecy capacity. We also show that, under\ncertain conditions, these bounds agree in some extreme cases of cooperation\nbetween the encoders. We illustrate our results through some numerical\nexamples. \n\n"}
{"id": "1206.0399", "contents": "Title: On the Computation of the Higher-Order Statistics of the Channel\n  Capacity for Amplify-and-Forward Multihop Transmission Abstract: Higher-order statistics (HOS) of the channel capacity provide useful\ninformation regarding the level of reliability of the signal transmission at a\nparticular rate. We propose in this letter a novel and unified analysis, which\nis based on the moment-generating function (MGF) approach, to efficiently and\naccurately compute the HOS of the channel capacity for amplify-and-forward\nmultihop transmission over generalized fading channels. More precisely, our\nmathematical formulism is easy-to-use and tractable specifically requiring only\nthe reciprocal MGFs of the instantaneous signal-to-noise ratio distributions of\nthe transmission hops. Numerical and simulation results, performed to exemplify\nthe usefulness of the proposed MGF-based analysis, are shown to be in perfect\nagreement. \n\n"}
{"id": "1206.0773", "contents": "Title: Changepoint Detection over Graphs with the Spectral Scan Statistic Abstract: We consider the change-point detection problem of deciding, based on noisy\nmeasurements, whether an unknown signal over a given graph is constant or is\ninstead piecewise constant over two connected induced subgraphs of relatively\nlow cut size. We analyze the corresponding generalized likelihood ratio (GLR)\nstatistics and relate it to the problem of finding a sparsest cut in a graph.\nWe develop a tractable relaxation of the GLR statistic based on the\ncombinatorial Laplacian of the graph, which we call the spectral scan\nstatistic, and analyze its properties. We show how its performance as a testing\nprocedure depends directly on the spectrum of the graph, and use this result to\nexplicitly derive its asymptotic properties on few significant graph\ntopologies. Finally, we demonstrate both theoretically and by simulations that\nthe spectral scan statistic can outperform naive testing procedures based on\nedge thresholding and $\\chi^2$ testing. \n\n"}
{"id": "1206.1307", "contents": "Title: Non-Additivity of the Entanglement of Purification (Beyond Reasonable\n  Doubt) Abstract: We demonstrate the convexity of the difference between the regularized\nentanglement of purification and the entropy, as a function of the state. This\nis proved by means of a new asymptotic protocol to prepare a state from\npre-shared entanglement and by local operations only. We go on to employ this\nconvexity property in an investigation of the additivity of the (single-copy)\nentanglement of purification: using numerical results for two-qubit Werner\nstates we find strong evidence that the entanglement of purification is\ndifferent from its regularization, hence that entanglement of purification is\nnot additive. \n\n"}
{"id": "1206.1389", "contents": "Title: Lossy Computing of Correlated Sources with Fractional Sampling Abstract: This paper considers the problem of lossy compression for the computation of\na function of two correlated sources, both of which are observed at the\nencoder. Due to presence of observation costs, the encoder is allowed to\nobserve only subsets of the samples from both sources, with a fraction of such\nsample pairs possibly overlapping. The rate-distortion function is\ncharacterized for memory-less sources, and then specialized to Gaussian and\nbinary sources for selected functions and with quadratic and Hamming distortion\nmetrics, respectively. The optimal measurement overlap fraction is shown to\ndepend on the function to be computed by the decoder, on the source statistics,\nincluding the correlation, and on the link rate. Special cases are discussed in\nwhich the optimal overlap fraction is the maximum or minimum possible value\ngiven the sampling budget, illustrating non-trivial performance trade-offs in\nthe design of the sampling strategy. Finally, the analysis is extended to the\nmulti-hop set-up with jointly Gaussian sources, where each encoder can observe\nonly one of the sources. \n\n"}
{"id": "1206.1973", "contents": "Title: Communications-Inspired Projection Design with Application to\n  Compressive Sensing Abstract: We consider the recovery of an underlying signal x \\in C^m based on\nprojection measurements of the form y=Mx+w, where y \\in C^l and w is\nmeasurement noise; we are interested in the case l < m. It is assumed that the\nsignal model p(x) is known, and w CN(w;0,S_w), for known S_W. The objective is\nto design a projection matrix M \\in C^(l x m) to maximize key\ninformation-theoretic quantities with operational significance, including the\nmutual information between the signal and the projections I(x;y) or the Renyi\nentropy of the projections h_a(y) (Shannon entropy is a special case). By\ncapitalizing on explicit characterizations of the gradients of the information\nmeasures with respect to the projections matrix, where we also partially extend\nthe well-known results of Palomar and Verdu from the mutual information to the\nRenyi entropy domain, we unveil the key operations carried out by the optimal\nprojections designs: mode exposure and mode alignment. Experiments are\nconsidered for the case of compressive sensing (CS) applied to imagery. In this\ncontext, we provide a demonstration of the performance improvement possible\nthrough the application of the novel projection designs in relation to\nconventional ones, as well as justification for a fast online projections\ndesign method with which state-of-the-art adaptive CS signal recovery is\nachieved. \n\n"}
{"id": "1206.2220", "contents": "Title: Representations of Genetic Tables, Bimagic Squares, Hamming Distances\n  and Shannon Entropy Abstract: In this paper we have established relations of the genetic tables with magic\nand bimagic squares. Connections with Hamming distances, binomial coefficients\nare established. The idea of Gray code is applied. Shannon entropy of magic\nsquares of order 4x4, 8x8 and 16x16 are also calculated. Some comparison is\nalso made. Symmetry among restriction enzymes having four letters is also\nstudied. \n\n"}
{"id": "1206.5365", "contents": "Title: Batched Sparse Codes Abstract: Network coding can significantly improve the transmission rate of\ncommunication networks with packet loss compared with routing. However, using\nnetwork coding usually incurs high computational and storage costs in the\nnetwork devices and terminals. For example, some network coding schemes require\nthe computational and/or storage capacities of an intermediate network node to\nincrease linearly with the number of packets for transmission, making such\nschemes difficult to be implemented in a router-like device that has only\nconstant computational and storage capacities. In this paper, we introduce\nBATched Sparse code (BATS code), which enables a digital fountain approach to\nresolve the above issue. BATS code is a coding scheme that consists of an outer\ncode and an inner code. The outer code is a matrix generation of a fountain\ncode. It works with the inner code that comprises random linear coding at the\nintermediate network nodes. BATS codes preserve such desirable properties of\nfountain codes as ratelessness and low encoding/decoding complexity. The\ncomputational and storage capacities of the intermediate network nodes required\nfor applying BATS codes are independent of the number of packets for\ntransmission. Almost capacity-achieving BATS code schemes are devised for\nunicast networks, two-way relay networks, tree networks, a class of three-layer\nnetworks, and the butterfly network. For general networks, under different\noptimization criteria, guaranteed decoding rates for the receiving nodes can be\nobtained. \n\n"}
{"id": "1207.0315", "contents": "Title: Multi-slot Coded ALOHA with Irregular Degree Distribution Abstract: This paper proposes an improvement of the random multiple access scheme for\nsatellite communication named Multislot coded ALOHA (MuSCA). MuSCA is a\ngeneralization of Contention Resolution Diversity Slotted ALOHA (CRDSA). In\nthis scheme, each user transmits several parts of a single codeword of an error\ncorrecting code instead of sending replicas. At the receiver level, the decoder\ncollects all these parts and includes them in the decoding process even if they\nare interfered. In this paper, we show that a high throughput can be obtained\nby selecting variable code rates and user degrees according to a probability\ndistribution. With an optimal irregular degree distribution, our system\nachieves a normalized throughput up to 1.43, resulting in a significant gain\ncompared to CRDSA and MuSCA. The spectral efficiency and the implementation\nissues of the scheme are also analyzed. \n\n"}
{"id": "1207.0543", "contents": "Title: Rate-splitting in the presence of multiple receivers Abstract: In the presence of multiple senders, one of the simplest decoding strategies\nthat can be employed by a receiver is successive decoding. In a successive\ndecoding strategy, the receiver decodes the messages one at a time using the\nknowledge of the previously decoded messages as side information. Recently,\nthere have been two separate attempts to construct codes for the interference\nchannel using successive decoding based on the idea of rate-splitting.\n  In this note, we highlight a difficulty that arises when a rate-splitting\ncodebook is to be decoded by multiple receivers. The main issue is that the\nrates of the split codebook are tightly coupled to the properties of the\nchannel to the receiver, thus, rates chosen for one of the receivers may not be\ndecodable for the other. We illustrate this issue by scrutinizing two recent\narguments claiming to achieve the Han-Kobayashi rate region for the\ninterference channel using rate-splitting and successive decoding. \n\n"}
{"id": "1207.1805", "contents": "Title: A Novel Ergodic Capacity Analysis of Diversity Combining and Multihop\n  Transmission Systems over Generalized Composite Fading Channels Abstract: Ergodic capacity is an important performance measure associated with reliable\ncommunication at the highest rate at which information can be sent over the\nchannel with a negligible probability of error. In the shadow of this\ndefinition, diversity receivers (such as selection combining, equal-gain\ncombining and maximal-ratio combining) and transmission techniques (such as\ncascaded fading channels, amplify-and-forward multihop transmission) are\ndeployed in mitigating various performance impairing effects such as fading and\nshadowing in digital radio communication links. However, the exact analysis of\nergodic capacity is in general not always possible for all of these forms of\ndiversity receivers and transmission techniques over generalized composite\nfading environments due to it's mathematical intractability. In the literature,\npublished papers concerning the exact analysis of ergodic capacity have been\ntherefore scarce (i.e., only [1] and [2]) when compared to those concerning the\nexact analysis of average symbol error probability. In addition, they are\nessentially targeting to the ergodic capacity of the maximal ratio combining\ndiversity receivers and are not readily applicable to the capacity analysis of\nthe other diversity combiners / transmission techniques. In this paper, we\npropose a novel moment generating function-based approach for the exact ergodic\ncapacity analysis of both diversity receivers and transmission techniques over\ngeneralized composite fading environments. As such, we demonstrate how to\nsimultaneously treat the ergodic capacity analysis of all forms of both\ndiversity receivers and multihop transmission techniques. \n\n"}
{"id": "1207.2137", "contents": "Title: Can One Achieve Multiuser Diversity in Uplink Multi-Cell Networks? Abstract: We introduce a distributed opportunistic scheduling (DOS) strategy, based on\ntwo pre-determined thresholds, for uplink $K$-cell networks with time-invariant\nchannel coefficients. Each base station (BS) opportunistically selects a mobile\nstation (MS) who has a large signal strength of the desired channel link among\na set of MSs generating a sufficiently small interference to other BSs. Then,\nperformance on the achievable throughput scaling law is analyzed. As our main\nresult, it is shown that the achievable sum-rate scales as\n$K\\log(\\text{SNR}\\log N)$ in a high signal-to-noise ratio (SNR) regime, if the\ntotal number of users in a cell, $N$, scales faster than\n$\\text{SNR}^{\\frac{K-1}{1-\\epsilon}}$ for a constant $\\epsilon\\in(0,1)$. This\nresult indicates that the proposed scheme achieves the multiuser diversity gain\nas well as the degrees-of-freedom gain even under multi-cell environments.\nSimulation results show that the DOS provides a better sum-rate throughput over\nconventional schemes. \n\n"}
{"id": "1207.4587", "contents": "Title: Causal relay networks Abstract: In this paper, we study causal discrete-memoryless relay networks (DMRNs).\nThe network consists of multiple nodes, each of which can be a source, relay,\nand/or destination. In the network, there are two types of relays, i.e., relays\nwith one sample delay (strictly causal) and relays without delay (causal) whose\ntransmit signal depends not only on the past received symbols but also on the\ncurrent received symbol. For this network, we derive two new cut-set bounds,\none when the causal relays have their own messages and the other when not.\nUsing examples of a causal vector Gaussian two-way relay channel and a causal\nvector Gaussian relay channel, we show that the new cut-set bounds can be\nachieved by a simple amplify-and-forward type relaying. Our result for the\ncausal relay channel strengthens the previously known capacity result for the\nsame channel by El Gamal, Hassanpour, and Mammen. \n\n"}
{"id": "1207.5063", "contents": "Title: Secrecy Sum-Rates for Multi-User MIMO Regularized Channel Inversion\n  Precoding Abstract: In this paper, we propose a linear precoder for the downlink of a multi-user\nMIMO system with multiple users that potentially act as eavesdroppers. The\nproposed precoder is based on regularized channel inversion (RCI) with a\nregularization parameter $\\alpha$ and power allocation vector chosen in such a\nway that the achievable secrecy sum-rate is maximized. We consider the\nworst-case scenario for the multi-user MIMO system, where the transmitter\nassumes users cooperate to eavesdrop on other users. We derive the achievable\nsecrecy sum-rate and obtain the closed-form expression for the optimal\nregularization parameter $\\alpha_{\\mathrm{LS}}$ of the precoder using\nlarge-system analysis. We show that the RCI precoder with\n$\\alpha_{\\mathrm{LS}}$ outperforms several other linear precoding schemes, and\nit achieves a secrecy sum-rate that has same scaling factor as the sum-rate\nachieved by the optimum RCI precoder without secrecy requirements. We propose a\npower allocation algorithm to maximize the secrecy sum-rate for fixed $\\alpha$.\nWe then extend our algorithm to maximize the secrecy sum-rate by jointly\noptimizing $\\alpha$ and the power allocation vector. The jointly optimized\nprecoder outperforms RCI with $\\alpha_{\\mathrm{LS}}$ and equal power allocation\nby up to 20 percent at practical values of the signal-to-noise ratio and for 4\nusers and 4 transmit antennas. \n\n"}
{"id": "1207.5660", "contents": "Title: Achieving the Capacity of the N-Relay Gaussian Diamond Network Within\n  log N Bits Abstract: We consider the N-relay Gaussian diamond network where a source node\ncommunicates to a destination node via N parallel relays through a cascade of a\nGaussian broadcast (BC) and a multiple access (MAC) channel. Introduced in 2000\nby Schein and Gallager, the capacity of this relay network is unknown in\ngeneral. The best currently available capacity approximation, independent of\nthe coefficients and the SNR's of the constituent channels, is within an\nadditive gap of 1.3 N bits, which follows from the recent capacity\napproximations for general Gaussian relay networks with arbitrary topology.\n  In this paper, we approximate the capacity of this network within 2 log N\nbits. We show that two strategies can be used to achieve the\ninformation-theoretic cutset upper bound on the capacity of the network up to\nan additive gap of O(log N) bits, independent of the channel configurations and\nthe SNR's. The first of these strategies is simple partial decode-and-forward.\nHere, the source node uses a superposition codebook to broadcast independent\nmessages to the relays at appropriately chosen rates; each relay decodes its\nintended message and then forwards it to the destination over the MAC channel.\nA similar performance can be also achieved with compress-and-forward type\nstrategies (such as quantize-map-and-forward and noisy network coding) that\nprovide the 1.3 N-bit approximation for general Gaussian networks, but only if\nthe relays quantize their observed signals at a resolution inversely\nproportional to the number of relay nodes N. This suggest that the\nrule-of-thumb to quantize the received signals at the noise level in the\ncurrent literature can be highly suboptimal. \n\n"}
{"id": "1207.6087", "contents": "Title: Automated Dynamic Offset Applied to Cell Association Abstract: In this paper, we develop a hierarchical Bayesian game framework for\nautomated dynamic offset selection. Users compete to maximize their throughput\nby picking the best locally serving radio access network (RAN) with respect to\ntheir own measurement, their demand and a partial statistical channel state\ninformation (CSI) of other users. In particular, we investigate the properties\nof a Stackelberg game, in which the base station is a player on its own. We\nderive analytically the utilities related to the channel quality perceived by\nusers to obtain the equilibria. We study the Price of Anarchy (PoA) of such\nsystem, where the PoA is the ratio of the social welfare attained when a\nnetwork planner chooses policies to maximize social welfare versus the social\nwelfare attained in Nash/Stackeleberg equilibrium when users choose their\npolicies strategically. We show by means of a Stackelberg formulation, how the\noperator, by sending appropriate information about the state of the channel,\ncan configure a dynamic offset that optimizes its global utility while users\nmaximize their individual utilities. The proposed hierarchical decision\napproach for wireless networks can reach a good trade-off between the global\nnetwork performance at the equilibrium and the requested amount of signaling.\nTypically, it is shown that when the network goal is orthogonal to user's goal,\nthis can lead the users to a misleading association problem. \n\n"}
{"id": "1207.6435", "contents": "Title: Capacity of optical reading, Part 1: Reading boundless error-free bits\n  using a single photon Abstract: We show that nature imposes no fundamental upper limit to the number of\ninformation bits per expended photon that can, in principle, be read reliably\nwhen classical data is encoded in a medium that can only passively modulate the\namplitude and phase of the probe light. We show that with a coherent-state\n(laser) source, an on-off (amplitude-modulation) pixel encoding, and\nshot-noise-limited direct detection (an overly-optimistic model for commercial\nCD/DVD drives), the highest photon information efficiency achievable in\nprinciple is about 0.5 bit per transmitted photon. We then show that a\ncoherent-state probe can read unlimited bits per photon when the receiver is\nallowed to make joint (inseparable) measurements on the reflected light from a\nlarge block of phase-modulated memory pixels. Finally, we show an example of a\nspatially-entangled non-classical light probe and a receiver\ndesign---constructable using a single-photon source, beam splitters, and\nsingle-photon detectors---that can in principle read any number of error-free\nbits of information. The probe is a single photon prepared in a uniform\ncoherent superposition of multiple orthogonal spatial modes, i.e., a W-state.\nThe code, target, and joint-detection receiver complexity required by a\ncoherent-state transmitter to achieve comparable photon efficiency performance\nis shown to be much higher in comparison to that required by the W-state\ntransceiver. \n\n"}
{"id": "1207.6902", "contents": "Title: Interference Alignment with Quantized Grassmannian Feedback in the\n  K-user Constant MIMO Interference Channel Abstract: A simple channel state information (CSI) feedback scheme is proposed for\ninterference alignment (IA) over the K-user constant\nMultiple-Input-Multiple-Output Interference Channel (MIMO IC). The proposed\ntechnique relies on the identification of invariants in the IA equations, which\nenables the reformulation of the CSI quantization problem as a single\nquantization on the Grassmann manifold at each receiver. The scaling of the\nnumber of feedback bits with the transmit power sufficient to preserve the\nmultiplexing gain that can be achieved under perfect CSI is established. We\nshow that the CSI feedback requirements of the proposed technique are better\n(lower) than what is required when using previously published methods, for\nsystem dimensions (number of users and antennas) of practical interest.\nFurthermore, we show through simulations that this advantage persists at low\nSNR, in the sense that the proposed technique yields a higher sum-rate\nperformance for a given number of feedback bits. Finally, to complement our\nanalysis, we introduce a statistical model that faithfully captures the\nproperties of the quantization error obtained for random vector quantization\n(RVQ) on the Grassmann manifold for large codebooks; this enables the numerical\n(Monte-Carlo) analysis of general Grassmannian RVQ schemes for codebook sizes\nthat would be impractically large to simulate. \n\n"}
{"id": "1208.2900", "contents": "Title: On Achievable Degrees of Freedom for MIMO X Channels Abstract: In this paper, the achievable DoF of MIMO X channels for constant channel\ncoefficients with $M_t$ antennas at transmitter $t$ and $N_r$ antennas at\nreceiver $r$ ($t,r=1,2$) is studied. A spatial interference alignment and\ncancelation scheme is proposed to achieve the maximum DoF of the MIMO X\nchannels. The scenario of $M_1\\geq M_2\\geq N_1\\geq N_2$ is first considered and\ndivided into 3 cases, $3N_2<M_1+M_2<2N_1+N_2$ (Case $A$), $M_1+M_2\\geq2N_1+N_2$\n(Case $B$), and $M_1+M_2\\leq3N_2$ (Case $C$). With the proposed scheme, it is\nshown that in Case $A$, the outer-bound $\\frac{M_1+M_2+N_2}{2}$ is achievable;\nin Case $B$, the achievable DoF equals the outer-bound $N_1+N_2$ if $M_2>N_1$,\notherwise it is 1/2 or 1 less than the outer-bound; in Case $C$, the achievable\nDoF is equal to the outer-bound $2/3(M_1+M_2)$ if $(3N_2-M_1-M_2)\\mod 3=0$, and\nit is 1/3 or 1/6 less than the outer-bound if $(3N_2-M_1-M_2)\\mod 3=1\n\\mathrm{or} 2$. In the scenario of $M_t\\leq N_r$, the exact symmetrical results\nof DoF can be obtained. \n\n"}
{"id": "1208.3806", "contents": "Title: Dynamic Rate Adaptation for Improved Throughput and Delay in Wireless\n  Network Coded Broadcast Abstract: In this paper we provide theoretical and simulation-based study of the\ndelivery delay performance of a number of existing throughput optimal coding\nschemes and use the results to design a new dynamic rate adaptation scheme that\nachieves improved overall throughput-delay performance.\n  Under a baseline rate control scheme, the receivers' delay performance is\nexamined. Based on their Markov states, the knowledge difference between the\nsender and receiver, three distinct methods for packet delivery are identified:\nzero state, leader state and coefficient-based delivery. We provide analyses of\neach of these and show that, in many cases, zero state delivery alone presents\na tractable approximation of the expected packet delivery behaviour.\nInterestingly, while coefficient-based delivery has so far been treated as a\nsecondary effect in the literature, we find that the choice of coefficients is\nextremely important in determining the delay, and a well chosen encoding scheme\ncan, in fact, contribute a significant improvement to the delivery delay.\n  Based on our delivery delay model, we develop a dynamic rate adaptation\nscheme which uses performance prediction models to determine the sender\ntransmission rate. Surprisingly, taking this approach leads us to the simple\nconclusion that the sender should regulate its addition rate based on the total\nnumber of undelivered packets stored at the receivers. We show that despite its\nsimplicity, our proposed dynamic rate adaptation scheme results in noticeably\nimproved throughput-delay performance over existing schemes in the literature. \n\n"}
{"id": "1209.1426", "contents": "Title: Power Control and Multiuser Diversity for the Distributed Cognitive\n  Uplink Abstract: This paper studies optimum power control and sum-rate scaling laws for the\ndistributed cognitive uplink. It is first shown that the optimum distributed\npower control policy is in the form of a threshold based water-filling power\ncontrol. Each secondary user executes the derived power control policy in a\ndistributed fashion by using local knowledge of its direct and interference\nchannel gains such that the resulting aggregate (average) interference does not\ndisrupt primary's communication. Then, the tight sum-rate scaling laws are\nderived as a function of the number of secondary users $N$ under the optimum\ndistributed power control policy. The fading models considered to derive\nsum-rate scaling laws are general enough to include Rayleigh, Rician and\nNakagami fading models as special cases. When transmissions of secondary users\nare limited by both transmission and interference power constraints, it is\nshown that the secondary network sum-rate scales according to\n$\\frac{1}{\\e{}n_h}\\log\\logp{N}$, where $n_h$ is a parameter obtained from the\ndistribution of direct channel power gains. For the case of transmissions\nlimited only by interference constraints, on the other hand, the secondary\nnetwork sum-rate scales according to $\\frac{1}{\\e{}\\gamma_g}\\logp{N}$, where\n$\\gamma_g$ is a parameter obtained from the distribution of interference\nchannel power gains. These results indicate that the distributed cognitive\nuplink is able to achieve throughput scaling behavior similar to that of the\ncentralized cognitive uplink up to a pre-log multiplier $\\frac{1}{\\e{}}$,\nwhilst primary's quality-of-service requirements are met. The factor\n$\\frac{1}{\\e{}}$ can be interpreted as the cost of distributed implementation\nof the cognitive uplink. \n\n"}
{"id": "1209.2688", "contents": "Title: Molecular Communication Between Two Populations of Bacteria Abstract: Molecular communication is an expanding body of research. Recent advances in\nbiology have encouraged using genetically engineered bacteria as the main\ncomponent in the molecular communication. This has stimulated a new line of\nresearch that attempts to study molecular communication among bacteria from an\ninformation-theoretic point of view. Due to high randomness in the individual\nbehavior of the bacterium, reliable communication between two bacteria is\nalmost impossible. Therefore, we recently proposed that a population of\nbacteria in a cluster is considered as a node capable of molecular transmission\nand reception. This proposition enables us to form a reliable node out of many\nunreliable bacteria. The bacteria inside a node sense the environment and\nrespond accordingly. In this paper, we study the communication between two\nnodes, one acting as the transmitter and the other as the receiver. We consider\nthe case in which the information is encoded in the concentration of molecules\nby the transmitter. The molecules produced by the bacteria in the transmitter\nnode propagate in the environment via the diffusion process. Then, their\nconcentration sensed by the bacteria in the receiver node would decode the\ninformation. The randomness in the communication is caused by both the error in\nthe molecular production at the transmitter and the reception of molecules at\nthe receiver. We study the theoretical limits of the information transfer rate\nin such a setup versus the number of bacteria per node. Finally, we consider\nM-ary modulation schemes and study the achievable rates and their error\nprobabilities. \n\n"}
{"id": "1209.3505", "contents": "Title: Cognitive Energy Harvesting and Transmission from a Network Perspective Abstract: Wireless networks can be self-sustaining by harvesting energy from\nradio-frequency (RF) signals. Building on classic cognitive radio networks, we\npropose a novel method for network coexisting where mobiles from a secondary\nnetwork, called secondary transmitters (STs), either harvest energy from\ntransmissions by nearby transmitters from a primary network, called primary\ntransmitters (PTs), or transmit information if PTs are sufficiently far away;\nSTs store harvested energy in rechargeable batteries with finite capacity and\nuse all available energy for subsequent transmission when batteries are fully\ncharged. In this model, each PT is centered at a guard zone and a harvesting\nzone that are disks with given radiuses; a ST harvests energy if it lies in\nsome harvesting zone, transmits fixed-power signals if it is outside all guard\nzones or else idles. Based on this model, the spatial throughput of the\nsecondary network is maximized using a stochastic-geometry model where PTs and\nSTs are modeled as independent homogeneous Poisson point processes (HPPPs),\nunder the outage constraints for coexisting networks and obtained in a simple\nclosed-form. It is observed from the result that the maximum secondary\nthroughput decreases linearly with the growing PT density, and the optimal ST\ndensity is inversely proportional to the derived transmission probability for\nSTs. \n\n"}
{"id": "1210.0100", "contents": "Title: On the Sum of Squared \\eta-\\mu Random Variates With Application to the\n  Performance of Wireless Communication Systems Abstract: The probability density function (PDF) and cumulative distribution function\nof the sum of L independent but not necessarily identically distributed squared\n\\eta-\\mu variates, applicable to the output statistics of maximal ratio\ncombining (MRC) receiver operating over \\eta-\\mu fading channels that includes\nthe Hoyt and the Nakagami-m models as special cases, is presented in\nclosed-form in terms of the Fox's H-bar function. Further analysis,\nparticularly on the bit error rate via PDF-based approach, is also represented\nin closed form in terms of the extended Fox's H-bar function (H-hat). The\nproposed new analytical results complement previous results and are illustrated\nby extensive numerical and Monte Carlo simulation results. \n\n"}
{"id": "1210.0149", "contents": "Title: LDPC Decoding with Limited-Precision Soft Information in Flash Memories Abstract: This paper investigates the application of low-density parity-check (LDPC)\ncodes to Flash memories. Multiple cell reads with distinct word-line voltages\nprovide limited-precision soft information for the LDPC decoder. The values of\nthe word-line voltages (also called reference voltages) are optimized by\nmaximizing the mutual information (MI) between the input and output of the\nmultiple-read channel. Constraining the maximum mutual-information (MMI)\nquantization to enforce a constant-ratio constraint provides a significant\nsimplification with no noticeable loss in performance.\n  Our simulation results suggest that for a well-designed LDPC code, the\nquantization that maximizes the mutual information will also minimize the frame\nerror rate. However, care must be taken to design the code to perform well in\nthe quantized channel. An LDPC code designed for a full-precision Gaussian\nchannel may perform poorly in the quantized setting. Our LDPC code designs\nprovide an example where quantization increases the importance of absorbing\nsets thus changing how the LDPC code should be optimized.\n  Simulation results show that small increases in precision enable the LDPC\ncode to significantly outperform a BCH code with comparable rate and block\nlength (but without the benefit of the soft information) over a range of frame\nerror rates. \n\n"}
{"id": "1210.1091", "contents": "Title: A Formula for the Capacity of the General Gel'fand-Pinsker Channel Abstract: We consider the Gel'fand-Pinsker problem in which the channel and state are\ngeneral, i.e., possibly non-stationary, non-memoryless and non-ergodic. Using\nthe information spectrum method and a non-trivial modification of the piggyback\ncoding lemma by Wyner, we prove that the capacity can be expressed as an\noptimization over the difference of a spectral inf- and a spectral sup-mutual\ninformation rate. We consider various specializations including the case where\nthe channel and state are memoryless but not necessarily stationary. \n\n"}
{"id": "1210.2182", "contents": "Title: Approximate Ergodic Capacity of a Class of Fading 2-user 2-hop Networks Abstract: We consider a fading AWGN 2-user 2-hop network where the channel coefficients\nare independent and identically distributed (i.i.d.) drawn from a continuous\ndistribution and vary over time. For a broad class of channel distributions, we\ncharacterize the ergodic sum capacity to within a constant number of\nbits/sec/Hz, independent of signal-to-noise ratio. The achievability follows\nfrom the analysis of an interference neutralization scheme where the relays are\npartitioned into $M$ pairs, and interference is neutralized separately by each\npair of relays. When $M=1$, the proposed ergodic interference neutralization\ncharacterizes the ergodic sum capacity to within $4$ bits/sec/Hz for i.i.d.\nuniform phase fading and approximately $4.7$ bits/sec/Hz for i.i.d. Rayleigh\nfading. We further show that this gap can be tightened to $4\\log \\pi-4$\nbits/sec/Hz (approximately $2.6$) for i.i.d. uniform phase fading and $4-4\\log(\n\\frac{3\\pi}{8})$ bits/sec/Hz (approximately $3.1$) for i.i.d. Rayleigh fading\nin the limit of large $M$. \n\n"}
{"id": "1210.3921", "contents": "Title: Stein's density approach and information inequalities Abstract: We provide a new perspective on Stein's so-called density approach by\nintroducing a new operator and characterizing class which are valid for a much\nwider family of probability distributions on the real line. We prove an\nelementary factorization property of this operator and propose a new Stein\nidentity which we use to derive information inequalities in terms of what we\ncall the \\emph{generalized Fisher information distance}. We provide explicit\nbounds on the constants appearing in these inequalities for several important\ncases. We conclude with a comparison between our results and known results in\nthe Gaussian case, hereby improving on several known inequalities from the\nliterature. \n\n"}
{"id": "1210.5539", "contents": "Title: Stability of Evolutionary Dynamics on Time Scales Abstract: We combine incentive, adaptive, and time-scale dynamics to study\nmultipopulation dynamics on the simplex equipped with a large class of\nRiemmanian metrics, simultaneously generalizing and extending many dynamics\ncommonly studied in dynamic game theory and evolutionary dynamics. Each\npopulation has its own geometry, method of adaptation (incentive), and\ntime-scale (discrete, continuous, and others). Using an information-theoretic\nmeasure of distance we give a widely-applicable Lyapunov result for the\ndynamic. We include a wealth of examples leading up to and beyond the main\nresults. \n\n"}
{"id": "1210.6722", "contents": "Title: Feng-Rao decoding of primary codes Abstract: We show that the Feng-Rao bound for dual codes and a similar bound by\nAndersen and Geil [H.E. Andersen and O. Geil, Evaluation codes from order\ndomain theory, Finite Fields Appl., 14 (2008), pp. 92-123] for primary codes\nare consequences of each other. This implies that the Feng-Rao decoding\nalgorithm can be applied to decode primary codes up to half their designed\nminimum distance. The technique applies to any linear code for which\ninformation on well-behaving pairs is available. Consequently we are able to\ndecode efficiently a large class of codes for which no non-trivial decoding\nalgorithm was previously known. Among those are important families of\nmultivariate polynomial codes. Matsumoto and Miura in [R. Matsumoto and S.\nMiura, On the Feng-Rao bound for the L-construction of algebraic geometry\ncodes, IEICE Trans. Fundamentals, E83-A (2000), pp. 926-930] (See also [P.\nBeelen and T. H{\\o}holdt, The decoding of algebraic geometry codes, in Advances\nin algebraic geometry codes, pp. 49-98]) derived from the Feng-Rao bound a\nbound for primary one-point algebraic geometric codes and showed how to decode\nup to what is guaranteed by their bound. The exposition by Matsumoto and Miura\nrequires the use of differentials which was not needed in [Andersen and Geil\n2008]. Nevertheless we demonstrate a very strong connection between Matsumoto\nand Miura's bound and Andersen and Geil's bound when applied to primary\none-point algebraic geometric codes. \n\n"}
{"id": "1210.7711", "contents": "Title: Refined support and entropic uncertainty inequalities Abstract: Generalized versions of the entropic (Hirschman-Beckner) and support\n(Elad-Bruckstein) uncertainty principle are presented for frames\nrepresentations. Moreover, a sharpened version of the support inequality has\nbeen obtained by introducing a generalization of the coherence. In the finite\ndimensional case and under certain conditions, minimizers of this inequalities\nare given as constant functions on their support. In addition, $\\ell^p$-norms\ninequalities are introduced as byproducts of the entropic inequalities. \n\n"}
{"id": "1211.0122", "contents": "Title: On Rational-Interpolation Based List-Decoding and List-Decoding Binary\n  Goppa Codes Abstract: We derive the Wu list-decoding algorithm for Generalised Reed-Solomon (GRS)\ncodes by using Gr\\\"obner bases over modules and the Euclidean algorithm (EA) as\nthe initial algorithm instead of the Berlekamp-Massey algorithm (BMA). We\npresent a novel method for constructing the interpolation polynomial fast. We\ngive a new application of the Wu list decoder by decoding irreducible binary\nGoppa codes up to the binary Johnson radius. Finally, we point out a connection\nbetween the governing equations of the Wu algorithm and the Guruswami-Sudan\nalgorithm (GSA), immediately leading to equality in the decoding range and a\nduality in the choice of parameters needed for decoding, both in the case of\nGRS codes and in the case of Goppa codes. \n\n"}
{"id": "1211.1621", "contents": "Title: Cram\\'er-Rao bounds for synchronization of rotations Abstract: Synchronization of rotations is the problem of estimating a set of rotations\nR_i in SO(n), i = 1, ..., N, based on noisy measurements of relative rotations\nR_i R_j^T. This fundamental problem has found many recent applications, most\nimportantly in structural biology. We provide a framework to study\nsynchronization as estimation on Riemannian manifolds for arbitrary n under a\nlarge family of noise models. The noise models we address encompass zero-mean\nisotropic noise, and we develop tools for Gaussian-like as well as heavy-tail\ntypes of noise in particular. As a main contribution, we derive the\nCram\\'er-Rao bounds of synchronization, that is, lower-bounds on the variance\nof unbiased estimators. We find that these bounds are structured by the\npseudoinverse of the measurement graph Laplacian, where edge weights are\nproportional to measurement quality. We leverage this to provide interpretation\nin terms of random walks and visualization tools for these bounds in both the\nanchored and anchor-free scenarios. Similar bounds previously established were\nlimited to rotations in the plane and Gaussian-like noise. \n\n"}
{"id": "1211.3729", "contents": "Title: Data-Efficient Quickest Change Detection in Minimax Settings Abstract: The classical problem of quickest change detection is studied with an\nadditional constraint on the cost of observations used in the detection\nprocess. The change point is modeled as an unknown constant, and minimax\nformulations are proposed for the problem. The objective in these formulations\nis to find a stopping time and an on-off observation control policy for the\nobservation sequence, to minimize a version of the worst possible average\ndelay, subject to constraints on the false alarm rate and the fraction of time\nobservations are taken before change. An algorithm called DE-CuSum is proposed\nand is shown to be asymptotically optimal for the proposed formulations, as the\nfalse alarm rate goes to zero. Numerical results are used to show that the\nDE-CuSum algorithm has good trade-off curves and performs significantly better\nthan the approach of fractional sampling, in which the observations are skipped\nusing the outcome of a sequence of coin tosses, independent of the observation\nprocess. This work is guided by the insights gained from an earlier study of a\nBayesian version of this problem. \n\n"}
{"id": "1211.5231", "contents": "Title: Sparsity-Aware Learning and Compressed Sensing: An Overview Abstract: This paper is based on a chapter of a new book on Machine Learning, by the\nfirst and third author, which is currently under preparation. We provide an\noverview of the major theoretical advances as well as the main trends in\nalgorithmic developments in the area of sparsity-aware learning and compressed\nsensing. Both batch processing and online processing techniques are considered.\nA case study in the context of time-frequency analysis of signals is also\npresented. Our intent is to update this review from time to time, since this is\na very hot research area with a momentum and speed that is sometimes difficult\nto follow up. \n\n"}
{"id": "1211.5380", "contents": "Title: Interference Alignment with Incomplete CSIT Sharing Abstract: In this work, we study the impact of having only incomplete channel state\ninformation at the transmitters (CSIT) over the feasibility of interference\nalignment (IA) in a K-user MIMO interference channel (IC). Incompleteness of\nCSIT refers to the perfect knowledge at each transmitter (TX) of only a\nsub-matrix of the global channel matrix, where the sub-matrix is specific to\neach TX. This paper investigates the notion of IA feasibility for CSIT\nconfigurations being as incomplete as possible, as this leads to feedback\noverhead reductions in practice. We distinguish between antenna configurations\nwhere (i) removing a single antenna makes IA unfeasible, referred to as\ntightly-feasible settings, and (ii) cases where extra antennas are available,\nreferred to as super-feasible settings. We show conditions for which IA is\nfeasible in strictly incomplete CSIT scenarios, even in tightly-feasible\nsettings. For such cases, we provide a CSIT allocation policy preserving IA\nfeasibility while reducing significantly the amount of CSIT required. For\nsuper-feasible settings, we develop a heuristic CSIT allocation algorithm which\nexploits the additional antennas to further reduce the size of the CSIT\nallocation. As a byproduct of our approach, a simple and intuitive algorithm\nfor testing feasibility of single stream IA is provided. \n\n"}
{"id": "1211.6218", "contents": "Title: Adaptive Interference Alignment with CSI Uncertainty Abstract: Interference alignment (IA) is known to significantly increase sum-throughput\nat high SNR in the presence of multiple interfering nodes, however, the\nreliability of IA is little known, which is the subject of this paper. We study\nthe error performance of IA and compare it with conventional orthogonal\ntransmission schemes. Since most IA algorithms require extensive channel state\ninformation (CSI), we also investigate the impact of CSI imperfection\n(uncertainty) on the error performance. Our results show that under identical\nrates, IA attains a better error performance than the orthogonal scheme for\npractical signal to noise ratio (SNR) values but is more sensitive to CSI\nuncertainty. We design bit loading algorithms that significantly improve error\nperformance of the existing IA schemes. Furthermore, we propose an adaptive\ntransmission scheme that not only considerably reduces error probability, but\nalso produces robustness to CSI uncertainty. \n\n"}
{"id": "1212.1223", "contents": "Title: Throughput Analysis of Primary and Secondary Networks in a Shared IEEE\n  802.11 System Abstract: In this paper, we analyze the coexistence of a primary and a secondary\n(cognitive) network when both networks use the IEEE 802.11 based distributed\ncoordination function for medium access control. Specifically, we consider the\nproblem of channel capture by a secondary network that uses spectrum sensing to\ndetermine the availability of the channel, and its impact on the primary\nthroughput. We integrate the notion of transmission slots in Bianchi's Markov\nmodel with the physical time slots, to derive the transmission probability of\nthe secondary network as a function of its scan duration. This is used to\nobtain analytical expressions for the throughput achievable by the primary and\nsecondary networks. Our analysis considers both saturated and unsaturated\nnetworks. By performing a numerical search, the secondary network parameters\nare selected to maximize its throughput for a given level of protection of the\nprimary network throughput. The theoretical expressions are validated using\nextensive simulations carried out in the Network Simulator 2. Our results\nprovide critical insights into the performance and robustness of different\nschemes for medium access by the secondary network. In particular, we find that\nthe channel captures by the secondary network does not significantly impact the\nprimary throughput, and that simply increasing the secondary contention window\nsize is only marginally inferior to silent-period based methods in terms of its\nthroughput performance. \n\n"}
{"id": "1212.2693", "contents": "Title: Towards the full information chain theory: question difficulty Abstract: A general problem of optimal information acquisition for its use in decision\nmaking problems is considered. This motivates the need for developing\nquantitative measures of information sources' capabilities for supplying\naccurate information depending on the particular content of the latter. In this\narticle, the notion of a real valued difficulty functional for questions\nidentified with partitions of problem parameter space is introduced and the\noverall form of this functional is derived that satisfies a particular system\nof reasonable postulates. It is found that, in an isotropic case, the resulting\ndifficulty functional depends on a single scalar function on the parameter\nspace that can be interpreted -- using parallels with classical thermodynamics\n-- as a temperature-like quantity, with the question difficulty itself playing\nthe role of thermal energy. Quantitative relationships between difficulty\nfunctionals of different questions are also explored. \n\n"}
{"id": "1212.4663", "contents": "Title: Concentration of Measure Inequalities in Information Theory,\n  Communications and Coding (Second Edition) Abstract: During the last two decades, concentration inequalities have been the subject\nof exciting developments in various areas, including convex geometry,\nfunctional analysis, statistical physics, high-dimensional statistics, pure and\napplied probability theory, information theory, theoretical computer science,\nand learning theory. This monograph focuses on some of the key modern\nmathematical tools that are used for the derivation of concentration\ninequalities, on their links to information theory, and on their various\napplications to communications and coding. In addition to being a survey, this\nmonograph also includes various new recent results derived by the authors. The\nfirst part of the monograph introduces classical concentration inequalities for\nmartingales, as well as some recent refinements and extensions. The power and\nversatility of the martingale approach is exemplified in the context of codes\ndefined on graphs and iterative decoding algorithms, as well as codes for\nwireless communication. The second part of the monograph introduces the entropy\nmethod, an information-theoretic technique for deriving concentration\ninequalities. The basic ingredients of the entropy method are discussed first\nin the context of logarithmic Sobolev inequalities, which underlie the\nso-called functional approach to concentration of measure, and then from a\ncomplementary information-theoretic viewpoint based on transportation-cost\ninequalities and probability in metric spaces. Some representative results on\nconcentration for dependent random variables are briefly summarized, with\nemphasis on their connections to the entropy method. Finally, we discuss\nseveral applications of the entropy method to problems in communications and\ncoding, including strong converses, empirical distributions of good channel\ncodes, and an information-theoretic converse for concentration of measure. \n\n"}
{"id": "1212.5032", "contents": "Title: Distributed Rate Allocation in Inter-Session Network Coding Abstract: In this work, we propose a distributed rate allocation algorithm that\nminimizes the average decoding delay for multimedia clients in inter-session\nnetwork coding systems. We consider a scenario where the users are organized in\na mesh network and each user requests the content of one of the available\nsources. We propose a novel distributed algorithm where network users determine\nthe coding operations and the packet rates to be requested from the parent\nnodes, such that the decoding delay is minimized for all the clients. A rate\nallocation problem is solved by every user, which seeks the rates that minimize\nthe average decoding delay for its children and for itself. Since the\noptimization problem is a priori non-convex, we introduce the concept of\nequivalent packet flows, which permits to estimate the expected number of\npackets that every user needs to collect for decoding. We then decompose our\noriginal rate allocation problem into a set of convex subproblems, which are\neventually combined to obtain an effective approximate solution to the delay\nminimization problem. The results demonstrate that the proposed scheme\neliminates the bottlenecks and reduces the decoding delay experienced by users\nwith limited bandwidth resources. We validate the performance of our\ndistributed rate allocation algorithm in different video streaming scenarios\nusing the NS-3 network simulator. We show that our system is able to take\nbenefit of inter-session network coding for simultaneous delivery of video\nsessions in networks with path diversity. \n\n"}
{"id": "1212.6437", "contents": "Title: Joint Sensing and Power Allocation in Nonconvex Cognitive Radio Games:\n  Nash Equilibria and Distributed Algorithms Abstract: In this paper, we propose a novel class of Nash problems for Cognitive Radio\n(CR) networks, modeled as Gaussian frequency-selective interference channels,\nwherein each secondary user (SU) competes against the others to maximize his\nown opportunistic throughput by choosing jointly the sensing duration, the\ndetection thresholds, and the vector power allocation. The proposed general\nformulation allows to accommodate several (transmit) power and\n(deterministic/probabilistic) interference constraints, such as constraints on\nthe maximum individual and/or aggregate (probabilistic) interference tolerable\nat the primary receivers. To keep the optimization as decentralized as\npossible, global (coupling) interference constraints are imposed by penalizing\neach SU with a set of time-varying prices based upon his contribution to the\ntotal interference; the prices are thus additional variable to optimize. The\nresulting players' optimization problems are nonconvex; moreover, there are\npossibly price clearing conditions associated with the global constraints to be\nsatisfied by the solution. All this makes the analysis of the proposed games a\nchallenging task; none of classical results in the game theory literature can\nbe successfully applied. The main contribution of this paper is to develop a\nnovel optimization-based theory for studying the proposed nonconvex games; we\nprovide a comprehensive analysis of the existence and uniqueness of a standard\nNash equilibrium, devise alternative best-response based algorithms, and\nestablish their convergence. \n\n"}
{"id": "1212.6734", "contents": "Title: Pushing the Limits of LTE: A Survey on Research Enhancing the Standard Abstract: Cellular networks are an essential part of todays communication\ninfrastructure. The ever-increasing demand for higher data-rates calls for a\nclose cooperation between researchers and industry/standardization experts\nwhich hardly exists in practice. In this article we give an overview about our\nefforts in trying to bridge this gap. Our research group provides a\nstandard-compliant open-source simulation platform for 3GPP LTE that enables\nreproducible research in a well-defined environment. We demonstrate that much\ninnovative research under the confined framework of a real-world standard is\nstill possible, sometimes even encouraged. With examplary samples of our\nresearch work we investigate on the potential of several important research\nareas under typical practical conditions. \n\n"}
{"id": "1212.6888", "contents": "Title: SU(1,1) Nonlinear Coherent States Abstract: The idea of construction of the nonlinear coherent states based on the\nhypergeometric- type operators associated to the Weyl-Heisenberg group [J:P\nhys:A 45(2012) 095304], are generalized to the similar states for the arbitrary\nLie group SU(1, 1). By using of a discrete, unitary and irreducible\nrepresentation of the Lie algebra su(1, 1) wide range of generalized nonlinear\ncoherent states(GNCS) have been introduced, which admit a resolution of the\nidentity through positive definite measures on the complex plane. We have shown\nthat realization of these states for different values of the deformation pa-\nrameters r = 1 and 2 lead to the well-known Klauder-Perelomov and\nBarut-Girardello coherent states associated to the Irreps of the Lie algebra\nsu(1, 1), respectively. It is worth to mention that, like the canonical\ncoherent states, GNCS possess the temporal stability property. Finally,\nstudying some statistical characters implies that they have indeed nonclassical\nfeatures such as squeezing, anti-bunching effect and sub-Poissonian statistics,\ntoo. \n\n"}
{"id": "1301.1415", "contents": "Title: On Complex LLL Algorithm for Integer Forcing Linear Receivers Abstract: Integer-forcing (IF) linear receiver has been recently introduced for\nmultiple-input multiple-output (MIMO) fading channels. The receiver has to\ncompute an integer linear combination of the symbols as a part of the decoding\nprocess. In particular, the integer coefficients have to be chosen based on the\nchannel realizations, and the choice of such coefficients is known to determine\nthe receiver performance. The original known solution of finding these integers\nwas based on exhaustive search. A practical algorithm based on\nHermite-Korkine-Zolotareff (HKZ) and Minkowski lattice reduction algorithms was\nalso proposed recently. In this paper, we propose a low-complexity method based\non complex LLL algorithm to obtain the integer coefficients for the IF\nreceiver. For the 2 X 2 MIMO channel, we study the effectiveness of the\nproposed method in terms of the ergodic rate. We also compare the bit error\nrate (BER) of our approach with that of other linear receivers, and show that\nthe suggested algorithm outperforms the minimum mean square estimator (MMSE)\nand zero-forcing (ZF) linear receivers, but trades-off error performance for\ncomplexity in comparison with the IF receiver based on exhaustive search or on\nHKZ and Minkowski lattice reduction algorithms. \n\n"}
{"id": "1301.2138", "contents": "Title: On the Degrees of Freedom of the K-User Time Correlated Broadcast\n  Channel with Delayed CSIT Abstract: The Degrees of Freedom (DoF) of a K-User MISO Broadcast Channel (BC) is\nstudied when the Transmitter (TX) has access to a delayed channel estimate in\naddition to an imperfect estimate of the current channel. The current estimate\ncould be for example obtained from prediction applied on past estimates, in the\ncase where feedback delay is within the coherence time. Building on previous\nrecent works on this setting with two users, the estimation error of the\ncurrent channel is characterized by its scaling as P at the exponent \\alpha,\nwhere \\alpha=1 (resp. \\alpha=0) corresponds to an estimate being essentially\nperfect (resp. useless) in terms of DoF. In this work, we contribute to the\ncharacterization of the DoF region in such a setting by deriving an outerbound\nfor the DoF region and by providing an achievable DoF region. The achievable\nDoF is obtained by developing a new alignment scheme, called the K\\alpha-MAT\nscheme, which builds upon both the principle of the MAT alignment scheme from\nMaddah-Ali and Tse and Zero-Forcing to achieve a larger DoF when the delayed\nCSIT received is correlated with the instantaneous channel state. \n\n"}
{"id": "1301.3021", "contents": "Title: Accurate detection of moving targets via random sensor arrays and\n  Kerdock codes Abstract: The detection and parameter estimation of moving targets is one of the most\nimportant tasks in radar. Arrays of randomly distributed antennas have been\npopular for this purpose for about half a century. Yet, surprisingly little\nrigorous mathematical theory exists for random arrays that addresses\nfundamental question such as how many targets can be recovered, at what\nresolution, at which noise level, and with which algorithm. In a different line\nof research in radar, mathematicians and engineers have invested significant\neffort into the design of radar transmission waveforms which satisfy various\ndesirable properties. In this paper we bring these two seemingly unrelated\nareas together. Using tools from compressive sensing we derive a theoretical\nframework for the recovery of targets in the azimuth-range-Doppler domain via\nrandom antennas arrays. In one manifestation of our theory we use Kerdock codes\nas transmission waveforms and exploit some of their peculiar properties in our\nanalysis. Our paper provides two main contributions: (i) We derive the first\nrigorous mathematical theory for the detection of moving targets using random\nsensor arrays. (ii) The transmitted waveforms satisfy a variety of properties\nthat are very desirable and important from a practical viewpoint. Thus our\napproach does not just lead to useful theoretical insights, but is also of\npractical importance. Various extensions of our results are derived and\nnumerical simulations confirming our theory are presented. \n\n"}
{"id": "1301.5359", "contents": "Title: Local Graph Coloring and Index Coding Abstract: We present a novel upper bound for the optimal index coding rate. Our bound\nuses a graph theoretic quantity called the local chromatic number. We show how\na good local coloring can be used to create a good index code. The local\ncoloring is used as an alignment guide to assign index coding vectors from a\ngeneral position MDS code. We further show that a natural LP relaxation yields\nan even stronger index code. Our bounds provably outperform the state of the\nart on index coding but at most by a constant factor. \n\n"}
{"id": "1301.6209", "contents": "Title: On the achievable region for interference networks with point-to-point\n  codes Abstract: This paper studies evaluation of the capacity region for interference\nnetworks with point-to-point (p2p) capacity-achieving codes. Such capacity\nregion has recently been characterized as union of several sub-regions each of\nwhich has distinctive operational characteristics. Detailed evaluation of this\nregion, therefore, can be accomplished in a very simple manner by acknowledging\nsuch characteristics, which, in turn, provides an insight for a simple\nimplementation scenario. Completely generalized message assignment which is\nalso practically relevant is considered in this paper, and it is shown to\nprovide strictly larger achievable rates than what traditional message\nassignment does when a receiver with joint decoding capability is used. \n\n"}
{"id": "1301.6291", "contents": "Title: Nested Lattice Codes for Gaussian Two-Way Relay Channels Abstract: In this paper, we consider a Gaussian two-way relay channel (GTRC), where two\nsources exchange messages with each other through a relay. We assume that there\nis no direct link between sources, and all nodes operate in full-duplex mode.\nBy utilizing nested lattice codes for the uplink (i.e., MAC phase), and\nstructured binning for the downlink (i.e., broadcast phase), we propose two\nachievable schemes. Scheme 1 is based on compute and forward scheme of [1]\nwhile scheme 2 utilizes two different lattices for source nodes based on a\nthree-stage lattice partition chain. We show that scheme 2 can achieve capacity\nregion at the high signal-to-noise ratio (SNR). Regardless all channel\nparameters, the achievable rate of scheme 2 is within 0.2654 bit from the\ncut-set outer bound for user 1. For user 2, the proposed scheme achieves within\n0.167 bit from the outer bound if channel coefficient is larger than one, and\nachieves within 0.2658 bit from the outer bound if channel coefficient is\nsmaller than one. Moreover, sum rate of the proposed scheme is within 0.334\nbits from the sum capacity. These gaps for GTRC are the best gap-to-capacity\nresults to date. \n\n"}
{"id": "1301.6345", "contents": "Title: On AVCs with Quadratic Constraints Abstract: In this work we study an Arbitrarily Varying Channel (AVC) with quadratic\npower constraints on the transmitter and a so-called \"oblivious\" jammer (along\nwith additional AWGN) under a maximum probability of error criterion, and no\nprivate randomness between the transmitter and the receiver. This is in\ncontrast to similar AVC models under the average probability of error criterion\nconsidered in [1], and models wherein common randomness is allowed [2] -- these\ndistinctions are important in some communication scenarios outlined below.\n  We consider the regime where the jammer's power constraint is smaller than\nthe transmitter's power constraint (in the other regime it is known no positive\nrate is possible). For this regime we show the existence of stochastic codes\n(with no common randomness between the transmitter and receiver) that enables\nreliable communication at the same rate as when the jammer is replaced with\nAWGN with the same power constraint. This matches known information-theoretic\nouter bounds. In addition to being a stronger result than that in [1] (enabling\nrecovery of the results therein), our proof techniques are also somewhat more\ndirect, and hence may be of independent interest. \n\n"}
{"id": "1302.0749", "contents": "Title: Multi-Way Information Exchange Over Completely-Connected Interference\n  Networks with a Multi-Antenna Relay Abstract: This paper considers a fully-connected interference network with a relay in\nwhich multiple users equipped with a single antenna want to exchange multiple\nunicast messages with other users in the network by sharing the relay equipped\nwith multiple antennas. For such a network, the degrees of freedom (DoF) are\nderived by considering various message exchange scenarios: a multi-user\nfully-connected Y channel, a two-pair two-way interference channel with the\nrelay, and a two-pair two-way X channel with the relay. Further, considering\ndistributed relays employing a single antenna in the two-way interference\nchannel and the three-user fully-connected Y channel, achievable sum-DoF are\nalso derived in the two-way interference channel and the three-user\nfully-connected Y channel. A major implication of the derived DoF results is\nthat a relay with multiple antennas or multiple relays employing a single\nantenna increases the capacity scaling law of the multi-user interference\nnetwork when multiple directional information flows are considered, even if the\nnetworks are fully-connected and all nodes operate in half-duplex. These\nresults reveal that the relay is useful in the multi-way interference network\nwith practical considerations. \n\n"}
{"id": "1302.1256", "contents": "Title: Repairing Multiple Failures in the Suh-Ramchandran Regenerating Codes Abstract: Using the idea of interference alignment, Suh and Ramchandran constructed a\nclass of minimum-storage regenerating codes which can repair one systematic or\none parity-check node with optimal repair bandwidth. With the same code\nstructure, we show that in addition to single node failure, double node\nfailures can be repaired collaboratively with optimal repair bandwidth as well.\nWe give an example of how to repair double failures in the Suh-Ramchandran\nregenerating code with six nodes, and give the proof for the general case. \n\n"}
{"id": "1302.2512", "contents": "Title: Which Boolean Functions are Most Informative? Abstract: We introduce a simply stated conjecture regarding the maximum mutual\ninformation a Boolean function can reveal about noisy inputs. Specifically, let\n$X^n$ be i.i.d. Bernoulli(1/2), and let $Y^n$ be the result of passing $X^n$\nthrough a memoryless binary symmetric channel with crossover probability\n$\\alpha$. For any Boolean function $b:\\{0,1\\}^n\\rightarrow \\{0,1\\}$, we\nconjecture that $I(b(X^n);Y^n)\\leq 1-H(\\alpha)$. While the conjecture remains\nopen, we provide substantial evidence supporting its validity. \n\n"}
{"id": "1302.5906", "contents": "Title: Achieving AWGN Channel Capacity With Lattice Gaussian Coding Abstract: We propose a new coding scheme using only one lattice that achieves the\n$\\frac{1}{2}\\log(1+\\SNR)$ capacity of the additive white Gaussian noise (AWGN)\nchannel with lattice decoding, when the signal-to-noise ratio $\\SNR>e-1$. The\nscheme applies a discrete Gaussian distribution over an AWGN-good lattice, but\notherwise does not require a shaping lattice or dither. Thus, it significantly\nsimplifies the default lattice coding scheme of Erez and Zamir which involves a\nquantization-good lattice as well as an AWGN-good lattice. Using the flatness\nfactor, we show that the error probability of the proposed scheme under minimum\nmean-square error (MMSE) lattice decoding is almost the same as that of Erez\nand Zamir, for any rate up to the AWGN channel capacity. We introduce the\nnotion of good constellations, which carry almost the same mutual information\nas that of continuous Gaussian inputs. We also address the implementation of\nGaussian shaping for the proposed lattice Gaussian coding scheme. \n\n"}
{"id": "1302.6660", "contents": "Title: Optimal rate algebraic list decoding using narrow ray class fields Abstract: We use class field theory, specifically Drinfeld modules of rank 1, to\nconstruct a family of asymptotically good algebraic-geometric (AG) codes over\nfixed alphabets. Over a field of size $\\ell^2$, these codes are within\n$2/(\\sqrt{\\ell}-1)$ of the Singleton bound. The functions fields underlying\nthese codes are subfields with a cyclic Galois group of the narrow ray class\nfield of certain function fields. The resulting codes are \"folded\" using a\ngenerator of the Galois group. This generalizes earlier work by the first\nauthor on folded AG codes based on cyclotomic function fields. Using the\nChebotarev density theorem, we argue the abundance of inert places of large\ndegree in our cyclic extension, and use this to devise a linear-algebraic\nalgorithm to list decode these folded codes up to an error fraction approaching\n$1-R$ where $R$ is the rate. The list decoding can be performed in polynomial\ntime given polynomial amount of pre-processed information about the function\nfield.\n  Our construction yields algebraic codes over constant-sized alphabets that\ncan be list decoded up to the Singleton bound --- specifically, for any desired\nrate $R \\in (0,1)$ and constant $\\eps > 0$, we get codes over an alphabet size\n$(1/\\eps)^{O(1/\\eps^2)}$ that can be list decoded up to error fraction\n$1-R-\\eps$ confining close-by messages to a subspace with $N^{O(1/\\eps^2)}$\nelements. Previous results for list decoding up to error-fraction $1-R-\\eps$\nover constant-sized alphabets were either based on concatenation or involved\ntaking a carefully sampled subcode of algebraic-geometric codes. In contrast,\nour result shows that these folded algebraic-geometric codes {\\em themselves}\nhave the claimed list decoding property. \n\n"}
{"id": "1303.0696", "contents": "Title: A Technique for Deriving One-Shot Achievability Results in Network\n  Information Theory Abstract: This paper proposes a novel technique to prove a one-shot version of\nachievability results in network information theory. The technique is not based\non covering and packing lemmas. In this technique, we use an stochastic encoder\nand decoder with a particular structure for coding that resembles both the ML\nand the joint-typicality coders. Although stochastic encoders and decoders do\nnot usually enhance the capacity region, their use simplifies the analysis. The\nJensen inequality lies at the heart of error analysis, which enables us to deal\nwith the expectation of many terms coming from stochastic encoders and decoders\nat once. The technique is illustrated via several examples: point-to-point\nchannel coding, Gelfand-Pinsker, Broadcast channel (Marton), Berger-Tung,\nHeegard-Berger/Kaspi, Multiple description coding and Joint source-channel\ncoding over a MAC. Most of our one-shot results are new. The asymptotic forms\nof these expressions is the same as that of classical results. Our one-shot\nbounds in conjunction with multi-dimensional Berry-Essen CLT imply new results\nin the finite blocklength regime. In particular applying the one-shot result\nfor the memoryless broadcast channel in the asymptotic case, we get the entire\nregion of Marton's inner bound without any need for time-sharing. \n\n"}
{"id": "1303.1201", "contents": "Title: Multi-Pair Amplify-and-Forward Relaying with Very Large Antenna Arrays Abstract: We consider a multi-pair relay channel where multiple sources simultaneously\ncommunicate with destinations using a relay. Each source or destination has\nonly a single antenna, while the relay is equipped with a very large antenna\narray. We investigate the power efficiency of this system when maximum ratio\ncombining/maximal ratio transmission (MRC/MRT) or zero-forcing (ZF) processing\nis used at the relay. Using a very large array, the transmit power of each\nsource or relay (or both) can be made inversely proportional to the number of\nrelay antennas while maintaining a given quality-of-service. At the same time,\nthe achievable sum rate can be increased by a factor of the number of\nsource-destination pairs. We show that when the number of antennas grows to\ninfinity, the asymptotic achievable rates of MRC/MRT and ZF are the same if we\nscale the power at the sources. Depending on the large scale fading effect,\nMRC/MRT can outperform ZF or vice versa if we scale the power at the relay. \n\n"}
{"id": "1303.1647", "contents": "Title: Relay Selection for Simultaneous Information Transmission and Wireless\n  Energy Transfer: A Tradeoff Perspective Abstract: In certain applications, relay terminals can be employed to simultaneously\ndeliver information and energy to a designated receiver and a radio frequency\n(RF) energy harvester, respectively. In such scenarios, the relay that is\npreferable for information transmission does not necessarily coincide with the\nrelay with the strongest channel to the energy harvester, since the\ncorresponding channels fade independently. Relay selection thus entails a\ntradeoff between the efficiency of the information transfer to the receiver and\nthe amount of energy transferred to the energy harvester. The study of this\ntradeoff is the subject on which this work mainly focuses. Specifically, we\ninvestigate the behavior of the ergodic capacity and the outage probability of\nthe information transmission to the receiver, for a given amount of energy\ntransferred to the RF energy harvester. We propose two relay selection methods\nthat apply to any number of available relays. Furthermore, for the case of two\nrelays, we develop the optimal relay selection method in a maximum capacity /\nminimum outage probability sense, for a given energy transfer constraint. A\nclose-to-optimal selection method that is easier to analyze than the optimal\none is also examined. Closed-form expressions for the capacity-energy and the\noutage-energy tradeoffs of the developed schemes are provided and corroborated\nby simulations. Interesting insights on the aforementioned tradeoffs are\nobtained. \n\n"}
{"id": "1303.2257", "contents": "Title: A stochastic gradient approach on compressive sensing signal\n  reconstruction based on adaptive filtering framework Abstract: Based on the methodological similarity between sparse signal reconstruction\nand system identification, a new approach for sparse signal reconstruction in\ncompressive sensing (CS) is proposed in this paper. This approach employs a\nstochastic gradient-based adaptive filtering framework, which is commonly used\nin system identification, to solve the sparse signal reconstruction problem.\nTwo typical algorithms for this problem: $l_0$-least mean square ($l_0$-LMS)\nalgorithm and $l_0$-exponentially forgetting window LMS ($l_0$-EFWLMS)\nalgorithm are hence introduced here. Both the algorithms utilize a zero\nattraction method, which has been implemented by minimizing a continuous\napproximation of $l_0$ norm of the studied signal. To improve the performances\nof these proposed algorithms, an $l_0$-zero attraction projection ($l_0$-ZAP)\nalgorithm is also adopted, which has effectively accelerated their convergence\nrates, making them much faster than the other existing algorithms for this\nproblem. Advantages of the proposed approach, such as its robustness against\nnoise etc., are demonstrated by numerical experiments. \n\n"}
{"id": "1303.2870", "contents": "Title: CoMP Meets Smart Grid: A New Communication and Energy Cooperation\n  Paradigm Abstract: In this paper, we pursue a unified study on smart grid and coordinated\nmulti-point (CoMP) enabled wireless communication by investigating a new joint\ncommunication and energy cooperation approach. We consider a practical CoMP\nsystem with clustered multiple-antenna base stations (BSs) cooperatively\ncommunicating with multiple single-antenna mobile terminals (MTs), where each\nBS is equipped with local renewable energy generators to supply power and also\na smart meter to enable two-way energy flow with the grid. We propose a new\nenergy cooperation paradigm, where a group of BSs dynamically share their\nrenewable energy for more efficient operation via locally injecting/drawing\npower to/from an aggregator with a zero effective sum-energy exchanged. Under\nthis new energy cooperation model, we consider the downlink transmission in one\nCoMP cluster with cooperative zero-forcing (ZF) based precoding at the BSs. We\nmaximize the weighted sum-rate for all MTs by jointly optimizing the transmit\npower allocations at cooperative BSs and their exchanged energy amounts subject\nto a new type of power constraints featuring energy cooperation among BSs with\npractical loss ratios. Our new setup with BSs' energy cooperation generalizes\nthe conventional CoMP transmit optimization under BSs' sum-power or\nindividual-power constraints. Finally, we validate our results by simulations\nunder various practical setups, and show that the proposed joint communication\nand energy cooperation scheme substantially improves the downlink throughput of\nCoMP systems powered by smart grid and renewable energy, as compared to other\nsuboptimal designs without communication and/or energy cooperation. \n\n"}
{"id": "1303.3381", "contents": "Title: Discrete versions of the transport equation and the Shepp-Olkin\n  conjecture Abstract: We introduce a framework to consider transport problems for integer-valued\nrandom variables. We introduce weighting coefficients which allow us to\ncharacterize transport problems in a gradient flow setting, and form the basis\nof our introduction of a discrete version of the Benamou-Brenier formula.\nFurther, we use these coefficients to state a new form of weighted\nlog-concavity. These results are applied to prove the monotone case of the\nShepp-Olkin entropy concavity conjecture. \n\n"}
{"id": "1303.5003", "contents": "Title: Convolutional Codes: Techniques of Construction Abstract: In this paper we show how to construct new convolutional codes from old ones\nby applying the well-known techniques: puncturing, extending, expanding, direct\nsum, the (u|u + v) construction and the product code construction. By applying\nthese methods, several new families of convolutional codes can be constructed.\nAs an example of code expansion, families of convolutional codes derived from\nclassical Bose- Chaudhuri-Hocquenghem (BCH), character codes and Melas codes\nare constructed. \n\n"}
{"id": "1303.6409", "contents": "Title: Information Measures for Deterministic Input-Output Systems Abstract: In this work the information loss in deterministic, memoryless systems is\ninvestigated by evaluating the conditional entropy of the input random variable\ngiven the output random variable. It is shown that for a large class of systems\nthe information loss is finite, even if the input is continuously distributed.\nBased on this finiteness, the problem of perfectly reconstructing the input is\naddressed and Fano-type bounds between the information loss and the\nreconstruction error probability are derived.\n  For systems with infinite information loss a relative measure is defined and\nshown to be tightly related to R\\'{e}nyi information dimension. Employing\nanother Fano-type argument, the reconstruction error probability is bounded by\nthe relative information loss from below.\n  In view of developing a system theory from an information-theoretic\npoint-of-view, the theoretical results are illustrated by a few example\nsystems, among them a multi-channel autocorrelation receiver. \n\n"}
{"id": "1303.6672", "contents": "Title: Living on the edge: Phase transitions in convex programs with random\n  data Abstract: Recent research indicates that many convex optimization problems with random\nconstraints exhibit a phase transition as the number of constraints increases.\nFor example, this phenomenon emerges in the $\\ell_1$ minimization method for\nidentifying a sparse vector from random linear measurements. Indeed, the\n$\\ell_1$ approach succeeds with high probability when the number of\nmeasurements exceeds a threshold that depends on the sparsity level; otherwise,\nit fails with high probability.\n  This paper provides the first rigorous analysis that explains why phase\ntransitions are ubiquitous in random convex optimization problems. It also\ndescribes tools for making reliable predictions about the quantitative aspects\nof the transition, including the location and the width of the transition\nregion. These techniques apply to regularized linear inverse problems with\nrandom measurements, to demixing problems under a random incoherence model, and\nalso to cone programs with random affine constraints.\n  The applied results depend on foundational research in conic geometry. This\npaper introduces a summary parameter, called the statistical dimension, that\ncanonically extends the dimension of a linear subspace to the class of convex\ncones. The main technical result demonstrates that the sequence of intrinsic\nvolumes of a convex cone concentrates sharply around the statistical dimension.\nThis fact leads to accurate bounds on the probability that a randomly rotated\ncone shares a ray with a fixed cone. \n\n"}
{"id": "1303.6801", "contents": "Title: Enumerating Some Fractional Repetition Codes Abstract: In a distributed storage systems (DSS), regenerating codes are used to\noptimize bandwidth in the repair process of a failed node. To optimize other\nDSS parameters such as computation and disk I/O, Distributed Replication-based\nSimple Storage (Dress) Codes consisting of an inner Fractional Repetition (FR)\ncode and an outer MDS code are commonly used. Thus constructing FR codes is an\nimportant research problem, and several constructions using graphs and designs\nhave been proposed. In this paper, we present an algorithm for constructing the\nnode-packet distribution matrix of FR codes and thus enumerate some FR codes up\nto a given number of nodes n. We also present algorithms for constructing\nregular graphs which give rise to FR codes. \n\n"}
{"id": "1303.7000", "contents": "Title: Index Coding Capacity: How far can one go with only Shannon\n  Inequalities? Abstract: An interference alignment perspective is used to identify the simplest\ninstances (minimum possible number of edges in the alignment graph, no more\nthan 2 interfering messages at any destination) of index coding problems where\nnon-Shannon information inequalities are necessary for capacity\ncharacterization. In particular, this includes the first known example of a\nmultiple unicast (one destination per message) index coding problem where\nnon-Shannon information inequalities are shown to be necessary. The simplest\nmultiple unicast example has 7 edges in the alignment graph and 11 messages.\nThe simplest multiple groupcast (multiple destinations per message) example has\n6 edges in the alignment graph, 6 messages, and 10 receivers. For both the\nsimplest multiple unicast and multiple groupcast instances, the best outer\nbound based on only Shannon inequalities is $\\frac{2}{5}$, which is tightened\nto $\\frac{11}{28}$ by the use of the Zhang-Yeung non-Shannon type information\ninequality, and the linear capacity is shown to be $\\frac{5}{13}$ using the\nIngleton inequality. Conversely, identifying the minimal challenging aspects of\nthe index coding problem allows an expansion of the class of solved index\ncoding problems up to (but not including) these instances. \n\n"}
{"id": "1303.7039", "contents": "Title: Joint Resource Partitioning and Offloading in Heterogeneous Cellular\n  Networks Abstract: In heterogeneous cellular networks (HCNs), it is desirable to offload mobile\nusers to small cells, which are typically significantly less congested than the\nmacrocells. To achieve sufficient load balancing, the offloaded users often\nhave much lower SINR than they would on the macrocell. This SINR degradation\ncan be partially alleviated through interference avoidance, for example time or\nfrequency resource partitioning, whereby the macrocell turns off in some\nfraction of such resources. Naturally, the optimal offloading strategy is\ntightly coupled with resource partitioning; the optimal amount of which in turn\ndepends on how many users have been offloaded. In this paper, we propose a\ngeneral and tractable framework for modeling and analyzing joint resource\npartitioning and offloading in a two-tier cellular network. With it, we are\nable to derive the downlink rate distribution over the entire network, and an\noptimal strategy for joint resource partitioning and offloading. We show that\nload balancing, by itself, is insufficient, and resource partitioning is\nrequired in conjunction with offloading to improve the rate of cell edge users\nin co-channel heterogeneous networks. \n\n"}
{"id": "1304.0941", "contents": "Title: Recovery of Sparse Signals via Generalized Orthogonal Matching Pursuit:\n  A New Analysis Abstract: As an extension of orthogonal matching pursuit (OMP) improving the recovery\nperformance of sparse signals, generalized OMP (gOMP) has recently been studied\nin the literature. In this paper, we present a new analysis of the gOMP\nalgorithm using restricted isometry property (RIP). We show that if the\nmeasurement matrix $\\mathbf{\\Phi} \\in \\mathcal{R}^{m \\times n}$ satisfies the\nRIP with $$\\delta_{\\max \\left\\{9, S + 1 \\right\\}K} \\leq \\frac{1}{8},$$ then\ngOMP performs stable reconstruction of all $K$-sparse signals $\\mathbf{x} \\in\n\\mathcal{R}^n$ from the noisy measurements $\\mathbf{y} = \\mathbf{\\Phi x} +\n\\mathbf{v}$ within $\\max \\left\\{K, \\left\\lfloor \\frac{8K}{S} \\right\\rfloor\n\\right\\}$ iterations where $\\mathbf{v}$ is the noise vector and $S$ is the\nnumber of indices chosen in each iteration of the gOMP algorithm. For Gaussian\nrandom measurements, our results indicate that the number of required\nmeasurements is essentially $m = \\mathcal{O}(K \\log \\frac{n}{K})$, which is a\nsignificant improvement over the existing result $m = \\mathcal{O}(K^2 \\log\n\\frac{n}{K})$, especially for large $K$. \n\n"}
{"id": "1304.3865", "contents": "Title: Distributed Cognitive Multiple Access Networks: Power Control,\n  Scheduling and Multiuser Diversity Abstract: This paper studies optimal distributed power allocation and scheduling\npolicies (DPASPs) for distributed total power and interference limited (DTPIL)\ncognitive multiple access networks in which secondary users (SU) independently\nperform power allocation and scheduling tasks using their local knowledge of\nsecondary transmitter secondary base-station (STSB) and secondary transmitter\nprimary base-station (STPB) channel gains. In such networks, transmission\npowers of SUs are limited by an average total transmission power constraint and\nby a constraint on the average interference power that SUs cause to the primary\nbase-station. We first establish the joint optimality of water-filling power\nallocation and threshold-based scheduling policies for DTPIL networks. We then\nshow that the secondary network throughput under the optimal DPASP scales\naccording to $\\frac{1}{\\e{}n_h}\\log\\logp{N}$, where $n_h$ is a parameter\nobtained from the distribution of STSB channel power gains and $N$ is the total\nnumber of SUs. From a practical point of view, our results signify the fact\nthat distributed cognitive multiple access networks are capable of harvesting\nmultiuser diversity gains without employing centralized schedulers and feedback\nlinks as well as without disrupting primary's quality-of-service (QoS) \n\n"}
{"id": "1304.3886", "contents": "Title: Minimum Variance Estimation of a Sparse Vector within the Linear\n  Gaussian Model: An RKHS Approach Abstract: We consider minimum variance estimation within the sparse linear Gaussian\nmodel (SLGM). A sparse vector is to be estimated from a linearly transformed\nversion embedded in Gaussian noise. Our analysis is based on the theory of\nreproducing kernel Hilbert spaces (RKHS). After a characterization of the RKHS\nassociated with the SLGM, we derive novel lower bounds on the minimum variance\nachievable by estimators with a prescribed bias function. This includes the\nimportant case of unbiased estimation. The variance bounds are obtained via an\northogonal projection of the prescribed mean function onto a subspace of the\nRKHS associated with the SLGM. Furthermore, we specialize our bounds to\ncompressed sensing measurement matrices and express them in terms of the\nrestricted isometry and coherence parameters. For the special case of the SLGM\ngiven by the sparse signal in noise model (SSNM), we derive closed-form\nexpressions of the minimum achievable variance (Barankin bound) and the\ncorresponding locally minimum variance estimator. We also analyze the effects\nof exact and approximate sparsity information and show that the minimum\nachievable variance for exact sparsity is not a limiting case of that for\napproximate sparsity. Finally, we compare our bounds with the variance of three\nwell-known estimators, namely, the maximum-likelihood estimator, the\nhard-thresholding estimator, and compressive reconstruction using the\northogonal matching pursuit. \n\n"}
{"id": "1304.4181", "contents": "Title: Rate-Distortion-Based Physical Layer Secrecy with Applications to\n  Multimode Fiber Abstract: Optical networks are vulnerable to physical layer attacks; wiretappers can\nimproperly receive messages intended for legitimate recipients. Our work\nconsiders an aspect of this security problem within the domain of multimode\nfiber (MMF) transmission. MMF transmission can be modeled via a broadcast\nchannel in which both the legitimate receiver's and wiretapper's channels are\nmultiple-input-multiple-output complex Gaussian channels. Source-channel coding\nanalyses based on the use of distortion as the metric for secrecy are\ndeveloped. Alice has a source sequence to be encoded and transmitted over this\nbroadcast channel so that the legitimate user Bob can reliably decode while\nforcing the distortion of wiretapper, or eavesdropper, Eve's estimate as high\nas possible. Tradeoffs between transmission rate and distortion under two\nextreme scenarios are examined: the best case where Eve has only her channel\noutput and the worst case where she also knows the past realization of the\nsource. It is shown that under the best case, an operationally separate\nsource-channel coding scheme guarantees maximum distortion at the same rate as\nneeded for reliable transmission. Theoretical bounds are given, and\nparticularized for MMF. Numerical results showing the rate distortion tradeoff\nare presented and compared with corresponding results for the perfect secrecy\ncase. \n\n"}
{"id": "1304.5038", "contents": "Title: One condition for solution uniqueness and robustness of both\n  l1-synthesis and l1-analysis minimizations Abstract: The $\\ell_1$-synthesis model and the $\\ell_1$-analysis model recover\nstructured signals from their undersampled measurements. The solution of former\nis a sparse sum of dictionary atoms, and that of the latter makes sparse\ncorrelations with dictionary atoms. This paper addresses the question: when can\nwe trust these models to recover specific signals? We answer the question with\na condition that is both necessary and sufficient to guarantee the recovery to\nbe unique and exact and, in presence of measurement noise, to be robust. The\ncondition is one--for--all in the sense that it applies to both of the\n$\\ell_1$-synthesis and $\\ell_1$-analysis models, to both of their constrained\nand unconstrained formulations, and to both the exact recovery and robust\nrecovery cases. Furthermore, a convex infinity--norm program is introduced for\nnumerically verifying the condition. A comprehensive comparison with related\nexisting conditions are included. \n\n"}
{"id": "1304.6159", "contents": "Title: Secrecy Sum-Rates with Regularized Channel Inversion Precoding under\n  Imperfect CSI at the Transmitter Abstract: In this paper, we study the performance of regularized channel inversion\nprecoding in MISO broadcast channels with confidential messages under imperfect\nchannel state information at the transmitter (CSIT). We obtain an approximation\nfor the achievable secrecy sum-rate which is almost surely exact as the number\nof transmit antennas and the number of users grow to infinity in a fixed ratio.\nSimulations prove this anaylsis accurate even for finite-size systems. For FDD\nsystems, we determine how the CSIT error must scale with the SNR, and we derive\nthe number of feedback bits required to ensure a constant high-SNR rate gap to\nthe case with perfect CSIT. For TDD systems, we study the optimum amount of\nchannel training that maximizes the high-SNR secrecy sum-rate. \n\n"}
{"id": "1304.6172", "contents": "Title: Outage Probability in Arbitrarily-Shaped Finite Wireless Networks Abstract: This paper analyzes the outage performance in finite wireless networks.\nUnlike most prior works, which either assumed a specific network shape or\nconsidered a special location of the reference receiver, we propose two general\nframeworks for analytically computing the outage probability at any arbitrary\nlocation of an arbitrarily-shaped finite wireless network: (i) a moment\ngenerating function-based framework which is based on the numerical inversion\nof the Laplace transform of a cumulative distribution and (ii) a reference link\npower gain-based framework which exploits the distribution of the fading power\ngain between the reference transmitter and receiver. The outage probability is\nspatially averaged over both the fading distribution and the possible locations\nof the interferers. The boundary effects are accurately accounted for using the\nprobability distribution function of the distance of a random node from the\nreference receiver. For the case of the node locations modeled by a Binomial\npoint process and Nakagami-$m$ fading channel, we demonstrate the use of the\nproposed frameworks to evaluate the outage probability at any location inside\neither a disk or polygon region. The analysis illustrates the location\ndependent performance in finite wireless networks and highlights the importance\nof accurately modeling the boundary effects. \n\n"}
{"id": "1304.7308", "contents": "Title: Improved Capacity Approximations for Gaussian Relay Networks Abstract: Consider a Gaussian relay network where a number of sources communicate to a\ndestination with the help of several layers of relays. Recent work has shown\nthat a compress-and-forward based strategy at the relays can achieve the\ncapacity of this network within an additive gap. In this strategy, the relays\nquantize their observations at the noise level and map it to a random Gaussian\ncodebook. The resultant capacity gap is independent of the SNR's of the\nchannels in the network but linear in the total number of nodes.\n  In this paper, we show that if the relays quantize their signals at a\nresolution decreasing with the number of nodes in the network, the additive gap\nto capacity can be made logarithmic in the number of nodes for a class of\nlayered, time-varying wireless relay networks. This suggests that the\nrule-of-thumb to quantize the received signals at the noise level used for\ncompress-and-forward in the current literature can be highly suboptimal. \n\n"}
{"id": "1304.7480", "contents": "Title: The Ergodic Capacity of the Multiple Access Channel Under Distributed\n  Scheduling - Order Optimality of Linear Receivers Abstract: Consider the problem of a Multiple-Input Multiple-Output (MIMO)\nMultiple-Access Channel (MAC) at the limit of large number of users. Clearly,\nin practical scenarios, only a small subset of the users can be scheduled to\nutilize the channel simultaneously. Thus, a problem of user selection arises.\nHowever, since solutions which collect Channel State Information (CSI) from all\nusers and decide on the best subset to transmit in each slot do not scale when\nthe number of users is large, distributed algorithms for user selection are\nadvantageous.\n  In this paper, we analyse a distributed user selection algorithm, which\nselects a group of users to transmit without coordinating between users and\nwithout all users sending CSI to the base station. This threshold-based\nalgorithm is analysed for both Zero-Forcing (ZF) and Minimum Mean Square Error\n(MMSE) receivers, and its expected sum-rate in the limit of large number of\nusers is investigated. It is shown that for large number of users it achieves\nthe same scaling laws as the optimal centralized scheme. \n\n"}
{"id": "1305.0060", "contents": "Title: Complexity penalized hydraulic fracture localization and moment tensor\n  estimation under limited model information Abstract: In this paper we present a novel technique for micro-seismic localization\nusing a group sparse penalization that is robust to the focal mechanism of the\nsource and requires only a velocity model of the stratigraphy rather than a\nfull Green's function model of the earth's response. In this technique we\nconstruct a set of perfect delta detector responses, one for each detector in\nthe array, to a seismic event at a given location and impose a group sparsity\nacross the array. This scheme is independent of the moment tensor and exploits\nthe time compactness of the incident seismic signal. Furthermore we present a\nmethod for improving the inversion of the moment tensor and Green's function\nwhen the geometry of seismic array is limited. In particular we demonstrate\nthat both Tikhonov regularization and truncated SVD can improve the recovery of\nthe moment tensor and be robust to noise. We evaluate our algorithm on\nsynthetic data and present error bounds for both estimation of the moment\ntensor as well as localization. Furthermore we discuss the estimated moment\ntensor accuracy as a function of both array geometry and fault orientation. \n\n"}
{"id": "1305.2789", "contents": "Title: Phaseless Signal Recovery in Infinite Dimensional Spaces using\n  Structured Modulations Abstract: This paper considers the recovery of continuous signals in infinite\ndimensional spaces from the magnitude of their frequency samples. It proposes a\nsampling scheme which involves a combination of oversampling and modulations\nwith complex exponentials. Sufficient conditions are given such that almost\nevery signal with compact support can be reconstructed up to a unimodular\nconstant using only its magnitude samples in the frequency domain. Finally it\nis shown that an average sampling rate of four times the Nyquist rate is enough\nto reconstruct almost every time-limited signal. \n\n"}
{"id": "1305.3498", "contents": "Title: An Improved Sub-Packetization Bound for Minimum Storage Regenerating\n  Codes Abstract: Distributed storage systems employ codes to provide resilience to failure of\nmultiple storage disks. Specifically, an $(n, k)$ MDS code stores $k$ symbols\nin $n$ disks such that the overall system is tolerant to a failure of up to\n$n-k$ disks. However, access to at least $k$ disks is still required to repair\na single erasure. To reduce repair bandwidth, array codes are used where the\nstored symbols or packets are vectors of length $\\ell$. MDS array codes have\nthe potential to repair a single erasure using a fraction $1/(n-k)$ of data\nstored in the remaining disks. We introduce new methods of analysis which\ncapitalize on the translation of the storage system problem into a geometric\nproblem on a set of operators and subspaces. In particular, we ask the\nfollowing question: for a given $(n, k)$, what is the minimum vector-length or\nsub-packetization factor $\\ell$ required to achieve this optimal fraction? For\n\\emph{exact recovery} of systematic disks in an MDS code of low redundancy,\ni.e. $k/n > 1/2$, the best known explicit codes \\cite{WTB12} have a\nsub-packetization factor $\\ell$ which is exponential in $k$. It has been\nconjectured \\cite{TWB12} that for a fixed number of parity nodes, it is in fact\nnecessary for $\\ell$ to be exponential in $k$. In this paper, we provide a new\nlog-squared converse bound on $k$ for a given $\\ell$, and prove that $k \\le\n2\\log_2\\ell\\left(\\log_{\\delta}\\ell+1\\right)$, for an arbitrary number of parity\nnodes $r = n-k$, where $\\delta = r/(r-1)$. \n\n"}
{"id": "1305.5278", "contents": "Title: The second laws of quantum thermodynamics Abstract: The second law of thermodynamics tells us which state transformations are so\nstatistically unlikely that they are effectively forbidden. Its original\nformulation, due to Clausius, states that \"Heat can never pass from a colder to\na warmer body without some other change, connected therewith, occurring at the\nsame time\". The second law applies to systems composed of many particles\ninteracting; however, we are seeing that one can make sense of thermodynamics\nin the regime where we only have a small number of particles interacting with a\nheat bath. Is there a second law of thermodynamics in this regime? Here, we\nfind that for processes which are cyclic or very close to cyclic, the second\nlaw for microscopic systems takes on a very different form than it does at the\nmacroscopic scale, imposing not just one constraint on what state\ntransformations are possible, but an entire family of constraints. In\nparticular, we find a family of free energies which generalise the traditional\none, and show that they can never increase. We further find that there are\nthree regimes which determine which family of second laws govern state\ntransitions, depending on how cyclic the process is. In one regime one can\ncause an apparent violation of the usual second law, through a process of\nembezzling work from a large system which remains arbitrarily close to its\noriginal state. These second laws are not only relevant for small systems, but\nalso apply to individual macroscopic systems interacting via long-range\ninteractions, which only satisfy the ordinary second law on average. By making\nprecise the definition of thermal operations, the laws of thermodynamics take\non a simple form with the first law defining the class of thermal operations,\nthe zeroeth law emerging as a unique condition ensuring the theory is\nnontrivial, and the remaining laws being a monotonicity property of our\ngeneralised free energies. \n\n"}
{"id": "1305.7323", "contents": "Title: Sub-Stream Fairness and Numerical Correctness in MIMO Interference\n  Channels Abstract: Signal-to-interference plus noise ratio (SINR) and rate fairness in a system\nare substantial quality-of-service (QoS) metrics. The acclaimed SINR\nmaximization (max-SINR) algorithm does not achieve fairness between user's\nstreams, i.e., sub-stream fairness is not achieved. To this end, we propose a\ndistributed power control algorithm to render sub-stream fairness in the\nsystem. Sub-stream fairness is a less restrictive design metric than stream\nfairness (i.e., fairness between all streams) thus sum-rate degradation is\nmilder. Algorithmic parameters can significantly differentiate the results of\nnumerical algorithms. A complete picture for comparison of algorithms can only\nbe depicted by varying these parameters. For example, a predetermined iteration\nnumber or a negligible increment in the sum-rate can be the stopping criteria\nof an algorithm. While the distributed interference alignment (DIA) can\nreasonably achieve sub-stream fairness for the later, the imbalance between\nsub-streams increases as the preset iteration number decreases. Thus comparison\nof max-SINR and DIA with a low preset iteration number can only depict a part\nof the picture. We analyze such important parameters and their effects on SINR\nand rate metrics to exhibit numerical correctness in executing the benchmarks.\nFinally, we propose group filtering schemes that jointly design the streams of\na user in contrast to max-SINR scheme that designs each stream of a user\nseparately. \n\n"}
{"id": "1306.0969", "contents": "Title: Secrecy Wireless Information and Power Transfer with MISO Beamforming Abstract: The dual use of radio signals for simultaneous wireless information and power\ntransfer (SWIPT) has recently drawn significant attention. To meet the\npractical requirement that energy receivers (ERs) operate with much higher\nreceived power than information receivers (IRs), ERs need to be deployed closer\nto the transmitter than IRs. However, due to the broadcast nature of wireless\nchannels, one critical issue is that the messages sent to IRs cannot be\neavesdropped by ERs, which possess better channels from the transmitter. In\nthis paper, we address this new secrecy communication problem in a multiuser\nmultiple-input single-output (MISO) SWIPT system where a multi-antenna\ntransmitter sends information and energy simultaneously to one IR and multiple\nERs, each with a single antenna. By optimizing transmit beamforming vectors and\ntheir power allocation, we maximize the weighted sum-energy transferred to ERs\nsubject to a secrecy rate constraint for the information sent to the IR. We\nsolve this non-convex problem optimally by reformulating it into a two-stage\nproblem. First, we fix the signal-to-interference-plus-noise ratio (SINR) at\nthe IR and obtain the optimal beamforming solution by applying the technique of\nsemidefinite relaxation (SDR). Then the original problem is solved by a\none-dimension search over the optimal SINR value for the IR. Furthermore, two\nsuboptimal low-complexity beamforming schemes are proposed, and their\nachievable (secrecy) rate-energy (R-E) regions are compared against that by the\noptimal scheme. \n\n"}
{"id": "1306.0992", "contents": "Title: Any network codes comes from an algebraic curve taking osculating spaces Abstract: In this note we prove that every network code over $\\mathbb {F}_q$ may be\nrealized taking some of the osculating spaces of a smooth projective curve. \n\n"}
{"id": "1306.1356", "contents": "Title: Analysis $\\ell_1$-recovery with frames and Gaussian measurements Abstract: This paper provides novel results for the recovery of signals from\nundersampled measurements based on analysis $\\ell_1$-minimization, when the\nanalysis operator is given by a frame. We both provide so-called uniform and\nnonuniform recovery guarantees for cosparse (analysis-sparse) signals using\nGaussian random measurement matrices. The nonuniform result relies on a\nrecovery condition via tangent cones and the uniform recovery guarantee is\nbased on an analysis version of the null space property. Examining these\nconditions for Gaussian random matrices leads to precise bounds on the number\nof measurements required for successful recovery. In the special case of\nstandard sparsity, our result improves a bound due to Rudelson and Vershynin\nconcerning the exact reconstruction of sparse signals from Gaussian\nmeasurements with respect to the constant and extends it to stability under\npassing to approximately sparse signals and to robustness under noise on the\nmeasurements. \n\n"}
{"id": "1306.3710", "contents": "Title: Symmetric Two-User MIMO BC and IC with Evolving Feedback Abstract: Extending recent findings on the two-user MISO broadcast channel (BC) with\nimperfect and delayed channel state information at the transmitter (CSIT), the\nwork here explores the performance of the two user MIMO BC and the two user\nMIMO interference channel (MIMO IC), in the presence of feedback with evolving\nquality and timeliness. Under standard assumptions, and in the presence of M\nantennas per transmitter and N antennas per receiver, the work derives the DoF\nregion, which is optimal for a large regime of sufficiently good (but\npotentially imperfect) delayed CSIT. This region concisely captures the effect\nof having predicted, current and delayed-CSIT, as well as concisely captures\nthe effect of the quality of CSIT offered at any time, about any channel. In\naddition to the progress towards describing the limits of using such imperfect\nand delayed feedback in MIMO settings, the work offers different insights that\ninclude the fact that, an increasing number of receive antennas can allow for\nreduced quality feedback, as well as that no CSIT is needed for the direct\nlinks in the IC. \n\n"}
{"id": "1306.3774", "contents": "Title: Under-determined linear systems and $\\ell_q$-optimization thresholds Abstract: Recent studies of under-determined linear systems of equations with sparse\nsolutions showed a great practical and theoretical efficiency of a particular\ntechnique called $\\ell_1$-optimization. Seminal works \\cite{CRT,DOnoho06CS}\nrigorously confirmed it for the first time. Namely, \\cite{CRT,DOnoho06CS}\nshowed, in a statistical context, that $\\ell_1$ technique can recover sparse\nsolutions of under-determined systems even when the sparsity is linearly\nproportional to the dimension of the system. A followup \\cite{DonohoPol} then\nprecisely characterized such a linearity through a geometric approach and a\nseries of work\\cite{StojnicCSetam09,StojnicUpper10,StojnicEquiv10} reaffirmed\nstatements of \\cite{DonohoPol} through a purely probabilistic approach. A\ntheoretically interesting alternative to $\\ell_1$ is a more general version\ncalled $\\ell_q$ (with an essentially arbitrary $q$). While $\\ell_1$ is\ntypically considered as a first available convex relaxation of sparsity norm\n$\\ell_0$, $\\ell_q,0\\leq q\\leq 1$, albeit non-convex, should technically be a\ntighter relaxation of $\\ell_0$. Even though developing polynomial (or close to\nbe polynomial) algorithms for non-convex problems is still in its initial\nphases one may wonder what would be the limits of an $\\ell_q,0\\leq q\\leq 1$,\nrelaxation even if at some point one can develop algorithms that could handle\nits non-convexity. A collection of answers to this and a few realted questions\nis precisely what we present in this paper. \n\n"}
{"id": "1306.3977", "contents": "Title: Compressed sensing of block-sparse positive vectors Abstract: In this paper we revisit one of the classical problems of compressed sensing.\nNamely, we consider linear under-determined systems with sparse solutions. A\nsubstantial success in mathematical characterization of an $\\ell_1$\noptimization technique typically used for solving such systems has been\nachieved during the last decade. Seminal works \\cite{CRT,DOnoho06CS} showed\nthat the $\\ell_1$ can recover a so-called linear sparsity (i.e. solve systems\neven when the solution has a sparsity linearly proportional to the length of\nthe unknown vector). Later considerations \\cite{DonohoPol,DonohoUnsigned} (as\nwell as our own ones \\cite{StojnicCSetam09,StojnicUpper10}) provided the\nprecise characterization of this linearity. In this paper we consider the\nso-called structured version of the above sparsity driven problem. Namely, we\nview a special case of sparse solutions, the so-called block-sparse solutions.\nTypically one employs $\\ell_2/\\ell_1$-optimization as a variant of the standard\n$\\ell_1$ to handle block-sparse case of sparse solution systems. We considered\nsystems with block-sparse solutions in a series of work\n\\cite{StojnicCSetamBlock09,StojnicUpperBlock10,StojnicICASSP09block,StojnicJSTSP09}\nwhere we were able to provide precise performance characterizations if the\n$\\ell_2/\\ell_1$-optimization similar to those obtained for the standard\n$\\ell_1$ optimization in \\cite{StojnicCSetam09,StojnicUpper10}. Here we look at\na similar class of systems where on top of being block-sparse the unknown\nvectors are also known to have components of the same sign. In this paper we\nslightly adjust $\\ell_2/\\ell_1$-optimization to account for the known signs and\nprovide a precise performance characterization of such an adjustment. \n\n"}
{"id": "1306.4391", "contents": "Title: On the Fundamental Limits of Recovering Tree Sparse Vectors from Noisy\n  Linear Measurements Abstract: Recent breakthrough results in compressive sensing (CS) have established that\nmany high dimensional signals can be accurately recovered from a relatively\nsmall number of non-adaptive linear observations, provided that the signals\npossess a sparse representation in some basis. Subsequent efforts have shown\nthat the performance of CS can be improved by exploiting additional structure\nin the locations of the nonzero signal coefficients during inference, or by\nutilizing some form of data-dependent adaptive measurement focusing during the\nsensing process. To our knowledge, our own previous work was the first to\nestablish the potential benefits that can be achieved when fusing the notions\nof adaptive sensing and structured sparsity -- that work examined the task of\nsupport recovery from noisy linear measurements, and established that an\nadaptive sensing strategy specifically tailored to signals that are tree-sparse\ncan significantly outperform adaptive and non-adaptive sensing strategies that\nare agnostic to the underlying structure. In this work we establish fundamental\nperformance limits for the task of support recovery of tree-sparse signals from\nnoisy measurements, in settings where measurements may be obtained either\nnon-adaptively (using a randomized Gaussian measurement strategy motivated by\ninitial CS investigations) or by any adaptive sensing strategy. Our main\nresults here imply that the adaptive tree sensing procedure analyzed in our\nprevious work is nearly optimal, in the sense that no other sensing and\nestimation strategy can perform fundamentally better for identifying the\nsupport of tree-sparse signals. \n\n"}
{"id": "1306.4934", "contents": "Title: On the Corner Points of the Capacity Region of a Two-User Gaussian\n  Interference Channel Abstract: This work considers the corner points of the capacity region of a two-user\nGaussian interference channel (GIC). In a two-user GIC, the rate pairs where\none user transmits its data at the single-user capacity (without interference),\nand the other at the largest rate for which reliable communication is still\npossible are called corner points. This paper relies on existing outer bounds\non the capacity region of a two-user GIC that are used to derive informative\nbounds on the corner points of the capacity region. The new bounds refer to a\nweak two-user GIC (i.e., when both cross-link gains in standard form are\npositive and below 1), and a refinement of these bounds is obtained for the\ncase where the transmission rate of one user is within $\\varepsilon > 0$ of the\nsingle-user capacity. The bounds on the corner points are asymptotically tight\nas the transmitted powers tend to infinity, and they are also useful for the\ncase of moderate SNR and INR. Upper and lower bounds on the gap (denoted by\n$\\Delta$) between the sum-rate and the maximal achievable total rate at the two\ncorner points are derived. This is followed by an asymptotic analysis analogous\nto the study of the generalized degrees of freedom (where the SNR and INR\nscalings are coupled such that $\\frac{\\log(\\text{INR})}{\\log(\\text{SNR})} =\n\\alpha \\geq 0$), leading to an asymptotic characterization of this gap which is\nexact for the whole range of $\\alpha$. The upper and lower bounds on $\\Delta$\nare asymptotically tight in the sense that they achieve the exact asymptotic\ncharacterization. Improved bounds on $\\Delta$ are derived for finite SNR and\nINR, and their improved tightness is exemplified numerically. \n\n"}
{"id": "1306.5299", "contents": "Title: Secret key generation from Gaussian sources using lattice hashing Abstract: We propose a simple yet complete lattice-based scheme for secret key\ngeneration from Gaussian sources in the presence of an eavesdropper, and show\nthat it achieves strong secret key rates up to 1/2 nat from the optimal in the\ncase of \"degraded\" source models. The novel ingredient of our scheme is a\nlattice-hashing technique, based on the notions of flatness factor and channel\nintrinsic randomness. The proposed scheme does not require dithering. \n\n"}
{"id": "1306.6909", "contents": "Title: Exact Support Recovery for Sparse Spikes Deconvolution Abstract: This paper studies sparse spikes deconvolution over the space of measures. We\nfocus our attention to the recovery properties of the support of the measure,\ni.e. the location of the Dirac masses. For non-degenerate sums of Diracs, we\nshow that, when the signal-to-noise ratio is large enough, total variation\nregularization (which is the natural extension of the L1 norm of vectors to the\nsetting of measures) recovers the exact same number of Diracs. We also show\nthat both the locations and the heights of these Diracs converge toward those\nof the input measure when the noise drops to zero. The exact speed of\nconvergence is governed by a specific dual certificate, which can be computed\nby solving a linear system. We draw connections between the support of the\nrecovered measure on a continuous domain and on a discretized grid. We show\nthat when the signal-to-noise level is large enough, the solution of the\ndiscretized problem is supported on pairs of Diracs which are neighbors of the\nDiracs of the input measure. This gives a precise description of the\nconvergence of the solution of the discretized problem toward the solution of\nthe continuous grid-free problem, as the grid size tends to zero. \n\n"}
{"id": "1307.0974", "contents": "Title: On Secure Source Coding with Side Information at the Encoder Abstract: We consider a secure source coding problem with side information (S.I.) at\nthe decoder and the eavesdropper. The encoder has a source that it wishes to\ndescribe with limited distortion through a rate limited link to a legitimate\ndecoder. The message sent is also observed by the eavesdropper. The encoder\naims to minimize both the distortion incurred by the legitimate decoder; and\nthe information leakage rate at the eavesdropper. When the encoder has access\nto the uncoded S.I. at the decoder, we characterize the\nrate-distortion-information leakage rate (R.D.I.) region under a Markov chain\nassumption and when S.I. at the encoder does not improve the rate-distortion\nregion as compared to the case when S.I. is absent. When the decoder also has\naccess to the eavesdroppers S.I., we characterize the R.D.I. region without the\nMarkov Chain condition. We then consider a related setting where the encoder\nand decoder obtain coded S.I. through a rate limited helper, and characterize\nthe R.D.I. region for several special cases, including special cases under\nlogarithmic loss distortion and for special cases of the Quadratic Gaussian\nsetting. Finally, we consider the amplification measures of list or entropy\nconstraint at the decoder, and show that the R.D.I. regions for the settings\nconsidered in this paper under these amplification measures coincide with\nR.D.I. regions under per symbol logarithmic loss distortion constraint at the\ndecoder. \n\n"}
{"id": "1307.2584", "contents": "Title: Massive MIMO Systems with Non-Ideal Hardware: Energy Efficiency,\n  Estimation, and Capacity Limits Abstract: The use of large-scale antenna arrays can bring substantial improvements in\nenergy and/or spectral efficiency to wireless systems due to the greatly\nimproved spatial resolution and array gain. Recent works in the field of\nmassive multiple-input multiple-output (MIMO) show that the user channels\ndecorrelate when the number of antennas at the base stations (BSs) increases,\nthus strong signal gains are achievable with little inter-user interference.\nSince these results rely on asymptotics, it is important to investigate whether\nthe conventional system models are reasonable in this asymptotic regime. This\npaper considers a new system model that incorporates general transceiver\nhardware impairments at both the BSs (equipped with large antenna arrays) and\nthe single-antenna user equipments (UEs). As opposed to the conventional case\nof ideal hardware, we show that hardware impairments create finite ceilings on\nthe channel estimation accuracy and on the downlink/uplink capacity of each UE.\nSurprisingly, the capacity is mainly limited by the hardware at the UE, while\nthe impact of impairments in the large-scale arrays vanishes asymptotically and\ninter-user interference (in particular, pilot contamination) becomes\nnegligible. Furthermore, we prove that the huge degrees of freedom offered by\nmassive MIMO can be used to reduce the transmit power and/or to tolerate larger\nhardware impairments, which allows for the use of inexpensive and\nenergy-efficient antenna elements. \n\n"}
{"id": "1307.5549", "contents": "Title: Insufficiency of Linear-Feedback Schemes In Gaussian Broadcast Channels\n  with Common Message Abstract: We consider the $K\\geq 2$-user memoryless Gaussian broadcast channel (BC)\nwith feedback and common message only. We show that linear-feedback schemes\nwith a message point, in the spirit of Schalkwijk & Kailath's scheme for\npoint-to-point channels or Ozarow & Leung's scheme for BCs with private\nmessages, are strictly suboptimal for this setup. Even with perfect feedback,\nthe largest rate achieved by these schemes is strictly smaller than capacity\n$C$ (which is the same with and without feedback). In the extreme case where\nthe number of receivers $K\\to \\infty$, the largest rate achieved by\nlinear-feedback schemes with a message point tends to 0.\n  To contrast this negative result, we describe a scheme for\n\\emph{rate-limited} feedback that uses the feedback in an intermittent way,\ni.e., the receivers send feedback signals only in few channel uses. This scheme\nachieves all rates $R$ up to capacity $C$ with an $L$-th order exponential\ndecay of the probability of error if the feedback rate $R_{\\textnormal{fb}}$ is\nat least $(L-1)R$ for some positive integer $L$. \n\n"}
{"id": "1307.6458", "contents": "Title: Distinguisher-Based Attacks on Public-Key Cryptosystems Using\n  Reed-Solomon Codes Abstract: Because of their interesting algebraic properties, several authors promote\nthe use of generalized Reed-Solomon codes in cryptography. Niederreiter was the\nfirst to suggest an instantiation of his cryptosystem with them but Sidelnikov\nand Shestakov showed that this choice is insecure. Wieschebrink proposed a\nvariant of the McEliece cryptosystem which consists in concatenating a few\nrandom columns to a generator matrix of a secretly chosen generalized\nReed-Solomon code. More recently, new schemes appeared which are the\nhomomorphic encryption scheme proposed by Bogdanov and Lee, and a variation of\nthe McEliece cryptosystem proposed by Baldi et \\textit{al.} which hides the\ngeneralized Reed-Solomon code by means of matrices of very low rank.\n  In this work, we show how to mount key-recovery attacks against these\npublic-key encryption schemes. We use the concept of distinguisher which aims\nat detecting a behavior different from the one that one would expect from a\nrandom code. All the distinguishers we have built are based on the notion of\ncomponent-wise product of codes. It results in a powerful tool that is able to\nrecover the secret structure of codes when they are derived from generalized\nReed-Solomon codes. Lastly, we give an alternative to Sidelnikov and Shestakov\nattack by building a filtration which enables to completely recover the support\nand the non-zero scalars defining the secret generalized Reed-Solomon code. \n\n"}
{"id": "1307.7087", "contents": "Title: Correcting Grain-Errors in Magnetic Media Abstract: This paper studies new bounds and constructions that are applicable to the\ncombinatorial granular channel model previously introduced by Sharov and Roth.\nWe derive new bounds on the maximum cardinality of a grain-error-correcting\ncode and propose constructions of codes that correct grain-errors. We\ndemonstrate that a permutation of the classical group codes (e.g.,\nConstantin-Rao codes) can correct a single grain-error. In many cases of\ninterest, our results improve upon the currently best known bounds and\nconstructions. Some of the approaches adopted in the context of grain-errors\nmay have application to other channel models. \n\n"}
{"id": "1308.4499", "contents": "Title: On a question of Babadi and Tarokh II Abstract: In this paper we continue to study a question proposed by Babadi and Tarokh\n\\cite{ba2} on the mysterious randomness of Gold sequences. Upon improving their\nresult, we establish the randomness of product of pseudorandom matrices formed\nfrom two linear block codes with respect to the empirical spectral\ndistribution, if the dual distance of both codes is at least 5, hence providing\nan affirmative answer to the question. \n\n"}
{"id": "1308.5000", "contents": "Title: Smoothing and Decomposition for Analysis Sparse Recovery Abstract: We consider algorithms and recovery guarantees for the analysis sparse model\nin which the signal is sparse with respect to a highly coherent frame. We\nconsider the use of a monotone version of the fast iterative shrinkage-\nthresholding algorithm (MFISTA) to solve the analysis sparse recovery problem.\nSince the proximal operator in MFISTA does not have a closed-form solution for\nthe analysis model, it cannot be applied directly. Instead, we examine two\nalternatives based on smoothing and decomposition transformations that relax\nthe original sparse recovery problem, and then implement MFISTA on the relaxed\nformulation. We refer to these two methods as smoothing-based and\ndecomposition-based MFISTA. We analyze the convergence of both algorithms, and\nestablish that smoothing- based MFISTA converges more rapidly when applied to\ngeneral nonsmooth optimization problems. We then derive a performance bound on\nthe reconstruction error using these techniques. The bound proves that our\nmethods can recover a signal sparse in a redundant tight frame when the\nmeasurement matrix satisfies a properly adapted restricted isometry property.\nNumerical examples demonstrate the performance of our methods and show that\nsmoothing-based MFISTA converges faster than the decomposition-based\nalternative in real applications, such as MRI image reconstruction. \n\n"}
{"id": "1308.6086", "contents": "Title: Distributed Compressed Sensing For Static and Time-Varying Networks Abstract: We consider the problem of in-network compressed sensing from distributed\nmeasurements. Every agent has a set of measurements of a signal $x$, and the\nobjective is for the agents to recover $x$ from their collective measurements\nusing only communication with neighbors in the network. Our distributed\napproach to this problem is based on the centralized Iterative Hard\nThresholding algorithm (IHT). We first present a distributed IHT algorithm for\nstatic networks that leverages standard tools from distributed computing to\nexecute in-network computations with minimized bandwidth consumption. Next, we\naddress distributed signal recovery in networks with time-varying topologies.\nThe network dynamics necessarily introduce inaccuracies to our in-network\ncomputations. To accommodate these inaccuracies, we show how centralized IHT\ncan be extended to include inexact computations while still providing the same\nrecovery guarantees as the original IHT algorithm. We then leverage these new\ntheoretical results to develop a distributed version of IHT for time-varying\nnetworks. Evaluations show that our distributed algorithms for both static and\ntime-varying networks outperform previously proposed solutions in time and\nbandwidth by several orders of magnitude. \n\n"}
{"id": "1308.6702", "contents": "Title: Adversarial hypothesis testing and a quantum Stein's Lemma for\n  restricted measurements Abstract: Recall the classical hypothesis testing setting with two convex sets of\nprobability distributions P and Q. One receives either n i.i.d. samples from a\ndistribution p in P or from a distribution q in Q and wants to decide from\nwhich set the points were sampled. It is known that the optimal exponential\nrate at which errors decrease can be achieved by a simple maximum-likelihood\nratio test which does not depend on p or q, but only on the sets P and Q.\n  We consider an adaptive generalization of this model where the choice of p in\nP and q in Q can change in each sample in some way that depends arbitrarily on\nthe previous samples. In other words, in the k'th round, an adversary, having\nobserved all the previous samples in rounds 1,...,k-1, chooses p_k in P and q_k\nin Q, with the goal of confusing the hypothesis test. We prove that even in\nthis case, the optimal exponential error rate can be achieved by a simple\nmaximum-likelihood test that depends only on P and Q.\n  We then show that the adversarial model has applications in hypothesis\ntesting for quantum states using restricted measurements. For example, it can\nbe used to study the problem of distinguishing entangled states from the set of\nall separable states using only measurements that can be implemented with local\noperations and classical communication (LOCC). The basic idea is that in our\nsetup, the deleterious effects of entanglement can be simulated by an adaptive\nclassical adversary.\n  We prove a quantum Stein's Lemma in this setting: In many circumstances, the\noptimal hypothesis testing rate is equal to an appropriate notion of quantum\nrelative entropy between two states. In particular, our arguments yield an\nalternate proof of Li and Winter's recent strengthening of strong subadditivity\nfor quantum relative entropy. \n\n"}
{"id": "1309.0482", "contents": "Title: Law of Log Determinant of Sample Covariance Matrix and Optimal\n  Estimation of Differential Entropy for High-Dimensional Gaussian\n  Distributions Abstract: Differential entropy and log determinant of the covariance matrix of a\nmultivariate Gaussian distribution have many applications in coding,\ncommunications, signal processing and statistical inference. In this paper we\nconsider in the high dimensional setting optimal estimation of the differential\nentropy and the log-determinant of the covariance matrix. We first establish a\ncentral limit theorem for the log determinant of the sample covariance matrix\nin the high dimensional setting where the dimension $p(n)$ can grow with the\nsample size $n$. An estimator of the differential entropy and the log\ndeterminant is then considered. Optimal rate of convergence is obtained. It is\nshown that in the case $p(n)/n \\rightarrow 0$ the estimator is asymptotically\nsharp minimax. The ultra-high dimensional setting where $p(n) > n$ is also\ndiscussed. \n\n"}
{"id": "1309.0799", "contents": "Title: Linear Degrees of Freedom of the X-Channel with Delayed CSIT Abstract: We establish the degrees of freedom of the two-user X-channel with delayed\nchannel knowledge at transmitters (i.e., delayed CSIT), assuming linear coding\nstrategies at the transmitters. We derive a new upper bound and characterize\nthe linear degrees of freedom of this network to be 6/5. The converse builds\nupon our development of a general lemma that shows that, if two distributed\ntransmitters employ linear strategies, the ratio of the dimensions of received\nlinear subspaces at the two receivers cannot exceed 3/2, due to delayed CSIT.\nAs a byproduct, we also apply this general lemma to the three-user interference\nchannel with delayed CSIT, thereby deriving a new upper bound of 9/7 on its\nlinear degrees of freedom. This is the first bound that captures the impact of\ndelayed CSIT on the degrees of freedom of this network, under the assumption of\nlinear encoding strategies. \n\n"}
{"id": "1309.1323", "contents": "Title: From Instantly Decodable to Random Linear Network Coding Abstract: Our primary goal in this paper is to traverse the performance gap between two\nlinear network coding schemes: random linear network coding (RLNC) and\ninstantly decodable network coding (IDNC) in terms of throughput and decoding\ndelay. We first redefine the concept of packet generation and use it to\npartition a block of partially-received data packets in a novel way, based on\nthe coding sets in an IDNC solution. By varying the generation size, we obtain\na general coding framework which consists of a series of coding schemes, with\nRLNC and IDNC identified as two extreme cases. We then prove that the\nthroughput and decoding delay performance of all coding schemes in this coding\nframework are bounded between the performance of RLNC and IDNC and hence\nthroughput-delay tradeoff becomes possible. We also propose implementations of\nthis coding framework to further improve its throughput and decoding delay\nperformance, to manage feedback frequency and coding complexity, or to achieve\nin-block performance adaption. Extensive simulations are then provided to\nverify the performance of the proposed coding schemes and their\nimplementations. \n\n"}
{"id": "1309.2304", "contents": "Title: Information Theory and Moduli of Riemann Surfaces Abstract: One interpretation of Torelli's Theorem, which asserts that a compact Riemann\nSurface $X$ of genus $g > 1$ is determined by the $g(g+1)/2$ entries of the\nperiod matrix, is that the period matrix is a message about $X$. Since this\nmessage depends on only $3g-3$ moduli, it is sparse, or at least approximately\nso, in the sense of information theory. Thus, methods from information theory\nmay be useful in reconstructing the period matrix, and hence the Riemann\nsurface, from a small subset of the periods. The results here show that, with\nhigh probability, any set of $3g-3$ periods form moduli for the surface. \n\n"}
{"id": "1309.2343", "contents": "Title: A Finite-Blocklength Perspective on Gaussian Multi-Access Channels Abstract: Motivated by the growing application of wireless multi-access networks with\nstringent delay constraints, we investigate the Gaussian multiple access\nchannel (MAC) in the finite blocklength regime. Building upon information\nspectrum concepts, we develop several non-asymptotic inner bounds on channel\ncoding rates over the Gaussian MAC with a given finite blocklength, positive\naverage error probability, and maximal power constraints. Employing Central\nLimit Theorem (CLT) approximations, we also obtain achievable second-order\ncoding rates for the Gaussian MAC based on an explicit expression for its\ndispersion matrix. We observe that, unlike the pentagon shape of the asymptotic\ncapacity region, the second-order region has a curved shape with no sharp\ncorners.\n  A main emphasis of the paper is to provide a new perspective on the procedure\nof handling input cost constraints for tight achievability proofs. Contrary to\nthe complicated achievability techniques in the literature, we show that with a\nproper choice of input distribution, tight bounds can be achieved via the\nstandard random coding argument and a modified typicality decoding. In\nparticular, we prove that codebooks generated randomly according to independent\nuniform distributions on the respective \"power shells\" perform far better than\nboth independent and identically distributed (i.i.d.) Gaussian inputs and TDMA\nwith power control. Interestingly, analogous to an error exponent result of\nGallager, the resulting achievable region lies roughly halfway between that of\nthe i.i.d. Gaussian inputs and that of a hypothetical \"sum-power shell\" input.\nHowever, dealing with such a non-i.i.d. input requires additional analysis such\nas a new change of measure technique and application of a Berry-Esseen CLT for\nfunctions of random variables. \n\n"}
{"id": "1309.5310", "contents": "Title: Conditioning of Random Block Subdictionaries with Applications to\n  Block-Sparse Recovery and Regression Abstract: The linear model, in which a set of observations is assumed to be given by a\nlinear combination of columns of a matrix, has long been the mainstay of the\nstatistics and signal processing literature. One particular challenge for\ninference under linear models is understanding the conditions on the dictionary\nunder which reliable inference is possible. This challenge has attracted\nrenewed attention in recent years since many modern inference problems deal\nwith the \"underdetermined\" setting, in which the number of observations is much\nsmaller than the number of columns in the dictionary. This paper makes several\ncontributions for this setting when the set of observations is given by a\nlinear combination of a small number of groups of columns of the dictionary,\ntermed the \"block-sparse\" case. First, it specifies conditions on the\ndictionary under which most block subdictionaries are well conditioned. This\nresult is fundamentally different from prior work on block-sparse inference\nbecause (i) it provides conditions that can be explicitly computed in\npolynomial time, (ii) the given conditions translate into near-optimal scaling\nof the number of columns of the block subdictionaries as a function of the\nnumber of observations for a large class of dictionaries, and (iii) it suggests\nthat the spectral norm and the quadratic-mean block coherence of the dictionary\n(rather than the worst-case coherences) fundamentally limit the scaling of\ndimensions of the well-conditioned block subdictionaries. Second, this paper\ninvestigates the problems of block-sparse recovery and block-sparse regression\nin underdetermined settings. Near-optimal block-sparse recovery and regression\nare possible for certain dictionaries as long as the dictionary satisfies\neasily computable conditions and the coefficients describing the linear\ncombination of groups of columns can be modeled through a mild statistical\nprior. \n\n"}
{"id": "1309.5979", "contents": "Title: Asymptotic Analysis of LASSOs Solution Path with Implications for\n  Approximate Message Passing Abstract: This paper concerns the performance of the LASSO (also knows as basis pursuit\ndenoising) for recovering sparse signals from undersampled, randomized, noisy\nmeasurements. We consider the recovery of the signal $x_o \\in \\mathbb{R}^N$\nfrom $n$ random and noisy linear observations $y= Ax_o + w$, where $A$ is the\nmeasurement matrix and $w$ is the noise. The LASSO estimate is given by the\nsolution to the optimization problem $x_o$ with $\\hat{x}_{\\lambda} = \\arg\n\\min_x \\frac{1}{2} \\|y-Ax\\|_2^2 + \\lambda \\|x\\|_1$. Despite major progress in\nthe theoretical analysis of the LASSO solution, little is known about its\nbehavior as a function of the regularization parameter $\\lambda$. In this paper\nwe study two questions in the asymptotic setting (i.e., where $N \\rightarrow\n\\infty$, $n \\rightarrow \\infty$ while the ratio $n/N$ converges to a fixed\nnumber in $(0,1)$): (i) How does the size of the active set\n$\\|\\hat{x}_\\lambda\\|_0/N$ behave as a function of $\\lambda$, and (ii) How does\nthe mean square error $\\|\\hat{x}_{\\lambda} - x_o\\|_2^2/N$ behave as a function\nof $\\lambda$? We then employ these results in a new, reliable algorithm for\nsolving LASSO based on approximate message passing (AMP). \n\n"}
{"id": "1309.7540", "contents": "Title: Joint Power and Antenna Selection Optimization in Large Cloud Radio\n  Access Networks Abstract: Large multiple-input multiple-output (MIMO) networks promise high energy\nefficiency, i.e., much less power is required to achieve the same capacity\ncompared to the conventional MIMO networks if perfect channel state information\n(CSI) is available at the transmitter. However, in such networks, huge overhead\nis required to obtain full CSI especially for Frequency-Division Duplex (FDD)\nsystems. To reduce overhead, we propose a downlink antenna selection scheme,\nwhich selects S antennas from M>S transmit antennas based on the large scale\nfading to serve K\\leq S users in large distributed MIMO networks employing\nregularized zero-forcing (RZF) precoding. In particular, we study the joint\noptimization of antenna selection, regularization factor, and power allocation\nto maximize the average weighted sum-rate. This is a mixed combinatorial and\nnon-convex problem whose objective and constraints have no closed-form\nexpressions. We apply random matrix theory to derive asymptotically accurate\nexpressions for the objective and constraints. As such, the joint optimization\nproblem is decomposed into subproblems, each of which is solved by an efficient\nalgorithm. In addition, we derive structural solutions for some special cases\nand show that the capacity of very large distributed MIMO networks scales as\nO\\left(K\\textrm{log}M\\right) when M\\rightarrow\\infty with K,S fixed.\nSimulations show that the proposed scheme achieves significant performance gain\nover various baselines. \n\n"}
{"id": "1310.0234", "contents": "Title: Group Sparse Beamforming for Green Cloud-RAN Abstract: A cloud radio access network (Cloud-RAN) is a network architecture that holds\nthe promise of meeting the explosive growth of mobile data traffic. In this\narchitecture, all the baseband signal processing is shifted to a single\nbaseband unit (BBU) pool, which enables efficient resource allocation and\ninterference management. Meanwhile, conventional powerful base stations can be\nreplaced by low-cost low-power remote radio heads (RRHs), producing a green and\nlow-cost infrastructure. However, as all the RRHs need to be connected to the\nBBU pool through optical transport links, the transport network power\nconsumption becomes significant. In this paper, we propose a new framework to\ndesign a green Cloud-RAN, which is formulated as a joint RRH selection and\npower minimization beamforming problem. To efficiently solve this problem, we\nfirst propose a greedy selection algorithm, which is shown to provide near-\noptimal performance. To further reduce the complexity, a novel group sparse\nbeamforming method is proposed by inducing the group-sparsity of beamformers\nusing the weighted $\\ell_1/\\ell_2$-norm minimization, where the group sparsity\npattern indicates those RRHs that can be switched off. Simulation results will\nshow that the proposed algorithms significantly reduce the network power\nconsumption and demonstrate the importance of considering the transport link\npower consumption. \n\n"}
{"id": "1310.3062", "contents": "Title: Channel Hardening-Exploiting Message Passing (CHEMP) Receiver in\n  Large-Scale MIMO Systems Abstract: In this paper, we propose a MIMO receiver algorithm that exploits {\\em\nchannel hardening} that occurs in large MIMO channels. Channel hardening refers\nto the phenomenon where the off-diagonal terms of the ${\\bf H}^H{\\bf H}$ matrix\nbecome increasingly weaker compared to the diagonal terms as the size of the\nchannel gain matrix ${\\bf H}$ increases. Specifically, we propose a message\npassing detection (MPD) algorithm which works with the real-valued matched\nfiltered received vector (whose signal term becomes ${\\bf H}^T{\\bf H}{\\bf x}$,\nwhere ${\\bf x}$ is the transmitted vector), and uses a Gaussian approximation\non the off-diagonal terms of the ${\\bf H}^T{\\bf H}$ matrix. We also propose a\nsimple estimation scheme which directly obtains an estimate of ${\\bf H}^T{\\bf\nH}$ (instead of an estimate of ${\\bf H}$), which is used as an effective\nchannel estimate in the MPD algorithm. We refer to this receiver as the {\\em\nchannel hardening-exploiting message passing (CHEMP)} receiver. The proposed\nCHEMP receiver achieves very good performance in large-scale MIMO systems\n(e.g., in systems with 16 to 128 uplink users and 128 base station antennas).\nFor the considered large MIMO settings, the complexity of the proposed MPD\nalgorithm is almost the same as or less than that of the minimum mean square\nerror (MMSE) detection. This is because the MPD algorithm does not need a\nmatrix inversion. It also achieves a significantly better performance compared\nto MMSE and other message passing detection algorithms using MMSE estimate of\n${\\bf H}$. We also present a convergence analysis of the proposed MPD\nalgorithm. Further, we design optimized irregular low density parity check\n(LDPC) codes specific to the considered large MIMO channel and the CHEMP\nreceiver through EXIT chart matching. The LDPC codes thus obtained achieve\nimproved coded bit error rate performance compared to off-the-shelf irregular\nLDPC codes. \n\n"}
{"id": "1310.4412", "contents": "Title: Delay on broadcast erasure channels under random linear combinations Abstract: We consider a transmitter broadcasting random linear combinations (over a\nfield of size $d$) formed from a block of $c$ packets to a collection of $n$\nreceivers, where the channels between the transmitter and each receiver are\nindependent erasure channels with reception probabilities $\\mathbf{q} =\n(q_1,\\ldots,q_n)$. We establish several properties of the random delay until\nall $n$ receivers have recovered all $c$ packets, denoted $Y_{n:n}^{(c)}$.\nFirst, we provide lower and upper bounds, exact expressions, and a recurrence\nfor the moments of $Y_{n:n}^{(c)}$. Second, we study the delay per packet\n$Y_{n:n}^{(c)}/c$ as a function of $c$, including the asymptotic delay (as $c\n\\to \\infty$), and monotonicity (in $c$) properties of the delay per packet.\nThird, we employ extreme value theory to investigate $Y_{n:n}^{(c)}$ as a\nfunction of $n$ (as $n \\to \\infty$). Several results are new, some results are\nextensions of existing results, and some results are proofs of known results\nusing new (probabilistic) proof techniques. \n\n"}
{"id": "1310.6265", "contents": "Title: Optimal Transmit Filters for ISI Channels under Channel Shortening\n  Detection Abstract: We consider channels affected by intersymbol interference with\nreduced-complexity, mutual information optimized, channel-shortening detection.\nFor such settings, we optimize the transmit filter, taking into consideration\nthe reduced receiver complexity constraint. As figure of merit, we consider the\nachievable information rate of the entire system and with functional analysis,\nwe establish a general form of the optimal transmit filter, which can then be\noptimized by standard numerical methods. As a corollary to our main result, we\nobtain some insight of the behavior of the standard waterfilling algorithm for\nintersymbol interference channels. With only some minor changes, the general\nform we derive can be applied to multiple-input multiple-output channels with\nintersymbol interference. To illuminate the practical use of our results, we\nprovide applications of our theoretical results by deriving the optimal shaping\npulse of a linear modulation transmitted over a bandlimited additive white\nGaussian noise channel which has possible applications in the\nfaster-than-Nyquist/time packing technique. \n\n"}
{"id": "1310.6657", "contents": "Title: MISO Broadcast Channel with Imperfect and (Un)matched CSIT in the\n  Frequency Domain: DoF Region and Transmission Strategies Abstract: In this contribution, we focus on a frequency domain two-user\nMultiple-Input-Single-Output Broadcast Channel (MISO BC) where the transmitter\nhas imperfect and (un)matched Channel State Information (CSI) of the two users\nin two subbands. We provide an upper-bound to the Degrees-of-Freedom (DoF)\nregion, which is tight compared to the state of the art. By decomposing the\nsubbands into subchannels according to the CSI feedback qualities, we interpret\nthe DoF region as the weighted-sum of that in each subchannel. Moreover, we\nstudy the sum \\emph{DoF} loss when employing sub-optimal schemes, namely\nFrequency Division Multiple Access (FDMA), Zero-Forcing Beamforming (ZFBF) and\nthe $S_3^{3/2}$ scheme proposed by Tandon et al. The results show that by\nswitching among the sub-optimal strategies, we can obtain at least 80% and\n66.7% of the optimal sum \\emph{DoF} performance for the unmatched and matched\nCSIT scenario respectively. \n\n"}
{"id": "1311.0776", "contents": "Title: The Composition Theorem for Differential Privacy Abstract: Sequential querying of differentially private mechanisms degrades the overall\nprivacy level. In this paper, we answer the fundamental question of\ncharacterizing the level of overall privacy degradation as a function of the\nnumber of queries and the privacy levels maintained by each privatization\nmechanism. Our solution is complete: we prove an upper bound on the overall\nprivacy level and construct a sequence of privatization mechanisms that\nachieves this bound. The key innovation is the introduction of an operational\ninterpretation of differential privacy (involving hypothesis testing) and the\nuse of new data processing inequalities. Our result improves over the\nstate-of-the-art, and has immediate applications in several problems studied in\nthe literature including differentially private multi-party computation. \n\n"}
{"id": "1311.1642", "contents": "Title: Quasi-Linear Compressed Sensing Abstract: Inspired by significant real-life applications, in particular, sparse phase\nretrieval and sparse pulsation frequency detection in Asteroseismology, we\ninvestigate a general framework for compressed sensing, where the measurements\nare quasi-linear. We formulate natural generalizations of the well-known\nRestricted Isometry Property (RIP) towards nonlinear measurements, which allow\nus to prove both unique identifiability of sparse signals as well as the\nconvergence of recovery algorithms to compute them efficiently. We show that\nfor certain randomized quasi-linear measurements, including Lipschitz\nperturbations of classical RIP matrices and phase retrieval from random\nprojections, the proposed restricted isometry properties hold with high\nprobability. We analyze a generalized Orthogonal Least Squares (OLS) under the\nassumption that magnitudes of signal entries to be recovered decay fast. Greed\nis good again, as we show that this algorithm performs efficiently in phase\nretrieval and asteroseismology. For situations where the decay assumption on\nthe signal does not necessarily hold, we propose two alternative algorithms,\nwhich are natural generalizations of the well-known iterative hard and\nsoft-thresholding. While these algorithms are rarely successful for the\nmentioned applications, we show their strong recovery guarantees for\nquasi-linear measurements which are Lipschitz perturbations of RIP matrices. \n\n"}
{"id": "1311.2540", "contents": "Title: Asymmetric numeral systems: entropy coding combining speed of Huffman\n  coding with compression rate of arithmetic coding Abstract: The modern data compression is mainly based on two approaches to entropy\ncoding: Huffman (HC) and arithmetic/range coding (AC). The former is much\nfaster, but approximates probabilities with powers of 2, usually leading to\nrelatively low compression rates. The latter uses nearly exact probabilities -\neasily approaching theoretical compression rate limit (Shannon entropy), but at\ncost of much larger computational cost.\n  Asymmetric numeral systems (ANS) is a new approach to accurate entropy\ncoding, which allows to end this trade-off between speed and rate: the recent\nimplementation [1] provides about $50\\%$ faster decoding than HC for 256 size\nalphabet, with compression rate similar to provided by AC. This advantage is\ndue to being simpler than AC: using single natural number as the state, instead\nof two to represent a range. Beside simplifying renormalization, it allows to\nput the entire behavior for given probability distribution into a relatively\nsmall table: defining entropy coding automaton. The memory cost of such table\nfor 256 size alphabet is a few kilobytes. There is a large freedom while\nchoosing a specific table - using pseudorandom number generator initialized\nwith cryptographic key for this purpose allows to simultaneously encrypt the\ndata.\n  This article also introduces and discusses many other variants of this new\nentropy coding approach, which can provide direct alternatives for standard AC,\nfor large alphabet range coding, or for approximated quasi arithmetic coding. \n\n"}
{"id": "1311.3284", "contents": "Title: A family of optimal locally recoverable codes Abstract: A code over a finite alphabet is called locally recoverable (LRC) if every\nsymbol in the encoding is a function of a small number (at most $r$) other\nsymbols. We present a family of LRC codes that attain the maximum possible\nvalue of the distance for a given locality parameter and code cardinality. The\ncodewords are obtained as evaluations of specially constructed polynomials over\na finite field, and reduce to a Reed-Solomon code if the locality parameter $r$\nis set to be equal to the code dimension. The size of the code alphabet for\nmost parameters is only slightly greater than the code length. The recovery\nprocedure is performed by polynomial interpolation over $r$ points. We also\nconstruct codes with several disjoint recovering sets for every symbol. This\nconstruction enables the system to conduct several independent and simultaneous\nrecovery processes of a specific symbol by accessing different parts of the\ncodeword. This property enables high availability of frequently accessed data\n(\"hot data\"). \n\n"}
{"id": "1311.3391", "contents": "Title: A Class of Six-weight Cyclic Codes and Their Weight Distribution Abstract: In this paper, a family of six-weight cyclic codes over GF(p) whose duals\nhave two zeros is presented, where p is an odd prime. And the weight\ndistribution of these cyclic codes is determined. \n\n"}
{"id": "1311.4111", "contents": "Title: Dynamic Resource Allocation for Multiple-Antenna Wireless Power Transfer Abstract: We consider a point-to-point multiple-input-single-output (MISO) system where\na receiver harvests energy from a wireless power transmitter to power itself\nfor various applications. The transmitter performs energy beamforming by using\nan instantaneous channel state information (CSI). The CSI is estimated at the\nreceiver by training via a preamble, and fed back to the transmitter. The\nchannel estimate is more accurate when longer preamble is used, but less time\nis left for wireless power transfer before the channel changes. To maximize the\nharvested energy, in this paper, we address the key challenge of balancing the\ntime resource used for channel estimation and wireless power transfer (WPT),\nand also investigate the allocation of energy resource used for wireless power\ntransfer. First, we consider the general scenario where the preamble length is\nallowed to vary dynamically. Taking into account the effects of imperfect CSI,\nthe optimal preamble length is obtained online by solving a dynamic programming\n(DP) problem. The solution is shown to be a threshold-type policy that depends\nonly on the channel estimate power. Next, we consider the scenario in which the\npreamble length is fixed. The optimal preamble length is optimized offline.\nFurthermore, we derive the optimal power allocation schemes for both scenarios.\nFor the scenario of dynamic-length preamble, the power is allocated according\nto both the optimal preamble length and the channel estimate power; while for\nthe scenario of fixed-length preamble, the power is allocated according to only\nthe channel estimate power. The analysis results are validated by numerical\nsimulations. Encouragingly, with optimal power allocation, the harvested energy\nby using optimized fixed-length preamble is almost the same as the harvested\nenergy by employing dynamic-length preamble, hence allowing a low-complexity\nWPT system to be implemented in practice. \n\n"}
{"id": "1311.6853", "contents": "Title: Channel, Phase Noise, and Frequency Offset in OFDM Systems: Joint\n  Estimation, Data Detection, and Hybrid Cramer-Rao Lower Bound Abstract: Oscillator phase noise (PHN) and carrier frequency offset (CFO) can adversely\nimpact the performance of orthogonal frequency division multiplexing (OFDM)\nsystems, since they can result in inter carrier interference and rotation of\nthe signal constellation. In this paper, we propose an expectation conditional\nmaximization (ECM) based algorithm for joint estimation of channel, PHN, and\nCFO in OFDM systems. We present the signal model for the estimation problem and\nderive the hybrid Cramer-Rao lower bound (HCRB) for the joint estimation\nproblem. Next, we propose an iterative receiver based on an extended Kalman\nfilter for joint data detection and PHN tracking. Numerical results show that,\ncompared to existing algorithms, the performance of the proposed ECM-based\nestimator is closer to the derived HCRB and outperforms the existing estimation\nalgorithms at moderate-to-high signal-to-noise ratio (SNR). In addition, the\ncombined estimation algorithm and iterative receiver are more computationally\nefficient than existing algorithms and result in improved average uncoded and\ncoded bit error rate (BER) performance. \n\n"}
{"id": "1312.0525", "contents": "Title: Near Optimal Compressed Sensing of a Class of Sparse Low-Rank Matrices\n  via Sparse Power Factorization Abstract: Compressed sensing of simultaneously sparse and low-rank matrices enables\nrecovery of sparse signals from a few linear measurements of their bilinear\nform. One important question is how many measurements are needed for a stable\nreconstruction in the presence of measurement noise. Unlike conventional\ncompressed sensing for sparse vectors, where convex relaxation via the\n$\\ell_1$-norm achieves near optimal performance, for compressed sensing of\nsparse low-rank matrices, it has been shown recently Oymak et al. that convex\nprogrammings using the nuclear norm and the mixed norm are highly suboptimal\neven in the noise-free scenario.\n  We propose an alternating minimization algorithm called sparse power\nfactorization (SPF) for compressed sensing of sparse rank-one matrices. For a\nclass of signals whose sparse representation coefficients are fast-decaying,\nSPF achieves stable recovery of the rank-1 matrix formed by their outer product\nand requires number of measurements within a logarithmic factor of the\ninformation-theoretic fundamental limit. For the recovery of general sparse\nlow-rank matrices, we propose subspace-concatenated SPF (SCSPF), which has\nanalogous near optimal performance guarantees to SPF in the rank-1 case.\nNumerical results show that SPF and SCSPF empirically outperform convex\nprogrammings using the best known combinations of mixed norm and nuclear norm. \n\n"}
{"id": "1312.1799", "contents": "Title: Space-Time Polar Coded Modulation Abstract: The polar codes are proven to be capacity-achieving and are shown to have\nequivalent or even better finite-length performance than the turbo/LDPC codes\nunder some improved decoding algorithms over the additive white Gaussian noise\n(AWGN) channels. Polar coding is based on the so-called channel polarization\nphenomenon induced by a transform over the underlying binary-input channel. The\nchannel polarization is found to be universal in many signal processing\nproblems and has been applied to the coded modulation schemes. In this paper,\nthe channel polarization is further extended to the multiple antenna\ntransmission following a multilevel coding principle. The multiple-input\nmultile-output (MIMO) channel under quadrature amplitude modulation (QAM) are\ntransformed into a series of synthesized binary-input channels under a\nthree-stage channel transform. Based on this generalized channel polarization,\nthe proposed space-time polar coded modulation (STPCM) scheme allows a joint\noptimization of the binary polar coding, modulation and MIMO transmission. In\naddition, a practical solution of polar code construction over the fading\nchannels is also provided, where the fading channels are approximated by an\nAWGN channel which shares the same capacity with the original. The simulations\nover the MIMO channel with uncorrelated Rayleigh fast fading show that the\nproposed STPCM scheme can outperform the bit-interleaved turbo coded scheme in\nall the simulated cases, where the latter is adopted in many existing\ncommunication systems. \n\n"}
{"id": "1312.2183", "contents": "Title: Maximum Likelihood Estimation from Sign Measurements with Sensing Matrix\n  Perturbation Abstract: The problem of estimating an unknown deterministic parameter vector from sign\nmeasurements with a perturbed sensing matrix is studied in this paper. We\nanalyze the best achievable mean square error (MSE) performance by exploring\nthe corresponding Cram\\'{e}r-Rao Lower Bound (CRLB). To estimate the parameter,\nthe maximum likelihood (ML) estimator is utilized and its consistency is\nproved. We show that the perturbation on the sensing matrix exacerbates the\nperformance of ML estimator in most cases. However, suitable perturbation may\nimprove the performance in some special cases. Then we reformulate the original\nML estimation problem as a convex optimization problem, which can be solved\nefficiently. Furthermore, theoretical analysis implies that the\nperturbation-ignored estimation is a scaled version with the same direction of\nthe ML estimation. Finally, numerical simulations are performed to validate our\ntheoretical analysis. \n\n"}
{"id": "1312.2267", "contents": "Title: IRCI Free Range Reconstruction for SAR Imaging with Arbitrary Length\n  OFDM Pulse Abstract: Our previously proposed OFDM with sufficient cyclic prefix (CP) synthetic\naperture radar (SAR) imaging algorithm is inter-range-cell interference (IRCI)\nfree and achieves ideally zero range sidelobes for range reconstruction. In\nthis OFDM SAR imaging algorithm, the minimum required CP length is almost equal\nto the number of range cells in a swath, while the number of subcarriers of an\nOFDM signal needs to be more than the CP length. This makes the length of a\ntransmitted OFDM sequence at least almost twice of the number of range cells in\na swath and for a wide swath imaging, the transmitted OFDM pulse length becomes\nlong, which may cause problems in some radar applications. In this paper, we\npropose a CP based OFDM SAR imaging with arbitrary pulse length, which has IRCI\nfree range reconstruction and its pulse length is independent of a swath width.\nWe then present a novel design method for our proposed arbitrary length OFDM\npulses. Simulation results are presented to illustrate the performances of the\nOFDM pulse design and the arbitrary pulse length CP based OFDM SAR imaging. \n\n"}
{"id": "1312.3389", "contents": "Title: Matrix Product Codes over Finite Commutative Frobenius Rings Abstract: Properties of matrix product codes over finite commutative Frobenius rings\nare investigated. The minimum distance of matrix product codes constructed with\nseveral types of matrices is bounded in different ways. The duals of matrix\nproduct codes are also explicitly described in terms of matrix product codes. \n\n"}
{"id": "1312.3590", "contents": "Title: Quantum computation and real multiplication Abstract: We propose a construction of anyon systems associated to quantum tori with\nreal multiplication and the embedding of quantum tori in AF algebras. These\nsystems generalize the Fibonacci anyons, with weaker categorical properties,\nand are obtained from the basic modules and the real multiplication structure. \n\n"}
{"id": "1312.3790", "contents": "Title: Sample Complexity of Dictionary Learning and other Matrix Factorizations Abstract: Many modern tools in machine learning and signal processing, such as sparse\ndictionary learning, principal component analysis (PCA), non-negative matrix\nfactorization (NMF), $K$-means clustering, etc., rely on the factorization of a\nmatrix obtained by concatenating high-dimensional vectors from a training\ncollection. While the idealized task would be to optimize the expected quality\nof the factors over the underlying distribution of training vectors, it is\nachieved in practice by minimizing an empirical average over the considered\ncollection. The focus of this paper is to provide sample complexity estimates\nto uniformly control how much the empirical average deviates from the expected\ncost function. Standard arguments imply that the performance of the empirical\npredictor also exhibit such guarantees. The level of genericity of the approach\nencompasses several possible constraints on the factors (tensor product\nstructure, shift-invariance, sparsity \\ldots), thus providing a unified\nperspective on the sample complexity of several widely used matrix\nfactorization schemes. The derived generalization bounds behave proportional to\n$\\sqrt{\\log(n)/n}$ w.r.t.\\ the number of samples $n$ for the considered matrix\nfactorization techniques. \n\n"}
{"id": "1312.3876", "contents": "Title: The Symmetric Convex Ordering: A Novel Partial Order for B-DMCs Ordering\n  the Information Sets of Polar Codes Abstract: In this paper, we propose a novel partial order for binary discrete\nmemoryless channels that we call the symmetric convex ordering. We show that\nAr{\\i}kan's polar transform preserves 'symmetric convex orders'. Furthermore,\nwe show that while for symmetric channels this ordering turns out to be\nequivalent to the stochastic degradation ordering already known to order the\ninformation sets of polar codes, a strictly weaker partial order is obtained\nwhen at least one of the channels is asymmetric. In between, we also discuss\ntwo tools which can be useful for verifying this ordering: a criterion known as\nthe cut criterion and channel symmetrization. Finally, we discuss potential\napplications of the results to polar coding over non-stationary channels. \n\n"}
{"id": "1312.5276", "contents": "Title: Integration by parts and representation of information functionals Abstract: We introduce a new formalism for computing expectations of functionals of\narbitrary random vectors, by using generalised integration by parts formulae.\nIn doing so we extend recent representation formulae for the score function\nintroduced in Nourdin, Peccati and Swan (JFA, to appear) and also provide a new\nproof of a central identity first discovered in Guo, Shamai, and Verd{\\'u}\n(IEEE Trans. Information Theory, 2005). We derive a representation for the\nstandardized Fisher information of sums of i.i.d. random vectors which use our\nidentities to provide rates of convergence in information theoretic central\nlimit theorems (both in Fisher information distance and in relative entropy). \n\n"}
{"id": "1312.6949", "contents": "Title: Joint Phase Tracking and Channel Decoding for OFDM Physical-Layer\n  Network Coding Abstract: This paper investigates the problem of joint phase tracking and channel\ndecoding in OFDM based Physical-layer Network Coding (PNC) systems. OFDM\nsignaling can obviate the need for tight time synchronization among multiple\nsimultaneous transmissions in the uplink of PNC systems. However, OFDM PNC\nsystems are susceptible to phase drifts caused by residual carrier frequency\noffsets (CFOs). In the traditional OFDM system in which a receiver receives\nfrom only one transmitter, pilot tones are employed to aid phase tracking. In\nOFDM PNC systems, multiple transmitters transmit to a receiver, and these pilot\ntones must be shared among the multiple transmitters. This reduces the number\nof pilots that can be used by each transmitting node. Phase tracking in OFDM\nPNC is more challenging as a result. To overcome the degradation due to the\nreduced number of per-node pilots, this work supplements the pilots with the\nchannel information contained in the data. In particular, we propose to solve\nthe problems of phase tracking and channel decoding jointly. Our solution\nconsists of the use of the expectation-maximization (EM) algorithm for phase\ntracking and the use of the belief propagation (BP) algorithm for channel\ndecoding. The two problems are solved jointly through iterative processing\nbetween the EM and BP algorithms. Simulations and real experiments based on\nsoftware-defined radio show that the proposed method can improve phase tracking\nas well as channel decoding performance. \n\n"}
{"id": "1312.7695", "contents": "Title: A discretization-free sparse and parametric approach for linear array\n  signal processing Abstract: Direction of arrival (DOA) estimation in array processing using\nuniform/sparse linear arrays is concerned in this paper. While sparse methods\nvia approximate parameter discretization have been popular in the past decade,\nthe discretization may cause problems, e.g., modeling error and increased\ncomputations due to dense sampling. In this paper, an exact discretization-free\nmethod, named as sparse and parametric approach (SPA), is proposed for uniform\nand sparse linear arrays. SPA carries out parameter estimation in the\ncontinuous range based on well-established covariance fitting criteria and\nconvex optimization. It guarantees to produce a sparse parameter estimate\nwithout discretization required by existing sparse methods. Theoretical\nanalysis shows that the SPA parameter estimator is a large-snapshot realization\nof the maximum likelihood estimator and is statistically consistent (in the\nnumber of snapshots) under uncorrelated sources. Other merits of SPA include\nimproved resolution, applicability to arbitrary number of snapshots, robustness\nto correlation of the sources and no requirement of user-parameters. Numerical\nsimulations are carried out to verify our analysis and demonstrate advantages\nof SPA compared to existing methods. \n\n"}
{"id": "1401.0892", "contents": "Title: Optimum Trade-offs Between the Error Exponent and the Excess-Rate\n  Exponent of Variable-Rate Slepian-Wolf Coding Abstract: We analyze the optimal trade-off between the error exponent and the\nexcess-rate exponent for variable-rate Slepian-Wolf codes. In particular, we\nfirst derive upper (converse) bounds on the optimal error and excess-rate\nexponents, and then lower (achievable) bounds, via a simple class of\nvariable-rate codes which assign the same rate to all source blocks of the same\ntype class. Then, using the exponent bounds, we derive bounds on the optimal\nrate functions, namely, the minimal rate assigned to each type class, needed in\norder to achieve a given target error exponent. The resulting excess-rate\nexponent is then evaluated. Iterative algorithms are provided for the\ncomputation of both bounds on the optimal rate functions and their excess-rate\nexponents. The resulting Slepian-Wolf codes bridge between the two extremes of\nfixed-rate coding, which has minimal error exponent and maximal excess-rate\nexponent, and average-rate coding, which has maximal error exponent and minimal\nexcess-rate exponent. \n\n"}
{"id": "1401.1711", "contents": "Title: Energy-Efficient Communication over the Unsynchronized Gaussian Diamond\n  Network Abstract: Communication networks are often designed and analyzed assuming tight\nsynchronization among nodes. However, in applications that require\ncommunication in the energy-efficient regime of low signal-to-noise ratios,\nestablishing tight synchronization among nodes in the network can result in a\nsignificant energy overhead. Motivated by a recent result showing that\nnear-optimal energy efficiency can be achieved over the AWGN channel without\nrequiring tight synchronization, we consider the question of whether the\npotential gains of cooperative communication can be achieved in the absence of\nsynchronization. We focus on the symmetric Gaussian diamond network and\nestablish that cooperative-communication gains are indeed feasible even with\nunsynchronized nodes. More precisely, we show that the capacity per unit energy\nof the unsynchronized symmetric Gaussian diamond network is within a constant\nfactor of the capacity per unit energy of the corresponding synchronized\nnetwork. To this end, we propose a distributed relaying scheme that does not\nrequire tight synchronization but nevertheless achieves most of the energy\ngains of coherent combining. \n\n"}
{"id": "1401.2422", "contents": "Title: Codes with Locality for Two Erasures Abstract: In this paper, we study codes with locality that can recover from two\nerasures via a sequence of two local, parity-check computations. By a local\nparity-check computation, we mean recovery via a single parity-check equation\nassociated to small Hamming weight. Earlier approaches considered recovery in\nparallel; the sequential approach allows us to potentially construct codes with\nimproved minimum distance. These codes, which we refer to as locally\n2-reconstructible codes, are a natural generalization along one direction, of\ncodes with all-symbol locality introduced by Gopalan \\textit{et al}, in which\nrecovery from a single erasure is considered. By studying the Generalized\nHamming Weights of the dual code, we derive upper bounds on the minimum\ndistance of locally 2-reconstructible codes and provide constructions for a\nfamily of codes based on Tur\\'an graphs, that are optimal with respect to this\nbound. The minimum distance bound derived here is universal in the sense that\nno code which permits all-symbol local recovery from $2$ erasures can have\nlarger minimum distance regardless of approach adopted. Our approach also leads\nto a new bound on the minimum distance of codes with all-symbol locality for\nthe single-erasure case. \n\n"}
{"id": "1401.2568", "contents": "Title: Zero-Delay Joint Source-Channel Coding for a Multivariate Gaussian on a\n  Gaussian MAC Abstract: In this paper, communication of a Multivariate Gaussian over a Gaussian\nMultiple Access Channel is studied. Distributed zero-delay joint source-channel\ncoding (JSCC) solutions to the problem are given. Both nonlinear and linear\napproaches are discussed. The performance upper bound (signal-to-distortion\nratio) for arbitrary code length is also derived and Zero-delay cooperative\nJSCC is briefly addressed in order to provide an approximate bound on the\nperformance of zero-delay schemes. The main contribution is a nonlinear hybrid\ndiscrete-analog JSSC scheme based on distributed quantization and a linear\ncontinuous mapping named Distributed Quantizer Linear Coder (DQLC). The DQLC\nhas promising performance which improves with increasing correlation, and is\nrobust against variations in noise level. The DQLC exhibits a constant gap to\nthe performance upper bound as the signal-to-noise ratio (SNR) becomes large\nfor any number of sources and values of correlation. Therefore it outperforms a\nlinear solution (uncoded transmission) in any case when the SNR gets\nsufficiently large. \n\n"}
{"id": "1401.2592", "contents": "Title: On the Optimality of Treating Interference as Noise: General Message\n  Sets Abstract: In a K-user Gaussian interference channel, it has been shown that if for each\nuser the desired signal strength is no less than the sum of the strengths of\nthe strongest interference from this user and the strongest interference to\nthis user (all values in dB scale), then treating interference as noise (TIN)\nis optimal from the perspective of generalized degrees-of-freedom (GDoF) and\nachieves the entire channel capacity region to within a constant gap. In this\nwork, we show that for such TIN-optimal interference channels, even if the\nmessage set is expanded to include an independent message from each transmitter\nto each receiver, operating the new channel as the original interference\nchannel and treating interference as noise is still optimal for the sum\ncapacity up to a constant gap. Furthermore, we extend the result to the\nsum-GDoF optimality of TIN in the general setting of X channels with arbitrary\nnumbers of transmitters and receivers. \n\n"}
{"id": "1401.2692", "contents": "Title: On the Optimality of Treating Interference as Noise for $K$ user\n  Parallel Gaussian Interference Networks Abstract: It has been shown recently by Geng et al. that in a $K$ user Gaussian\ninterference network, if for each user the desired signal strength is no less\nthan the sum of the strengths of the strongest interference from this user and\nthe strongest interference to this user (all signal strengths measured in dB\nscale), then power control and treating interference as noise (TIN) is\nsufficient to achieve the entire generalized degrees of freedom (GDoF) region.\nMotivated by the intuition that the deterministic model of Avestimehr et al.\n(ADT deterministic model) is particularly suited for exploring the optimality\nof TIN, the results of Geng et al. are first re-visited under the ADT\ndeterministic model, and are shown to directly translate between the Gaussian\nand deterministic settings. Next, we focus on the extension of these results to\nparallel interference networks, from a sum-capacity/sum-GDoF perspective. To\nthis end, we interpret the explicit characterization of the\nsum-capacity/sum-GDoF of a TIN optimal network (without parallel channels) as a\nminimum weighted matching problem in combinatorial optimization, and obtain a\nsimple characterization in terms of a partition of the interference network\ninto vertex-disjoint cycles. Aided by insights from the cyclic partition, the\nsum-capacity optimality of TIN for $K$ user parallel interference networks is\ncharacterized for the ADT deterministic model, leading ultimately to\ncorresponding GDoF results for the Gaussian setting. In both cases, subject to\na mild invertibility condition the optimality of TIN is shown to extend to\nparallel networks in a separable fashion. \n\n"}
{"id": "1401.3682", "contents": "Title: Broadcast Classical-Quantum Capacity Region of Two-Phase Bidirectional\n  Relaying Channel Abstract: We study a three-node quantum network which enables bidirectional\ncommunication between two nodes with a half-duplex relay node. A\ndecode-and-forward protocol is used to perform the communication in two phases.\nIn the first phase, the messages of two nodes are transmitted to the relay\nnode. In the second phase, the relay node broadcasts a re-encoded composition\nto the two nodes. We determine the capacity region of the broadcast phase. \n\n"}
{"id": "1401.3801", "contents": "Title: Finite-length Analysis on Tail probability for Markov Chain and\n  Application to Simple Hypothesis Testing Abstract: Using terminologies of information geometry, we derive upper and lower bounds\nof the tail probability of the sample mean. Employing these bounds, we obtain\nupper and lower bounds of the minimum error probability of the 2nd kind of\nerror under the exponential constraint for the error probability of the 1st\nkind of error in a simple hypothesis testing for a finite-length Markov chain,\nwhich yields the Hoeffding type bound. For these derivations, we derive upper\nand lower bounds of cumulant generating function for Markov chain. As a\nbyproduct, we obtain another simple proof of central limit theorem for Markov\nchain. \n\n"}
{"id": "1401.3814", "contents": "Title: Information Geometry Approach to Parameter Estimation in Markov Chains Abstract: We consider the parameter estimation of Markov chain when the unknown\ntransition matrix belongs to an exponential family of transition matrices.\nThen, we show that the sample mean of the generator of the exponential family\nis an asymptotically efficient estimator. Further, we also define a curved\nexponential family of transition matrices. Using a transition matrix version of\nthe Pythagorean theorem, we give an asymptotically efficient estimator for a\ncurved exponential family. \n\n"}
{"id": "1401.5234", "contents": "Title: On the third weight of generalized Reed-Muller codes Abstract: In this paper, we study the third weight of generalized Reed-Muller codes. We\nprove under some restrictive condition that the third weight of generalized\nReed-Muller codes depends on the third weight of generalized Reed-Muller codes\nof small order with two variables. In some cases, we are able to determine the\nthird weight and the third weight codewords of generalized Reed-Muller codes. \n\n"}
{"id": "1401.5676", "contents": "Title: A Novel Proof for the DoF Region of the MIMO Broadcast Channel with No\n  CSIT Abstract: In this paper, a new proof for the degrees of freedom (DoF) region of the\nK-user multiple-input multiple-output (MIMO) broadcast channel (BC) with no\nchannel state information at the transmitter (CSIT) and perfect channel state\ninformation at the receivers (CSIR) is provided. Based on this proof, the\ncapacity region of a certain class of MIMO BC with channel distribution\ninformation at the transmitter (CDIT) and perfect CSIR is derived. Finally, an\nouter bound for the DoF region of the MIMO interference channel (IC) with no\nCSIT is provided. \n\n"}
{"id": "1401.6036", "contents": "Title: On involutions in extremal self-dual codes and the dual distance of semi\n  self-dual codes Abstract: A classical result of Conway and Pless is that a natural projection of the\nfixed code of an automorphism of odd prime order of a self-dual binary linear\ncode is self-dual. In this paper we prove that the same holds for involutions\nunder some (quite strong) conditions on the codes. In order to prove it, we\nintroduce a new family of binary codes: the semi self-dual codes. A binary\nself-orthogonal code is called semi self-dual if it contains the all-ones\nvector and is of codimension 2 in its dual code. We prove upper bounds on the\ndual distance of semi self-dual codes. As an application we get the following:\nlet C be an extremal self-dual binary linear code of length 24m and s in Aut(C)\nbe a fixed point free automorphism of order 2. If m is odd or if m=2k with\nbinom{5k-1}{k-1} odd then C is a free F_2<s>-module. This result has quite\nstrong consequences on the structure of the automorphism group of such codes. \n\n"}
{"id": "1401.6219", "contents": "Title: Coding Schemes with Rate-Limited Feedback that Improve over the\n  Nofeedback Capacity for a Large Class of Broadcast Channels Abstract: We propose two coding schemes for the two-receiver discrete memoryless\nbroadcast channel (BC) with rate-limited feedback from one or both receivers.\nThey improve over the nofeedback capacity region for a large class of channels,\nincluding the class of \\emph{strictly essentially less-noisy BCs} that we\nintroduce in this article. Examples of strictly essentially less-noisy BCs are\nthe binary symmetric BC (BSBC) or the binary erasure BC (BEBC) with unequal\ncross-over or erasure probabilities at the two receivers. When the feedback\nrates are sufficiently large, our schemes recover all previously known capacity\nresults for discrete memoryless BCs with feedback.\n  In both our schemes, we let the receivers feed back quantization messages\nabout their receive signals. In the first scheme, the transmitter simply\n\\emph{relays} the quantization information obtained from Receiver 1 to Receiver\n2, and vice versa. This provides each receiver with a second observation of the\ninput signal and can thus improve its decoding performance unless the BC is\nphysically degraded. Moreover, each receiver uses its knowledge of the\nquantization message describing its own outputs so as to attain the same\nperformance as if this message had not been transmitted at all.\n  In our second scheme the transmitter first \\emph{reconstructs and processes}\nthe quantized output signals, and then sends the outcome as a common update\ninformation to both receivers. A special case of our second scheme applies also\nto memoryless BCs without feedback but with strictly-causal state-information\nat the transmitter and causal state-information at the receivers. It recovers\nall previous achievable regions also for this setup with state-information. \n\n"}
{"id": "1401.6338", "contents": "Title: Encoding Tasks and R\\'enyi Entropy Abstract: A task is randomly drawn from a finite set of tasks and is described using a\nfixed number of bits. All the tasks that share its description must be\nperformed. Upper and lower bounds on the minimum $\\rho$-th moment of the number\nof performed tasks are derived. The case where a sequence of tasks is produced\nby a source and $n$ tasks are jointly described using $nR$ bits is considered.\nIf $R$ is larger than the R\\'enyi entropy rate of the source of order\n$1/(1+\\rho)$ (provided it exists), then the $\\rho$-th moment of the ratio of\nperformed tasks to $n$ can be driven to one as $n$ tends to infinity. If $R$ is\nsmaller than the R\\'enyi entropy rate, this moment tends to infinity. The\nresults are generalized to account for the presence of side-information. In\nthis more general setting, the key quantity is a conditional version of R\\'enyi\nentropy that was introduced by Arimoto. For IID sources two additional\nextensions are solved, one of a rate-distortion flavor and the other where\ndifferent tasks may have different nonnegative costs. Finally, a divergence\nthat was identified by Sundaresan as a mismatch penalty in the Massey-Arikan\nguessing problem is shown to play a similar role here. \n\n"}
{"id": "1401.6578", "contents": "Title: Simple Error Bounds for Regularized Noisy Linear Inverse Problems Abstract: Consider estimating a structured signal $\\mathbf{x}_0$ from linear,\nunderdetermined and noisy measurements\n$\\mathbf{y}=\\mathbf{A}\\mathbf{x}_0+\\mathbf{z}$, via solving a variant of the\nlasso algorithm: $\\hat{\\mathbf{x}}=\\arg\\min_\\mathbf{x}\\{\n\\|\\mathbf{y}-\\mathbf{A}\\mathbf{x}\\|_2+\\lambda f(\\mathbf{x})\\}$. Here, $f$ is a\nconvex function aiming to promote the structure of $\\mathbf{x}_0$, say\n$\\ell_1$-norm to promote sparsity or nuclear norm to promote low-rankness. We\nassume that the entries of $\\mathbf{A}$ are independent and normally\ndistributed and make no assumptions on the noise vector $\\mathbf{z}$, other\nthan it being independent of $\\mathbf{A}$. Under this generic setup, we derive\na general, non-asymptotic and rather tight upper bound on the $\\ell_2$-norm of\nthe estimation error $\\|\\hat{\\mathbf{x}}-\\mathbf{x}_0\\|_2$. Our bound is\ngeometric in nature and obeys a simple formula; the roles of $\\lambda$, $f$ and\n$\\mathbf{x}_0$ are all captured by a single summary parameter\n$\\delta(\\lambda\\partial((f(\\mathbf{x}_0)))$, termed the Gaussian squared\ndistance to the scaled subdifferential. We connect our result to the literature\nand verify its validity through simulations. \n\n"}
{"id": "1401.7074", "contents": "Title: Phase Precoded Compute-and-Forward with Partial Feedback Abstract: In this work, we propose phase precoding for the compute-and-forward (CoF)\nprotocol. We derive the phase precoded computation rate and show that it is\ngreater than the original computation rate of CoF protocol without precoder. To\nmaximize the phase precoded computation rate, we need to 'jointly' find the\noptimum phase precoding matrix and the corresponding network equation\ncoefficients. This is a mixed integer programming problem where the optimum\nprecoders should be obtained at the transmitters and the network equation\ncoefficients have to be computed at the relays. To solve this problem, we\nintroduce phase precoded CoF with partial feedback. It is a quantized precoding\nsystem where the relay jointly computes both a quasi-optimal precoder from a\nfinite codebook and the corresponding network equations. The index of the\nobtained phase precoder within the codebook will then be fedback to the\ntransmitters. A \"deep hole phase precoder\" is presented as an example of such a\nscheme. We further simulate our scheme with a lattice code carved out of the\nGosset lattice and show that significant coding gains can be obtained in terms\nof equation error performance. \n\n"}
{"id": "1401.7085", "contents": "Title: Reverse Edge Cut-Set Bounds for Secure Network Coding Abstract: We consider the problem of secure communication over a network in the\npresence of wiretappers. We give a new cut-set bound on secrecy capacity which\ntakes into account the contribution of both forward and backward edges crossing\nthe cut, and the connectivity between their endpoints in the rest of the\nnetwork. We show the bound is tight on a class of networks, which demonstrates\nthat it is not possible to find a tighter bound by considering only cut set\nedges and their connectivity. \n\n"}
{"id": "1401.7229", "contents": "Title: MIMO Multiway Relaying with Pairwise Data Exchange: A Degrees of Freedom\n  Perspective Abstract: In this paper, we study achievable degrees of freedom (DoF) of a\nmultiple-input multiple-output (MIMO) multiway relay channel (mRC) where $K$\nusers, each equipped with $M$ antennas, exchange messages in a pairwise manner\nvia a common $N$-antenna relay node. % A novel and systematic way of joint\nbeamforming design at the users and at the relay is proposed to align signals\nfor efficient implementation of physical-layer network coding (PNC). It is\nshown that, when the user number $K=3$, the proposed beamforming design can\nachieve the DoF capacity of the considered mRC for any $(M,N)$ setups. % For\nthe scenarios with $K>3$, we show that the proposed signaling scheme can be\nimproved by disabling a portion of relay antennas so as to align signals more\nefficiently. Our analysis reveals that the obtained achievable DoF is always\npiecewise linear, and is bounded either by the number of user antennas $M$ or\nby the number of relay antennas $N$. Further, we show that the DoF capacity can\nbe achieved for $\\frac{M}{N} \\in \\left(0,\\frac{K-1}{K(K-2)} \\right]$ and\n$\\frac{M}{N} \\in \\left[\\frac{1}{K(K-1)}+\\frac{1}{2},\\infty \\right)$, which\nprovides a broader range of the DoF capacity than the existing results.\nAsymptotic DoF as $K\\rightarrow \\infty$ is also derived based on the proposed\nsignaling scheme. \n\n"}
{"id": "1401.7293", "contents": "Title: Polar coding for interference networks Abstract: A polar coding scheme for interference networks is introduced. The scheme\ncombines Arikan's monotone chain rules for multiple-access channels and a\nmethod by Hassani and Urbanke to 'align' two incompatible polarization\nprocesses. It achieves the Han--Kobayashi inner bound for two-user interference\nchannels and generalizes to interference networks. \n\n"}
{"id": "1401.7485", "contents": "Title: Superimposed Codes and Threshold Group Testing Abstract: We will discuss superimposed codes and non-adaptive group testing designs\narising from the potentialities of compressed genotyping models in molecular\nbiology. The given paper was motivated by the 30th anniversary of\nD'yachkov-Rykov recurrent upper bound on the rate of superimposed codes\npublished in 1982. We were also inspired by recent results obtained for\nnon-adaptive threshold group testing which develop the theory of superimposed\ncodes \n\n"}
{"id": "1401.8022", "contents": "Title: Synchronizing Rankings via Interactive Communication Abstract: We consider the problem of exact synchronization of two rankings at remote\nlocations connected by a two-way channel. Such synchronization problems arise\nwhen items in the data are distinguishable, as is the case for playlists,\ntasklists, crowdvotes and recommender systems rankings. Our model accounts for\ndifferent constraints on the communication throughput of the forward and\nfeedback links, resulting in different anchoring, syndrome and checksum\ncomputation strategies. Information editing is assumed of the form of\ndeletions, insertions, block deletions/insertions, translocations and\ntranspositions. The protocols developed under the given model are order-optimal\nwith respect to genie aided lower bounds. \n\n"}
{"id": "1401.8265", "contents": "Title: Sub-optimality of Treating Interference as Noise in the Cellular Uplink\n  with Weak Interference Abstract: Despite the simplicity of the scheme of treating interference as noise (TIN),\nit was shown to be sum-capacity optimal in the Gaussian interference channel\n(IC) with very-weak (noisy) interference. In this paper, the 2-user IC is\naltered by introducing an additional transmitter that wants to communicate with\none of the receivers of the IC. The resulting network thus consists of a\npoint-to-point channel interfering with a multiple access channel (MAC) and is\ndenoted PIMAC. The sum-capacity of the PIMAC is studied with main focus on the\noptimality of TIN. It turns out that TIN in its naive variant, where all\ntransmitters are active and both receivers use TIN for decoding, is not the\nbest choice for the PIMAC. In fact, a scheme that combines both time division\nmultiple access and TIN (TDMA-TIN) strictly outperforms the naive-TIN scheme.\nFurthermore, it is shown that in some regimes, TDMA-TIN achieves the\nsum-capacity for the deterministic PIMAC and the sum-capacity within a constant\ngap for the Gaussian PIMAC. Additionally, it is shown that, even for very-weak\ninterference, there are some regimes where a combination of interference\nalignment with power control and treating interference as noise at the receiver\nside outperforms TDMA-TIN. As a consequence, on the one hand treating\ninterference as noise in a cellular uplink is approximately optimal in certain\nregimes. On the other hand those regimes cannot be simply described by the\nstrength of interference. \n\n"}
{"id": "1402.0258", "contents": "Title: A Rate-Distortion Approach to Index Coding Abstract: We approach index coding as a special case of rate-distortion with multiple\nreceivers, each with some side information about the source. Specifically,\nusing techniques developed for the rate-distortion problem, we provide two\nupper bounds and one lower bound on the optimal index coding rate. The upper\nbounds involve specific choices of the auxiliary random variables in the best\nexisting scheme for the rate-distortion problem. The lower bound is based on a\nnew lower bound for the general rate-distortion problem. The bounds are shown\nto coincide for a number of (groupcast) index coding instances, including all\ninstances for which the number of decoders does not exceed three. \n\n"}
{"id": "1402.2707", "contents": "Title: Analysis of Non-Coherent Joint-Transmission Cooperation in Heterogeneous\n  Cellular Networks Abstract: Base station (BS) cooperation is set to play a key role in managing\ninterference in dense heterogeneous cellular networks (HCNs). Non-coherent\njoint transmission (JT) is particularly appealing due to its low complexity,\nsmaller overhead, and ability for load balancing. However, a general analysis\nof this technique is difficult mostly due to the lack of tractable models. This\npaper addresses this gap and presents a tractable model for analyzing\nnon-coherent JT in HCNs, while incorporating key system parameters such as\nuser-centric BS clustering and channel-dependent cooperation activation.\nAssuming all BSs of each tier follow a stationary Poisson point process, the\ncoverage probability for non-coherent JT is derived. Using the developed model,\nit is shown that for small cooperative clusters of small-cell BSs, non-coherent\nJT by small cells provides spectral efficiency gains without significantly\nincreasing cell load. Further, when cooperation is aggressively triggered\nintra-cluster frequency reuse within small cells is favorable over\nintra-cluster coordinated scheduling. \n\n"}
{"id": "1402.3801", "contents": "Title: On Heterogeneous Regenerating Codes and Capacity of Distributed Storage\n  Systems Abstract: Heterogeneous Distributed Storage Systems (DSS) are close to real world\napplications for data storage. Internet caching system and peer-to-peer storage\nclouds are the examples of such DSS. In this work, we calculate the capacity\nformula for such systems where each node store different number of packets and\neach having a different repair bandwidth (node can be repaired by contacting a\nspecific set of nodes). The tradeoff curve between storage and repair bandwidth\nis studied for such heterogeneous DSS. By analyzing the capacity formula new\nminimum bandwidth regenerating (MBR) and minimum storage regenerating (MBR)\npoints are obtained on the curve. It is shown that in some cases these are\nbetter than the homogeneous DSS. \n\n"}
{"id": "1402.6299", "contents": "Title: Necessary and sufficient optimality conditions for classical simulations\n  of quantum communication processes Abstract: We consider the process consisting of preparation, transmission through a\nquantum channel, and subsequent measurement of quantum states. The\ncommunication complexity of the channel is the minimal amount of classical\ncommunication required for classically simulating it. Recently, we reduced the\ncomputation of this quantity to a convex minimization problem with linear\nconstraints. Every solution of the constraints provides an upper bound on the\ncommunication complexity. In this paper, we derive the dual maximization\nproblem of the original one. The feasible points of the dual constraints, which\nare inequalities, give lower bounds on the communication complexity, as\nillustrated with an example. The optimal values of the two problems turn out to\nbe equal (zero duality gap). By this property, we provide necessary and\nsufficient conditions for optimality in terms of a set of equalities and\ninequalities. We use these conditions and two reasonable but unproven\nhypotheses to derive the lower bound $n 2^{n-1}$ for a noiseless quantum\nchannel with capacity equal to $n$ qubits. This lower bound can have\ninteresting consequences in the context of the recent debate on the reality of\nthe quantum state. \n\n"}
{"id": "1402.6305", "contents": "Title: About Adaptive Coding on Countable Alphabets: Max-Stable Envelope\n  Classes Abstract: In this paper, we study the problem of lossless universal source coding for\nstationary memoryless sources on countably infinite alphabets. This task is\ngenerally not achievable without restricting the class of sources over which\nuniversality is desired. Building on our prior work, we propose natural\nfamilies of sources characterized by a common dominating envelope. We\nparticularly emphasize the notion of adaptivity, which is the ability to\nperform as well as an oracle knowing the envelope, without actually knowing it.\nThis is closely related to the notion of hierarchical universal source coding,\nbut with the important difference that families of envelope classes are not\ndiscretely indexed and not necessarily nested.\n  Our contribution is to extend the classes of envelopes over which adaptive\nuniversal source coding is possible, namely by including max-stable\n(heavy-tailed) envelopes which are excellent models in many applications, such\nas natural language modeling. We derive a minimax lower bound on the redundancy\nof any code on such envelope classes, including an oracle that knows the\nenvelope. We then propose a constructive code that does not use knowledge of\nthe envelope. The code is computationally efficient and is structured to use an\n{E}xpanding {T}hreshold for {A}uto-{C}ensoring, and we therefore dub it the\n\\textsc{ETAC}-code. We prove that the \\textsc{ETAC}-code achieves the lower\nbound on the minimax redundancy within a factor logarithmic in the sequence\nlength, and can be therefore qualified as a near-adaptive code over families of\nheavy-tailed envelopes. For finite and light-tailed envelopes the penalty is\neven less, and the same code follows closely previous results that explicitly\nmade the light-tailed assumption. Our technical results are founded on methods\nfrom regular variation theory and concentration of measure. \n\n"}
{"id": "1402.7170", "contents": "Title: Improving the Finite-Length Performance of Spatially Coupled LDPC Codes\n  by Connecting Multiple Code Chains Abstract: In this paper, we analyze the finite-length performance of codes on graphs\nconstructed by connecting spatially coupled low-density parity-check (SC-LDPC)\ncode chains. Successive (peeling) decoding is considered for the binary erasure\nchannel (BEC). The evolution of the undecoded portion of the bipartite graph\nremaining after each iteration is analyzed as a dynamical system. When\nconnecting short SC-LDPC chains, we show that, in addition to superior\niterative decoding thresholds, connected chain ensembles have better\nfinite-length performance than single chain ensembles of the same rate and\nlength. In addition, we present a novel encoding/transmission scheme to improve\nthe performance of a system using long SC-LDPC chains, where, instead of\ntransmitting codewords corresponding to a single SC-LDPC chain independently,\nwe connect consecutive chains in a multi-layer format to form a connected chain\nensemble. We refer to such a transmission scheme to as continuous chain (CC)\ntransmission of SC-LDPC codes. We show that CC transmission can be implemented\nwith no significant increase in encoding/decoding complexity or decoding delay\nwith respect a system using a single SC-LDPC code chain for encoding. \n\n"}
{"id": "1403.2201", "contents": "Title: SMML estimators for linear regression and tessellations of hyperbolic\n  space Abstract: The strict minimum message length (SMML) principle links data compression\nwith inductive inference. The corresponding estimators have many useful\nproperties but they can be hard to calculate. We investigate SMML estimators\nfor linear regression models and we show that they have close connections to\nhyperbolic geometry. When equipped with the Fisher information metric, the\nlinear regression model with $p$ covariates and a sample size of $n$ becomes a\nRiemannian manifold, and we show that this is isometric to $(p+1)$-dimensional\nhyperbolic space $\\mathbb{H}^{p+1}$ equipped with a metric tensor which is $2n$\ntimes the usual metric tensor on $\\mathbb{H}^{p+1}$. A natural identification\nthen allows us to also view the set of sufficient statistics for the linear\nregression model as a hyperbolic space. We show that the partition of an SMML\nestimator corresponds to a tessellation of this hyperbolic space. \n\n"}
{"id": "1403.2535", "contents": "Title: A Delay-Constrained Protocol with Adaptive Mode Selection for\n  Bidirectional Relay Networks Abstract: In this paper, we consider a bidirectional relay network with half-duplex\nnodes and block fading where the nodes transmit with a fixed transmission rate.\nThereby, user 1 and user 2 exchange information only via a relay node, i.e., a\ndirect link between both users is not present. Recently in [1], it was shown\nthat a considerable gain in terms of sum throughput can be obtained in\nbidirectional relaying by optimally selecting the transmission modes or,\nequivalently, the states of the nodes, i.e., the transmit, the receive, and the\nsilent states, in each time slot based on the qualities of the involved links.\nTo enable adaptive transmission mode selection, the relay has to be equipped\nwith two buffers for storage of the data received from the two users. However,\nthe protocol proposed in [1] was delay-unconstrained and provides an upper\nbound for the performance of practical delay-constrained protocols. In this\npaper, we propose a heuristic but efficient delay-constrained protocol which\ncan approach the performance upper bound reported in [1], even in cases where\nonly a small average delay is permitted. In particular, the proposed protocol\ndoes not only take into account the instantaneous qualities of the involved\nlinks for adaptive mode selection but also the states of the queues at the\nbuffers. The average throughput and the average delay of the proposed\ndelay-constrained protocol are evaluated by analyzing the Markov chain of the\nstates of the queues. \n\n"}
{"id": "1403.2580", "contents": "Title: Optimal Resource Allocation in Full-Duplex Wireless-Powered\n  Communication Network Abstract: This paper studies optimal resource allocation in the wireless-powered\ncommunication network (WPCN), where one hybrid access-point (H-AP) operating in\nfull-duplex (FD) broadcasts wireless energy to a set of distributed users in\nthe downlink (DL) and at the same time receives independent information from\nthe users via time-division-multiple-access (TDMA) in the uplink (UL). We\ndesign an efficient protocol to support simultaneous wireless energy transfer\n(WET) in the DL and wireless information transmission (WIT) in the UL for the\nproposed FD-WPCN. We jointly optimize the time allocations to the H-AP for DL\nWET and different users for UL WIT as well as the transmit power allocations\nover time at the H-AP to maximize the users' weighted sum-rate of UL\ninformation transmission with harvested energy. We consider both the cases with\nperfect and imperfect self-interference cancellation (SIC) at the H-AP, for\nwhich we obtain optimal and suboptimal time and power allocation solutions,\nrespectively. Furthermore, we consider the half-duplex (HD) WPCN as a baseline\nscheme and derive its optimal resource allocation solution. Simulation results\nshow that the FD-WPCN outperforms HD-WPCN when effective SIC can be implemented\nand more stringent peak power constraint is applied at the H-AP. \n\n"}
{"id": "1403.3991", "contents": "Title: Throughput Optimization for Massive MIMO Systems Powered by Wireless\n  Energy Transfer Abstract: This paper studies a wireless-energy-transfer (WET) enabled massive\nmultiple-input-multiple-output (MIMO) system (MM) consisting of a hybrid\ndata-and-energy access point (H-AP) and multiple single-antenna users. In the\nWET-MM system, the H-AP is equipped with a large number $M$ of antennas and\nfunctions like a conventional AP in receiving data from users, but additionally\nsupplies wireless power to the users. We consider frame-based transmissions.\nEach frame is divided into three phases: the uplink channel estimation (CE)\nphase, the downlink WET phase, as well as the uplink wireless information\ntransmission (WIT) phase. Firstly, users use a fraction of the previously\nharvested energy to send pilots, while the H-AP estimates the uplink channels\nand obtains the downlink channels by exploiting channel reciprocity. Next, the\nH-AP utilizes the channel estimates just obtained to transfer wireless energy\nto all users in the downlink via energy beamforming. Finally, the users use a\nportion of the harvested energy to send data to the H-AP simultaneously in the\nuplink (reserving some harvested energy for sending pilots in the next frame).\nTo optimize the throughput and ensure rate fairness, we consider the problem of\nmaximizing the minimum rate among all users. In the large-$M$ regime, we obtain\nthe asymptotically optimal solutions and some interesting insights for the\noptimal design of WET-MM system. We define a metric, namely, the massive MIMO\ndegree-of-rate-gain (MM-DoRG), as the asymptotic UL rate normalized by\n$\\log(M)$. We show that the proposed WET-MM system is optimal in terms of\nMM-DoRG, i.e., it achieves the same MM-DoRG as the case with ideal CE. \n\n"}
{"id": "1403.4661", "contents": "Title: An Optimal-Dimensionality Sampling Scheme on the Sphere with Fast\n  Spherical Harmonic Transforms Abstract: We develop a sampling scheme on the sphere that permits accurate computation\nof the spherical harmonic transform and its inverse for signals band-limited at\n$L$ using only $L^2$ samples. We obtain the optimal number of samples given by\nthe degrees of freedom of the signal in harmonic space. The number of samples\nrequired in our scheme is a factor of two or four fewer than existing\ntechniques, which require either $2L^2$ or $4L^2$ samples. We note, however,\nthat we do not recover a sampling theorem on the sphere, where spherical\nharmonic transforms are theoretically exact. Nevertheless, we achieve high\naccuracy even for very large band-limits. For our optimal-dimensionality\nsampling scheme, we develop a fast and accurate algorithm to compute the\nspherical harmonic transform (and inverse), with computational complexity\ncomparable with existing schemes in practice. We conduct numerical experiments\nto study in detail the stability, accuracy and computational complexity of the\nproposed transforms. We also highlight the advantages of the proposed sampling\nscheme and associated transforms in the context of potential applications. \n\n"}
{"id": "1403.5616", "contents": "Title: Quantum-noise limited communication with low probability of detection Abstract: We demonstrate the achievability of a square root limit on the amount of\ninformation transmitted reliably and with low probability of detection (LPD)\nover the single-mode lossy bosonic channel if either the eavesdropper's\nmeasurements or the channel itself is subject to the slightest amount of excess\nnoise. Specifically, Alice can transmit $\\mathcal{O}(\\sqrt{n})$ bits to Bob\nover $n$ channel uses such that Bob's average codeword error probability is\nupper-bounded by an arbitrarily small $\\delta>0$ while a passive eavesdropper,\nWarden Willie, who is assumed to be able to collect all the transmitted photons\nthat do not reach Bob, has an average probability of detection error that is\nlower-bounded by $1/2-\\epsilon$ for an arbitrarily small $\\epsilon>0$. We\nanalyze the thermal noise and pure loss channels. The square root law holds for\nthe thermal noise channel even if Willie employs a quantum-optimal measurement,\nwhile Bob is equipped with a standard coherent detection receiver. We also show\nthat LPD communication is not possible on the pure loss channel. However, this\nresult assumes Willie to possess an ideal receiver that is not subject to\nexcess noise. If Willie is restricted to a practical receiver with a non-zero\ndark current, the square root law is achievable on the pure loss channel. \n\n"}
{"id": "1403.6974", "contents": "Title: Design and Analysis of a Greedy Pursuit for Distributed Compressed\n  Sensing Abstract: We consider a distributed compressed sensing scenario where many sensors\nmeasure correlated sparse signals and the sensors are connected through a\nnetwork. Correlation between sparse signals is modeled by a partial common\nsupport-set. For such a scenario, the main objective of this paper is to\ndevelop a greedy pursuit algorithm. We develop a distributed parallel pursuit\n(DIPP) algorithm based on exchange of information about estimated support-sets\nat sensors. The exchange of information helps to improve estimation of the\npartial common support-set, that in turn helps to gradually improve estimation\nof support-sets in all sensors, leading to a better quality reconstruction\nperformance. We provide restricted isometry property (RIP) based theoretical\nanalysis on the algorithm's convergence and reconstruction performance. Under\ncertain theoretical requirements on the quality of information exchange over\nnetwork and RIP parameters of sensor nodes, we show that the DIPP algorithm\nconverges to a performance level that depends on a scaled additive measurement\nnoise power (convergence in theory) where the scaling coefficient is a function\nof RIP parameters and information processing quality parameters. Using\nsimulations, we show practical reconstruction performance of DIPP vis-a-vis\namount of undersampling, signal-to-measurement-noise ratios and\nnetwork-connectivity conditions. \n\n"}
{"id": "1403.7682", "contents": "Title: Downlink Analysis for a Heterogeneous Cellular Network Abstract: In this paper, a comprehensive study of the the downlink performance in a\nheterogeneous cellular network (or hetnet) is conducted. A general hetnet model\nis considered consisting of an arbitrary number of open-access and\nclosed-access tier of base stations (BSs) arranged according to independent\nhomogeneous Poisson point processes. The BSs of each tier have a constant\ntransmission power, random fading coefficient with an arbitrary distribution\nand arbitrary path-loss exponent of the power-law path-loss model. For such a\nsystem, analytical characterizations for the coverage probability and average\nrate at an arbitrary mobile-station (MS), and average per-tier load are derived\nfor both the max-SINR connectivity and nearest-BS connectivity models. Using\nstochastic ordering, interesting properties and simplifications for the hetnet\ndownlink performance are derived by relating these two connectivity models to\nthe maximum instantaneous received power (MIRP) connectivity model and the\nmaximum biased received power (MBRP) connectivity models, respectively,\nproviding good insights about the hetnets and the downlink performance in these\ncomplex networks. Furthermore, the results also demonstrate the effectiveness\nand analytical tractability of the stochastic geometric approach to study the\nhetnet performance. \n\n"}
{"id": "1403.7870", "contents": "Title: Optimized Training Design for Wireless Energy Transfer Abstract: Radio-frequency (RF) enabled wireless energy transfer (WET), as a promising\nsolution to provide cost-effective and reliable power supplies for\nenergy-constrained wireless networks, has drawn growing interests recently. To\novercome the significant propagation loss over distance, employing\nmulti-antennas at the energy transmitter (ET) to more efficiently direct\nwireless energy to desired energy receivers (ERs), termed \\emph{energy\nbeamforming}, is an essential technique for enabling WET. However, the\nachievable gain of energy beamforming crucially depends on the available\nchannel state information (CSI) at the ET, which needs to be acquired\npractically. In this paper, we study the design of an efficient channel\nacquisition method for a point-to-point multiple-input multiple-output (MIMO)\nWET system by exploiting the channel reciprocity, i.e., the ET estimates the\nCSI via dedicated reverse-link training from the ER. Considering the limited\nenergy availability at the ER, the training strategy should be carefully\ndesigned so that the channel can be estimated with sufficient accuracy, and yet\nwithout consuming excessive energy at the ER. To this end, we propose to\nmaximize the \\emph{net} harvested energy at the ER, which is the average\nharvested energy offset by that used for channel training. An optimization\nproblem is formulated for the training design over MIMO Rician fading channels,\nincluding the subset of ER antennas to be trained, as well as the training time\nand power allocated. Closed-form solutions are obtained for some special\nscenarios, based on which useful insights are drawn on when training should be\nemployed to improve the net transferred energy in MIMO WET systems. \n\n"}
{"id": "1404.0218", "contents": "Title: Sparse Model Uncertainties in Compressed Sensing with Application to\n  Convolutions and Sporadic Communication Abstract: The success of the compressed sensing paradigm has shown that a substantial\nreduction in sampling and storage complexity can be achieved in certain linear\nand non-adaptive estimation problems. It is therefore an advisable strategy for\nnoncoherent information retrieval in, for example, sporadic blind and\nsemi-blind communication and sampling problems. But, the conventional model is\nnot practical here since the compressible signals have to be estimated from\nsamples taken solely on the output of an un-calibrated system which is unknown\nduring measurement but often compressible. Conventionally, one has either to\noperate at suboptimal sampling rates or the recovery performance substantially\nsuffers from the dominance of model mismatch. In this work we discuss such type\nof estimation problems and we focus on bilinear inverse problems. We link this\nproblem to the recovery of low-rank and sparse matrices and establish stable\nlow-dimensional embeddings of the uncalibrated receive signals whereby\naddressing also efficient communication-oriented methods like universal random\ndemodulation. Exemplary, we investigate in more detail sparse convolutions\nserving as a basic communication channel model. In using some recent results\nfrom additive combinatorics we show that such type of signals can be\nefficiently low-rate sampled by semi-blind methods. Finally, we present a\nfurther application of these results in the field of phase retrieval from\nintensity Fourier measurements. \n\n"}
{"id": "1404.2796", "contents": "Title: Linear Batch Codes Abstract: In an application, where a client wants to obtain many elements from a large\ndatabase, it is often desirable to have some load balancing. Batch codes\n(introduced by Ishai et al. in STOC 2004) make it possible to do exactly that:\nthe large database is divided between many servers, so that the client has to\nonly make a small number of queries to every server to obtain sufficient\ninformation to reconstruct all desired elements. Other important parameters of\nthe batch codes are total storage and the number of servers. Batch codes also\nhave applications in cryptography (namely, in the construction of multi-query\ncomputationally-private information retrieval protocols).\n  In this work, we initiate the study of linear batch codes. These codes, in\nparticular, are of potential use in distributed storage systems. We show that a\ngenerator matrix of a binary linear batch code is also a generator matrix of\nclassical binary linear error-correcting code. This immediately yields that a\nvariety of upper bounds, which were developed for error-correcting codes, are\napplicable also to binary linear batch codes. We also propose new methods to\nconstruct large linear batch codes from the smaller ones. \n\n"}
{"id": "1404.3022", "contents": "Title: Multi-Trial Guruswami-Sudan Decoding for Generalised Reed--Solomon Codes Abstract: An iterated refinement procedure for the Guruswami-Sudan list decoding\nalgorithm for Generalised Reed-Solomon codes based on Alekhnovich's module\nminimisation is proposed. The method is parametrisable and allows variants of\nthe usual list decoding approach. In particular, finding the list of closest\ncodewords within an intermediate radius can be performed with improved\naverage-case complexity while retaining the worst-case complexity. We provide a\ndetailed description of the module minimisation, reanalysing the\nMulders-Storjohann algorithm and drawing new connections to both Alekhnovich's\nalgorithm and Lee-O'Sullivan's. Furthermore, we show how to incorporate the\nre-encoding technique of K\\\"otter and Vardy into our iterative algorithm. \n\n"}
{"id": "1404.3250", "contents": "Title: On the rank of random matrices over finite fields Abstract: A novel lower bound is introduced for the full rank probability of random\nfinite field matrices, where a number of elements with known location are\nidentically zero, and remaining elements are chosen independently of each\nother, uniformly over the field. The main ingredient is a result showing that\nconstraining additional elements to be zero cannot result in a higher\nprobability of full rank. The bound then follows by \"zeroing\" elements to\nproduce a block-diagonal matrix, whose full rank probability can be computed\nexactly. The bound is shown to be at least as tight and can be strictly tighter\nthan existing bounds. \n\n"}
{"id": "1404.3733", "contents": "Title: Quantum Information Complexity and Amortized Communication Abstract: We define a new notion of information cost for quantum protocols, and a\ncorresponding notion of quantum information complexity for bipartite quantum\nchannels, and then investigate the properties of such quantities. These are the\nfully quantum generalizations of the analogous quantities for bipartite\nclassical functions that have found many applications recently, in particular\nfor proving communication complexity lower bounds. Our definition is strongly\ntied to the quantum state redistribution task.\n  Previous attempts have been made to define such a quantity for quantum\nprotocols, with particular applications in mind; our notion differs from these\nin many respects. First, it directly provides a lower bound on the quantum\ncommunication cost, independent of the number of rounds of the underlying\nprotocol. Secondly, we provide an operational interpretation for quantum\ninformation complexity: we show that it is exactly equal to the amortized\nquantum communication complexity of a bipartite channel on a given state. This\ngeneralizes a result of Braverman and Rao to quantum protocols, and even\nstrengthens the classical result in a bounded round scenario. Also, this\nprovides an analogue of the Schumacher source compression theorem for\ninteractive quantum protocols, and answers a question raised by Braverman.\n  We also discuss some potential applications to quantum communication\ncomplexity lower bounds by specializing our definition for classical functions\nand inputs. Building on work of Jain, Radhakrishnan and Sen, we provide new\nevidence suggesting that the bounded round quantum communication complexity of\nthe disjointness function is \\Omega (n/M + M), for M-message protocols. This\nwould match the best known upper bound. \n\n"}
{"id": "1404.3997", "contents": "Title: Lossless Coding of Correlated Sources with Actions Abstract: This work studies the problem of distributed compression of correlated\nsources with an action-dependent joint distribution. This class of problems is,\nin fact, an extension of the Slepian-Wolf model, but where cost-constrained\nactions taken by the encoder or the decoder affect the generation of one of the\nsources. The purpose of this work is to study the implications of actions on\nthe achievable rates.\n  In particular, two cases where transmission occurs over a rate-limited link\nare studied; case A for actions taken at the decoder and case B where actions\nare taken at the encoder. A complete single-letter characterization of the set\nof achievable rates is given in both cases. Furthermore, a network coding setup\nis investigated for the case where actions are taken at the encoder. The\nsources are generated at different nodes of the network and are required at a\nset of terminal nodes, yet transmission occurs over a general, acyclic,\ndirected network. For this setup, generalized cut-set bounds are derived, and a\nfull characterization of the set of achievable rates using single-letter\nexpressions is provided. For this scenario, random linear network coding is\nproved to be optimal, even though this is not a classical multicast problem.\nAdditionally, two binary examples are investigated and demonstrate how actions\ntaken at different nodes of the system have a significant affect on the\nachievable rate region in comparison to a naive time-sharing strategy. \n\n"}
{"id": "1404.4157", "contents": "Title: Phase Precoding for the Compute-and-Forward Protocol Abstract: The compute-and-forward (CoF) is a relaying protocol, which uses algebraic\nstructured codes to harness the interference and remove the noise in wireless\nnetworks. We propose the use of phase precoders at the transmitters of a\nnetwork, where relays apply CoF strategy. We define the {\\em phase precoded\ncomputation rate} and show that it is greater than the original computation\nrate of CoF protocol. We further give a new low-complexity method for finding\nnetwork equations. We finally show that the proposed precoding scheme increases\nthe degrees-of-freedom (DoF) of CoF protocol. This overcomes the limitations on\nthe DoF of the CoF protocol, recently presented by Niesen and Whiting. Using\ntools from Diophantine approximation and algebraic geometry, we prove the\nexistence of a phase precoder that approaches the maximum DoF when the number\nof transmitters tends to infinity. \n\n"}
{"id": "1404.5683", "contents": "Title: The Likelihood Encoder for Lossy Source Compression Abstract: In this work, a likelihood encoder is studied in the context of lossy source\ncompression. The analysis of the likelihood encoder is based on a soft-covering\nlemma. It is demonstrated that the use of a likelihood encoder together with\nthe soft-covering lemma gives alternative achievability proofs for classical\nsource coding problems. The case of the rate-distortion function with side\ninformation at the decoder (i.e. the Wyner-Ziv problem) is carefully examined\nand an application of the likelihood encoder to the multi-terminal source\ncoding inner bound (i.e. the Berger-Tung region) is outlined. \n\n"}
{"id": "1404.6012", "contents": "Title: Degrees of Freedom of Uplink-Downlink Multiantenna Cellular Networks Abstract: An uplink-downlink two-cell cellular network is studied in which the first\nbase station (BS) with $M_1$ antennas receives independent messages from its\n$N_1$ serving users, while the second BS with $M_2$ antennas transmits\nindependent messages to its $N_2$ serving users. That is, the first and second\ncells operate as uplink and downlink, respectively. Each user is assumed to\nhave a single antenna. Under this uplink-downlink setting, the sum degrees of\nfreedom (DoF) is completely characterized as the minimum of\n$(N_1N_2+\\min(M_1,N_1)(N_1-N_2)^++\\min(M_2,N_2)(N_2-N_1)^+)/\\max(N_1,N_2)$,\n$M_1+N_2,M_2+N_1$, $\\max(M_1,M_2)$, and $\\max(N_1,N_2)$, where $a^+$ denotes\n$\\max(0,a)$. The result demonstrates that, for a broad class of network\nconfigurations, operating one of the two cells as uplink and the other cell as\ndownlink can strictly improve the sum DoF compared to the conventional uplink\nor downlink operation, in which both cells operate as either uplink or\ndownlink. The DoF gain from such uplink-downlink operation is further shown to\nbe achievable for heterogeneous cellular networks having hotspots and with\ndelayed channel state information. \n\n"}
{"id": "1404.6026", "contents": "Title: Proximal linearized iteratively reweighted least squares for a class of\n  nonconvex and nonsmooth problems Abstract: For solving a wide class of nonconvex and nonsmooth problems, we propose a\nproximal linearized iteratively reweighted least squares (PL-IRLS) algorithm.\nWe first approximate the original problem by smoothing methods, and second\nwrite the approximated problem into an auxiliary problem by introducing new\nvariables. PL-IRLS is then built on solving the auxiliary problem by utilizing\nthe proximal linearization technique and the iteratively reweighted least\nsquares (IRLS) method, and has remarkable computation advantages. We show that\nPL-IRLS can be extended to solve more general nonconvex and nonsmooth problems\nvia adjusting generalized parameters, and also to solve nonconvex and nonsmooth\nproblems with two or more blocks of variables. Theoretically, with the help of\nthe Kurdyka- Lojasiewicz property, we prove that each bounded sequence\ngenerated by PL-IRLS globally converges to a critical point of the approximated\nproblem. To the best of our knowledge, this is the first global convergence\nresult of applying IRLS idea to solve nonconvex and nonsmooth problems. At\nlast, we apply PL-IRLS to solve three representative nonconvex and nonsmooth\nproblems in sparse signal recovery and low-rank matrix recovery and obtain new\nglobally convergent algorithms. \n\n"}
{"id": "1404.6348", "contents": "Title: A DoF-Optimal Scheme for the two-user X-channel with Synergistic\n  Alternating CSIT Abstract: In this paper, the degrees of freedom (DoF) of the two-user single input\nsingle output (SISO) X-channel are investigated. Three cases are considered for\nthe availability of channel state information at the transmitters (CSIT);\nperfect, delayed, and no-CSIT. A new achievable scheme is proposed to elucidate\nthe potency of interference creation-resurrection (IRC) when the available CSIT\nalternates between these three cases. For some patterns of alternating CSIT,\nthe proposed scheme achieves $4/3$ DoF, and hence, coincides with the\ninformation theoretic upper bound on the DoF of the two-user X-channel with\nperfect and instantaneous CSIT. The CSIT alternation patterns are investigated\nwhere the patterns that provide extraordinary synergistic gain and dissociative\nones are identified. \n\n"}
{"id": "1404.6563", "contents": "Title: Coded Caching for Multi-level Popularity and Access Abstract: To address the exponentially rising demand for wireless content, use of\ncaching is emerging as a potential solution. It has been recently established\nthat joint design of content delivery and storage (coded caching) can\nsignificantly improve performance over conventional caching. Coded caching is\nwell suited to emerging heterogeneous wireless architectures which consist of a\ndense deployment of local-coverage wireless access points (APs) with high data\nrates, along with sparsely-distributed, large-coverage macro-cell base stations\n(BS). This enables design of coded caching-and-delivery schemes that equip APs\nwith storage, and place content in them in a way that creates coded-multicast\nopportunities for combining with macro-cell broadcast to satisfy users even\nwith different demands. Such coded-caching schemes have been shown to be\norder-optimal with respect to the BS transmission rate, for a system with\nsingle-level content, i.e., one where all content is uniformly popular. In this\nwork, we consider a system with non-uniform popularity content which is divided\ninto multiple levels, based on varying degrees of popularity. The main\ncontribution of this work is the derivation of an order-optimal scheme which\njudiciously shares cache memory among files with different popularities. To\nshow order-optimality we derive new information-theoretic lower bounds, which\nuse a sliding-window entropy inequality, effectively creating a non-cutset\nbound. We also extend the ideas to when users can access multiple caches along\nwith the broadcast. Finally we consider two extreme cases of user distribution\nacross caches for the multi-level popularity model: a single user per cache\n(single-user setup) versus a large number of users per cache (multi-user\nsetup), and demonstrate a dichotomy in the order-optimal strategies for these\ntwo extreme cases. \n\n"}
{"id": "1404.7041", "contents": "Title: Super-resolution Line Spectrum Estimation with Block Priors Abstract: We address the problem of super-resolution line spectrum estimation of an\nundersampled signal with block prior information. The component frequencies of\nthe signal are assumed to take arbitrary continuous values in known frequency\nblocks. We formulate a general semidefinite program to recover these\ncontinuous-valued frequencies using theories of positive trigonometric\npolynomials. The proposed semidefinite program achieves super-resolution\nfrequency recovery by taking advantage of known structures of frequency blocks.\nNumerical experiments show great performance enhancements using our method. \n\n"}
{"id": "1405.0879", "contents": "Title: Integrated Information-induced quantum collapse Abstract: We present a novel spontaneous collapse model where size is no longer the\nproperty of a physical system which determines its rate of collapse. Instead,\nwe argue that the rate of spontaneous localization should depend on a system's\nquantum Integrated Information (QII), a novel physical property which describes\na system's capacity to act like a quantum observer. We introduce quantum\nIntegrated Information, present our QII collapse model and briefly explain how\nit may be experimentally tested against quantum theory. \n\n"}
{"id": "1405.1472", "contents": "Title: An Exploration of the Role of Principal Inertia Components in\n  Information Theory Abstract: The principal inertia components of the joint distribution of two random\nvariables $X$ and $Y$ are inherently connected to how an observation of $Y$ is\nstatistically related to a hidden variable $X$. In this paper, we explore this\nconnection within an information theoretic framework. We show that, under\ncertain symmetry conditions, the principal inertia components play an important\nrole in estimating one-bit functions of $X$, namely $f(X)$, given an\nobservation of $Y$. In particular, the principal inertia components bear an\ninterpretation as filter coefficients in the linear transformation of\n$p_{f(X)|X}$ into $p_{f(X)|Y}$. This interpretation naturally leads to the\nconjecture that the mutual information between $f(X)$ and $Y$ is maximized when\nall the principal inertia components have equal value. We also study the role\nof the principal inertia components in the Markov chain $B\\rightarrow\nX\\rightarrow Y\\rightarrow \\widehat{B}$, where $B$ and $\\widehat{B}$ are binary\nrandom variables. We illustrate our results for the setting where $X$ and $Y$\nare binary strings and $Y$ is the result of sending $X$ through an additive\nnoise binary channel. \n\n"}
{"id": "1405.2029", "contents": "Title: Mutual Information as a Figure of Merit for Optical Fiber Systems Abstract: Advanced channel decoders rely on soft-decision decoder inputs for which\nmutual information (MI) is the natural figure of merit. In this paper, we\nanalyze an optical fiber system by evaluating MI as the maximum achievable rate\nof transmission of such a system. MI is estimated by means of histograms for\nwhich the correct bin number is determined in a blind way. The MI estimate\nobtained this way shows excellent accuracy in comparison with the true MI of\n16-state quadrature amplitude modulation (QAM) over an additive white Gaussian\nnoise channel with additional phase noise, which is a simplified model of a\nnonlinear optical fiber channel. We thereby justify to use the MI estimation\nmethod to accurately estimate the MI of an optical fiber system. In the second\npart of this work, a transoceanic fiber system with 6000 km of standard\nsingle-mode fiber is simulated and its MI determined. Among rectangular QAMs,\n16-QAM is found to be the optimal modulation scheme for this link as to\nperformance in terms of MI and requirements on components and digital signal\nprocessing. For the reported MI of 3.1 bits/symbol, a minimum coding overhead\nof 29% is required when the channel memory is not taken into account. By\nemploying ideal single-channel digital back-propagation, an increase in MI by\n0.25 bits/symbol and 0.28 bits/symbol is reported for 16-QAM and 64-QAM,\nrespectively, lowering the required overhead to 19% and 16%. When the channel\nspacing is decreased to be close to the Nyquist rate, the dual-polarization\nspectral efficiency is 5.7 bits/s/Hz, an increase of more than 2 bits/symbol\ncompared to a 50 GHz spacing. \n\n"}
{"id": "1405.2492", "contents": "Title: Unified and Distributed QoS-Driven Cell Association Algorithms in\n  Heterogeneous Networks Abstract: This paper addresses the cell association problem in the downlink of a\nmulti-tier heterogeneous network (HetNet), where base stations (BSs) have\nfinite number of resource blocks (RBs) available to distribute among their\nassociated users. Two problems are defined and treated in this paper: sum\nutility of long term rate maximization with long term rate quality of service\n(QoS) constraints, and global outage probability minimization with outage QoS\nconstraints. The first problem is well-suited for low mobility environments,\nwhile the second problem provides a framework to deal with environments with\nfast fading. The defined optimization problems in this paper are solved in two\nphases: cell association phase followed by the optional RB distribution phase.\nWe show that the cell association phase of both problems have the same\nstructure. Based on this similarity, we propose a unified distributed algorithm\nwith low levels of message passing to for the cell association phase. This\ndistributed algorithm is derived by relaxing the association constraints and\nusing Lagrange dual decomposition method. In the RB distribution phase, the\nremaining RBs after the cell association phase are distributed among the users.\nSimulation results show the superiority of our distributed cell association\nscheme compared to schemes that are based on maximum signal to interference\nplus noise ratio (SINR). \n\n"}
{"id": "1405.3182", "contents": "Title: Scalable Coordinated Beamforming for Dense Wireless Cooperative Networks Abstract: To meet the ever growing demand for both high throughput and uniform coverage\nin future wireless networks, dense network deployment will be ubiquitous, for\nwhich co- operation among the access points is critical. Considering the\ncomputational complexity of designing coordinated beamformers for dense\nnetworks, low-complexity and suboptimal precoding strategies are often adopted.\nHowever, it is not clear how much performance loss will be caused. To enable\noptimal coordinated beamforming, in this paper, we propose a framework to\ndesign a scalable beamforming algorithm based on the alternative direction\nmethod of multipliers (ADMM) method. Specifically, we first propose to apply\nthe matrix stuffing technique to transform the original optimization problem to\nan equivalent ADMM-compliant problem, which is much more efficient than the\nwidely-used modeling framework CVX. We will then propose to use the ADMM\nalgorithm, a.k.a. the operator splitting method, to solve the transformed\nADMM-compliant problem efficiently. In particular, the subproblems of the ADMM\nalgorithm at each iteration can be solved with closed-forms and in parallel.\nSimulation results show that the proposed techniques can result in significant\ncomputational efficiency compared to the state- of-the-art interior-point\nsolvers. Furthermore, the simulation results demonstrate that the optimal\ncoordinated beamforming can significantly improve the system performance\ncompared to sub-optimal zero forcing beamforming. \n\n"}
{"id": "1405.3980", "contents": "Title: Sampling and Distortion Tradeoffs for Bandlimited Periodic Signals Abstract: In this paper, the optimal sampling strategies (uniform or nonuniform) and\ndistortion tradeoffs for Gaussian bandlimited periodic signals with additive\nwhite Gaussian noise are studied. Our emphasis is on characterizing the optimal\nsampling locations as well as the optimal pre-sampling filter to minimize the\nreconstruction distortion. We first show that to achieve the optimal\ndistortion, no pre-sampling filter is necessary for any arbitrary sampling\nrate. Then, we provide a complete characterization of optimal distortion for\nlow and high sampling rates (with respect to the signal bandwidth). We also\nprovide bounds on the reconstruction distortion for rates in the intermediate\nregion. It is shown that nonuniform sampling outperforms uniform sampling for\nlow sampling rates. In addition, the optimal nonuniform sampling set is robust\nwith respect to missing sampling values. On the other hand, for the sampling\nrates above the Nyquist rate, the uniform sampling strategy is optimal. An\nextension of the results for random discrete periodic signals is discussed with\nsimulation results indicating that the intuitions from the continuous domain\ncarry over to the discrete domain. Sparse signals are also considered, where it\nis shown that uniform sampling is optimal above the Nyquist rate. \n\n"}
{"id": "1405.4981", "contents": "Title: Distributed Storage for Data Security Abstract: We study the secrecy of a distributed storage system for passwords. The\nencoder, Alice, observes a length-n password and describes it using two hints,\nwhich she then stores in different locations. The legitimate receiver, Bob,\nobserves both hints. The eavesdropper, Eve, sees only one of the hints; Alice\ncannot control which. We characterize the largest normalized (by n) exponent\nthat we can guarantee for the number of guesses it takes Eve to guess the\npassword subject to the constraint that either the number of guesses it takes\nBob to guess the password or the size of the list that Bob must form to\nguarantee that it contain the password approach 1 as n tends to infinity. \n\n"}
{"id": "1405.6249", "contents": "Title: On LDPC Codes for Gaussian Interference Channels Abstract: In this paper, we focus on the two-user Gaussian interference channel (GIC),\nand study the Han-Kobayashi (HK) coding/decoding strategy with the objective of\ndesigning low-density parity-check (LDPC) codes. A code optimization algorithm\nis proposed which adopts a random perturbation technique via tracking the\naverage mutual information. The degree distribution optimization and\nconvergence threshold computation are carried out for strong and weak\ninterference channels, employing binary phase-shift keying (BPSK). Under strong\ninterference, it is observed that optimized codes operate close to the capacity\nboundary. For the case of weak interference, it is shown that via the newly\ndesigned codes, a nontrivial rate pair is achievable, which is not attainable\nby single user codes with time-sharing. Performance of the designed LDPC codes\nare also studied for finite block lengths through simulations of specific codes\npicked from the optimized degree distributions. \n\n"}
{"id": "1406.2255", "contents": "Title: Energy-Efficient Cooperative Cognitive Relaying Schemes for Cognitive\n  Radio Networks Abstract: We investigate a cognitive radio network in which a primary user (PU) may\ncooperate with a cognitive radio user (i.e., a secondary user (SU)) for\ntransmissions of its data packets. The PU is assumed to be a buffered node\noperating in a time-slotted fashion where the time is partitioned into\nequal-length slots. We develop two schemes which involve cooperation between\nprimary and secondary users. To satisfy certain quality of service (QoS)\nrequirements, users share time slot duration and channel frequency bandwidth.\nMoreover, the SU may leverage the primary feedback message to further increase\nboth its data rate and satisfy the PU QoS requirements. The proposed\ncooperative schemes are designed such that the SU data rate is maximized under\nthe constraint that the PU average queueing delay is maintained less than the\naverage queueing delay in case of non-cooperative PU. In addition, the proposed\nschemes guarantee the stability of the PU queue and maintain the average energy\nemitted by the SU below a certain value. The proposed schemes also provide more\nrobust and potentially continuous service for SUs compared to the conventional\npractice in cognitive networks where SUs transmit in the spectrum holes and\nsilence sessions of the PUs. We include primary source burstiness, sensing\nerrors, and feedback decoding errors to the analysis of our proposed\ncooperative schemes. The optimization problems are solved offline and require a\nsimple 2-dimensional grid-based search over the optimization variables.\nNumerical results show the beneficial gains of the cooperative schemes in terms\nof SU data rate and PU throughput, average PU queueing delay, and average PU\nenergy savings. \n\n"}
{"id": "1406.4178", "contents": "Title: On asymptotic structure in compressed sensing Abstract: This paper demonstrates how new principles of compressed sensing, namely\nasymptotic incoherence, asymptotic sparsity and multilevel sampling, can be\nutilised to better understand underlying phenomena in practical compressed\nsensing and improve results in real-world applications. The contribution of the\npaper is fourfold:\n  First, it explains how the sampling strategy depends not only on the signal\nsparsity but also on its structure, and shows how to design effective sampling\nstrategies utilising this.\n  Second, it demonstrates that the optimal sampling strategy and the efficiency\nof compressed sensing also depends on the resolution of the problem, and shows\nhow this phenomenon markedly affects compressed sensing results and how to\nexploit it.\n  Third, as the new framework also fits analog (infinite dimensional) models\nthat govern many inverse problems in practice, the paper describes how it can\nbe used to yield substantial improvements.\n  Fourth, by using multilevel sampling, which exploits the structure of the\nsignal, the paper explains how one can outperform random Gaussian/Bernoulli\nsampling even when the classical $l^1$ recovery algorithm is replaced by\nmodified algorithms which aim to exploit structure such as model based or\nBayesian compressed sensing or approximate message passaging. This final\nobservation raises the question whether universality is desirable even when\nsuch matrices are applicable.\n  Examples of practical applications investigated in this paper include\nMagnetic Resonance Imaging (MRI), Electron Microscopy (EM), Compressive Imaging\n(CI) and Fluorescence Microscopy (FM). For the latter, a new compressed sensing\napproach is also presented. \n\n"}
{"id": "1406.5786", "contents": "Title: Queued cross-bar network models for replication and coded storage\n  systems Abstract: Coding techniques may be useful for data center data survivability as well as\nfor reducing traffic congestion. We present a queued cross-bar network (QCN)\nmethod that can be used for traffic analysis of both replication/uncoded and\ncoded storage systems. We develop a framework for generating QCN rate regions\n(RRs) by analyzing their conflict graph stable set polytopes (SSPs). In doing\nso, we apply recent results from graph theory on the characterization of\nparticular graph SSPs. We characterize the SSP of QCN conflict graphs under a\nvariety of traffic patterns, allowing for their efficient RR computation. For\nuncoded systems, we show how to compute RRs and find rate optimal scheduling\nalgorithms. For coded storage, we develop a RR upper bound, for which we\nprovide an intuitive interpretation. We show that the coded storage RR upper\nbound is achievable in certain coded systems in which drives store sufficient\ncoded information, as well in certain dynamic coding systems. Numerical\nillustrations show that coded storage can result in gains in RR volume of\napproximately 50%, averaged across traffic patterns. \n\n"}
{"id": "1406.5988", "contents": "Title: Large System Analysis of the Energy Consumption Distribution in\n  Multi-User MIMO Systems with Mobility Abstract: In this work, we consider the downlink of a single-cell multi-user MIMO\nsystem in which the base station (BS) makes use of $N$ antennas to communicate\nwith $K$ single-antenna user equipments (UEs). The UEs move around in the cell\naccording to a random walk mobility model. We aim at determining the energy\nconsumption distribution when different linear precoding techniques are used at\nthe BS to guarantee target rates within a finite time interval $T$. The\nanalysis is conducted in the asymptotic regime where $N$ and $K$ grow large\nwith fixed ratio under the assumption of perfect channel state information\n(CSI). Both recent and standard results from large system analysis are used to\nprovide concise formulae for the asymptotic transmit powers and beamforming\nvectors for all considered schemes. These results are eventually used to\nprovide a deterministic approximation of the energy consumption and to study\nits fluctuations around this value in the form of a central limit theorem.\nClosed-form expressions for the asymptotic means and variances are given.\nNumerical results are used to validate the accuracy of the theoretical analysis\nand to make comparisons. We show how the results can be used to approximate the\nprobability that a battery-powered BS runs out of energy and also to design the\ncell radius for minimizing the energy consumption per unit area. The imperfect\nCSI case is also briefly considered. \n\n"}
{"id": "1406.7373", "contents": "Title: How to Achieve the Capacity of Asymmetric Channels Abstract: We survey coding techniques that enable reliable transmission at rates that\napproach the capacity of an arbitrary discrete memoryless channel. In\nparticular, we take the point of view of modern coding theory and discuss how\nrecent advances in coding for symmetric channels help provide more efficient\nsolutions for the asymmetric case. We consider, in more detail, three basic\ncoding paradigms.\n  The first one is Gallager's scheme that consists of concatenating a linear\ncode with a non-linear mapping so that the input distribution can be\nappropriately shaped. We explicitly show that both polar codes and spatially\ncoupled codes can be employed in this scenario. Furthermore, we derive a\nscaling law between the gap to capacity, the cardinality of the input and\noutput alphabets, and the required size of the mapper.\n  The second one is an integrated scheme in which the code is used both for\nsource coding, in order to create codewords distributed according to the\ncapacity-achieving input distribution, and for channel coding, in order to\nprovide error protection. Such a technique has been recently introduced by\nHonda and Yamamoto in the context of polar codes, and we show how to apply it\nalso to the design of sparse graph codes.\n  The third paradigm is based on an idea of B\\\"ocherer and Mathar, and\nseparates the two tasks of source coding and channel coding by a chaining\nconstruction that binds together several codewords. We present conditions for\nthe source code and the channel code, and we describe how to combine any source\ncode with any channel code that fulfill those conditions, in order to provide\ncapacity-achieving schemes for asymmetric channels. In particular, we show that\npolar codes, spatially coupled codes, and homophonic codes are suitable as\nbasic building blocks of the proposed coding strategy. \n\n"}
{"id": "1407.0381", "contents": "Title: Minimax rates of entropy estimation on large alphabets via best\n  polynomial approximation Abstract: Consider the problem of estimating the Shannon entropy of a distribution over\n$k$ elements from $n$ independent samples. We show that the minimax mean-square\nerror is within universal multiplicative constant factors of $$\\Big(\\frac{k }{n\n\\log k}\\Big)^2 + \\frac{\\log^2 k}{n}$$ if $n$ exceeds a constant factor of\n$\\frac{k}{\\log k}$; otherwise there exists no consistent estimator. This\nrefines the recent result of Valiant-Valiant \\cite{VV11} that the minimal\nsample size for consistent entropy estimation scales according to\n$\\Theta(\\frac{k}{\\log k})$. The apparatus of best polynomial approximation\nplays a key role in both the construction of optimal estimators and, via a\nduality argument, the minimax lower bound. \n\n"}
{"id": "1407.1338", "contents": "Title: Extremal Mechanisms for Local Differential Privacy Abstract: Local differential privacy has recently surfaced as a strong measure of\nprivacy in contexts where personal information remains private even from data\nanalysts. Working in a setting where both the data providers and data analysts\nwant to maximize the utility of statistical analyses performed on the released\ndata, we study the fundamental trade-off between local differential privacy and\nutility. This trade-off is formulated as a constrained optimization problem:\nmaximize utility subject to local differential privacy constraints. We\nintroduce a combinatorial family of extremal privatization mechanisms, which we\ncall staircase mechanisms, and show that it contains the optimal privatization\nmechanisms for a broad class of information theoretic utilities such as mutual\ninformation and $f$-divergences. We further prove that for any utility function\nand any privacy level, solving the privacy-utility maximization problem is\nequivalent to solving a finite-dimensional linear program, the outcome of which\nis the optimal staircase mechanism. However, solving this linear program can be\ncomputationally expensive since it has a number of variables that is\nexponential in the size of the alphabet the data lives in. To account for this,\nwe show that two simple privatization mechanisms, the binary and randomized\nresponse mechanisms, are universally optimal in the low and high privacy\nregimes, and well approximate the intermediate regime. \n\n"}
{"id": "1407.1492", "contents": "Title: Joint Beamforming Design for Multi-User Wireless Information and Power\n  Transfer Abstract: In this paper, we propose a joint beamforming algorithm for a multiuser\nwireless information and power transfer (MU-WIPT) system that is compatible\nwith the conventional multiuser multiple input multiple output (MU-MIMO)\nsystem. The proposed joint beamforming vectors are initialized using the well\nestablished MU-MIMO zero-forcing beamforming (ZFBF) and are further updated to\nmaximize the total harvested energy of energy harvesting (EH) users and\nguarantee the signal to interference plus noise ratio (SINR) constraints of the\nco-scheduled information decoding (ID) users. When ID and EH users are\nsimultaneously served by joint beamforming vectors, the harvested energy can be\nincreased at the cost of an SINR loss for ID users. To characterize the SINR\nloss, the target SINR ratio,u, is introduced as the target SINR (i.e., SINR\nconstraint) normalized by the received SINR achievable with ZFBF. Based on that\nratio, the sum rate and harvested energy obtained from the proposed algorithm\nare analyzed under perfect/imperfect channel state information at the\ntransmitter (CSIT). Through simulations and numerical results, we validate the\nderived analyses and demonstrate the EH and ID performance compared to both\nstate of the art and conventional schemes. \n\n"}
{"id": "1407.3474", "contents": "Title: Multichannel group sparsity methods for compressive channel estimation\n  in doubly selective multicarrier MIMO systems (extended version) Abstract: We consider channel estimation within pulse-shaping multicarrier\nmultiple-input multiple-output (MIMO) systems transmitting over doubly\nselective MIMO channels. This setup includes MIMO orthogonal frequency-division\nmultiplexing (MIMO-OFDM) systems as a special case. We show that the component\nchannels tend to exhibit an approximate joint group sparsity structure in the\ndelay-Doppler domain. We then develop a compressive channel estimator that\nexploits this structure for improved performance. The proposed channel\nestimator uses the methodology of multichannel group sparse compressed sensing,\nwhich combines the methodologies of group sparse compressed sensing and\nmultichannel compressed sensing. We derive an upper bound on the channel\nestimation error and analyze the estimator's computational complexity. The\nperformance of the estimator is further improved by introducing a basis\nexpansion yielding enhanced joint group sparsity, along with a basis\noptimization algorithm that is able to utilize prior statistical information if\navailable. Simulations using a geometry-based channel simulator demonstrate the\nperformance gains due to leveraging the joint group sparsity and optimizing the\nbasis. \n\n"}
{"id": "1407.4177", "contents": "Title: Power Control for Sum Rate Maximization on Interference Channels Under\n  Sum Power Constraint Abstract: In this paper, we consider the problem of power control for sum rate\nmaximization on multiple interfering links (TX-RX pairs)under sum power\nconstraint. We consider a single frequency network, where all pairs are\noperating in same frequency band,thereby creating interference for each other.\nWe study the power allocation problem for sum rate maximization with and\nwithout QoS requirements on individual links. When the objective is only sum\nrate maximization without QoS guarantees, we develop an analytic solution to\ndecide optimal power allocation for two TX-RX pair problem. We also develop a\nlow complexity iterative algorithm for three TX-RX pair problem. For a generic\nN>3 TX-RX pair problem, we develop two low-complexity sub-optimal power\nallocation algorithms. The first algorithm is based on the idea of making\nclusters of two or three TX-RX pairs and then leverage the power allocation\nresults obtained for two and three TX-RX pair problems. The second algorithm is\ndeveloped by using a high SINR approximation and this algorithm can also be\nimplemented in a distributed manner by individual TXs. We then consider the\nsame problem but with additional QoS guarantees for individual links. We again\ndevelop an analytic solution for two TX-RX pair problem, and a distributed\nalgorithm for N>2 TX-RX pairs. \n\n"}
{"id": "1407.4694", "contents": "Title: Distributed Pricing-Based User Association for Downlink Heterogeneous\n  Cellular Networks Abstract: This paper considers the optimization of the user and base-station (BS)\nassociation in a wireless downlink heterogeneous cellular network under the\nproportional fairness criterion. We first consider the case where each BS has a\nsingle antenna and transmits at fixed power, and propose a distributed price\nupdate strategy for a pricing-based user association scheme, in which the users\nare assigned to the BS based on the value of a utility function minus a price.\nThe proposed price update algorithm is based on a coordinate descent method for\nsolving the dual of the network utility maximization problem, and it has a\nrigorous performance guarantee. The main advantage of the proposed algorithm as\ncompared to the existing subgradient method for price update is that the\nproposed algorithm is independent of parameter choices and can be implemented\nasynchronously. Further, this paper considers the joint user association and BS\npower control problem, and proposes an iterative dual coordinate descent and\nthe power optimization algorithm that significantly outperforms existing\napproaches. Finally, this paper considers the joint user association and BS\nbeamforming problem for the case where the BSs are equipped with multiple\nantennas and spatially multiplex multiple users. We incorporate dual coordinate\ndescent with the weighted minimum mean-squared error (WMMSE) algorithm, and\nshow that it achieves nearly the same performance as a computationally more\ncomplex benchmark algorithm (which applies the WMMSE algorithm on the entire\nnetwork for BS association), while avoiding excessive BS handover. \n\n"}
{"id": "1407.7405", "contents": "Title: Partition-Symmetrical Entropy Functions Abstract: Let $\\cal{N}=\\{1,\\cdots,n\\}$. The entropy function $\\bf h$ of a set of $n$\ndiscrete random variables $\\{X_i:i\\in\\cal N\\}$ is a $2^n$-dimensional vector\nwhose entries are ${\\bf{h}}({\\cal{A}})\\triangleq\nH(X_{\\cal{A}}),\\cal{A}\\subset{\\cal N} $, the (joint) entropies of the subsets\nof the set of $n$ random variables with $H(X_\\emptyset)=0$ by convention. The\nset of all entropy functions for $n$ discrete random variables, denoted by\n$\\Gamma^*_n$, is called the entropy function region for $n$. Characterization\nof $\\Gamma^*_n$ and its closure $\\overline{\\Gamma^*_n}$ are well-known open\nproblems in information theory. They are important not only because they play\nkey roles in information theory problems but also they are related to other\nsubjects in mathematics and physics.\n  In this paper, we consider \\emph{partition-symmetrical entropy functions}.\nLet $p=\\{\\cal{N}_1,\\cdots, \\cal{N}_t\\}$ be a $t$-partition of $\\cal N$. An\nentropy function $\\bf h$ is called $p$-symmetrical if for all ${\\cal A},{\\cal\nB} \\subset {\\cal N}$, $\\bf{h}({\\cal A}) = \\bf{h}({\\cal B})$ whenever $|{\\cal A}\n\\cap {\\cal N}_i| = |{\\cal B} \\cap {\\cal N}_i|$, $i = 1, \\cdots,t$. The set of\nall the $p$-symmetrical entropy functions, denoted by $\\Psi^*_p$, is called\n$p$-symmetrical entropy function region. We prove that $\\overline{\\Psi^*_p}$,\nthe closure of $\\Psi^*_p$, is completely characterized by Shannon-type\ninformation inequalities if and only if $p$ is the $1$-partition or a\n$2$-partition with one of its blocks being a singleton.\n  The characterization of the partition-symmetrical entropy functions can be\nuseful for solving some information theory and related problems where symmetry\nexists in the structure of the problems.\n  Keywords: entropy, entropy function, information inequality, polymatroid. \n\n"}
{"id": "1407.8249", "contents": "Title: Design of Quantum Stabilizer Codes From Quadratic Residues Sets Abstract: We propose two types, namely Type-I and Type-II, quantum stabilizer codes\nusing quadratic residue sets of prime modulus given by the form $p=4n\\pm1$. The\nproposed Type-I stabilizer codes are of cyclic structure and code length $N=p$.\nThey are constructed based on multi-weight circulant matrix generated from\nidempotent polynomial, which is obtained from a quadratic residue set. The\nproposed Type-II stabilizer codes are of quasi-cyclic (QC) structure and code\nlength $N=pk$, where $k$ is the size of a quadratic residue set. They are\nconstructed based on structured sparse-graphs codes derived from proto-matrix\nand circulant permutation matrix. With the proposed methods, we design rich\nclasses of cyclic and quasi-cyclic quantum stabilizer codes with variable code\nlength. We show how the commutative constraint (also referred to as the\nSymplectic Inner Product constraint) for quantum codes can be satisfied for\neach proposed construction method. We also analyze both the dimension and\ndistance for Type-I stabilizer codes and the dimension of Type-II stabilizer\ncodes. For the cyclic quantum stabilizer codes, we show that they meet the\nexisting distance bounds in literature. \n\n"}
{"id": "1407.8469", "contents": "Title: On the Equivalence between Interference and Eavesdropping in Wireless\n  Communications Abstract: We show that the problem of analyzing the outage probability in cellular\nsystems affected by co-channel interference and background noise is\nmathematically equivalent to the problem of analyzing the wireless\ninformation-theoretic security in terms of the maximum secrecy rate in fading\nchannels. Hence, these both apparently unrelated problems can be addressed by\nusing a common approach. We illustrate the applicability of the connection\nunveiled herein to provide new results for the secrecy outage probability in\ndifferent scenarios. \n\n"}
{"id": "1408.0549", "contents": "Title: Downlink Cellular Network Analysis with Multi-slope Path Loss Models Abstract: Existing cellular network analyses, and even simulations, typically use the\nstandard path loss model where received power decays like $\\|x\\|^{-\\alpha}$\nover a distance $\\|x\\|$. This standard path loss model is quite idealized, and\nin most scenarios the path loss exponent $\\alpha$ is itself a function of\n$\\|x\\|$, typically an increasing one. Enforcing a single path loss exponent can\nlead to orders of magnitude differences in average received and interference\npowers versus the true values. In this paper we study \\emph{multi-slope} path\nloss models, where different distance ranges are subject to different path loss\nexponents. We focus on the dual-slope path loss function, which is a piece-wise\npower law and continuous and accurately approximates many practical scenarios.\nWe derive the distributions of SIR, SNR, and finally SINR before finding the\npotential throughput scaling, which provides insight on the observed\ncell-splitting rate gain. The exact mathematical results show that the SIR\nmonotonically decreases with network density, while the converse is true for\nSNR, and thus the network coverage probability in terms of SINR is maximized at\nsome finite density. With ultra-densification (network density goes to\ninfinity), there exists a \\emph{phase transition} in the near-field path loss\nexponent $\\alpha_0$: if $\\alpha_0 >1$ unbounded potential throughput can be\nachieved asymptotically; if $\\alpha_0 <1$, ultra-densification leads in the\nextreme case to zero throughput. \n\n"}
{"id": "1408.1469", "contents": "Title: A Multiple Hypothesis Testing Approach to Low-Complexity Subspace\n  Unmixing Abstract: Subspace-based signal processing traditionally focuses on problems involving\na few subspaces. Recently, a number of problems in different application areas\nhave emerged that involve a significantly larger number of subspaces relative\nto the ambient dimension. It becomes imperative in such settings to first\nidentify a smaller set of active subspaces that contribute to the observation\nbefore further processing can be carried out. This problem of identification of\na small set of active subspaces among a huge collection of subspaces from a\nsingle (noisy) observation in the ambient space is termed subspace unmixing.\nThis paper formally poses the subspace unmixing problem under the parsimonious\nsubspace-sum (PS3) model, discusses connections of the PS3 model to problems in\nwireless communications, hyperspectral imaging, high-dimensional statistics and\ncompressed sensing, and proposes a low-complexity algorithm, termed marginal\nsubspace detection (MSD), for subspace unmixing. The MSD algorithm turns the\nsubspace unmixing problem for the PS3 model into a multiple hypothesis testing\n(MHT) problem and its analysis in the paper helps control the family-wise error\nrate of this MHT problem at any level $\\alpha \\in [0,1]$ under two random\nsignal generation models. Some other highlights of the analysis of the MSD\nalgorithm include: (i) it is applicable to an arbitrary collection of subspaces\non the Grassmann manifold; (ii) it relies on properties of the collection of\nsubspaces that are computable in polynomial time; and ($iii$) it allows for\nlinear scaling of the number of active subspaces as a function of the ambient\ndimension. Finally, numerical results are presented in the paper to better\nunderstand the performance of the MSD algorithm. \n\n"}
{"id": "1408.2232", "contents": "Title: Interference-Aware RZF Precoding for Multi Cell Downlink Systems Abstract: Recently, a structure of an optimal linear precoder for multi cell downlink\nsystems has been described in [1, Eq (3.33)]. Other references (e.g., [2,3])\nhave used simplified versions of the precoder to obtain promising performance\ngains. These gains have been hypothesized to stem from the additional degrees\nof freedom that allow for interference mitigation through interference\nrelegation to orthogonal subspaces. However, no conclusive or rigorous\nunderstanding has yet been developed. In this paper, we build on an intuitive\ninterference induction trade-off and the aforementioned precoding structure to\npropose an interference aware RZF (iaRZF) precoding scheme for multi cell\ndownlink systems and we analyze its rate performance. Special emphasis is\nplaced on the induced interference mitigation mechanism of iaRZF. For example,\nwe will verify the intuitive expectation that the precoder structure can either\ncompletely remove induced inter-cell or intra-cell interference. We state new\nresults from large-scale random matrix theory that make it possible to give\nmore intuitive and insightful explanations of the precoder behavior, also for\ncases involving imperfect channel state information (CSI). We remark especially\nthat the interference-aware precoder makes use of all available information\nabout interfering channels to improve performance. Even very poor CSI allows\nfor significant sum-rate gains. Our obtained insights are then used to propose\nheuristic precoder parameters for arbitrary systems, whose effectiveness are\nshown in more involved system scenarios. Furthermore, calculation and\nimplementation of these parameters does not require explicit inter base station\ncooperation. \n\n"}
{"id": "1408.5780", "contents": "Title: Fractional repetition codes with flexible repair from combinatorial\n  designs Abstract: Fractional repetition (FR) codes are a class of regenerating codes for\ndistributed storage systems with an exact (table-based) repair process that is\nalso uncoded, i.e., upon failure, a node is regenerated by simply downloading\npackets from the surviving nodes. In our work, we present constructions of FR\ncodes based on Steiner systems and resolvable combinatorial designs such as\naffine geometries, Hadamard designs and mutually orthogonal Latin squares. The\nfailure resilience of our codes can be varied in a simple manner. We construct\ncodes with normalized repair bandwidth ($\\beta$) strictly larger than one;\nthese cannot be obtained trivially from codes with $\\beta = 1$. Furthermore, we\npresent the Kronecker product technique for generating new codes from existing\nones and elaborate on their properties. FR codes with locality are those where\nthe repair degree is smaller than the number of nodes contacted for\nreconstructing the stored file. For these codes we establish a tradeoff between\nthe local repair property and failure resilience and construct codes that meet\nthis tradeoff. Much of prior work only provided lower bounds on the FR code\nrate. In our work, for most of our constructions we determine the code rate for\ncertain parameter ranges. \n\n"}
{"id": "1409.0875", "contents": "Title: Massive MIMO with Non-Ideal Arbitrary Arrays: Hardware Scaling Laws and\n  Circuit-Aware Design Abstract: Massive multiple-input multiple-output (MIMO) systems are cellular networks\nwhere the base stations (BSs) are equipped with unconventionally many antennas,\ndeployed on co-located or distributed arrays. Huge spatial degrees-of-freedom\nare achieved by coherent processing over these massive arrays, which provide\nstrong signal gains, resilience to imperfect channel knowledge, and low\ninterference. This comes at the price of more infrastructure; the hardware cost\nand circuit power consumption scale linearly/affinely with the number of BS\nantennas $N$. Hence, the key to cost-efficient deployment of large arrays is\nlow-cost antenna branches with low circuit power, in contrast to today's\nconventional expensive and power-hungry BS antenna branches. Such low-cost\ntransceivers are prone to hardware imperfections, but it has been conjectured\nthat the huge degrees-of-freedom would bring robustness to such imperfections.\nWe prove this claim for a generalized uplink system with multiplicative\nphase-drifts, additive distortion noise, and noise amplification. Specifically,\nwe derive closed-form expressions for the user rates and a scaling law that\nshows how fast the hardware imperfections can increase with $N$ while\nmaintaining high rates. The connection between this scaling law and the power\nconsumption of different transceiver circuits is rigorously exemplified. This\nreveals that one can make the circuit power increase as $\\sqrt{N}$, instead of\nlinearly, by careful circuit-aware system design. \n\n"}
{"id": "1409.1662", "contents": "Title: Separate Random Number Generation from Correlated Sources Abstract: This work studies the problem of separate random number generation from\ncorrelated general sources with side information at the tester under the\ncriterion of statistical distance. Tight one-shot lower and upper performance\nbounds are obtained using the random-bin approach. A refined analysis is\nfurther performed for two important random-bin maps. One is the pure-random-bin\nmap that is uniformly distributed over the set of all maps (with the same\ndomain and codomain). The other is the equal-random-bin map that is uniformly\ndistributed over the set of all surjective maps that induce an equal or\nquasi-equal partition of the domain. Both of them are proved to have a\ndoubly-exponential concentration of the performance of their sample maps. As an\napplication, an open and transparent lottery scheme, using a random number\ngenerator on a public data source, is proposed to solve the social problem of\nscarce resource allocation. The core of the proposed framework of lottery\nalgorithms is a permutation, a good rateless randomness extractor, whose\nexistence is confirmed by the theoretical performance of equal-random-bin maps.\nThis extractor, together with other important details of the scheme, ensures\nthat the lottery scheme is immune to all kinds of fraud under some reasonable\nassumptions. \n\n"}
{"id": "1409.1673", "contents": "Title: Spectral Super-resolution With Prior Knowledge Abstract: We address the problem of super-resolution frequency recovery using prior\nknowledge of the structure of a spectrally sparse, undersampled signal. In many\napplications of interest, some structure information about the signal spectrum\nis often known. The prior information might be simply knowing precisely some\nsignal frequencies or the likelihood of a particular frequency component in the\nsignal. We devise a general semidefinite program to recover these frequencies\nusing theories of positive trigonometric polynomials. Our theoretical analysis\nshows that, given sufficient prior information, perfect signal reconstruction\nis possible using signal samples no more than thrice the number of signal\nfrequencies. Numerical experiments demonstrate great performance enhancements\nusing our method. We show that the nominal resolution necessary for the\ngrid-free results can be improved if prior information is suitably employed. \n\n"}
{"id": "1409.2100", "contents": "Title: Multi layer Gelfand Pinsker Strategies for the Generalized Multiple\n  Access Channel Abstract: We study a two-user state-dependent generalized multiple-access channel\n(GMAC) with correlated states. It is assumed that each encoder has\n\\emph{noncausal} access to channel state information (CSI). We develop an\nachievable rate region by employing rate-splitting, block Markov encoding,\nGelfand--Pinsker multicoding, superposition coding and joint typicality\ndecoding. In the proposed scheme, the encoders use a partial decoding strategy\nto collaborate in the next block, and the receiver uses a backward decoding\nstrategy with joint unique decoding at each stage. Our achievable rate region\nincludes several previously known regions proposed in the literature for\ndifferent scenarios of multiple-access and relay channels. Then, we consider\ntwo Gaussian GMACs with additive interference. In the first model, we assume\nthat the interference is known noncausally at both of the encoders and\nconstruct a multi-layer Costa precoding scheme that removes \\emph{completely}\nthe effect of the interference. In the second model, we consider a doubly dirty\nGaussian GMAC in which each of interferences is known noncausally only at one\nencoder. We derive an inner bound and analyze the achievable rate region for\nthe latter model and interestingly prove that if one of the encoders knows the\nfull CSI, there exists an achievable rate region which is \\emph{independent} of\nthe power of interference. \n\n"}
{"id": "1409.2592", "contents": "Title: On Spatial Capacity of Wireless Ad Hoc Networks with Threshold Based\n  Scheduling Abstract: This paper studies spatial capacity in a stochastic wireless ad hoc network,\nwhere multi-stage probing and data transmission are sequentially performed. We\npropose a novel signal-to-interference-ratio (SIR) threshold based scheduling\nscheme, where by starting with the first probing, each transmitter iteratively\ndecides to further probe or stay idle, depending on whether the estimated SIR\nin the proceeding probing is larger or smaller than a predefined threshold.\nAlthough one can assume that the transmitters are initially deployed according\nto a homogeneous Poisson point process (PPP), the SIR based scheduling makes\nthe PPP no longer applicable to model the locations of retained transmitters in\nthe subsequent probing and data transmission phases, due to the interference\ninduced coupling in their decisions. We first focus on single-stage probing and\nfind that when the SIR threshold is set sufficiently small to assure an\nacceptable interference level in the network, the proposed scheme can greatly\noutperform the non-scheduling reference scheme in terms of spatial capacity. We\nclearly characterize the spatial capacity and obtain exact/approximate\nclosed-form expressions, by proposing a new approximate approach to deal with\nthe correlated SIR distributions over non-Poisson point processes. Then we\nsuccessfully extend to multi-stage probing by properly designing the multiple\nSIR thresholds to assure gradual improvement of the spatial capacity.\nFurthermore, we analyze the impact of multi-stage probing overhead and present\na probing-capacity tradeoff in scheduling design. Finally, extensive numerical\nresults are presented to demonstrate the performance of the proposed scheduling\nas compared to existing schemes. \n\n"}
{"id": "1409.3188", "contents": "Title: Counterexample to the $l$-modular Belfiore-Sol\\'e Conjecture Abstract: We show that the secrecy function conjecture that states that the maximum of\nthe secrecy function of an $l$-modular lattice occurs at $1/\\sqrt{l}$ is false,\nby proving that the 4-modular lattice $C^(4) = \\mathbb{Z} \\oplus\n\\sqrt{2}\\mathbb{Z} \\oplus 2\\mathbb{Z}$ fails to satisfy this conjecture. We\nalso indicate how the secrecy function must be modified in the $l$-modular case\nto have a more reasonable chance for it to have a maximum at $1/\\sqrt{l}$, and\nshow that the conjecture, modified with this new secrecy function, is true for\nvarious odd 2-modular lattices. \n\n"}
{"id": "1409.3893", "contents": "Title: Causal Erasure Channels Abstract: We consider the communication problem over binary causal adversarial erasure\nchannels. Such a channel maps $n$ input bits to $n$ output symbols in\n$\\{0,1,\\wedge\\}$, where $\\wedge$ denotes erasure. The channel is causal if, for\nevery $i$, the channel adversarially decides whether to erase the $i$th bit of\nits input based on inputs $1,...,i$, before it observes bits $i+1$ to $n$. Such\na channel is $p$-bounded if it can erase at most a $p$ fraction of the input\nbits over the whole transmission duration. Causal channels provide a natural\nmodel for channels that obey basic physical restrictions but are otherwise\nunpredictable or highly variable. For a given erasure rate $p$, our goal is to\nunderstand the optimal rate (the capacity) at which a randomized (stochastic)\nencoder/decoder can transmit reliably across all causal $p$-bounded erasure\nchannels. In this paper, we introduce the causal erasure model and provide new\nupper bounds and lower bounds on the achievable rate. Our bounds separate the\nachievable rate in the causal erasures setting from the rates achievable in two\nrelated models: random erasure channels (strictly weaker) and fully adversarial\nerasure channels (strictly stronger). Specifically, we show:\n  - A strict separation between random and causal erasures for all constant\nerasure rates $p\\in(0,1)$.\n  - A strict separation between causal and fully adversarial erasures for\n$p\\in(0,\\phi)$ where $\\phi \\approx 0.348$.\n  - For $p\\in[\\phi,1/2)$, we show codes for causal erasures that have higher\nrate than the best known constructions for fully adversarial channels.\n  Our results contrast with existing results on correcting causal bit-flip\nerrors (as opposed to erasures) [Dey et. al 2008, 2009], [Haviv-Langberg 2011].\nFor the separations we provide, the analogous separations for bit-flip models\nare either not known at all or much weaker. \n\n"}
{"id": "1409.4398", "contents": "Title: Application of K\\\"ahler manifold to signal processing and Bayesian\n  inference Abstract: We review the information geometry of linear systems and its application to\nBayesian inference, and the simplification available in the K\\\"ahler manifold\ncase. We find conditions for the information geometry of linear systems to be\nK\\\"ahler, and the relation of the K\\\"ahler potential to information geometric\nquantities such as $\\alpha $-divergence, information distance and the dual\n$\\alpha $-connection structure. The K\\\"ahler structure simplifies the\ncalculation of the metric tensor, connection, Ricci tensor and scalar\ncurvature, and the $\\alpha $-generalization of the geometric objects. The\nLaplace--Beltrami operator is also simplified in the K\\\"ahler geometry. One of\nthe goals in information geometry is the construction of Bayesian priors\noutperforming the Jeffreys prior, which we use to demonstrate the utility of\nthe K\\\"ahler structure. \n\n"}
{"id": "1409.7808", "contents": "Title: Resource-Constrained Adaptive Search for Sparse Multi-Class Targets with\n  Varying Importance Abstract: In sparse target inference problems it has been shown that significant gains\ncan be achieved by adaptive sensing using convex criteria. We generalize\nprevious work on adaptive sensing to (a) include multiple classes of targets\nwith different levels of importance and (b) accommodate multiple sensor models.\nNew optimization policies are developed to allocate a limited resource budget\nto simultaneously locate, classify and estimate a sparse number of targets\nembedded in a large space. Upper and lower bounds on the performance of the\nproposed policies are derived by analyzing a baseline policy, which allocates\nresources uniformly across the scene, and an oracle policy which has a priori\nknowledge of the target locations/classes. These bounds quantify analytically\nthe potential benefit of adaptive sensing as a function of target frequency and\nimportance. Numerical results indicate that the proposed policies perform close\nto the oracle bound (<3dB) when signal quality is sufficiently high\n(e.g.~performance within 3 dB for SNR above 15 dB). Moreover, the proposed\npolicies improve on previous policies in terms of reducing estimation error,\nreducing misclassification probability, and increasing expected return. To\naccount for sensors with different levels of agility, three sensor models are\nconsidered: global adaptive (GA), which can allocate different amounts of\nresource to each location in the space; global uniform (GU), which can allocate\nresources uniformly across the scene; and local adaptive (LA), which can\nallocate fixed units to a subset of locations. Policies that use a mixture of\nGU and LA sensors are shown to perform similarly to those that use GA sensors\nwhile being more easily implementable. \n\n"}
{"id": "1410.1710", "contents": "Title: A Cost / Speed / Reliability Trade-off to Erasing Abstract: We present a KL-control treatment of the fundamental problem of erasing a\nbit. We introduce notions of \"reliability\" of information storage via a\nreliability timescale $\\tau_r$, and \"speed\" of erasing via an erasing timescale\n$\\tau_e$. Our problem formulation captures the tradeoff between speed,\nreliability, and the Kullback-Leibler (KL) cost required to erase a bit. We\nshow that rapid erasing of a reliable bit costs at least $\\log 2 - \\log\\left(1\n- \\operatorname{e}^{-\\frac{\\tau_e}{\\tau_r}}\\right) > \\log 2$, which goes to\n$\\frac{1}{2} \\log\\frac{2\\tau_r}{\\tau_e}$ when $\\tau_r>>\\tau_e$. \n\n"}
{"id": "1410.1828", "contents": "Title: Sampling and Galerkin reconstruction in reproducing kernel spaces Abstract: In this paper, we consider sampling in a reproducing kernel subspace of\n$L^p$. We introduce a pre-reconstruction operator associated with a sampling\nscheme and propose a Galerkin reconstruction in general Banach space setting.\nWe show that the proposed Galerkin method provides a quasi-optimal\napproximation, and the corresponding Galerkin equations could be solved by an\niterative approximation-projection algorithm. We also present detailed analysis\nand numerical simulations of the Galerkin method for reconstructing signals\nwith finite rate of innovation. \n\n"}
{"id": "1410.2687", "contents": "Title: Second-Order Coding Rates for Conditional Rate-Distortion Abstract: This paper characterizes the second-order coding rates for lossy source\ncoding with side information available at both the encoder and the decoder. We\nfirst provide non-asymptotic bounds for this problem and then specialize the\nnon-asymptotic bounds for three different scenarios: discrete memoryless\nsources, Gaussian sources, and Markov sources. We obtain the second-order\ncoding rates for these settings. It is interesting to observe that the\nsecond-order coding rate for Gaussian source coding with Gaussian side\ninformation available at both the encoder and the decoder is the same as that\nfor Gaussian source coding without side information. Furthermore, regardless of\nthe variance of the side information, the dispersion is $1/2$ nats squared per\nsource symbol. \n\n"}
{"id": "1410.3422", "contents": "Title: Achieving Secrecy Capacity of the Wiretap Channel and Broadcast Channel\n  with a Confidential Component Abstract: The wiretap channel model of Wyner is one of the first communication models\nwith both reliability and security constraints. Capacity-achieving schemes for\nvarious models of the wiretap channel have received considerable attention in\nrecent literature. In this paper, we show that capacity of the general (not\nnecessarily degraded or symmetric) wiretap channel under a \"strong secrecy\nconstraint\" can be achieved using a transmission scheme based on polar codes.\nWe also extend our construction to the case of broadcast channels with\nconfidential messages defined by Csisz{\\'a}r and K{\\\"orner}, achieving the\nentire capacity region of this communication model. \n\n"}
{"id": "1410.3656", "contents": "Title: Compute-and-Forward: Finding the Best Equation Abstract: Compute-and-Forward is an emerging technique to deal with interference. It\nallows the receiver to decode a suitably chosen integer linear combination of\nthe transmitted messages. The integer coefficients should be adapted to the\nchannel fading state. Optimizing these coefficients is a Shortest Lattice\nVector (SLV) problem. In general, the SLV problem is known to be prohibitively\ncomplex. In this paper, we show that the particular SLV instance resulting from\nthe Compute-and-Forward problem can be solved in low polynomial complexity and\ngive an explicit deterministic algorithm that is guaranteed to find the optimal\nsolution. \n\n"}
{"id": "1410.5085", "contents": "Title: On the Capacity Regions of Two-Way Diamond Channels Abstract: In this paper, we study the capacity regions of two-way diamond channels. We\nshow that for a linear deterministic model the capacity of the diamond channel\nin each direction can be simultaneously achieved for all values of channel\nparameters, where the forward and backward channel parameters are not\nnecessarily the same. We divide the achievability scheme into three cases,\ndepending on the forward and backward channel parameters. For the first case,\nwe use a reverse amplify-and-forward strategy in the relays. For the second\ncase, we use four relay strategies based on the reverse amplify-and-forward\nwith some modifications in terms of replacement and repetition of some stream\nlevels. For the third case, we use two relay strategies based on performing two\nrounds of repetitions in a relay. The proposed schemes for deterministic\nchannels are used to find the capacity regions within constant gaps for two\nspecial cases of the Gaussian two-way diamond channel. First, for the general\nGaussian two-way relay channel with a simple coding scheme the smallest gap is\nachieved compared to the prior works. Then, a special symmetric Gaussian\ntwo-way diamond model is considered and the capacity region is achieved within\nfour bits. \n\n"}
{"id": "1410.6913", "contents": "Title: Low rank matrix recovery from rank one measurements Abstract: We study the recovery of Hermitian low rank matrices $X \\in \\mathbb{C}^{n\n\\times n}$ from undersampled measurements via nuclear norm minimization. We\nconsider the particular scenario where the measurements are Frobenius inner\nproducts with random rank-one matrices of the form $a_j a_j^*$ for some\nmeasurement vectors $a_1,...,a_m$, i.e., the measurements are given by $y_j =\n\\mathrm{tr}(X a_j a_j^*)$. The case where the matrix $X=x x^*$ to be recovered\nis of rank one reduces to the problem of phaseless estimation (from\nmeasurements, $y_j = |\\langle x,a_j\\rangle|^2$ via the PhaseLift approach,\nwhich has been introduced recently. We derive bounds for the number $m$ of\nmeasurements that guarantee successful uniform recovery of Hermitian rank $r$\nmatrices, either for the vectors $a_j$, $j=1,...,m$, being chosen independently\nat random according to a standard Gaussian distribution, or $a_j$ being sampled\nindependently from an (approximate) complex projective $t$-design with $t=4$.\nIn the Gaussian case, we require $m \\geq C r n$ measurements, while in the case\nof $4$-designs we need $m \\geq Cr n \\log(n)$. Our results are uniform in the\nsense that one random choice of the measurement vectors $a_j$ guarantees\nrecovery of all rank $r$-matrices simultaneously with high probability.\nMoreover, we prove robustness of recovery under perturbation of the\nmeasurements by noise. The result for approximate $4$-designs generalizes and\nimproves a recent bound on phase retrieval due to Gross, Kueng and Krahmer. In\naddition, it has applications in quantum state tomography. Our proofs employ\nthe so-called bowling scheme which is based on recent ideas by Mendelson and\nKoltchinskii. \n\n"}
{"id": "1410.7184", "contents": "Title: Symmetric bilinear forms over finite fields with applications to coding\n  theory Abstract: Let $q$ be an odd prime power and let $X(m,q)$ be the set of symmetric\nbilinear forms on an $m$-dimensional vector space over $\\mathbb{F}_q$. The\npartition of $X(m,q)$ induced by the action of the general linear group gives\nrise to a commutative translation association scheme. We give explicit\nexpressions for the eigenvalues of this scheme in terms of linear combinations\nof generalised Krawtchouk polynomials. We then study $d$-codes in this scheme,\nnamely subsets $Y$ of $X(m,q)$ with the property that, for all distinct $A,B\\in\nY$, the rank of $A-B$ is at least $d$. We prove bounds on the size of a\n$d$-code and show that, under certain conditions, the inner distribution of a\n$d$-code is determined by its parameters. Constructions of $d$-codes are given,\nwhich are optimal among the $d$-codes that are subgroups of $X(m,q)$. Finally,\nwith every subset $Y$ of $X(m,q)$, we associate two classical codes over\n$\\mathbb{F}_q$ and show that their Hamming distance enumerators can be\nexpressed in terms of the inner distribution of $Y$. As an example, we obtain\nthe distance enumerators of certain cyclic codes, for which many special cases\nhave been previously obtained using long ad hoc calculations. \n\n"}
{"id": "1410.8023", "contents": "Title: Variable-length Convolutional Coding for Short Blocklengths with\n  Decision Feedback Abstract: This paper presents a variable-length decision-feedback scheme that uses\ntail-biting convolutional codes and the tail-biting Reliability-Output Viterbi\nAlgoritm (ROVA). Comparing with recent results in finite-blocklength\ninformation theory, simulation results for both the BSC and the AWGN channel\nshow that the decision-feedback scheme using ROVA can surpass the random-coding\nlower bound on throughput for feedback codes at average blocklengths less than\n100 symbols. This paper explores ROVA-based decision feedback both with\ndecoding after every symbol and with decoding limited to a small number of\nincrements. The performance of the reliability-based stopping rule with the\nROVA is compared to retransmission decisions based on CRCs. For short\nblocklengths where the latency overhead of the CRC bits is severe, the\nROVA-based approach delivers superior rates. \n\n"}
{"id": "1410.8433", "contents": "Title: Binary Polarization Kernels from Code Decompositions Abstract: In this paper, code decompositions (a.k.a. code nestings) are used to design\nbinary polarization kernels. The proposed kernels are in general non-linear.\nThey provide a better polarization exponent than the previously known kernels\nof the same dimensions. In particular, non-linear kernels of dimensions 14, 15,\nand 16 are constructed and are shown to have optimal asymptotic\nerror-correction performance. The optimality is proved by showing that the\nexponents of these kernels achieve a new upper bound that is developed in this\npaper. \n\n"}
{"id": "1411.0060", "contents": "Title: Secrecy in Cascade Networks Abstract: We consider a cascade network where a sequence of nodes each send a message\nto their downstream neighbor to enable coordination, the first node having\naccess to an information signal. An adversary also receives all of the\ncommunication as well as additional side-information. The performance of the\nsystem is measured by a payoff function evaluated on actions produced at each\nof the nodes, including the adversary. The challenge is to effectively use a\nsecret key to infuse some level of privacy into the encoding, in order thwart\nthe adversary's attempt to reduce the payoff. We obtain information-theoretic\ninner and outer bounds on performance, and give examples where they are tight.\nFrom these bounds, we also derive the optimal equivocation for this setting as\na special case. \n\n"}
{"id": "1411.0294", "contents": "Title: Capacity Region Continuity of the Compound Broadcast Channel with\n  Confidential Messages Abstract: The compound broadcast channel with confidential messages (BCC) generalizes\nthe BCC by modeling the uncertainty of the channel. For the compound BCC, it is\nonly known that the actual channel realization belongs to a pre-specified\nuncertainty set of channels and that it is constant during the whole\ntransmission. For reliable and secure communication is necessary to operate at\na rate pair within the compound BCC capacity region. Therefore, the question\nwhether small variations of the uncertainty set lead to large losses of the\ncompound BCC capacity region is studied. It is shown that the compound BCC\nmodel is robust, i.e., the capacity region depends continuously on the\nuncertainty set. \n\n"}
{"id": "1411.0319", "contents": "Title: Achievable and Converse bounds over a general channel and general\n  decoding metric Abstract: Achievable and converse bounds for general channels and mismatched decoding\nare derived. The direct (achievable) bound is derived using random coding and\nthe analysis is tight up to factor 2. The converse is given in term of the\nachievable bound and the factor between them is given. This gives performance\nof the best rate-R code with possible mismatched decoding metric over a general\nchannel, up to the factor that is identified. In the matched case we show that\nthe converse equals the minimax meta-converse of Polyanskiy et al. \n\n"}
{"id": "1411.0650", "contents": "Title: Proof of the satisfiability conjecture for large k Abstract: We establish the satisfiability threshold for random $k$-SAT for all $k\\ge\nk_0$, with $k_0$ an absolute constant. That is, there exists a limiting density\n$\\alpha_*(k)$ such that a random $k$-SAT formula of clause density $\\alpha$ is\nwith high probability satisfiable for $\\alpha<\\alpha_*$, and unsatisfiable for\n$\\alpha>\\alpha_*$. We show that the threshold $\\alpha_*(k)$ is given explicitly\nby the one-step replica symmetry breaking prediction from statistical physics.\nThe proof develops a new analytic method for moment calculations on random\ngraphs, mapping a high-dimensional optimization problem to a more tractable\nproblem of analyzing tree recursions. We believe that our method may apply to a\nrange of random CSPs in the 1-RSB universality class. \n\n"}
{"id": "1411.1580", "contents": "Title: Guaranteeing Positive Secrecy Capacity with Finite-Rate Feedback using\n  Artificial Noise Abstract: While the impact of finite-rate feedback on the capacity of fading channels\nhas been extensively studied in the literature, not much attention has been\npaid to this problem under secrecy constraint. In this work, we study the\nergodic secret capacity of a multiple-input multiple-output\nmultiple-antenna-eavesdropper (MIMOME) wiretap channel with quantized channel\nstate information (CSI) at the transmitter and perfect CSI at the legitimate\nreceiver, under the assumption that only the statistics of eavesdropper CSI is\nknown at the transmitter. We refine the analysis of the random vector\nquantization (RVQ) based artificial noise (AN) scheme in [1], where a heuristic\nupper bound on the secrecy rate loss, when compared to the perfect CSI case,\nwas given. We propose a lower bound on the ergodic secrecy capacity. We show\nthat the lower bound and the secrecy capacity with perfect CSI coincide\nasymptotically as the number of feedback bits and the AN power go to infinity.\nFor practical applications, we propose a very efficient quantization codebook\nconstruction method for the two transmit antennas case. \n\n"}
{"id": "1411.3601", "contents": "Title: Subspace codes in PG(2n-1,q) Abstract: An $(r,M,2\\delta;k)_q$ constant--dimension subspace code, $\\delta >1$, is a\ncollection $\\cal C$ of $(k-1)$--dimensional projective subspaces of ${\\rm\nPG(r-1,q)}$ such that every $(k-\\delta)$--dimensional projective subspace of\n${\\rm PG(r-1,q)}$ is contained in at most a member of $\\cal C$.\nConstant--dimension subspace codes gained recently lot of interest due to the\nwork by Koetter and Kschischang, where they presented an application of such\ncodes for error-correction in random network coding. Here a $(2n,M,4;n)_q$\nconstant--dimension subspace code is constructed, for every $n \\ge 4$. The size\nof our codes is considerably larger than all known constructions so far,\nwhenever $n > 4$. When $n=4$ a further improvement is provided by constructing\nan $(8,M,4;4)_q$ constant--dimension subspace code, with $M =\nq^{12}+q^2(q^2+1)^2(q^2+q+1)+1$. \n\n"}
{"id": "1411.4139", "contents": "Title: Cost-Aware Green Cellular Networks with Energy and Communication\n  Cooperation Abstract: Energy cost of cellular networks is ever-increasing to match the surge of\nwireless data traffic, and the saving of this cost is important to reduce the\noperational expenditure (OPEX) of wireless operators in future. The recent\nadvancements of renewable energy integration and two-way energy flow in smart\ngrid provide potential new solutions to save the cost. However, they also\nimpose challenges, especially on how to use the stochastically and spatially\ndistributed renewable energy harvested at cellular base stations (BSs) to\nreliably supply time- and space-varying wireless traffic over cellular\nnetworks. To overcome these challenges, in this article we present three\napproaches, namely, {\\emph{energy cooperation, communication cooperation, and\njoint energy and communication cooperation}}, in which different BSs\nbidirectionally trade or share energy via the aggregator in smart grid, and/or\nshare wireless resources and shift loads with each other to reduce the total\nenergy cost. \n\n"}
{"id": "1411.4253", "contents": "Title: Energy-efficient Decoders for Compressive Sensing: Fundamental Limits\n  and Implementations Abstract: The fundamental problem considered in this paper is \"What is the\n\\textit{energy} consumed for the implementation of a \\emph{compressive sensing}\ndecoding algorithm on a circuit?\". Using the \"information-friction\" framework,\nwe examine the smallest amount of \\textit{bit-meters} as a measure for the\nenergy consumed by a circuit. We derive a fundamental lower bound for the\nimplementation of compressive sensing decoding algorithms on a circuit. In the\nsetting where the number of measurements scales linearly with the sparsity and\nthe sparsity is sub-linear with the length of the signal, we show that the\n\\textit{bit-meters} consumption for these algorithms is order-tight, i.e., it\nmatches the lower bound asymptotically up to a constant factor. Our\nimplementations yield interesting insights into design of energy-efficient\ncircuits that are not captured by the notion of computational efficiency alone. \n\n"}
{"id": "1411.4590", "contents": "Title: Reed-Muller codes for random erasures and errors Abstract: This paper studies the parameters for which Reed-Muller (RM) codes over\n$GF(2)$ can correct random erasures and random errors with high probability,\nand in particular when can they achieve capacity for these two classical\nchannels. Necessarily, the paper also studies properties of evaluations of\nmulti-variate $GF(2)$ polynomials on random sets of inputs.\n  For erasures, we prove that RM codes achieve capacity both for very high rate\nand very low rate regimes. For errors, we prove that RM codes achieve capacity\nfor very low rate regimes, and for very high rates, we show that they can\nuniquely decode at about square root of the number of errors at capacity.\n  The proofs of these four results are based on different techniques, which we\nfind interesting in their own right. In particular, we study the following\nquestions about $E(m,r)$, the matrix whose rows are truth tables of all\nmonomials of degree $\\leq r$ in $m$ variables. What is the most (resp. least)\nnumber of random columns in $E(m,r)$ that define a submatrix having full column\nrank (resp. full row rank) with high probability? We obtain tight bounds for\nvery small (resp. very large) degrees $r$, which we use to show that RM codes\nachieve capacity for erasures in these regimes.\n  Our decoding from random errors follows from the following novel reduction.\nFor every linear code $C$ of sufficiently high rate we construct a new code\n$C'$, also of very high rate, such that for every subset $S$ of coordinates, if\n$C$ can recover from erasures in $S$, then $C'$ can recover from errors in $S$.\nSpecializing this to RM codes and using our results for erasures imply our\nresult on unique decoding of RM codes at high rate.\n  Finally, two of our capacity achieving results require tight bounds on the\nweight distribution of RM codes. We obtain such bounds extending the recent\n\\cite{KLP} bounds from constant degree to linear degree polynomials. \n\n"}
{"id": "1411.4591", "contents": "Title: Number field lattices achieve Gaussian and Rayleigh channel capacity\n  within a constant gap Abstract: This paper proves that a family of number field lattice codes simultaneously\nachieves a constant gap to capacity in Rayleigh fast fading and Gaussian\nchannels.\n  The key property in the proof is the existence of infinite towers of Hilbert\nclass fields with bounded root discriminant. The gap to capacity of the\nproposed families is determined by the root discriminant.\n  The comparison between the Gaussian and fading case reveals that in Rayleigh\nfading channels the normalized minimum product distance plays an analogous role\nto the Hermite invariant in Gaussian channels. \n\n"}
{"id": "1411.6469", "contents": "Title: Resource Allocation for Energy-Efficient 3-Way Relay Channels Abstract: Throughput and energy efficiency in 3-way relay channels are studied in this\npaper. Unlike previous contributions, we consider a circular message exchange.\nFirst, an outer bound and achievable sum rate expressions for different\nrelaying protocols are derived for 3-way relay channels. The sum capacity is\ncharacterized for certain SNR regimes. Next, leveraging the derived achievable\nsum rate expressions, cooperative and competitive maximization of the energy\nefficiency are considered. For the cooperative case, both low-complexity and\nglobally optimal algorithms for joint power allocation at the users and at the\nrelay are designed so as to maximize the system global energy efficiency. For\nthe competitive case, a game theoretic approach is taken, and it is shown that\nthe best response dynamics is guaranteed to converge to a Nash equilibrium. A\npower consumption model for mmWave board-to-board communications is developed,\nand numerical results are provided to corroborate and provide insight on the\ntheoretical findings. \n\n"}
{"id": "1411.7632", "contents": "Title: Semidefinite Programming Approach to Gaussian Sequential Rate-Distortion\n  Trade-offs Abstract: Sequential rate-distortion (SRD) theory provides a framework for studying the\nfundamental trade-off between data-rate and data-quality in real-time\ncommunication systems. In this paper, we consider the SRD problem for\nmulti-dimensional time-varying Gauss-Markov processes under mean-square\ndistortion criteria. We first revisit the sensor-estimator separation\nprinciple, which asserts that considered SRD problem is equivalent to a joint\nsensor and estimator design problem in which data-rate of the sensor output is\nminimized while the estimator's performance satisfies the distortion criteria.\nWe then show that the optimal joint design can be performed by semidefinite\nprogramming. A semidefinite representation of the corresponding SRD function is\nobtained. Implications of the obtained result in the context of zero-delay\nsource coding theory and applications to networked control theory are also\ndiscussed. \n\n"}
{"id": "1412.0765", "contents": "Title: Performance Analysis of mmWave Ad Hoc Networks Abstract: Ad hoc networks provide an on-demand, infrastructure-free means to\ncommunicate between soldiers in war zones, aid workers in disaster areas, or\nconsumers in device-to-device (D2D) applications. Unfortunately, ad hoc\nnetworks are limited by interference due to nearby transmissions.\nMillimeter-wave (mmWave) devices offer several potential advantages for ad hoc\nnetworks including reduced interference due to directional antennas and\nbuilding blockages, not to mention huge bandwidth channels for large data\nrates.. This paper uses a stochastic geometry approach to characterize the\none-way and two-way signal-to-interference ratio distribution of a mmWave ad\nhoc network with directional antennas, random blockages, and ALOHA channel\naccess. The interference-to-noise ratio shows that a fundamental limitation of\nan ad hoc network, interference, may still be an issue. The performance of\nmmWave ad hoc networks is bounded by the transmission capacity and area\nspectral efficiency. The results show that mmWave networks can support much\nhigher densities and larger spectral efficiencies, even in the presence of\nblockage, compared with lower frequency communication for certain link\ndistances. Due to the increased bandwidth, the rate coverage of mmWave can be\nmuch greater than lower frequency devices. \n\n"}
{"id": "1412.2669", "contents": "Title: Two step recovery of jointly sparse and low-rank matrices: theoretical\n  guarantees Abstract: We introduce a two step algorithm with theoretical guarantees to recover a\njointly sparse and low-rank matrix from undersampled measurements of its\ncolumns. The algorithm first estimates the row subspace of the matrix using a\nset of common measurements of the columns. In the second step, the subspace\naware recovery of the matrix is solved using a simple least square algorithm.\nThe results are verified in the context of recovering CINE data from\nundersampled measurements; we obtain good recovery when the sampling conditions\nare satisfied. \n\n"}
{"id": "1412.3238", "contents": "Title: Loop-Back Interference Suppression for OFDM Signals via Sampled-Data\n  Control Abstract: In this article, we consider the problem of loop-back interference\nsuppression for orthogonal frequency division multiplexing (OFDM) signals in\namplify-and-forward single-frequency full-duplex relay stations. The loop-back\ninterference makes the system a closed-loop system, and hence it is important\nnot only to suppress the interference but also to stabilize the system. For\nthis purpose, we propose sampled-data $H^{\\infty}$ design of digital filters\nthat ensure the stability of the system and suppress the continuous-time effect\nof interference at the same time. Simulation results are shown to illustrate\nthe effectiveness of the proposed method. \n\n"}
{"id": "1412.4958", "contents": "Title: Universal Hashing for Information Theoretic Security Abstract: The information theoretic approach to security entails harnessing the\ncorrelated randomness available in nature to establish security. It uses tools\nfrom information theory and coding and yields provable security, even against\nan adversary with unbounded computational power. However, the feasibility of\nthis approach in practice depends on the development of efficiently\nimplementable schemes. In this article, we review a special class of practical\nschemes for information theoretic security that are based on 2-universal hash\nfamilies. Specific cases of secret key agreement and wiretap coding are\nconsidered, and general themes are identified. The scheme presented for wiretap\ncoding is modular and can be implemented easily by including an extra\npre-processing layer over the existing transmission codes. \n\n"}
{"id": "1412.5065", "contents": "Title: A Stochastic Geometry Framework for LOS/NLOS Propagation in Dense Small\n  Cell Networks Abstract: The need to carry out analytical studies of wireless systems often motivates\nthe usage of simplified models which, despite their tractability, can easily\nlead to an overestimation of the achievable performance. In the case of dense\nsmall cells networks, the standard single slope path-loss model has been shown\nto provide interesting, but supposedly too optimistic, properties such as the\ninvariance of the outage/coverage probability and of the spectral efficiency to\nthe base station density. This paper seeks to explore the performance of dense\nsmall cells networks when a more accurate path-loss model is taken into\naccount. We first propose a stochastic geometry based framework for small cell\nnetworks where the signal propagation accounts for both the Line-of-Sight (LOS)\nand Non-Line-Of-Sight (NLOS) components, such as the model provided by the 3GPP\nfor evaluation of pico-cells in Heterogeneous Networks. We then study the\nperformance of these networks and we show the dependency of some metrics such\nas the outage/coverage probability, the spectral efficiency and Area Spectral\nEfficiency (ASE) on the base station density and on the LOS likelihood of the\npropagation environment. Specifically, we show that, with LOS/NLOS propagation,\ndense networks still achieve large ASE gain but, at the same time, suffer from\nhigh outage probability. \n\n"}
{"id": "1412.5694", "contents": "Title: Capacity-Approaching PhaseCode for Low-Complexity Compressive Phase\n  Retrieval Abstract: In this paper, we tackle the general compressive phase retrieval problem. The\nproblem is to recover a K-sparse complex vector of length n, $x\\in\n\\mathbb{C}^n$, from the magnitudes of m linear measurements, $y=|Ax|$, where $A\n\\in \\mathbb{C}^{m \\times n}$ can be designed, and the magnitudes are taken\ncomponent-wise for vector $Ax\\in \\mathbb{C}^m$. We propose a variant of the\nPhaseCode algorithm, and show that, using an irregular left-degree sparse-graph\ncode construction, the algorithm can recover almost all the K non-zero signal\ncomponents using only slightly more than 4K measurements under some mild\nassumptions, with optimal time and memory complexity of ${\\cal O}(K)$. It is\nknown that the fundamental limit for the number of measurements in compressive\nphase retrieval problem is $4K - o(K)$. To the best of our knowledge, this is\nthe first constructive capacity-approaching compressive phase retrieval\nalgorithm. As a second contribution, we propose another variant of the\nPhaseCode algorithm that is based on a Compressive Sensing framework involving\nsparse-graph codes. Our proposed algorithm is an instance of a more powerful\n\"separation\" architecture that can be used to address the compressive\nphase-retrieval problem in general. This modular design features a compressive\nsensing outer layer, and a trigonometric-based phase-retrieval inner layer. The\ncompressive-sensing layer operates as a linear phase-aware compressive\nmeasurement subsystem, while the trig-based phase-retrieval layer provides the\ndesired abstraction between the actually targeted nonlinear phase-retrieval\nproblem and the induced linear compressive-sensing problem. Invoking this\narchitecture based on the use of sparse-graph codes for the compressive sensing\nlayer, we show that we can exactly recover a signal from only the magnitudes of\nits linear measurements using only slightly more than 6K measurements. \n\n"}
{"id": "1412.6058", "contents": "Title: A Distributed, Asynchronous and Incremental Algorithm for Nonconvex\n  Optimization: An ADMM Based Approach Abstract: The alternating direction method of multipliers (ADMM) has been popular for\nsolving many signal processing problems, convex or nonconvex. In this paper, we\nstudy an asynchronous implementation of the ADMM for solving a nonconvex\nnonsmooth optimization problem, whose objective is the sum of a number of\ncomponent functions. The proposed algorithm allows the problem to be solved in\na distributed, asynchronous and incremental manner. First, the component\nfunctions can be distributed to different computing nodes, who perform the\nupdates asynchronously without coordinating with each other. Two sources of\nasynchrony are covered by our algorithm: one is caused by the heterogeneity of\nthe computational nodes, and the other arises from unreliable communication\nlinks. Second, the algorithm can be viewed as implementing an incremental\nalgorithm where at each step the (possibly delayed) gradients of only a subset\nof component functions are update d. We show that when certain bounds are put\non the level of asynchrony, the proposed algorithm converges to the set of\nstationary solutions (resp. optimal solutions) for the nonconvex (resp. convex)\nproblem. To the best of our knowledge, the proposed ADMM implementation can\ntolerate the highest degree of asynchrony, among all known asynchronous\nvariants of the ADMM. Moreover, it is the first ADMM implementation that can\ndeal with nonconvexity and asynchrony at the same time. \n\n"}
{"id": "1412.6135", "contents": "Title: Multi-Scale Stochastic Simulation for Diffusive Molecular Communication Abstract: Recently, hybrid models have emerged that combine microscopic and mesoscopic\nregimes in a single stochastic reaction-diffusion simulation. Microscopic\nsimulations track every individual molecule and are generally more accurate.\nMesoscopic simulations partition the environment into subvolumes, track when\nmolecules move between adjacent subvolumes, and are generally more\ncomputationally efficient. In this paper, we present the foundation of a\nmulti-scale stochastic simulator from the perspective of molecular\ncommunication, for both mesoscopic and hybrid models, where we emphasize\nsimulation accuracy at the receiver and efficiency in regions that are far from\nthe communication link. Our multi-scale models use subvolumes of different\nsizes, between which we derive the diffusion event transition rate. Simulation\nresults compare the accuracy and efficiency of traditional approaches with that\nof a regular hybrid method and with those of our proposed multi-scale methods. \n\n"}
{"id": "1412.8520", "contents": "Title: Understanding and Designing Complex Systems: Response to \"A framework\n  for optimal high-level descriptions in science and engineering---preliminary\n  report\" Abstract: We recount recent history behind building compact models of nonlinear,\ncomplex processes and identifying their relevant macroscopic patterns or\n\"macrostates\". We give a synopsis of computational mechanics, predictive\nrate-distortion theory, and the role of information measures in monitoring\nmodel complexity and predictive performance. Computational mechanics provides a\nmethod to extract the optimal minimal predictive model for a given process.\nRate-distortion theory provides methods for systematically approximating such\nmodels. We end by commenting on future prospects for developing a general\nframework that automatically discovers optimal compact models. As a response to\nthe manuscript cited in the title above, this brief commentary corrects\npotentially misleading claims about its state space compression method and\nplaces it in a broader historical setting. \n\n"}
{"id": "1412.8708", "contents": "Title: Full Duplex Operation for Small Cells Abstract: Full duplex (FD) communications has the potential to double the capacity of a\nhalf duplex (HD) system at the link level. However, FD operation increases the\naggregate interference on each communication link, which limits the capacity\nimprovement. In this paper, we investigate how much of the potential doubling\ncan be practically achieved in the resource-managed, small multi-cellular\nsystem, similar to the TDD variant of LTE, both in indoor and outdoor\nenvironments, assuming FD base stations (BSs) and HD user equipment (UEs). We\nfocus on low-powered small cellular systems, because they are more suitable for\nFD operation given practical self-interference cancellation limits. A joint UE\nselection and power allocation method for a multi-cell scenario is presented,\nwhere a hybrid scheduling policy assigns FD timeslots when it provides a\nthroughput advantage by pairing UEs with appropriate power levels to mitigate\nthe mutual interference, but otherwise defaults to HD operation. Due to the\ncomplexity of finding the globally optimum solution of the proposed algorithm,\na sub-optimal method based on a heuristic greedy algorithm for UE selection,\nand a novel solution using geometric programming for power allocation, is\nproposed. With practical self-interference cancellation, antennas and circuits,\nit is shown that the proposed hybrid FD system achieves as much as 94%\nthroughput improvement in the downlink, and 92% in the uplink, compared to a HD\nsystem in an indoor multi-cell scenario and 54% in downlink and 61% in uplink\nin an outdoor multi-cell scenario. Further, we also compare the energy\nefficiency of FD operation. \n\n"}
{"id": "1501.01706", "contents": "Title: Error Performance Analysis of the Symbol-Decision SC Polar Decoder Abstract: Polar codes are the first provably capacity-achieving forward error\ncorrection codes. To improve decoder throughput, the symbol-decision SC\nalgorithm makes hard-decision for multiple bits at a time. In this paper, we\nprove that for polar codes, the symbol-decision SC algorithm is better than the\nbit-decision SC algorithm in terms of the frame error rate (FER) performance\nbecause the symbol-decision SC algorithm performs a local maximum likelihood\ndecoding within a symbol. Moreover, the bigger the symbol size, the better the\nFER performance. Finally, simulation results over both the additive white\nGaussian noise channel and the binary erasure channel confirm our theoretical\nanalysis. \n\n"}
{"id": "1501.01742", "contents": "Title: LDPC Coded Modulation with Probabilistic Shaping for Optical Fiber\n  Systems Abstract: An LDPC coded modulation scheme with probabilistic shaping, optimized\ninterleavers and noniterative demapping is proposed. Full-field simulations\nshow an increase in transmission distance by 8% compared to uniformly\ndistributed input. \n\n"}
{"id": "1501.02046", "contents": "Title: Multiuser MIMO Wireless Energy Transfer With Coexisting Opportunistic\n  Communication Abstract: This letter considers spectrum sharing between a primary multiuser\nmultiple-input multiple-output (MIMO) wireless energy transfer (WET) system and\na coexisting secondary point-to-point MIMO wireless information transmission\n(WIT) system, where WET generates interference to WIT and degrades its\nthroughput performance. We show that due to the interference, the WIT system\nsuffers from a loss of the degrees of freedom (DoF) proportional to the number\nof energy beams sent by the energy transmitter (ET), which, in general, needs\nto be larger than one in order to optimize the multiuser WET with user fairness\nconsideration. To minimize the DoF loss in WIT, we further propose a new\nsingle-beam energy transmission scheme based on the principle of time sharing,\nwhere the ET transmits one of the optimal energy beams at each time. This new\nscheme achieves the same optimal performance for the WET system, and minimizes\nthe impact of its interference to the WIT system. \n\n"}
{"id": "1501.03616", "contents": "Title: On the Renyi Divergence, Joint Range of Relative Entropies, and a\n  Channel Coding Theorem Abstract: This paper starts by considering the minimization of the Renyi divergence\nsubject to a constraint on the total variation distance. Based on the solution\nof this optimization problem, the exact locus of the points $\\bigl( D(Q\\|P_1),\nD(Q\\|P_2) \\bigr)$ is determined when $P_1, P_2, Q$ are arbitrary probability\nmeasures which are mutually absolutely continuous, and the total variation\ndistance between $P_1$ and $P_2$ is not below a given value. It is further\nshown that all the points of this convex region are attained by probability\nmeasures which are defined on a binary alphabet. This characterization yields a\ngeometric interpretation of the minimal Chernoff information subject to a\nconstraint on the total variation distance. This paper also derives an\nexponential upper bound on the performance of binary linear block codes (or\ncode ensembles) under maximum-likelihood decoding. Its derivation relies on the\nGallager bounding technique, and it reproduces the Shulman-Feder bound as a\nspecial case. The bound is expressed in terms of the Renyi divergence from the\nnormalized distance spectrum of the code (or the average distance spectrum of\nthe ensemble) to the binomially distributed distance spectrum of the\ncapacity-achieving ensemble of random block codes. This exponential bound\nprovides a quantitative measure of the degradation in performance of binary\nlinear block codes (or code ensembles) as a function of the deviation of their\ndistance spectra from the binomial distribution. An efficient use of this bound\nis considered. \n\n"}
{"id": "1501.04764", "contents": "Title: Optimized Uplink Transmission in Multi-Antenna C-RAN with Spatial\n  Compression and Forward Abstract: Massive MIMO and C-RAN are two promising techniques for implementing future\nwireless communication systems, where a large number of antennas are deployed\neither being co-located at the base station (BS) or totally distributed at\nseparate sites called remote radio heads (RRHs). In this paper, we consider a\ngeneral antenna deployment design for wireless networks, termed multi-antenna\nC-RAN, where a flexible number of antennas can be equipped at each RRH to more\neffectively balance the performance and fronthaul complexity trade-off beyond\nthe conventional massive MIMO and single-antenna C-RAN. Under the uplink\ncommunication setup, we propose a new \"spatial-compression-and-forward (SCF)\"\nscheme, where each RRH first performs a linear spatial filtering to denoise and\nmaximally compress its received signals from multiple users to a reduced number\nof dimensions, then conducts uniform scalar quantization over each of the\nresulting dimensions in parallel, and finally sends the total quantized bits to\nthe baseband unit (BBU) via a finite-rate fronthaul link for joint information\ndecoding. Under this scheme, we maximize the minimum\nsignal-to-interference-plus-noise ratio (SINR) of all users at the BBU by a\njoint resource allocation over the wireless transmission and fronthaul links.\nSpecifically, each RRH determines its own spatial filtering solution in a\ndistributed manner to reduce the signalling overhead with the BBU, while the\nBBU jointly optimizes the users' transmit power, the RRHs' fronthaul bits\nallocation, and the BBU's receive beamforming with fixed spatial filters at\nindividual RRHs. Through numerical results, it is shown that given a total\nnumber of antennas to be deployed, multi-antenna C-RAN with the proposed SCF\nand joint optimization significantly outperforms both massive MIMO and\nsingle-antenna C-RAN under practical fronthaul capacity constraints. \n\n"}
{"id": "1501.05683", "contents": "Title: Polar Lattices for Lossy Compression Abstract: Polar lattices, which are constructed from polar codes, have recently been\nproved to be able to achieve the capacity of the additive white Gaussian noise\n(AWGN) channel. In this work, we propose a new construction of polar lattices\nto solve the dual problem, i.e., achieving the rate-distortion bound of a\nmemoryless Gaussian source, which means that polar lattices can also be good\nfor the lossy compression of continuous sources. The structure of the proposed\npolar lattices enables us to integrate the post-entropy coding process into the\nlattice quantizer, which simplifies the quantization process. The overall\ncomplexity of encoding and decoding complexity is $O(N \\log^2 N)$ for a\nsub-exponentially decaying excess distortion. Moreover, the nesting structure\nof polar lattices further provides solutions for some multi-terminal coding\nproblems. The Wyner-Ziv coding problem for a Gaussian source can be solved by\nan AWGN capacity-achieving polar lattice nested in a rate-distortion bound\nachieving one, and the Gelfand-Pinsker problem can be solved in a reversed\nmanner. \n\n"}
{"id": "1501.05887", "contents": "Title: First- and Second-Order Coding Theorems for Mixed Memoryless Channels\n  with General Mixture Abstract: This paper investigates the first- and second-order maximum achievable rates\nof codes with/without cost constraints for mixed {channels} whose channel law\nis characterized by a general mixture of (at most) uncountably many stationary\nand memoryless discrete channels. These channels are referred to as {mixed\nmemoryless channels with general mixture} and include the class of mixed\nmemoryless channels of finitely or countably memoryless channels as a special\ncase. For mixed memoryless channels with general mixture, the first-order\ncoding theorem which gives a formula for the $\\varepsilon$-capacity is\nestablished, and then a direct part of the second-order coding theorem is\nprovided. A subclass of mixed memoryless channels whose component channels can\nbe ordered according to their capacity is introduced, and the first- and\nsecond-order coding theorems are established. It is shown that the established\nformulas reduce to several known formulas for restricted scenarios. \n\n"}
{"id": "1501.06026", "contents": "Title: Energy Harvesting Wireless Communications: A Review of Recent Advances Abstract: This article summarizes recent contributions in the broad area of energy\nharvesting wireless communications. In particular, we provide the current state\nof the art for wireless networks composed of energy harvesting nodes, starting\nfrom the information-theoretic performance limits to transmission scheduling\npolicies and resource allocation, medium access and networking issues. The\nemerging related area of energy transfer for self-sustaining energy harvesting\nwireless networks is considered in detail covering both energy cooperation\naspects and simultaneous energy and information transfer. Various potential\nmodels with energy harvesting nodes at different network scales are reviewed as\nwell as models for energy consumption at the nodes. \n\n"}
{"id": "1502.00137", "contents": "Title: Hybrid Radio/Free-Space Optical Design for Next Generation Backhaul\n  Systems Abstract: The deluge of date rate in today's networks imposes a cost burden on the\nbackhaul network design. Developing cost efficient backhaul solutions becomes\nan exciting, yet challenging, problem. Traditional technologies for backhaul\nnetworks include either radio-frequency backhauls (RF) or optical fibers (OF).\nWhile RF is a cost-effective solution as compared to OF, it supports lower data\nrate requirements. Another promising backhaul solution is the free-space optics\n(FSO) as it offers both a high data rate and a relatively low cost. FSO,\nhowever, is sensitive to nature conditions, e.g., rain, fog, line-of-sight.\nThis paper combines both RF and FSO advantages and proposes a hybrid RF/FSO\nbackhaul solution. It considers the problem of minimizing the cost of the\nbackhaul network by choosing either OF or hybrid RF/FSO backhaul links between\nthe base-stations (BS) so as to satisfy data rate, connectivity, and\nreliability constraints. It shows that under a specified realistic assumption\nabout the cost of OF and hybrid RF/FSO links, the problem is equivalent to a\nmaximum weight clique problem, which can be solved with moderate complexity.\nSimulation results show that the proposed solution shows a close-to-optimal\nperformance, especially for practical prices of the hybrid RF/FSO links. \n\n"}
{"id": "1502.00536", "contents": "Title: Quantum Tomography Protocols with Positivity are Compressed Sensing\n  Protocols Abstract: Characterizing complex quantum systems is a vital task in quantum information\nscience. Quantum tomography, the standard tool used for this purpose, uses a\nwell-designed measurement record to reconstruct quantum states and processes.\nIt is, however, notoriously inefficient. Recently, the classical signal\nreconstruction technique known as \"compressed sensing\" has been ported to\nquantum information science to overcome this challenge: accurate tomography can\nbe achieved with substantially fewer measurement settings, thereby greatly\nenhancing the efficiency of quantum tomography. Here we show that compressed\nsensing tomography of quantum systems is essentially guaranteed by a special\nproperty of quantum mechanics itself---that the mathematical objects that\ndescribe the system in quantum mechanics are matrices with nonnegative\neigenvalues. This result has an impact on the way quantum tomography is\nunderstood and implemented. In particular, it implies that the information\nobtained about a quantum system through compressed sensing methods exhibits a\nnew sense of \"informational completeness.\" This has important consequences on\nthe efficiency of data taking for quantum tomography, and enables us to\nconstruct informationally complete measurements that are robust to noise and\nmodeling errors. Moreover, our result shows that one can expand the numerical\ntool-box used in quantum tomography and employ highly efficient algorithms\ndeveloped to handle large dimensional matrices on a large dimensional Hilbert\nspace. While we mainly present our results in the context of quantum\ntomography, they apply to the general case of positive semidefinite matrix\nrecovery. \n\n"}
{"id": "1502.00842", "contents": "Title: Erasure codes with symbol locality and group decodability for\n  distributed storage Abstract: We introduce a new family of erasure codes, called group decodable code\n(GDC), for distributed storage system. Given a set of design parameters\n{\\alpha; \\beta; k; t}, where k is the number of information symbols, each\ncodeword of an (\\alpha; \\beta; k; t)-group decodable code is a t-tuple of\nstrings, called buckets, such that each bucket is a string of \\beta symbols\nthat is a codeword of a [\\beta; \\alpha] MDS code (which is encoded from \\alpha\ninformation symbols). Such codes have the following two properties: (P1)\nLocally Repairable: Each code symbol has locality (\\alpha; \\beta-\\alpha + 1).\n(P2) Group decodable: From each bucket we can decode \\alpha information\nsymbols. We establish an upper bound of the minimum distance of (\\alpha; \\beta;\nk; t)-group decodable code for any given set of {\\alpha; \\beta; k; t}; We also\nprove that the bound is achievable when the coding field F has size |F| > n-1\n\\choose k-1. \n\n"}
{"id": "1502.01975", "contents": "Title: Optimal Haplotype Assembly from High-Throughput Mate-Pair Reads Abstract: Humans have $23$ pairs of homologous chromosomes. The homologous pairs are\nalmost identical pairs of chromosomes. For the most part, differences in\nhomologous chromosome occur at certain documented positions called single\nnucleotide polymorphisms (SNPs). A haplotype of an individual is the pair of\nsequences of SNPs on the two homologous chromosomes. In this paper, we study\nthe problem of inferring haplotypes of individuals from mate-pair reads of\ntheir genome. We give a simple formula for the coverage needed for haplotype\nassembly, under a generative model. The analysis here leverages connections of\nthis problem with decoding convolutional codes. \n\n"}
{"id": "1502.02539", "contents": "Title: Random variate generation using only finitely many unbiased,\n  independently and identically distributed random bits Abstract: For any discrete probability distributions with bounded entropy, we can\ngenerate exactly a random variate using only a finite expected number of\nperfect coin flips. A perfect coin flip is the outcome of an unbiased Bernoulli\nrandom variable. Coin flips are unbiased, independently and identically\ndistributed in all our work. We survey well-known algorithms for the discrete\ncase such as the one from Knuth and Yao as well as the one from Han and Hoshi.\nWe also discuss briefly about a practical implementation for the algorithm\nproposed by Knuth and Yao. For the continuous case, only approximations can be\nhoped for. The freedom to choose the accuracy for the approximations matters,\nand, for that, we propose to measure accuracy in terms of the Wasserstein\n$L_\\infty$-metric. We derive a universal lower bound for the expected number of\nperfect coin flips required to reach a desired accuracy. We also provide\nseveral algorithms for absolutely continuous distributions that come within our\nuniversal lower bound. \n\n"}
{"id": "1502.03147", "contents": "Title: Topological Interference Management with just Retransmission: What are\n  the \"Best\" Topologies? Abstract: We study the problem of interference management in fast fading wireless\nnetworks, in which the transmitters are only aware of network topology. We\nconsider a class of retransmission-based schemes, where transmitters in the\nnetwork are only allowed to resend their symbols in order to assist with the\nneutralization of interference at the receivers. We introduce a necessary and\nsufficient condition on the network topology, under which half symmetric\ndegrees-of-freedom (DoF) is achievable through the considered\nretransmission-based schemes. This corresponds to the \"best\" topologies since\nhalf symmetric DoF is the highest possible value for the symmetric DoF in the\npresence of interference. We show that when the condition is satisfied, there\nalways exists a set of carefully chosen transmitters in the network, such that\nby retransmission of their symbols at an appropriate time slot, we can\nneutralize all the interfering signals at the receivers. Quite surprisingly, we\nalso show that for any given network topology, if we cannot achieve half\nsymmetric DoF by retransmission-based schemes, then there does not exist any\nlinear scheme that can do so. We also consider a practical network scenario\nthat models cell edge users in a heterogeneous network, and show that the\ncharacterized condition on the network topology occurs frequently. Furthermore,\nwe numerically evaluate the achievable rates of the DoF-optimal\nretransmission-based scheme in such network scenario, and show that its\nthroughput gain is not restricted to the asymptotic DoF analysis. \n\n"}
{"id": "1502.05516", "contents": "Title: Outage Capacity of Rayleigh Product Channels: a Free Probability\n  Approach Abstract: The Rayleigh product channel model is useful in capturing the performance\ndegradation due to rank deficiency of MIMO channels. In this paper, such a\nperformance degradation is investigated via the channel outage probability\nassuming slowly varying channel with delay-constrained decoding. Using\ntechniques of free probability theory, the asymptotic variance of channel\ncapacity is derived when the dimensions of the channel matrices approach\ninfinity. In this asymptotic regime, the channel capacity is rigorously proven\nto be Gaussian distributed. Using the obtained results, a fundamental tradeoff\nbetween multiplexing gain and diversity gain of Rayleigh product channels can\nbe characterized by closed-form expression at any finite signal-to-noise ratio.\nNumerical results are provided to compare the relative outage performance\nbetween Rayleigh product channels and conventional Rayleigh MIMO channels. \n\n"}
{"id": "1502.05775", "contents": "Title: A Secret Common Information Duality for Tripartite Noisy Correlations Abstract: We explore the duality between the simulation and extraction of secret\ncorrelations in light of a similar well-known operational duality between the\ntwo notions of common information due to Wyner, and G\\'acs and K\\\"orner. For\nthe inverse problem of simulating a tripartite noisy correlation from noiseless\nsecret key and unlimited public communication, we show that Winter's (2005)\nresult for the key cost in terms of a conditional version of Wyner's common\ninformation can be simply reexpressed in terms of the existence of a bipartite\nprotocol monotone. For the forward problem of key distillation from noisy\ncorrelations, we construct simple distributions for which the conditional\nG\\'acs and K\\\"orner common information achieves a tight bound on the secret key\nrate. We conjecture that this holds in general for non-communicative key\nagreement models. We also comment on the interconvertibility of secret\ncorrelations under local operations and public communication. \n\n"}
{"id": "1502.06435", "contents": "Title: Hyperspectral Unmixing via Turbo Bilinear Approximate Message Passing Abstract: The goal of hyperspectral unmixing is to decompose an electromagnetic\nspectral dataset measured over M spectral bands and T pixels into N constituent\nmaterial spectra (or \"end-members\") with corresponding spatial abundances. In\nthis paper, we propose a novel approach to hyperspectral unmixing based on\nloopy belief propagation (BP) that enables the exploitation of spectral\ncoherence in the endmembers and spatial coherence in the abundances. In\nparticular, we partition the factor graph into spectral coherence, spatial\ncoherence, and bilinear subgraphs, and pass messages between them using a\n\"turbo\" approach. To perform message passing within the bilinear subgraph, we\nemploy the bilinear generalized approximate message passing algorithm\n(BiG-AMP), a recently proposed belief-propagation-based approach to matrix\nfactorization. Furthermore, we propose an expectation-maximization (EM)\nstrategy to tune the prior parameters and a model-order selection strategy to\nselect the number of materials N. Numerical experiments conducted with both\nsynthetic and real-world data show favorable unmixing performance relative to\nexisting methods. \n\n"}
{"id": "1502.07123", "contents": "Title: Degrees-of-Freedom of the K-User MISO Interference Channel with Delayed\n  Local CSIT Abstract: This paper considers a K-user Multiple-Input-Single-Output (MISO)\nInterference Channel (IC), where the channel state information obtained by the\ntransmitters (CSIT) is perfect, but completely outdated. A Retrospective\nInterference Alignment (RIA) using such delayed CSIT was proposed by the\nauthors of [1] for the MISO Broadcast Channel (BC), but the extension to the\nMISO IC is a non-trivial step as each transmitter only has the message intended\nfor the corresponding user. Recently, [7] focused on a\nSingle-Input-Single-Output (SISO) IC and solved such bottleneck by inventing a\ndistributed higher order symbol generation. Our main work is to extend [7] to\nthe MISO case by integrating some features of the scheme proposed in [1]. The\nachieved sum Degrees-of-Freedom (DoF) performance is asymptotically given by\n64/15 when $K\\to\\infty$, outperforming all the previously known results. \n\n"}
{"id": "1502.07425", "contents": "Title: Analysis and Optimization of Interference Nulling in Downlink\n  Multi-Antenna HetNets with Offloading Abstract: Heterogeneous networks (HetNets) with offloading is considered as an\neffective way to meet the high data rate demand of future wireless service.\nHowever, the offloaded users suffer from strong inter-tier interference, which\nreduces the benefits of offloading and is one of the main limiting factors of\nthe system performance. In this paper, we investigate the use of an\ninterference nulling (IN) beamforming scheme to improve the system performance\nby carefully managing the inter-tier interference to the offloaded users in\ndownlink two-tier HetNets with multi-antenna base stations. Utilizing tools\nfrom stochastic geometry, we derive a tractable expression for the rate\ncoverage probability of the IN scheme. Then, we optimize the design parameter,\ni.e., the degrees of freedom that can be used for IN, to maximize the rate\ncoverage probability. Specifically, in the asymptotic scenario where the rate\nthreshold is small, by studying the order behavior of the rate coverage\nprobability, we characterize the optimal design parameter. For the general\nscenario, we show some properties of the optimal design parameter. Finally, by\nnumerical simulations, we show the IN scheme can outperform both the simple\noffloading scheme without interference management and the almost blank\nsubframes scheme in 3GPP LTE, especially in large antenna regime. \n\n"}
{"id": "1503.01245", "contents": "Title: Large Dimensional Analysis of Robust M-Estimators of Covariance with\n  Outliers Abstract: A large dimensional characterization of robust M-estimators of covariance (or\nscatter) is provided under the assumption that the dataset comprises\nindependent (essentially Gaussian) legitimate samples as well as arbitrary\ndeterministic samples, referred to as outliers. Building upon recent random\nmatrix advances in the area of robust statistics, we specifically show that the\nso-called Maronna M-estimator of scatter asymptotically behaves similar to\nwell-known random matrices when the population and sample sizes grow together\nto infinity. The introduction of outliers leads the robust estimator to behave\nasymptotically as the weighted sum of the sample outer products, with a\nconstant weight for all legitimate samples and different weights for the\noutliers. A fine analysis of this structure reveals importantly that the\npropensity of the M-estimator to attenuate (or enhance) the impact of outliers\nis mostly dictated by the alignment of the outliers with the inverse population\ncovariance matrix of the legitimate samples. Thus, robust M-estimators can\nbring substantial benefits over more simplistic estimators such as the\nper-sample normalized version of the sample covariance matrix, which is not\ncapable of differentiating the outlying samples. The analysis shows that,\nwithin the class of Maronna's estimators of scatter, the Huber estimator is\nmost favorable for rejecting outliers. On the contrary, estimators more similar\nto Tyler's scale invariant estimator (often preferred in the literature) run\nthe risk of inadvertently enhancing some outliers. \n\n"}
{"id": "1503.01402", "contents": "Title: Deterministic construction of sparse binary and ternary matrices from\n  existing binary sensing matrices Abstract: In the present work, we discuss a procedure for constructing sparse binary\nand ternary matrices from existing two binary sensing matrices. The matrices\nthat we construct have several attractive properties such as smaller density,\nwhich supports algorithms with low computational complexity. As an application\nof our method, we show that a CS matrix of general row size different from $p,\np^2, pq$ (for different primes $p,q$) can be constructed. \n\n"}
{"id": "1503.02045", "contents": "Title: Estimation after Parameter Selection: Performance Analysis and\n  Estimation Methods Abstract: In many practical parameter estimation problems, prescreening and parameter\nselection are performed prior to estimation. In this paper, we consider the\nproblem of estimating a preselected unknown deterministic parameter chosen from\na parameter set based on observations according to a predetermined selection\nrule, $\\Psi$. The data-based parameter selection process may impact the\nsubsequent estimation by introducing a selection bias and creating coupling\nbetween decoupled parameters. This paper introduces a post-selection mean\nsquared error (PSMSE) criterion as a performance measure. A corresponding\nCram\\'er-Rao-type bound on the PSMSE of any $\\Psi$-unbiased estimator is\nderived, where the $\\Psi$-unbiasedness is in the Lehmann-unbiasedness sense.\nThe post-selection maximum-likelihood (PSML) estimator is presented .It is\nproved that if there exists an $\\Psi$-unbiased estimator that achieves the\n$\\Psi$-Cram\\'er-Rao bound (CRB), i.e. an $\\Psi$-efficient estimator, then it is\nproduced by the PSML estimator. In addition, iterative methods are developed\nfor the practical implementation of the PSML estimator. Finally, the proposed\n$\\Psi$-CRB and PSML estimator are examined in estimation after parameter\nselection with different distributions. \n\n"}
{"id": "1503.05113", "contents": "Title: Quantifying Morphological Computation based on an Information\n  Decomposition of the Sensorimotor Loop Abstract: The question how an agent is affected by its embodiment has attracted growing\nattention in recent years. A new field of artificial intelligence has emerged,\nwhich is based on the idea that intelligence cannot be understood without\ntaking into account embodiment. We believe that a formal approach to\nquantifying the embodiment's effect on the agent's behaviour is beneficial to\nthe fields of artificial life and artificial intelligence. The contribution of\nan agent's body and environment to its behaviour is also known as morphological\ncomputation. Therefore, in this work, we propose a quantification of\nmorphological computation, which is based on an information decomposition of\nthe sensorimotor loop into shared, unique and synergistic information. In\nnumerical simulation based on a formal representation of the sensorimotor loop,\nwe show that the unique information of the body and environment is a good\nmeasure for morphological computation. The results are compared to our\npreviously derived quantification of morphological computation. \n\n"}
{"id": "1503.06854", "contents": "Title: Massive MIMO: Ten Myths and One Critical Question Abstract: Wireless communications is one of the most successful technologies in modern\nyears, given that an exponential growth rate in wireless traffic has been\nsustained for over a century (known as Cooper's law). This trend will certainly\ncontinue driven by new innovative applications; for example, augmented reality\nand internet-of-things.\n  Massive MIMO (multiple-input multiple-output) has been identified as a key\ntechnology to handle orders of magnitude more data traffic. Despite the\nattention it is receiving from the communication community, we have personally\nwitnessed that Massive MIMO is subject to several widespread misunderstandings,\nas epitomized by following (fictional) abstract:\n  \"The Massive MIMO technology uses a nearly infinite number of high-quality\nantennas at the base stations. By having at least an order of magnitude more\nantennas than active terminals, one can exploit asymptotic behaviors that some\nspecial kinds of wireless channels have. This technology looks great at first\nsight, but unfortunately the signal processing complexity is off the charts and\nthe antenna arrays would be so huge that it can only be implemented in\nmillimeter wave bands.\"\n  The statements above are, in fact, completely false. In this overview\narticle, we identify ten myths and explain why they are not true. We also ask a\nquestion that is critical for the practical adoption of the technology and\nwhich will require intense future research activities to answer properly. We\nprovide references to key technical papers that support our claims, while a\nfurther list of related overview and technical papers can be found at the\nMassive MIMO Info Point: http://massivemimo.eu \n\n"}
{"id": "1503.06966", "contents": "Title: Multicast Multigroup Beamforming for Per-antenna Power Constrained\n  Large-scale Arrays Abstract: Large in the number of transmit elements, multi-antenna arrays with\nper-element limitations are in the focus of the present work. In this context,\nphysical layer multigroup multicasting under per-antenna power constrains, is\ninvestigated herein. To address this complex optimization problem\nlow-complexity alternatives to semi-definite relaxation are proposed. The goal\nis to optimize the per-antenna power constrained transmitter in a maximum\nfairness sense, which is formulated as a non-convex quadratically constrained\nquadratic problem. Therefore, the recently developed tool of feasible point\npursuit and successive convex approximation is extended to account for\npractical per-antenna power constraints. Interestingly, the novel iterative\nmethod exhibits not only superior performance in terms of approaching the\nrelaxed upper bound but also a significant complexity reduction, as the\ndimensions of the optimization variables increase. Consequently, multicast\nmultigroup beamforming for large-scale array transmitters with per-antenna\ndedicated amplifiers is rendered computationally efficient and accurate. A\npreliminary performance evaluation in large-scale systems for which the\nsemi-definite relaxation constantly yields non rank-1 solutions is presented. \n\n"}
{"id": "1503.07236", "contents": "Title: Isotropically Random Orthogonal Matrices: Performance of LASSO and\n  Minimum Conic Singular Values Abstract: Recently, the precise performance of the Generalized LASSO algorithm for\nrecovering structured signals from compressed noisy measurements, obtained via\ni.i.d. Gaussian matrices, has been characterized. The analysis is based on a\nframework introduced by Stojnic and heavily relies on the use of Gordon's\nGaussian min-max theorem (GMT), a comparison principle on Gaussian processes.\nAs a result, corresponding characterizations for other ensembles of measurement\nmatrices have not been developed. In this work, we analyze the corresponding\nperformance of the ensemble of isotropically random orthogonal (i.r.o.)\nmeasurements. We consider the constrained version of the Generalized LASSO and\nderive a sharp characterization of its normalized squared error in the\nlarge-system limit. When compared to its Gaussian counterpart, our result\nanalytically confirms the superiority in performance of the i.r.o. ensemble.\nOur second result, derives an asymptotic lower bound on the minimum conic\nsingular values of i.r.o. matrices. This bound is larger than the corresponding\nbound on Gaussian matrices. To prove our results we express i.r.o. matrices in\nterms of Gaussians and show that, with some modifications, the GMT framework is\nstill applicable. \n\n"}
{"id": "1503.08139", "contents": "Title: Bounds on entanglement distillation and secret key agreement for quantum\n  broadcast channels Abstract: The squashed entanglement of a quantum channel is an additive function of\nquantum channels, which finds application as an upper bound on the rate at\nwhich secret key and entanglement can be generated when using a quantum channel\na large number of times in addition to unlimited classical communication. This\nquantity has led to an upper bound of $\\log((1+\\eta)/(1-\\eta))$ on the capacity\nof a pure-loss bosonic channel for such a task, where $\\eta$ is the average\nfraction of photons that make it from the input to the output of the channel.\nThe purpose of the present paper is to extend these results beyond the\nsingle-sender single-receiver setting to the more general case of a single\nsender and multiple receivers (a quantum broadcast channel). We employ\nmultipartite generalizations of the squashed entanglement to constrain the\nrates at which secret key and entanglement can be generated between any subset\nof the users of such a channel, along the way developing several new properties\nof these measures. We apply our results to the case of a pure-loss broadcast\nchannel with one sender and two receivers. \n\n"}
{"id": "1503.08453", "contents": "Title: Quantum walk, entanglement and thermodynamic laws Abstract: We consider an special dynamics of a quantum walk (QW) on a line. Initially,\nthe walker localized at the origin of the line with arbitrary chirality,\nevolves to an asymptotic stationary state. In this stationary state a\nmeasurement is performed and the state resulting from this measurement is used\nto start a second QW evolution to achieve a second asymptotic stationary state.\nIn previous works, we developed the thermodynamics associated with the\nentanglement between the coin and position degrees of freedom in the QW. Here\nwe study the application of the first and second laws of thermodynamics to the\nprocess between the two stationary states mentioned above. We show that: i) the\nentropy change has upper and lower bounds that are obtained analytically as a\nfunction of the initial conditions. ii) the energy change is associated to a\nheat-transfer process. \n\n"}
{"id": "1503.09092", "contents": "Title: Efficiently decoding Reed-Muller codes from random errors Abstract: Reed-Muller codes encode an $m$-variate polynomial of degree $r$ by\nevaluating it on all points in $\\{0,1\\}^m$. We denote this code by $RM(m,r)$.\nThe minimal distance of $RM(m,r)$ is $2^{m-r}$ and so it cannot correct more\nthan half that number of errors in the worst case. For random errors one may\nhope for a better result.\n  In this work we give an efficient algorithm (in the block length $n=2^m$) for\ndecoding random errors in Reed-Muller codes far beyond the minimal distance.\nSpecifically, for low rate codes (of degree $r=o(\\sqrt{m})$) we can correct a\nrandom set of $(1/2-o(1))n$ errors with high probability. For high rate codes\n(of degree $m-r$ for $r=o(\\sqrt{m/\\log m})$), we can correct roughly $m^{r/2}$\nerrors.\n  More generally, for any integer $r$, our algorithm can correct any error\npattern in $RM(m,m-(2r+2))$ for which the same erasure pattern can be corrected\nin $RM(m,m-(r+1))$. The results above are obtained by applying recent results\nof Abbe, Shpilka and Wigderson (STOC, 2015), Kumar and Pfister (2015) and\nKudekar et al. (2015) regarding the ability of Reed-Muller codes to correct\nrandom erasures.\n  The algorithm is based on solving a carefully defined set of linear equations\nand thus it is significantly different than other algorithms for decoding\nReed-Muller codes that are based on the recursive structure of the code. It can\nbe seen as a more explicit proof of a result of Abbe et al. that shows a\nreduction from correcting erasures to correcting errors, and it also bares some\nsimilarities with the famous Berlekamp-Welch algorithm for decoding\nReed-Solomon codes. \n\n"}
{"id": "1504.00434", "contents": "Title: Coordinated Multi-cell Beamforming for Massive MIMO: A Random Matrix\n  Approach Abstract: We consider the problem of coordinated multi- cell downlink beamforming in\nmassive multiple input multiple output (MIMO) systems consisting of N cells, Nt\nantennas per base station (BS) and K user terminals (UTs) per cell.\nSpecifically, we formulate a multi-cell beamforming algorithm for massive MIMO\nsystems which requires limited amount of information exchange between the BSs.\nThe design objective is to minimize the aggregate transmit power across all the\nBSs subject to satisfying the user signal to interference noise ratio (SINR)\nconstraints. The algorithm requires the BSs to exchange parameters which can be\ncomputed solely based on the channel statistics rather than the instantaneous\nCSI. We make use of tools from random matrix theory to formulate the\ndecentralized algorithm. We also characterize a lower bound on the set of\ntarget SINR values for which the decentralized multi-cell beamforming algorithm\nis feasible. We further show that the performance of our algorithm\nasymptotically matches the performance of the centralized algorithm with full\nCSI sharing. While the original result focuses on minimizing the aggregate\ntransmit power across all the BSs, we formulate a heuristic extension of this\nalgorithm to incorporate a practical constraint in multi-cell systems, namely\nthe individual BS transmit power constraints. Finally, we investigate the\nimpact of imperfect CSI and pilot contamination effect on the performance of\nthe decentralized algorithm, and propose a heuristic extension of the algorithm\nto accommodate these issues. Simulation results illustrate that our algorithm\nclosely satisfies the target SINR constraints and achieves minimum power in the\nregime of massive MIMO systems. In addition, it also provides substantial power\nsavings as compared to zero-forcing beamforming when the number of antennas per\nBS is of the same orders of magnitude as the number of UTs per cell. \n\n"}
{"id": "1504.01185", "contents": "Title: Byzantine Attack and Defense in Cognitive Radio Networks: A Survey Abstract: The Byzantine attack in cooperative spectrum sensing (CSS), also known as the\nspectrum sensing data falsification (SSDF) attack in the literature, is one of\nthe key adversaries to the success of cognitive radio networks (CRNs). In the\npast couple of years, the research on the Byzantine attack and defense\nstrategies has gained worldwide increasing attention. In this paper, we provide\na comprehensive survey and tutorial on the recent advances in the Byzantine\nattack and defense for CSS in CRNs. Specifically, we first briefly present the\npreliminaries of CSS for general readers, including signal detection\ntechniques, hypothesis testing, and data fusion. Second, we analyze the spear\nand shield relation between Byzantine attack and defense from three aspects:\nthe vulnerability of CSS to attack, the obstacles in CSS to defense, and the\ngames between attack and defense. Then, we propose a taxonomy of the existing\nByzantine attack behaviors and elaborate on the corresponding attack\nparameters, which determine where, who, how, and when to launch attacks. Next,\nfrom the perspectives of homogeneous or heterogeneous scenarios, we classify\nthe existing defense algorithms, and provide an in-depth tutorial on the\nstate-of-the-art Byzantine defense schemes, commonly known as robust or secure\nCSS in the literature. Furthermore, we highlight the unsolved research\nchallenges and depict the future research directions. \n\n"}
{"id": "1504.01467", "contents": "Title: Uncertainty principle, Shannon-Nyquist sampling and beyond Abstract: Donoho and Stark have shown that a precise deterministic recovery of missing\ninformation contained in a time interval shorter than the time-frequency\nuncertainty limit is possible. We analyze this signal recovery mechanism from a\nphysics point of view and show that the well-known Shannon-Nyquist sampling\ntheorem, which is fundamental in signal processing, also uses essentially the\nsame mechanism. The uncertainty relation in the context of information theory,\nwhich is based on Fourier analysis, provides a criterion to distinguish\nShannon-Nyquist sampling from compressed sensing. A new signal recovery\nformula, which is analogous to Donoho-Stark formula, is given using the idea of\nShannon-Nyquist sampling; in this formulation, the smearing of information\nbelow the uncertainty limit as well as the recovery of information with\nspecified bandwidth take place. We also discuss the recovery of states from the\ndomain below the uncertainty limit of coordinate and momentum in quantum\nmechanics and show that in principle the state recovery works by assuming ideal\nmeasurement procedures. The recovery of the lost information in the\nsub-uncertainty domain means that the loss of information in such a small\ndomain is not fatal, which is in accord with our common understanding of the\nuncertainty principle, although its precise recovery is something we are not\nused to in quantum mechanics. The uncertainty principle provides a universal\nsampling criterion covering both the classical Shannon-Nyquist sampling theorem\nand the quantum mechanical measurement. \n\n"}
{"id": "1504.01690", "contents": "Title: Expanding the Compute-and-Forward Framework: Unequal Powers, Signal\n  Levels, and Multiple Linear Combinations Abstract: The compute-and-forward framework permits each receiver in a Gaussian network\nto directly decode a linear combination of the transmitted messages. The\nresulting linear combinations can then be employed as an end-to-end\ncommunication strategy for relaying, interference alignment, and other\napplications. Recent efforts have demonstrated the advantages of employing\nunequal powers at the transmitters and decoding more than one linear\ncombination at each receiver. However, neither of these techniques fit\nnaturally within the original formulation of compute-and-forward. This paper\nproposes an expanded compute-and-forward framework that incorporates both of\nthese possibilities and permits an intuitive interpretation in terms of signal\nlevels. Within this framework, recent achievability and optimality results are\nunified and generalized. \n\n"}
{"id": "1504.02360", "contents": "Title: Multi-Objective Power Allocation for Energy Efficient Wireless\n  Information and Power Transfer Systems Abstract: Simultaneous wireless information and power transfer (SWIPT) provides a\npromising solution for enabling perpetual wireless networks. As energy\nefficiency (EE) is an im- portant evaluation of system performance, this thesis\nstudies energy-efficient resource allocation algorithm designs in SWIPT\nsystems. We first investigate the trade-off between the EE for information\ntransmission, the EE for power transfer, and the total transmit power in a\nbasic SWIPT system with separated receivers. A multi-objective optimization\nproblem is formulated under the constraint of maximum transmit power. We\npropose an algorithm which achieves flexible resource allocation for energy\nefficiencies maxi- mization and transmit power minimization. The trade-off\nregion of the system design objectives is shown in simulation results. Further,\nwe consider secure communication in a SWIPT system with power splitting\nreceivers. Artificial noise is injected to the com- munication channel to\ncombat the eavesdropping capability of potential eavesdroppers. A\npower-efficient resource allocation algorithm is developed when multiple\nlegitimate information receivers and multi-antenna potential eavesdroppers\nco-exist in the system. Simulation results demonstrate a significant\nperformance gain by the proposed optimal algorithm compared to suboptimal\nbaseline schemes. \n\n"}
{"id": "1504.02923", "contents": "Title: Compressed Sensing Recovery via Nonconvex Shrinkage Penalties Abstract: The $\\ell^0$ minimization of compressed sensing is often relaxed to $\\ell^1$,\nwhich yields easy computation using the shrinkage mapping known as soft\nthresholding, and can be shown to recover the original solution under certain\nhypotheses. Recent work has derived a general class of shrinkages and\nassociated nonconvex penalties that better approximate the original $\\ell^0$\npenalty and empirically can recover the original solution from fewer\nmeasurements. We specifically examine p-shrinkage and firm thresholding. In\nthis work, we prove that given data and a measurement matrix from a broad class\nof matrices, one can choose parameters for these classes of shrinkages to\nguarantee exact recovery of the sparsest solution. We further prove convergence\nof the algorithm iterative p-shrinkage (IPS) for solving one such relaxed\nproblem. \n\n"}
{"id": "1504.03024", "contents": "Title: Almost Lossless Analog Compression without Phase Information Abstract: We propose an information-theoretic framework for phase retrieval.\nSpecifically, we consider the problem of recovering an unknown n-dimensional\nvector x up to an overall sign factor from m=Rn phaseless measurements with\ncompression rate R and derive a general achievability bound for R.\nSurprisingly, it turns out that this bound on the compression rate is the same\nas the one for almost lossless analog compression obtained by Wu and Verd\\'u\n(2010): Phaseless linear measurements are as good as linear measurements with\nfull phase information in the sense that ignoring the sign of m measurements\nonly leaves us with an ambiguity with respect to an overall sign factor of x. \n\n"}
{"id": "1504.04113", "contents": "Title: On the Performance of the Relay-ARQ Networks Abstract: This paper investigates the performance of relay networks in the presence of\nhybrid automatic repeat request (ARQ) feedback and adaptive power allocation.\nThe throughput and the outage probability of different hybrid ARQ protocols are\nstudied for independent and spatially-correlated fading channels. The results\nare obtained for the cases where there is a sum power constraint on the source\nand the relay or when each of the source and the relay are power-limited\nindividually. With adaptive power allocation, the results demonstrate the\nefficiency of relay-ARQ techniques in different conditions. \n\n"}
{"id": "1504.04540", "contents": "Title: One-Bit Massive MIMO: Channel Estimation and High-Order Modulations Abstract: We investigate the information-theoretic throughout achievable on a fading\ncommunication link when the receiver is equipped with one-bit analog-to-digital\nconverters (ADCs). The analysis is conducted for the setting where neither the\ntransmitter nor the receiver have a priori information on the realization of\nthe fading channels. This means that channel-state information needs to be\nacquired at the receiver on the basis of the one-bit quantized channel outputs.\nWe show that least-squares (LS) channel estimation combined with joint pilot\nand data processing is capacity achieving in the single-user,\nsingle-receive-antenna case.\n  We also investigate the achievable uplink throughput in a massive\nmultiple-input multiple-output system where each element of the antenna array\nat the receiver base-station feeds a one-bit ADC. We show that LS channel\nestimation and maximum-ratio combining are sufficient to support both multiuser\noperation and the use of high-order constellations. This holds in spite of the\nsevere nonlinearity introduced by the one-bit ADCs. \n\n"}
{"id": "1504.04615", "contents": "Title: MISO Broadcast Channel with Hybrid CSIT: Beyond Two Users Abstract: We study the impact of heterogeneity of channel-state-information available\nat the transmitters (CSIT) on the capacity of broadcast channels with a\nmultiple-antenna transmitter and $k$ single-antenna receivers (MISO BC). In\nparticular, we consider the $k$-user MISO BC, where the CSIT with respect to\neach receiver can be either instantaneous/perfect, delayed, or not available;\nand we study the impact of this heterogeneity of CSIT on the degrees-of-freedom\n(DoF) of such network. We first focus on the $3$-user MISO BC; and we\ncompletely characterize the DoF region for all possible heterogeneous CSIT\nconfigurations, assuming linear encoding strategies at the transmitters. The\nresult shows that the state-of-the-art achievable schemes in the literature are\nindeed sum-DoF optimal, when restricted to linear encoding schemes. To prove\nthe result, we develop a novel bound, called Interference Decomposition Bound,\nwhich provides a lower bound on the interference dimension at a receiver which\nsupplies delayed CSIT based on the average dimension of constituents of that\ninterference, thereby decomposing the interference into its individual\ncomponents. Furthermore, we extend our outer bound on the DoF region to the\ngeneral $k$-user MISO BC, and demonstrate that it leads to an approximate\ncharacterization of linear sum-DoF to within an additive gap of $0.5$ for a\nbroad range of CSIT configurations. Moreover, for the special case where only\none receiver supplies delayed CSIT, we completely characterize the linear\nsum-DoF. \n\n"}
{"id": "1504.04950", "contents": "Title: Algorithmic statistics revisited Abstract: The mission of statistics is to provide adequate statistical hypotheses\n(models) for observed data. But what is an \"adequate\" model? To answer this\nquestion, one needs to use the notions of algorithmic information theory. It\nturns out that for every data string $x$ one can naturally define\n\"stochasticity profile\", a curve that represents a trade-off between complexity\nof a model and its adequacy. This curve has four different equivalent\ndefinitions in terms of (1)~randomness deficiency, (2)~minimal description\nlength, (3)~position in the lists of simple strings and (4)~Kolmogorov\ncomplexity with decompression time bounded by busy beaver function. We present\na survey of the corresponding definitions and results relating them to each\nother. \n\n"}
{"id": "1504.05294", "contents": "Title: On Approximating the Sum-Rate for Multiple-Unicasts Abstract: We study upper bounds on the sum-rate of multiple-unicasts. We approximate\nthe Generalized Network Sharing Bound (GNS cut) of the multiple-unicasts\nnetwork coding problem with $k$ independent sources. Our approximation\nalgorithm runs in polynomial time and yields an upper bound on the joint source\nentropy rate, which is within an $O(\\log^2 k)$ factor from the GNS cut. It\nfurther yields a vector-linear network code that achieves joint source entropy\nrate within an $O(\\log^2 k)$ factor from the GNS cut, but \\emph{not} with\nindependent sources: the code induces a correlation pattern among the sources.\n  Our second contribution is establishing a separation result for vector-linear\nnetwork codes: for any given field $\\mathbb{F}$ there exist networks for which\nthe optimum sum-rate supported by vector-linear codes over $\\mathbb{F}$ for\nindependent sources can be multiplicatively separated by a factor of\n$k^{1-\\delta}$, for any constant ${\\delta>0}$, from the optimum joint entropy\nrate supported by a code that allows correlation between sources. Finally, we\nestablish a similar separation result for the asymmetric optimum vector-linear\nsum-rates achieved over two distinct fields $\\mathbb{F}_{p}$ and\n$\\mathbb{F}_{q}$ for independent sources, revealing that the choice of field\ncan heavily impact the performance of a linear network code. \n\n"}
{"id": "1504.05526", "contents": "Title: Secret Key Generation with One Communicator and a One-Shot Converse via\n  Hypercontractivity Abstract: A new model of multi-party secret key agreement is proposed, in which one\nterminal called the communicator can transmit public messages to other\nterminals before all terminals agree on a secret key. A single-letter\ncharacterization of the achievable region is derived in the stationary\nmemoryless case. The new model generalizes some other (old and new) models of\nkey agreement. In particular, key generation with an omniscient helper is the\nspecial case where the communicator knows all sources, for which we derive a\nzero-rate one-shot converse for the secret key per bit of communication. \n\n"}
{"id": "1504.05538", "contents": "Title: Joint Source-Channel Secrecy Using Hybrid Coding Abstract: The secrecy performance of a source-channel model is studied in the context\nof lossy source compression over a noisy broadcast channel. The source is\ncausally revealed to the eavesdropper during decoding. The fidelity of the\ntransmission to the legitimate receiver and the secrecy performance at the\neavesdropper are both measured by a distortion metric. Two achievability\nschemes using the technique of hybrid coding are analyzed and compared with an\noperationally separate source-channel coding scheme. A numerical example is\nprovided and the comparison results show that the hybrid coding schemes\noutperform the operationally separate scheme. \n\n"}
{"id": "1504.05628", "contents": "Title: Key Rate of the B92 Quantum Key Distribution Protocol with Finite Qubits Abstract: The key rate of the B92 quantum key distribution protocol had not been\nreported before this research when the number of qubits is finite. We compute\nit by using the security analysis framework proposed by Scarani and Renner in\n2008. \n\n"}
{"id": "1504.05764", "contents": "Title: The $\\kappa$-$\\mu$ Shadowed Fading Model: Unifying the $\\kappa$-$\\mu$\n  and $\\eta$-$\\mu$ Distributions Abstract: This paper shows that the recently proposed $\\kappa$-$\\mu$ shadowed fading\nmodel includes, besides the $\\kappa$-$\\mu$ model, the $\\eta$-$\\mu$ fading model\nas a particular case. This has important relevance in practice, as it allows\nfor the unification of these popular fading distributions through a more\ngeneral, yet equally tractable, model. The convenience of new underlying\nphysical models is discussed. Then, we derive simple and novel closed-form\nexpressions for the asymptotic ergodic capacity in $\\kappa$-$\\mu$ shadowed\nfading channels, which illustrate the effects of the different fading\nparameters on the system performance. By exploiting the unification here\nunveiled, the asymptotic capacity expressions for the $\\kappa$-$\\mu$ and\n$\\eta$-$\\mu$ fading models are also obtained in closed-form as special cases. \n\n"}
{"id": "1504.06249", "contents": "Title: Quantifying Loss of Information in Network-based Dimensionality\n  Reduction Techniques Abstract: To cope with the complexity of large networks, a number of dimensionality\nreduction techniques for graphs have been developed. However, the extent to\nwhich information is lost or preserved when these techniques are employed has\nnot yet been clear. Here we develop a framework, based on algorithmic\ninformation theory, to quantify the extent to which information is preserved\nwhen network motif analysis, graph spectra and spectral sparsification methods\nare applied to over twenty different biological and artificial networks. We\nfind that the spectral sparsification is highly sensitive to high number of\nedge deletion, leading to significant inconsistencies, and that graph spectral\nmethods are the most irregular, capturing algebraic information in a condensed\nfashion but largely losing most of the information content of the original\nnetworks. However, the approach shows that network motif analysis excels at\npreserving the relative algorithmic information content of a network, hence\nvalidating and generalizing the remarkable fact that despite their inherent\ncombinatorial possibilities, local regularities preserve information to such an\nextent that essential properties are fully recoverable across different\nnetworks to determine their family group to which they belong to (eg genetic vs\nsocial network). Our algorithmic information methodology thus provides a\nrigorous framework enabling a fundamental assessment and comparison between\ndifferent data dimensionality reduction methods thereby facilitating the\nidentification and evaluation of the capabilities of old and new methods. \n\n"}
{"id": "1504.06746", "contents": "Title: Massive MIMO Full-Duplex Relaying with Optimal Power Allocation for\n  Independent Multipairs Abstract: With the help of an in-band full-duplex relay station, it is possible to\nsimultaneously transmit and receive signals from multiple users. The\nperformance of such system can be greatly increased when the relay station is\nequipped with a large number of antennas on both transmitter and receiver\nsides. In this paper, we exploit the use of massive arrays to effectively\nsuppress the loopback interference (LI) of a decode-and-forward relay (DF) and\nevaluate the performance of the end-to-end (e2e) transmission. This paper\nassumes imperfect channel state information is available at the relay and\ndesigns a minimum mean-square error (MMSE) filter to mitigate the interference.\nSubsequently, we adopt zero-forcing (ZF) filters for both detection and\nbeamforming. The performance of such system is evaluated in terms of bit error\nrate (BER) at both relay and destinations, and an optimal choice for the\ntransmission power at the relay is shown. We then propose a complexity\nefficient optimal power allocation (OPA) algorithm that, using the channel\nstatistics, computes the minimum power that satisfies the rate constraints of\neach pair. The results obtained via simulation show that when both MMSE\nfiltering and OPA method are used, better values for the energy efficiency are\nattained. \n\n"}
{"id": "1505.00178", "contents": "Title: Shortened regenerating codes Abstract: For general exact repair regenerating codes, the optimal trade-offs between\nstorage size and repair bandwith remain undetermined. Various outer bounds and\npartial results have been proposed. Using a simple chain rule argument we\nidentify nonnegative differences between the functional repair and the exact\nrepair outer bounds. One of the differences is then bounded from below by the\nrepair data of a shortened subcode. Our main result is a new outer bound for an\nexact repair regenerating code in terms of its shortened subcodes. In general\nthe new outer bound is implicit and depends on the choice of shortened\nsubcodes. For the linear case we obtain explicit bounds. \n\n"}
{"id": "1505.00919", "contents": "Title: Constructions of High-Rate MSR Codes over Small Fields Abstract: A novel technique for construction of minimum storage regenerating (MSR)\ncodes is presented. Based on this technique, three explicit constructions of\nMSR codes are given. The first two constructions provide access-optimal MSR\ncodes, with two and three parities, respectively, which attain the\nsub-packetization bound for access-optimal codes. The third construction\nprovides longer MSR codes with three parities, which are not access-optimal,\nand do not necessarily attain the sub-packetization bound.\n  In addition to a minimum storage in a node, all three constructions allow the\nentire data to be recovered from a minimal number of storage nodes. That is,\ngiven storage $\\ell$ in each node, the entire stored data can be recovered from\nany $2\\log_2 \\ell$ for 2 parity nodes, and either $3\\log_3\\ell$ or\n$4\\log_3\\ell$ for 3 parity nodes. Second, in the first two constructions, a\nhelper node accesses the minimum number of its symbols for repair of a failed\nnode (access-optimality). The generator matrix of these codes is based on\nperfect matchings of complete graphs and hypergraphs, and on a rational\ncanonical form of matrices. The goal of this paper is to provide a construction\nof such optimal codes over the smallest possible finite fields. For two\nparities, the field size is reduced by a factor of two for access-optimal codes\ncompared to previous constructions. For three parities, in the first\nconstruction the field size is $6\\log_3 \\ell+1$ (or $3\\log_3 \\ell+1$ for fields\nwith characteristic 2), and in the second construction the field size is\nlarger, yet linear in $\\log_3\\ell$. Both constructions with 3 parities provide\na significant improvement over existing previous works, since only non-explicit\nconstructions with exponential field size (in $\\log_3\\ell$) were known so far. \n\n"}
{"id": "1505.01133", "contents": "Title: Outer Bounds on the Admissible Source Region for Broadcast Channels with\n  Correlated Sources Abstract: Two outer bounds on the admissible source region for broadcast channels with\ncorrelated sources are presented: the first one is strictly tighter than the\nexisting outer bound by Gohari and Anantharam while the second one provides a\ncomplete characterization of the admissible source region in the case where the\ntwo sources are conditionally independent given the common part. These outer\nbounds are deduced from the general necessary conditions established for the\nlossy source broadcast problem via suitable comparisons between the virtual\nbroadcast channel (induced by the source and the reconstructions) and the\nphysical broadcast channel. \n\n"}
{"id": "1505.01858", "contents": "Title: Energy Efficiency and Sum Rate when Massive MIMO meets Device-to-Device\n  Communication Abstract: This paper considers a scenario of short-range communication, known as\ndevice-to-device (D2D) communication, where D2D users reuse the downlink\nresources of a cellular network to transmit directly to their corresponding\nreceivers. In addition, multiple antennas at the base station (BS) are used in\norder to simultaneously support multiple cellular users using multiuser or\nmassive MIMO. The network model considers a fixed number of cellular users and\nthat D2D users are distributed according to a homogeneous Poisson point process\n(PPP). Two metrics are studied, namely, average sum rate (ASR) and energy\nefficiency (EE). We derive tractable expressions and study the tradeoffs\nbetween the ASR and EE as functions of the number of BS antennas and density of\nD2D users for a given coverage area. \n\n"}
{"id": "1505.02141", "contents": "Title: Error Performance Analysis of FSO Links with Equal Gain Diversity\n  Receivers over Double Generalized Gamma Fading Channels Abstract: Free space optical (FSO) communication has been receiving increasing\nattention in recent years with its ability to achieve ultra-high data rates\nover unlicensed optical spectrum. A major performance limiting factor in FSO\nsystems is atmospheric turbulence which severely degrades the system\nperformance. To address this issue, multiple transmit and/or receive apertures\ncan be employed, and the performance can be improved via diversity gain. In\nthis paper, we investigate the bit error rate (BER) performance of FSO systems\nwith transmit diversity or receive diversity with equal gain combining (EGC)\nover atmospheric turbulence channels described by the Double Generalized Gamma\n(Double GG) distribution. The Double GG distribution, recently proposed,\ngeneralizes many existing turbulence models in a closed-form expression and\ncovers all turbulence conditions. Since the distribution function of a sum of\nDouble GG random variables (RVs) appears in BER expression, we first derive a\nclosed-form upper bound for the distribution of the sum of Double GG\ndistributed RVs. A novel union upper bound for the average BER as well as\ncorresponding asymptotic expression is then derived and evaluated in terms of\nMeijer's G-functions. \n\n"}
{"id": "1505.02862", "contents": "Title: A Numerical Study on the Wiretap Network with a Simple Network Topology Abstract: In this paper, we study a security problem on a simple wiretap network,\nconsisting of a source node S, a destination node D, and an intermediate node\nR. The intermediate node connects the source and the destination nodes via a\nset of noiseless parallel channels, with sizes $n_1$ and $n_2$, respectively. A\nmessage $M$ is to be sent from S to D. The information in the network may be\neavesdropped by a set of wiretappers. The wiretappers cannot communicate with\none another. Each wiretapper can access a subset of channels, called a wiretap\nset. All the chosen wiretap sets form a wiretap pattern. A random key $K$ is\ngenerated at S and a coding scheme on $(M, K)$ is employed to protect $M$. We\ndefine two decoding classes at D: In Class-I, only $M$ is required to be\nrecovered and in Class-II, both $M$ and $K$ are required to be recovered. The\nobjective is to minimize $H(K)/H(M)$ {for a given wiretap pattern} under the\nperfect secrecy constraint. The first question we address is whether routing is\noptimal on this simple network. By enumerating all the wiretap patterns on the\nClass-I/II $(3,3)$ networks and harnessing the power of Shannon-type\ninequalities, we find that gaps exist between the bounds implied by routing and\nthe bounds implied by Shannon-type inequalities for a small fraction~($<2\\%$)\nof all the wiretap patterns. The second question we investigate is the\nfollowing: What is $\\min H(K)/H(M)$ for the remaining wiretap patterns where\ngaps exist? We study some simple wiretap patterns and find that their Shannon\nbounds (i.e., the lower bound induced by Shannon-type inequalities) can be\nachieved by linear codes, which means routing is not sufficient even for the\n($3$, $3$) network. For some complicated wiretap patterns, we study the\nstructures of linear coding schemes under the assumption that they can achieve\nthe corresponding Shannon bounds.... \n\n"}
{"id": "1505.02992", "contents": "Title: Large-Scale MIMO Relaying Techniques for Physical Layer Security: AF or\n  DF? Abstract: In this paper, we consider a large scale multiple input multiple output\n(LS-MIMO) relaying system, where an information source sends the message to its\nintended destination aided by an LS-MIMO relay, while a passive eavesdropper\ntries to intercept the information forwarded by the relay. The advantage of a\nlarge scale antenna array is exploited to improve spectral efficiency and\nenhance wireless security. In particular, the challenging issue incurred by\nshort-distance interception is well addressed. Under very practical\nassumptions, i.e., no eavesdropper channel state information (CSI) and\nimperfect legitimate CSI at the relay, this paper gives a thorough secrecy\nperformance analysis and comparison of two classic relaying techniques, i.e.,\namplify-and-forward (AF) and decode-and-forward (DF). Furthermore, asymptotical\nanalysis is carried out to provide clear insights on the secrecy performance\nfor such an LS-MIMO relaying system. We show that under large transmit powers,\nAF is a better choice than DF from the perspectives of both secrecy performance\nand implementation complexity, and prove that there exits an optimal transmit\npower at medium regime that maximizes the secrecy outage capacity. \n\n"}
{"id": "1505.03898", "contents": "Title: Pinball Loss Minimization for One-bit Compressive Sensing: Convex Models\n  and Algorithms Abstract: The one-bit quantization is implemented by one single comparator that\noperates at low power and a high rate. Hence one-bit compressive sensing\n(1bit-CS) becomes attractive in signal processing. When measurements are\ncorrupted by noise during signal acquisition and transmission, 1bit-CS is\nusually modeled as minimizing a loss function with a sparsity constraint. The\none-sided $\\ell_1$ loss and the linear loss are two popular loss functions for\n1bit-CS. To improve the decoding performance on noisy data, we consider the\npinball loss, which provides a bridge between the one-sided $\\ell_1$ loss and\nthe linear loss. Using the pinball loss, two convex models, an elastic-net\npinball model and its modification with the $\\ell_1$-norm constraint, are\nproposed. To efficiently solve them, the corresponding dual coordinate ascent\nalgorithms are designed and their convergence is proved. The numerical\nexperiments confirm the effectiveness of the proposed algorithms and the\nperformance of the pinball loss minimization for 1bit-CS. \n\n"}
{"id": "1505.05290", "contents": "Title: Sparsest Error Detection via Sparsity Invariant Transformation based\n  $\\ell_1$ Minimization Abstract: This paper presents a new method, referred to here as the sparsity invariant\ntransformation based $\\ell_1$ minimization, to solve the $\\ell_0$ minimization\nproblem for an over-determined linear system corrupted by additive sparse\nerrors with arbitrary intensity. Many previous works have shown that $\\ell_1$\nminimization can be applied to realize sparse error detection in many\nover-determined linear systems. However, performance of this approach is\nstrongly dependent on the structure of the measurement matrix, which limits\napplication possibility in practical problems. Here, we present a new approach\nbased on transforming the $\\ell_0$ minimization problem by a linear\ntransformation that keeps sparsest solutions invariant. We call such a property\na sparsity invariant property (SIP), and a linear transformation with SIP is\nreferred to as a sparsity invariant transformation (SIT). We propose the\nSIT-based $\\ell_1$ minimization method by using an SIT in conjunction with\n$\\ell_1$ relaxation on the $\\ell_0$ minimization problem. We prove that for any\nover-determined linear system, there always exists a specific class of SIT's\nthat guarantees a solution to the SIT-based $\\ell_1$ minimization is a\nsparsest-errors solution. Besides, a randomized algorithm based on Monte Carlo\nsimulation is proposed to search for a feasible SIT. \n\n"}
{"id": "1505.05291", "contents": "Title: Structure dependent sampling in compressed sensing: theoretical\n  guarantees for tight frames Abstract: Many of the applications of compressed sensing have been based on variable\ndensity sampling, where certain sections of the sampling coefficients are\nsampled more densely. Furthermore, it has been observed that these sampling\nschemes are dependent not only on sparsity but also on the sparsity structure\nof the underlying signal. This paper extends the result of (Adcock, Hansen,\nPoon and Roman, arXiv:1302.0561, 2013) to the case where the sparsifying system\nforms a tight frame. By dividing the sampling coefficients into levels, our\nmain result will describe how the amount of subsampling in each level is\ndetermined by the local coherences between the sampling and sparsifying\noperators and the localized level sparsities -- the sparsity in each level\nunder the sparsifying operator. \n\n"}
{"id": "1505.05428", "contents": "Title: Simplex and MacDonald Codes over $R_{q}$ Abstract: In this paper, we introduce the homogeneous weight and homogeneous Gray map\nover the ring $R_{q}=\\mathbb{F}_{2}[u_{1},u_{2},\\ldots,u_{q}]/\\left\\langle\nu_{i}^{2}=0,u_{i}u_{j}=u_{j}u_{i}\\right\\rangle$ for $q \\geq 2$. We also\nconsider the construction of simplex and MacDonald codes of types $\\alpha$ and\n$\\beta$ over this ring. \n\n"}
{"id": "1505.07493", "contents": "Title: Duality Preserving Gray Maps for Codes over Rings Abstract: Given a finite ring $A$ which is a free left module over a subring $R$ of\n$A$, two types of $R$-bases, pseudo-self-dual bases (similar to trace\northogonal bases) and symmetric bases, are defined which in turn are used to\ndefine duality preserving maps from codes over $A$ to codes over $R$. Both\ntypes of bases are generalizations of similar concepts for fields. Many\nillustrative examples are given to shed light on the advantages to such\nmappings as well as their abundance. \n\n"}
{"id": "1505.07534", "contents": "Title: Impact of Multipath Reflections on the Performance of Indoor Visible\n  Light Positioning Systems Abstract: Visible light communication (VLC) using light-emitting-diodes (LEDs) has been\na popular research area recently. VLC can provide a practical solution for\nindoor positioning. In this paper, the impact of multipath reflections on\nindoor VLC positioning is investigated, considering a complex indoor\nenvironment with walls, floor and ceiling. For the proposed positioning system,\nan LED bulb is the transmitter and a photo-diode (PD) is the receiver to detect\nreceived signal strength (RSS) information. Combined deterministic and modified\nMonte Carlo (CDMMC) method is applied to compute the impulse response of the\noptical channel. Since power attenuation is applied to calculate the distance\nbetween the transmitter and receiver, the received power from each reflection\norder is analyzed. Finally, the positioning errors are estimated for all the\nlocations over the room and compared with the previous works where no\nreflections considered. Three calibration approaches are proposed to decrease\nthe effect of multipath reflections. \n\n"}
{"id": "1506.00034", "contents": "Title: Bracketing numbers of convex and $m$-monotone functions on polytopes Abstract: We study bracketing covering numbers for spaces of bounded convex functions\nin the $L_p$ norms. Bracketing numbers are crucial quantities for understanding\nasymptotic behavior for many statistical nonparametric estimators. Bracketing\nnumber upper bounds in the supremum distance are known for bounded classes that\nalso have a fixed Lipschitz constraint. However, in most settings of interest,\nthe classes that arise do not include Lipschitz constraints, and so standard\ntechniques based on known bracketing numbers cannot be used. In this paper, we\nfind upper bounds for bracketing numbers of classes of convex functions without\nLipschitz constraints on arbitrary polytopes. Our results are of particular\ninterest in many multidimensional estimation problems based on convexity shape\nconstraints.\n  Additionally, we show other applications of our proof methods; in particular\nwe define a new class of multivariate functions, the so-called $m$-monotone\nfunctions. Such functions have been considered mathematically and statistically\nin the univariate case but never in the multivariate case. We show how our\nproof for convex bracketing upper bounds also applies to the $m$-monotone case. \n\n"}
{"id": "1506.00231", "contents": "Title: Channel Equalization and Beamforming for Quaternion-Valued Wireless\n  Communication Systems Abstract: Quaternion-valued wireless communication systems have been studied in the\npast. Although progress has been made in this promising area, a crucial missing\nlink is lack of effective and efficient quaternion-valued signal processing\nalgorithms for channel equalization and beamforming. With most recent\ndevelopments in quaternion-valued signal processing, in this work, we fill the\ngap to solve the problem by studying two quaternion-valued adaptive algorithms:\none is the reference signal based quaternion-valued least mean square (QLMS)\nalgorithm and the other one is the quaternion-valued constant modulus algorithm\n(QCMA). The quaternion-valued Wiener solution for possible block-based\ncalculation is also derived. Simulation results are provided to show the\nworking of the system. \n\n"}
{"id": "1506.01051", "contents": "Title: Energy-Efficient Future Wireless Networks: A Marriage between Massive\n  MIMO and Small Cells Abstract: How would a cellular network designed for high energy efficiency look like?\nTo answer this fundamental question, we model cellular networks using\nstochastic geometry and optimize the energy efficiency with respect to the\ndensity of base stations, the number of antennas and users per cell, the\ntransmit power levels, and the pilot reuse. The highest efficiency is neither\nachieved by a pure small-cell approach, nor by a pure massive MIMO solution.\nInterestingly, it is the combination of these approaches that provides the\nhighest energy efficiency; small cells contributes by reducing the propagation\nlosses while massive MIMO enables multiplexing of users with controlled\ninterference. \n\n"}
{"id": "1506.04444", "contents": "Title: Transformed Schatten-1 Iterative Thresholding Algorithms for Low Rank\n  Matrix Completion Abstract: We study a non-convex low-rank promoting penalty function, the transformed\nSchatten-1 (TS1), and its applications in matrix completion. The TS1 penalty,\nas a matrix quasi-norm defined on its singular values, interpolates the rank\nand the nuclear norm through a nonnegative parameter a. We consider the\nunconstrained TS1 regularized low-rank matrix recovery problem and develop a\nfixed point representation for its global minimizer. The TS1 thresholding\nfunctions are in closed analytical form for all parameter values. The TS1\nthreshold values differ in subcritical (supercritical) parameter regime where\nthe TS1 threshold functions are continuous (discontinuous). We propose TS1\niterative thresholding algorithms and compare them with some state-of-the-art\nalgorithms on matrix completion test problems. For problems with known rank, a\nfully adaptive TS1 iterative thresholding algorithm consistently performs the\nbest under different conditions with ground truth matrix being multivariate\nGaussian at varying covariance. For problems with unknown rank, TS1 algorithms\nwith an additional rank estimation procedure approach the level of IRucL-q\nwhich is an iterative reweighted algorithm, non-convex in nature and best in\nperformance. \n\n"}
{"id": "1506.04822", "contents": "Title: Some Improvements on Locally Repairable Codes Abstract: The locally repairable codes (LRCs) were introduced to correct erasures\nefficiently in distributed storage systems. LRCs are extensively studied\nrecently.\n  In this paper, we first deal with the open case remained in \\cite{q} and\nderive an improved upper bound for the minimum distances of LRCs. We also give\nan explicit construction for LRCs attaining this bound. Secondly, we consider\nthe constructions of LRCs with any locality and availability which have high\ncode rate and minimum distance as large as possible. We give a graphical model\nfor LRCs. By using the deep results from graph theory, we construct a family of\nLRCs with any locality $r$ and availability $2$ with code rate\n$\\frac{r-1}{r+1}$ and optimal minimum distance $O(\\log n)$ where $n$ is the\nlength of the code. \n\n"}
{"id": "1506.04830", "contents": "Title: Maximizing the Link Throughput between Smart-meters and Aggregators as\n  Secondary Users under Power and Outage Constraints Abstract: This paper assesses the communication link from smart meters to aggregators\nas (unlicensed) secondary users that transmit their data over the (licensed)\nprimary uplink channel. The proposed scenario assumes: (i) meters' and\naggregators' positions are fixed so highly directional antennas are employed,\n(ii) secondary users transmit with limited power in relation to the primary,\n(iii) meters' transmissions are coordinated to avoid packet collisions, and\n(iv) the secondary links' robustness is guaranteed by an outage constraint.\nUnder these assumptions, the interference caused by secondary users in both\nprimary (base-stations) and other secondary users can be neglected. As\nunlicensed users, however, meter-aggregator links do experience interference\nfrom the mobile users of the primary network, whose positions and traffic\nactivity are unknown. To cope with this uncertainty, we model the mobile users\nspatial distribution as a Poisson point process. We then derive a closed-form\nsolution for the maximum achievable throughput with respect to a reference\nsecondary link subject to transmit power and outage constraints. Our numerical\nresults illustrate the effects of such constraints on the optimal throughput,\nevincing that more frequent outage events improve the system performance in the\nscenario under study. We also show that relatively high outage probabilities\nhave little effect on the reconstruction of the average power demand curve that\nis transmitted from the smart-meter to the aggregator. \n\n"}
{"id": "1506.06479", "contents": "Title: The Classical-Quantum Channel with Random State Parameters Known to the\n  Sender Abstract: We study an analog of the well-known Gel'fand Pinsker Channel which uses\nquantum states for the transmission of the data. We consider the case where\nboth the sender's inputs to the channel and the channel states are to be taken\nfrom a finite set (cq-channel with state information at the sender). We\ndistinguish between causal and non-causal channel state information at the\nsender. The receiver remains ignorant, throughout. We give a single-letter\ndescription of the capacity in the first case. In the second case we present\ntwo different regularized expressions for the capacity. It is an astonishing\nand unexpected result of our work that a simple change from causal to\nnon-causal channel state information at the encoder causes the complexity of a\nnumerical computation of the capacity formula to change from trivial to\nseemingly difficult. Still, even the non-single letter formula allows one to\ndraw nontrivial conclusions, for example regarding continuity of the capacity\nwith respect to changes in the system parameters. The direct parts of both\ncoding theorems are based on a special class of POVMs which are derived from\northogonal projections onto certain representations of the symmetric groups.\nThis approach supports a reasoning that is inspired by the classical method of\ntypes. In combination with the non-commutative union bound these POVMs yield an\nelegant method of proof for the direct part of the coding theorem in the first\ncase. \n\n"}
{"id": "1507.00091", "contents": "Title: Capacity of Coded Index Modulation Abstract: We consider the special case of index coding over the Gaussian broadcast\nchannel where each receiver has prior knowledge of a subset of messages at the\ntransmitter and demands all the messages from the source. We propose a\nconcatenated coding scheme for this problem, using an index code for the\nGaussian channel as an inner code/modulation to exploit side information at the\nreceivers, and an outer code to attain coding gain against the channel noise.\nWe derive the capacity region of this scheme by viewing the resulting channel\nas a multiple-access channel with many receivers, and relate it to the 'side\ninformation gain' -- which is a measure of the advantage of a code in utilizing\nreceiver side information -- of the inner index code/modulation. We demonstrate\nthe utility of the proposed architecture by simulating the performance of an\nindex code/modulation concatenated with an off-the-shelf convolutional code\nthrough bit-interleaved coded-modulation. \n\n"}
{"id": "1507.01255", "contents": "Title: Universal Decoding for Source-Channel Coding with Side Information Abstract: We consider a setting of Slepian--Wolf coding, where the random bin of the\nsource vector undergoes channel coding, and then decoded at the receiver, based\non additional side information, correlated to the source. For a given\ndistribution of the randomly selected channel codewords, we propose a universal\ndecoder that depends on the statistics of neither the correlated sources nor\nthe channel, assuming first that they are both memoryless. Exact analysis of\nthe random-binning/random-coding error exponent of this universal decoder shows\nthat it is the same as the one achieved by the optimal maximum a-posteriori\n(MAP) decoder. Previously known results on universal Slepian-Wolf source\ndecoding, universal channel decoding, and universal source-channel decoding,\nare all obtained as special cases of this result. Subsequently, we further\ngeneralize the results in several directions, including: (i) finite-state\nsources and finite-state channels, along with a universal decoding metric that\nis based on Lempel-Ziv parsing, (ii) arbitrary sources and channels, where the\nuniversal decoding is with respect to a given class of decoding metrics, and\n(iii) full (symmetric) Slepian-Wolf coding, where both source streams are\nseparately fed into random-binning source encoders, followed by random channel\nencoders, which are then jointly decoded by a universal decoder. \n\n"}
{"id": "1507.01757", "contents": "Title: Effect of LOS/NLOS Propagation on Ultra-Dense Networks Abstract: This paper aims at investigating the achievable performance and the issues\nthat arise in ultra-dense networks (UDNs), when the signal propagation includes\nboth the Line-of-Sight (LOS) and Non-Line-Of-Sight (NLOS) components. Backed by\nan analytical stochastic geometry-based model, we study the coverage, the Area\nSpectral Efficiency (ASE) and the energy efficiency of UDNs with LOS/NLOS\npropagation. We show that when LOS/NLOS propagation components are accounted\nfor, the network suffers from low coverage and the ASE gain is lower than\nlinear at high base station densities. However, this performance drop can\npartially be attenuated by means of frequency reuse, which is shown to improve\nthe ASE vs coverage trade-off of cell densification, provided that we have a\ndegree of freedom on the density of cells. In addition, from an energy\nefficiency standpoint, cell densification is shown to be inefficient when both\nLOS and NLOS components are taken into account. Overall, based on the findings\nof our work that assumes a more advanced system model compared to the current\nstate-of-the-art, we claim that highly crowded environments of users represent\nthe worst case scenario for ultra-dense networks. Namely, these are likely to\nface serious issues in terms of limited coverage. \n\n"}
{"id": "1507.02796", "contents": "Title: Locally Repairable Codes with Functional Repair and Multiple Erasure\n  Tolerance Abstract: We consider the problem of designing [n; k] linear codes for distributed\nstorage systems (DSS) that satisfy the (r, t)-Local Repair Property, where any\nt'(<=t) simultaneously failed nodes can be locally repaired, each with locality\nr. The parameters n, k, r, t are positive integers such that r<k<n and t <=\nn-k. We consider the functional repair model and the sequential approach for\nrepairing multiple failed nodes. By functional repair, we mean that the packet\nstored in each newcomer is not necessarily an exact copy of the lost data but a\nsymbol that keep the (r, t)-local repair property. By the sequential approach,\nwe mean that the t' newcomers are ordered in a proper sequence such that each\nnewcomer can be repaired from the live nodes and the newcomers that are ordered\nbefore it. Such codes, which we refer to as (n, k, r, t)-functional locally\nrepairable codes (FLRC), are the most general class of LRCs and contain several\nsubclasses of LRCs reported in the literature.\n  In this paper, we aim to optimize the storage overhead (equivalently, the\ncode rate) of FLRCs. We derive a lower bound on the code length n given t\nbelongs to {2,3} and any possible k, r. For t=2, our bound generalizes the rate\nbound proved in [14]. For t=3, our bound improves the rate bound proved in\n[10]. We also give some onstructions of exact LRCs for t belongs to {2,3} whose\nlength n achieves the bound of (n, k, r, t)-FLRC, which proves the tightness of\nour bounds and also implies that there is no gap between the optimal code\nlength of functional LRCs and exact LRCs for certain sets of parameters.\nMoreover, our constructions are over the binary field, hence are of interest in\npractice. \n\n"}
{"id": "1507.03418", "contents": "Title: Explicit Construction of AG Codes from Generalized Hermitian Curves Abstract: We present multi-point algebraic geometric codes overstepping the\nGilbert-Varshamov bound. The construction is based on the generalized Hermitian\ncurve introduced by A. Bassa, P. Beelen, A. Garcia, and H. Stichtenoth. These\ncodes are described in detail by constrcting a generator matrix. It turns out\nthat these codes have nice properties similar to those of Hermitian codes. It\nis shown that the duals are also such codes and an explicit formula is given. \n\n"}
{"id": "1507.04452", "contents": "Title: Near Maximum-Likelihood Detector and Channel Estimator for Uplink\n  Multiuser Massive MIMO Systems with One-Bit ADCs Abstract: In massive multiple-input multiple-output (MIMO) systems, it may not be power\nefficient to have a high-resolution analog-to-digital converter (ADC) for each\nantenna element. In this paper, a near maximum likelihood (nML) detector for\nuplink multiuser massive MIMO systems is proposed where each antenna is\nconnected to a pair of one-bit ADCs, i.e., one for each real and imaginary\ncomponent of the baseband signal. The exhaustive search over all the possible\ntransmitted vectors required in the original maximum likelihood (ML) detection\nproblem is relaxed to formulate an ML estimation problem. Then, the ML\nestimation problem is converted into a convex optimization problem which can be\nefficiently solved. Using the solution, the base station can perform simple\nsymbol-by-symbol detection for the transmitted signals from multiple users. To\nfurther improve detection performance, we also develop a two-stage nML detector\nthat exploits the structures of both the original ML and the proposed\n(one-stage) nML detectors. Numerical results show that the proposed nML\ndetectors are efficient enough to simultaneously support multiple uplink users\nadopting higher-order constellations, e.g., 16 quadrature amplitude modulation.\nSince our detectors exploit the channel state information as part of the\ndetection, an ML channel estimation technique with one-bit ADCs that shares the\nsame structure with our proposed nML detector is also developed. The proposed\ndetectors and channel estimator provide a complete low power solution for the\nuplink of a massive MIMO system. \n\n"}
{"id": "1507.05379", "contents": "Title: Hodge Laplacians on graphs Abstract: This is an elementary introduction to the Hodge Laplacian on a graph, a\nhigher-order generalization of the graph Laplacian. We will discuss basic\nproperties including cohomology and Hodge theory. The main feature of our\napproach is simplicity, requiring only knowledge of linear algebra and graph\ntheory. We have also isolated the algebra from the topology to show that a\nlarge part of cohomology and Hodge theory is nothing more than the linear\nalgebra of matrices satisfying $AB = 0$. For the remaining topological aspect,\nwe cast our discussions entirely in terms of graphs as opposed to less-familiar\ntopological objects like simplicial complexes. \n\n"}
{"id": "1507.06038", "contents": "Title: Quantum data hiding in the presence of noise Abstract: When classical or quantum information is broadcast to separate receivers,\nthere exist codes that encrypt the encoded data such that the receivers cannot\nrecover it when performing local operations and classical communication, but\nthey can decode reliably if they bring their systems together and perform a\ncollective measurement. This phenomenon is known as quantum data hiding and\nhitherto has been studied under the assumption that noise does not affect the\nencoded systems. With the aim of applying the quantum data hiding effect in\npractical scenarios, here we define the data-hiding capacity for hiding\nclassical information using a quantum channel. Using this notion, we establish\na regularized upper bound on the data hiding capacity of any quantum broadcast\nchannel, and we prove that coherent-state encodings have a strong limitation on\ntheir data hiding rates. We then prove a lower bound on the data hiding\ncapacity of channels that map the maximally mixed state to the maximally mixed\nstate (we call these channels \"mictodiactic\"---they can be seen as a\ngeneralization of unital channels when the input and output spaces are not\nnecessarily isomorphic) and argue how to extend this bound to generic channels\nand to more than two receivers. \n\n"}
{"id": "1507.07267", "contents": "Title: Network MIMO with Partial Cooperation between Radar and Cellular Systems Abstract: To meet the growing spectrum demands, future cellular systems are expected to\nshare the spectrum of other services such as radar. In this paper, we consider\na network multiple-input multiple-output (MIMO) with partial cooperation model\nwhere radar stations cooperate with cellular base stations (BS)s to deliver\nmessages to intended mobile users. So the radar stations act as BSs in the\ncellular system. However, due to the high power transmitted by radar stations\nfor detection of far targets, the cellular receivers could burnout when\nreceiving these high radar powers. Therefore, we propose a new projection\nmethod called small singular values space projection (SSVSP) to mitigate these\nharmful high power and enable radar stations to collaborate with cellular base\nstations. In addition, we formulate the problem into a MIMO interference\nchannel with general constraints (MIMO-IFC-GC). Finally, we provide a solution\nto minimize the weighted sum mean square error minimization problem (WSMMSE)\nwith enforcing power constraints on both radar and cellular stations. \n\n"}
{"id": "1507.07290", "contents": "Title: A Mixed-ADC Receiver Architecture for Massive MIMO Systems Abstract: Motivated by the demand for energy-efficient communication solutions in the\nnext generation cellular network, a mixed-ADC receiver architecture for massive\nmultiple input multiple output (MIMO) systems is proposed, which differs from\nprevious works in that herein one-bit analog-to-digital converters (ADCs)\npartially replace the conventionally assumed high-resolution ADCs. The\ninformation-theoretic tool of generalized mutual information (GMI) is exploited\nto analyze the achievable data rates of the proposed system architecture and an\narray of analytical results of engineering interest are obtained. For\ndeterministic single input multiple output (SIMO) channels, a closed-form\nexpression of the GMI is derived, based on which the linear combiner is\noptimized. Then, the asymptotic behaviors of the GMI in both low and high SNR\nregimes are explored, and the analytical results suggest a plausible ADC\nassignment scheme. Finally, the analytical framework is applied to the\nmulti-user access scenario, and the corresponding numerical results demonstrate\nthat the mixed system architecture with a relatively small number of\nhigh-resolution ADCs is able to achieve a large fraction of the channel\ncapacity without output quantization. \n\n"}
{"id": "1508.00168", "contents": "Title: Completion Time in Two-user Channels: An Information-Theoretic\n  Perspective Abstract: In a two-user channel, completion time refers to the number of channel uses\nspent by each user to transmit a bit pool with some given size. In this paper,\nthe information-theoretic formulation of completion time is based on the\nconcept of constrained rates, where users are allowed to employ different\nnumbers of channel uses for transmission as opposed to the equal channel use of\nthe standard information-theoretic formulation. Analogous to the capacity\nregion, the completion time region characterizes all possible trade-offs among\nusers' completion times. For a multi-access channel, it is shown that the\ncompletion time region is achieved by operating the channel in two independent\nphases: a multi-access phase when both users are transmitting, and a\npoint-to-point phase when one user has finished and the other is still\ntransmitting. Using a similar two-phase approach, the completion time region\n(or inner and outer bounds) is established for a Gaussian broadcast channel and\na Gaussian interference channel. It is observed that although consisting of two\nconvex subregions, the completion time region may not be convex in general.\nFinally an optimization problem of minimizing the weighted sum completion time\nfor a Gaussian multi-access channel and a Gaussian broadcast channel is solved,\ndemonstrating the utility of the completion time approach. \n\n"}
{"id": "1508.00246", "contents": "Title: On double truncated (interval) WCRE and WCE Abstract: Measure of the weighted cumulative entropy about the predictability of\nfailure time of a system have been introduced in [3]. Referring properties of\ndoubly truncated (interval) cumulative residual and past entropy, several\nbounds and assertions are proposed in weighted version. \n\n"}
{"id": "1508.00335", "contents": "Title: $f$-divergence Inequalities Abstract: This paper develops systematic approaches to obtain $f$-divergence\ninequalities, dealing with pairs of probability measures defined on arbitrary\nalphabets. Functional domination is one such approach, where special emphasis\nis placed on finding the best possible constant upper bounding a ratio of\n$f$-divergences. Another approach used for the derivation of bounds among\n$f$-divergences relies on moment inequalities and the logarithmic-convexity\nproperty, which results in tight bounds on the relative entropy and\nBhattacharyya distance in terms of $\\chi^2$ divergences. A rich variety of\nbounds are shown to hold under boundedness assumptions on the relative\ninformation. Special attention is devoted to the total variation distance and\nits relation to the relative information and relative entropy, including\n\"reverse Pinsker inequalities,\" as well as on the $E_\\gamma$ divergence, which\ngeneralizes the total variation distance. Pinsker's inequality is extended for\nthis type of $f$-divergence, a result which leads to an inequality linking the\nrelative entropy and relative information spectrum. Integral expressions of the\nR\\'enyi divergence in terms of the relative information spectrum are derived,\nleading to bounds on the R\\'enyi divergence in terms of either the variational\ndistance or relative entropy. \n\n"}
{"id": "1508.00540", "contents": "Title: Temporal Pattern of Online Communication Spike Trains in Spreading a\n  Scientific Rumor: How Often, Who Interacts with Whom? Abstract: We study complex time series (spike trains) of online user communication\nwhile spreading messages about the discovery of the Higgs boson in Twitter. We\nfocus on online social interactions among users such as retweet, mention, and\nreply, and construct different types of active (performing an action) and\npassive (receiving an action) spike trains for each user. The spike trains are\nanalyzed by means of local variation, to quantify the temporal behavior of\nactive and passive users, as a function of their activity and popularity. We\nshow that the active spike trains are bursty, independently of their activation\nfrequency. For passive spike trains, in contrast, the local variation of\npopular users presents uncorrelated (Poisson random) dynamics. We further\ncharacterize the correlations of the local variation in different interactions.\nWe obtain high values of correlation, and thus consistent temporal behavior,\nbetween retweets and mentions, but only for popular users, indicating that\ncreating online attention suggests an alignment in the dynamics of the two\ninteractions. \n\n"}
{"id": "1508.02454", "contents": "Title: Multi-Resolution Compressed Sensing via Approximate Message Passing Abstract: In this paper, we consider the problem of multi-resolution compressed sensing\n(MR-CS) reconstruction, which has received little attention in the literature.\nInstead of always reconstructing the signal at the original high resolution\n(HR), we enable the reconstruction of a low-resolution (LR) signal when there\nare not enough CS samples to recover a HR signal. We propose an approximate\nmessage passing (AMP)-based framework dubbed MR-AMP, and derive its state\nevolution, phase transition, and noise sensitivity, which show that in addition\nto reduced complexity, our method can recover a LR signal with bounded noise\nsensitivity even when the noise sensitivity of the conventional HR\nreconstruction is unbounded. We then apply the MR-AMP to image reconstruction\nusing either soft-thresholding or total variation denoiser, and develop three\npairs of up-/down-sampling operators in transform or spatial domain. The\nperformance of the proposed scheme is demonstrated by both 1D synthetic data\nand 2D images. \n\n"}
{"id": "1508.02808", "contents": "Title: Microscopic Analysis of the Uplink Interference in FDMA Small Cell\n  Networks Abstract: In this paper, we analytically derive an upper bound on the error in\napproximating the uplink (UL) single-cell interference by a lognormal\ndistribution in frequency division multiple access (FDMA) small cell networks\n(SCNs). Such an upper bound is measured by the Kolmogorov Smirnov (KS) distance\nbetween the actual cumulative density function (CDF) and the approximate CDF.\nThe lognormal approximation is important because it allows tractable network\nperformance analysis. Our results are more general than the existing works in\nthe sense that we do not pose any requirement on (i) the shape and/or size of\ncell coverage areas, (ii) the uniformity of user equipment (UE) distribution,\nand (iii) the type of multi-path fading. Based on our results, we propose a new\nframework to directly and analytically investigate a complex network with\npractical deployment of multiple BSs placed at irregular locations, using a\npower lognormal approximation of the aggregate UL interference. The proposed\nnetwork performance analysis is particularly useful for the 5th generation (5G)\nsystems with general cell deployment and UE distribution. \n\n"}
{"id": "1508.03599", "contents": "Title: Efficient Redundancy Techniques for Latency Reduction in Cloud Systems Abstract: In cloud computing systems, assigning a task to multiple servers and waiting\nfor the earliest copy to finish is an effective method to combat the\nvariability in response time of individual servers, and reduce latency. But\nadding redundancy may result in higher cost of computing resources, as well as\nan increase in queueing delay due to higher traffic load. This work helps\nunderstand when and how redundancy gives a cost-efficient reduction in latency.\nFor a general task service time distribution, we compare different redundancy\nstrategies in terms of the number of redundant tasks, and time when they are\nissued and canceled. We get the insight that the log-concavity of the task\nservice time creates a dichotomy of when adding redundancy helps. If the\nservice time distribution is log-convex (i.e. log of the tail probability is\nconvex) then adding maximum redundancy reduces both latency and cost. And if it\nis log-concave (i.e. log of the tail probability is concave), then less\nredundancy, and early cancellation of redundant tasks is more effective. Using\nthese insights, we design a general redundancy strategy that achieves a good\nlatency-cost trade-off for an arbitrary service time distribution. This work\nalso generalizes and extends some results in the analysis of fork-join queues. \n\n"}
{"id": "1508.04921", "contents": "Title: Robust Node Estimation and Topology Discovery Algorithm in Large-Scale\n  Wireless Sensor Networks Abstract: This paper introduces a novel algorithm for cardinality, i.e., the number of\nnodes, estimation in large scale anonymous graphs using statistical inference\nmethods. Applications of this work include estimating the number of sensor\ndevices, online social users, active protein cells, etc. In anonymous graphs,\neach node possesses little or non-existing information on the network topology.\nIn particular, this paper assumes that each node only knows its unique\nidentifier. The aim is to estimate the cardinality of the graph and the\nneighbours of each node by querying a small portion of them. While the former\nallows the design of more efficient coding schemes for the network, the second\nprovides a reliable way for routing packets. As a reference for comparison,\nthis work considers the Best Linear Unbiased Estimators (BLUE). For dense\ngraphs and specific running times, the proposed algorithm produces a\ncardinality estimate proportional to the BLUE. Furthermore, for an arbitrary\nnumber of iterations, the estimate converges to the BLUE as the number of\nqueried nodes tends to the total number of nodes in the network. Simulation\nresults confirm the theoretical results by revealing that, for a moderate\nrunning time, asking a small group of nodes is sufficient to perform an\nestimation of 95% of the whole network. \n\n"}
{"id": "1508.05673", "contents": "Title: Constructing bent functions and bent idempotents of any possible\n  algebraic degrees Abstract: Bent functions as optimal combinatorial objects are difficult to characterize\nand construct. In the literature, bent idempotents are a special class of bent\nfunctions and few constructions have been presented, which are restricted by\nthe degree of finite fields and have algebraic degree no more than 4. In this\npaper, several new infinite families of bent functions are obtained by adding\nthe the algebraic combination of linear functions to some known bent functions\nand their duals are calculated. These bent functions contain some previous work\non infinite families of bent functions by Mesnager \\cite{M2014} and Xu et al.\n\\cite{XCX2015}. Further, infinite families of bent idempotents of any possible\nalgebraic degree are constructed from any quadratic bent idempotent. To our\nknowledge, it is the first univariate representation construction of infinite\nfamilies of bent idempotents over $\\mathbb{F}_{2^{2m}}$ of algebraic degree\nbetween 2 and $m$, which solves the open problem on bent idempotents proposed\nby Carlet \\cite{C2014}. And an infinite family of anti-self-dual bent functions\nare obtained. The sum of three anti-self-dual bent functions in such a family\nis also anti-self-dual bent and belongs to this family. This solves the open\nproblem proposed by Mesnager \\cite{M2014}. \n\n"}
{"id": "1508.05703", "contents": "Title: Impact of CFO Estimation on the Performance of ZF Receiver in Massive\n  MU-MIMO Systems Abstract: In this paper, we study the impact of carrier frequency offset (CFO)\nestimation/compensation on the information rate performance of the zero-forcing\n(ZF) receiver in the uplink of a multi-user massive multiple-input\nmultiple-output (MIMO) system. Analysis of the derived closed-form expression\nof the per-user information rate reveals that with increasing number of BS\nantennas $M$, an $\\mathcal{O}(\\sqrt{M})$ array gain is achievable, which is\nsame as that achieved in the ideal zero CFO scenario. Also it is observed that\ncompared to the ideal zero CFO case, the performance degradation in the\npresence of residual CFO (after CFO compensation) is the same for both ZF and\nMRC. \n\n"}
{"id": "1508.06019", "contents": "Title: Dense Subset Sum may be the hardest Abstract: The Subset Sum problem asks whether a given set of $n$ positive integers\ncontains a subset of elements that sum up to a given target $t$. It is an\noutstanding open question whether the $O^*(2^{n/2})$-time algorithm for Subset\nSum by Horowitz and Sahni [J. ACM 1974] can be beaten in the worst-case setting\nby a \"truly faster\", $O^*(2^{(0.5-\\delta)n})$-time algorithm, with some\nconstant $\\delta > 0$. Continuing an earlier work [STACS 2015], we study Subset\nSum parameterized by the maximum bin size $\\beta$, defined as the largest\nnumber of subsets of the $n$ input integers that yield the same sum. For every\n$\\epsilon > 0$ we give a truly faster algorithm for instances with $\\beta \\leq\n2^{(0.5-\\epsilon)n}$, as well as instances with $\\beta \\geq 2^{0.661n}$.\nConsequently, we also obtain a characterization in terms of the popular density\nparameter $n/\\log_2 t$: if all instances of density at least $1.003$ admit a\ntruly faster algorithm, then so does every instance. This goes against the\ncurrent intuition that instances of density 1 are the hardest, and therefore is\na step toward answering the open question in the affirmative. Our results stem\nfrom novel combinations of earlier algorithms for Subset Sum and a study of an\nextremal question in additive combinatorics connected to the problem of\nUniquely Decodable Code Pairs in information theory. \n\n"}
{"id": "1509.00453", "contents": "Title: PLC-to-DSL Interference: Statistical Model and Impact on DSL Abstract: Newly available standards for broadband access using Digital Subscriber Lines\n(DSL) have a high degree of spectrum overlap with home networking technologies\nusing broadband Power Line Communications (BB-PLC) and this overlap leads to\nElectromagnetic Compatibility issues that may cause performance degradation in\nDSL systems. This paper studies the characteristics of measured PLC-to-DSL\ninterference and presents novel results on its statistical characterization.\nThe frequency-dependent couplings between power line cables and twisted-pairs\nare estimated from measurements and a statistical model based on a mixture of\ntwo truncated Gaussian distributions is set forth. The proposed statistical\nmodel allows the accurate evaluation of the impact of BB-PLC interference on\nvarious DSL technologies, in terms of both average and worst-case impacts on\ndata rate. This paper further provides an extensive assessment of the impact of\nPLC-to-DSL interference at various loop lengths and for multiple profiles of\nVery-high rate Digital Subscriber Lines (VDSL2), Vectored VDSL2 (V-VDSL2), and\nG.fast. The results of this paper confirm that the impact of PLC interference\nvaries with loop length and whether vectoring is used or not. Furthermore, the\naverage impact is found to be generally small but worst-case couplings can lead\nto substantial degradation of DSL. \n\n"}
{"id": "1509.00935", "contents": "Title: Secrecy Wireless Information and Power Transfer in OFDMA Systems Abstract: In this paper, we consider simultaneous wireless information and power\ntransfer (SWIPT) in orthogonal frequency division multiple access (OFDMA)\nsystems with the coexistence of information receivers (IRs) and energy\nreceivers (ERs). The IRs are served with best-effort secrecy data and the ERs\nharvest energy with minimum required harvested power. To enhance physical-layer\nsecurity and yet satisfy energy harvesting requirements, we introduce a new\nfrequency-domain artificial noise based approach. We study the optimal resource\nallocation for the weighted sum secrecy rate maximization via transmit power\nand subcarrier allocation. The considered problem is non-convex, while we\npropose an efficient algorithm for solving it based on Lagrange duality method.\nSimulation results illustrate the effectiveness of the proposed algorithm as\ncompared against other heuristic schemes. \n\n"}
{"id": "1509.01229", "contents": "Title: A Theory of Solving TAP Equations for Ising Models with General\n  Invariant Random Matrices Abstract: We consider the problem of solving TAP mean field equations by iteration for\nIsing model with coupling matrices that are drawn at random from general\ninvariant ensembles. We develop an analysis of iterative algorithms using a\ndynamical functional approach that in the thermodynamic limit yields an\neffective dynamics of a single variable trajectory. Our main novel contribution\nis the expression for the implicit memory term of the dynamics for general\ninvariant ensembles. By subtracting these terms, that depend on magnetizations\nat previous time steps, the implicit memory terms cancel making the iteration\ndependent on a Gaussian distributed field only. The TAP magnetizations are\nstable fixed points if an AT stability criterion is fulfilled. We illustrate\nour method explicitly for coupling matrices drawn from the random orthogonal\nensemble. \n\n"}
{"id": "1509.01653", "contents": "Title: Millimeter Wave Energy Harvesting Abstract: The millimeter wave (mmWave) band, which is a prime candidate for 5G cellular\nnetworks, seems attractive for wireless energy harvesting. This is because it\nwill feature large antenna arrays as well as extremely dense base station (BS)\ndeployments. The viability of mmWave for energy harvesting though is unclear,\ndue to the differences in propagation characteristics such as extreme\nsensitivity to building blockages. This paper considers a scenario where\nlow-power devices extract energy and/or information from the mmWave signals.\nUsing stochastic geometry, analytical expressions are derived for the energy\ncoverage probability, the average harvested power, and the overall\n(energy-and-information) coverage probability at a typical wireless-powered\ndevice in terms of the BS density, the antenna geometry parameters, and the\nchannel parameters. Numerical results reveal several network and device level\ndesign insights. At the BSs, optimizing the antenna geometry parameters such as\nbeamwidth can maximize the network-wide energy coverage for a given user\npopulation. At the device level, the performance can be substantially improved\nby optimally splitting the received signal for energy and information\nextraction, and by deploying multi-antenna arrays. For the latter, an efficient\nlow-power multi-antenna mmWave receiver architecture is proposed for\nsimultaneous energy and information transfer. Overall, simulation results\nsuggest that mmWave energy harvesting generally outperforms lower frequency\nsolutions. \n\n"}
{"id": "1509.01942", "contents": "Title: Newtonized Orthogonal Matching Pursuit: Frequency Estimation over the\n  Continuum Abstract: We propose a fast sequential algorithm for the fundamental problem of\nestimating frequencies and amplitudes of a noisy mixture of sinusoids. The\nalgorithm is a natural generalization of Orthogonal Matching Pursuit (OMP) to\nthe continuum using Newton refinements, and hence is termed Newtonized OMP\n(NOMP). Each iteration consists of two phases: detection of a new sinusoid, and\nsequential Newton refinements of the parameters of already detected sinusoids.\nThe refinements play a critical role in two ways: (1) sidestepping the\npotential basis mismatch from discretizing a continuous parameter space, (2)\nproviding feedback for locally refining parameters estimated in previous\niterations. We characterize convergence, and provide a Constant False Alarm\nRate (CFAR) based termination criterion. By benchmarking against the Cramer Rao\nBound, we show that NOMP achieves near-optimal performance under a variety of\nconditions. We compare the performance of NOMP with classical algorithms such\nas MUSIC and more recent Atomic norm Soft Thresholding (AST) and Lasso\nalgorithms, both in terms of frequency estimation accuracy and run time. \n\n"}
{"id": "1509.04225", "contents": "Title: Average Error Probability Analysis in mmWave Cellular Networks Abstract: In this paper, a mathematical framework for the analysis of average symbol\nerror probability (ASEP) in millimeter wave (mmWave) cellular networks with\nPoisson Point Process (PPP) distributed base stations (BSs) is developed using\ntools from stochastic geometry. The distinguishing features of mmWave\ncommunications such as directional beamforming and having different path loss\nlaws for line-of-sight (LOS) and non-line-of-sight (NLOS) links are\nincorporated in the average error probability analysis. First, average pairwise\nerror probability (APEP) expression is obtained by averaging pairwise error\nprobability (PEP) over fading and random shortest distance from mobile user\n(MU) to its serving BS. Subsequently, average symbol error probability is\napproximated from APEP using the nearest neighbor (NN) approximation. ASEP is\nanalyzed for different antenna gains and base station densities. Finally, the\neffect of beamforming alignment errors on ASEP is investigated to get insight\non more realistic cases. \n\n"}
{"id": "1509.08490", "contents": "Title: Recoverability of Group Sparse Signals from Corrupted Measurements via\n  Robust Group Lasso Abstract: This paper considers the problem of recovering a group sparse signal matrix\n$\\mathbf{Y} = [\\mathbf{y}_1, \\cdots, \\mathbf{y}_L]$ from sparsely corrupted\nmeasurements $\\mathbf{M} = [\\mathbf{A}_{(1)}\\mathbf{y}_{1}, \\cdots,\n\\mathbf{A}_{(L)}\\mathbf{y}_{L}] + \\mathbf{S}$, where $\\mathbf{A}_{(i)}$'s are\nknown sensing matrices and $\\mathbf{S}$ is an unknown sparse error matrix. A\nrobust group lasso (RGL) model is proposed to recover $\\mathbf{Y}$ and\n$\\mathbf{S}$ through simultaneously minimizing the $\\ell_{2,1}$-norm of\n$\\mathbf{Y}$ and the $\\ell_1$-norm of $\\mathbf{S}$ under the measurement\nconstraints. We prove that $\\mathbf{Y}$ and $\\mathbf{S}$ can be exactly\nrecovered from the RGL model with a high probability for a very general class\nof $\\mathbf{A}_{(i)}$'s. \n\n"}
{"id": "1509.08836", "contents": "Title: Experimental Demonstration of Capacity Increase and Rate-Adaptation by\n  Probabilistically Shaped 64-QAM Abstract: We implemented a flexible transmission system operating at adjustable data\nrate and fixed bandwidth, baudrate, constellation and overhead using\nprobabilistic shaping. We demonstrated in a transmission experiment up to 15%\ncapacity and 43% reach increase versus 200 Gbit/s 16-QAM. \n\n"}
{"id": "1509.08844", "contents": "Title: Subverting Massive MIMO by Smart Jamming Abstract: We consider uplink transmission of a massive multi-user multiple-input\nmultiple-output (MU-MIMO) system in the presence of a smart jammer. The jammer\naims to degrade the sum spectral efficiency of the legitimate system by\nattacking both the training and data transmission phases. First, we derive a\nclosed-form expression for the sum spectral efficiency by taking into account\nthe presence of a smart jammer. Then, we determine how a jammer with a given\nenergy budget should attack the training and data transmission phases to induce\nthe maximum loss to the sum spectral efficiency. Numerical results illustrate\nthe impact of optimal jamming specifically in the large limit of the number of\nbase station (BS) antennas. \n\n"}
{"id": "1509.09059", "contents": "Title: Message-Passing Receiver for Joint Channel Estimation and Decoding in 3D\n  Massive MIMO-OFDM Systems Abstract: In this paper, we address the message-passing receiver design for the 3D\nmassive MIMO-OFDM systems. With the aid of the central limit argument and\nTaylor-series approximation, a computationally efficient receiver that performs\njoint channel estimation and decoding is devised by the framework of\nexpectation propagation. Specially, the local belief defined at the channel\ntransition function is expanded up to the second order with Wirtinger calculus,\nto transform the messages sent by the channel transition function to a\ntractable form. As a result, the channel impulse response (CIR) between each\npair of antennas is estimated by Gaussian message passing. In addition, a\nvariational expectation-maximization (EM)-based method is derived to learn the\nchannel power-delay-profile (PDP). The proposed joint algorithm is assessed in\n3D massive MIMO systems with spatially correlated channels, and the empirical\nresults corroborate its superiority in terms of performance and complexity. \n\n"}
{"id": "1510.01367", "contents": "Title: Cooperation Alignment for Distributed Interference Management Abstract: We consider a cooperative Gaussian interference channel in which each\nreceiver must decode its intended message locally, with the help of cooperation\neither at the receivers side or at the transmitter side. In the case of\nreceiver cooperation, the receivers can process and share information through\nlimited capacity backhaul links. In contrast to various previously considered\ndistributed antenna architectures, where processing is utterly performed in a\ncentralized fashion, the model considered in this paper aims to capture the\nessence of decentralized processing, allowing for a more general class of\n\"interactive\" interference management strategies. Focusing on the three-user\ncase, we characterize the fundamental tradeoff between the achievable\ncommunication rates and the corresponding backhaul cooperation rate, in terms\nof degrees of freedom (DoF). Surprisingly, we show that the optimum\ncommunication-cooperation tradeoff per user remains the same when we move from\ntwo-user to three-user interference channels. In the absence of cooperation,\nthis is due to interference alignment, which keeps the fraction of\ncommunication dimensions wasted for interference unchanged. When backhaul\ncooperation is available, we develop a new idea that we call cooperation\nalignment, which guarantees that the average (per user) backhaul load remains\nthe same as we increase the number of users. In the case of transmitter\ncooperation, the transmitters can form their jointly precoded signals through\nan interactive protocol over the backhaul. In this case, we show that the\noptimal (per user) tradeoff between the achievable communication rates and the\ncorresponding backhaul cooperation rate in the three-user case is the same as\nfor receiver cooperation. \n\n"}
{"id": "1510.03510", "contents": "Title: Repeat-Accumulate Codes for Reconciliation in Continuous Variable\n  Quantum Key Distribution Abstract: This paper investigates the design of low-complexity error correction codes\nfor the verification step in continuous variable quantum key distribution\n(CVQKD) systems. We design new coding schemes based on quasi-cyclic\nrepeat-accumulate codes which demonstrate good performances for CVQKD\nreconciliation. \n\n"}
{"id": "1510.04763", "contents": "Title: Density Evolution Analysis of Spatially Coupled LDPC Codes Over BIAWGN\n  Channel Abstract: In this paper, we study the density evolution analysis of spatially coupled\nlow-density parity-check (SC-LDPC) codes over binary input additive white\nGaussian noise (BIAWGN) channels under the belief propagation (BP) decoding\nalgorithm. Using reciprocal channel approximation and Gaussian approximation,\nwe propose averaging techniques for the density evolution of SC-LDPC codes over\nBIAWGN channels. We show that the proposed techniques can closely predict the\ndecoding threshold while offering reduced complexity compared to the existing\nmulti-edge-type density evolution. \n\n"}
{"id": "1510.06095", "contents": "Title: Optimality of Large MIMO Detection via Approximate Message Passing Abstract: Optimal data detection in multiple-input multiple-output (MIMO) communication\nsystems with a large number of antennas at both ends of the wireless link\nentails prohibitive computational complexity. In order to reduce the\ncomputational complexity, a variety of sub-optimal detection algorithms have\nbeen proposed in the literature. In this paper, we analyze the optimality of a\nnovel data-detection method for large MIMO systems that relies on approximate\nmessage passing (AMP). We show that our algorithm, referred to as\nindividually-optimal (IO) large-MIMO AMP (short IO-LAMA), is able to perform IO\ndata detection given certain conditions on the MIMO system and the\nconstellation set (e.g., QAM or PSK) are met. \n\n"}
{"id": "1510.06454", "contents": "Title: Many Access for Small Packets Based on Precoding and Sparsity-aware\n  Recovery Abstract: Modern mobile terminals produce massive small data packets. For these\nshort-length packets, it is inefficient to follow the current multiple access\nschemes to allocate transmission resources due to heavy signaling overhead. We\npropose a non-orthogonal many-access scheme that is well suited for the future\ncommunication systems equipped with many receive antennas. The system is\nmodeled as having a block-sparsity pattern with unknown sparsity level (i.e.,\nunknown number of transmitted messages). Block precoding is employed at each\nsingle-antenna transmitter to enable the simultaneous transmissions of many\nusers. The number of simultaneously served active users is allowed to be even\nmore than the number of receive antennas. Sparsity-aware recovery is designed\nat the receiver for joint user detection and symbol demodulation. To reduce the\neffects of channel fading on signal recovery, normalized block orthogonal\nmatching pursuit (BOMP) algorithm is introduced, and based on its approximate\nperformance analysis, we develop interference cancellation based BOMP (ICBOMP)\nalgorithm. The ICBOMP performs error correction and detection in each iteration\nof the normalized BOMP. Simulation results demonstrate the effectiveness of the\nproposed scheme in small packet services, as well as the advantages of ICBOMP\nin improving signal recovery accuracy and reducing computational cost. \n\n"}
{"id": "1510.06488", "contents": "Title: When ICN Meets C-RAN for HetNets: An SDN Approach Abstract: In this paper, we contribute to novelly proposing and elaborating the\nintegration of the ICN, C-RAN and SDN for the HetNet to achieve win-win\nsituation. The vision of the proposed system is demonstrated, followed by the\nadvantages and challenges. We further present the hybrid system with a\nlarge-scale wireless heterogeneous campus network. \n\n"}
{"id": "1510.08213", "contents": "Title: Optimal Point-to-Point Codes in Interference Channels: An Incremental\n  I-MMSE approach Abstract: A recent result of the authors shows a so-called I-MMSE-like relationship\nthat, for the two-user Gaussian interference channel, an I-MMSE relationship\nholds in the limit, as n $\\to \\infty$, between the interference and the\ninterfered-with receiver, assuming that the interfered-with transmission is an\noptimal point-to-point sequence (achieves the point-to-point capacity). This\nresult was further used to provide a proof of the \"missing corner points\" of\nthe two-user Gaussian interference channel. This paper provides an information\ntheoretic proof of the above-mentioned I-MMSE-like relationship which follows\nthe incremental channel approach, an approach which was used by Guo, Shamai and\nVerd\\'u to provide an insightful proof of the original I-MMSE relationship for\npoint-to-point channels. Finally, some additional applications of this result\nare shown for other multi-user settings: the Gaussian multiple-access channel\nwith interference and specific K-user Gaussian Z-interference channel settings. \n\n"}
{"id": "1510.08887", "contents": "Title: Phase Retrieval Using Unitary 2-Designs Abstract: We consider a variant of the phase retrieval problem, where vectors are\nreplaced by unitary matrices, i.e., the unknown signal is a unitary matrix U,\nand the measurements consist of squared inner products |Tr(C*U)|^2 with unitary\nmatrices C that are chosen by the observer. This problem has applications to\nquantum process tomography, when the unknown process is a unitary operation.\n  We show that PhaseLift, a convex programming algorithm for phase retrieval,\ncan be adapted to this matrix setting, using measurements that are sampled from\nunitary 4- and 2-designs. In the case of unitary 4-design measurements, we show\nthat PhaseLift can reconstruct all unitary matrices, using a near-optimal\nnumber of measurements. This extends previous work on PhaseLift using spherical\n4-designs.\n  In the case of unitary 2-design measurements, we show that PhaseLift still\nworks pretty well on average: it recovers almost all signals, up to a constant\nadditive error, using a near-optimal number of measurements. These 2-design\nmeasurements are convenient for quantum process tomography, as they can be\nimplemented via randomized benchmarking techniques. This is the first positive\nresult on PhaseLift using 2-designs. \n\n"}
{"id": "1511.01646", "contents": "Title: Polar Subcodes Abstract: An extension of polar codes is proposed, which allows some of the frozen\nsymbols, called dynamic frozen symbols, to be data-dependent. A construction of\npolar codes with dynamic frozen symbols, being subcodes of extended BCH codes,\nis proposed. The proposed codes have higher minimum distance than classical\npolar codes, but still can be efficiently decoded using the successive\ncancellation algorithm and its extensions. The codes with Arikan, extended BCH\nand Reed-Solomon kernel are considered. The proposed codes are shown to\noutperform LDPC and turbo codes, as well as polar codes with CRC. \n\n"}
{"id": "1511.01854", "contents": "Title: Trace-distance measure of coherence Abstract: We show that trace distance measure of coherence is a strong monotone for all\nqubit and, so called, $X$ states. An expression for the trace distance\ncoherence for all pure states and a semi definite program for arbitrary states\nis provided. We also explore the relation between $l_1$-norm and relative\nentropy based measures of coherence, and give a sharp inequality connecting the\ntwo. In addition, it is shown that both $l_p$-norm- and Schatten-$p$-norm-based\nmeasures violate the (strong) monotonicity for all $p\\in(1,\\infty)$. \n\n"}
{"id": "1511.02128", "contents": "Title: Hierarchical Codebook Design for Beamforming Training in Millimeter-Wave\n  Communication Abstract: In millimeter-wave communication, large antenna arrays are required to\nachieve high power gain by steering towards each other with narrow beams, which\nposes the problem to efficiently search the best beam direction in the angle\ndomain at both Tx and Rx sides. As the exhaustive search is time consuming,\nhierarchical search has been widely accepted to reduce the complexity, and its\nperformance is highly dependent on the codebook design. In this paper, we\npropose two basic criteria for the hierarchical codebook design, and devise an\nefficient hierarchical codebook by jointly exploiting sub-array and\ndeactivation (turning-off) antenna processing techniques, where closed-form\nexpressions are provided to generate the codebook. Performance evaluations are\nconducted under different system and channel models. Results show superiority\nof the proposed codebook over the existing alternatives. \n\n"}
{"id": "1511.02256", "contents": "Title: On the Optimality of Uncoded Cache Placement Abstract: Caching is an efficient way to reduce peak-hour network traffic congestion by\nstoring some contents at user's local cache without knowledge of later demands.\nMaddah-Ali and Niesen initiated a fundamental study of caching systems; they\nproposed a scheme (with uncoded cache placement and linear network coding\ndelivery) that is provably optimal to within a factor 12. In this paper, by\nnoticing that when the cache contents and the demands are fixed, the caching\nproblem can be seen as an index coding problem, we show the optimality of\nMaddah-Ali and Niesen's scheme assuming that cache placement is restricted to\nbe uncoded and the number of users is not less than the number of files.\nFurthermore, this result states that further improvement to the Maddah-Ali and\nNiesen's scheme in this regimes can be obtained only by coded cache placement. \n\n"}
{"id": "1511.02285", "contents": "Title: Multiuser MIMO Sequential Beamforming with Full-duplex Training Abstract: Multiple transmitting antennas can considerably increase the downlink\nspectral efficiency by beamforming to multiple users at the same time. However,\nmultiuser beamforming requires channel state information (CSI) at the\ntransmitter, which leads to training overhead and reduces overall achievable\nspectral efficiency. In this paper, we propose and analyze a sequential\nbeamforming strategy that utilizes full-duplex base station to implement\ndownlink data transmission concurrently with CSI acquisition via in-band closed\nor open loop training. Our results demonstrate that full-duplex capability can\nimprove the spectral efficiency of uni-directional traffic, by leveraging it to\nreduce the control overhead of CSI estimation. In moderate SNR regimes, we\nanalytically derive tight approximations for the optimal training duration and\ncharacterize the associated respective spectral efficiency. We further\ncharacterize the enhanced multiplexing gain performance in the high SNR regime.\nIn both regimes, the performance of the proposed full-duplex strategy is\ncompared to the half-duplex counterpart to quantify spectral efficiency\nimprovement. With experimental data [1] and 3D channel model [2] from 3GPP, in\na 1.4 MHz 8X8 system LTE system with the block length of 500 symbols, the\nproposed strategy attains a spectral efficiency improvement of 130% and 8% with\nclosed and open loop training, respectively. \n\n"}
{"id": "1511.02574", "contents": "Title: Wireless Multihop Device-to-Device Caching Networks Abstract: We consider a wireless device-to-device (D2D) network where $n$ nodes are\nuniformly distributed at random over the network area. We let each node with\nstorage capacity $M$ cache files from a library of size $m \\geq M$. Each node\nin the network requests a file from the library independently at random,\naccording to a popularity distribution, and is served by other nodes having the\nrequested file in their local cache via (possibly) multihop transmissions.\nUnder the classical \"protocol model\" of wireless networks, we characterize the\noptimal per-node capacity scaling law for a broad class of heavy-tailed\npopularity distributions including Zipf distributions with exponent less than\none. In the parameter regimes of interest, we show that a decentralized random\ncaching strategy with uniform probability over the library yields the optimal\nper-node capacity scaling of $\\Theta(\\sqrt{M/m})$, which is constant with $n$,\nthus yielding throughput scalability with the network size. Furthermore, the\nmultihop capacity scaling can be significantly better than for the case of\nsingle-hop caching networks, for which the per-node capacity is $\\Theta(M/m)$.\nThe multihop capacity scaling law can be further improved for a Zipf\ndistribution with exponent larger than some threshold $> 1$, by using a\ndecentralized random caching uniformly across a subset of most popular files in\nthe library. Namely, ignoring a subset of less popular files (i.e., effectively\nreducing the size of the library) can significantly improve the throughput\nscaling while guaranteeing that all nodes will be served with high probability\nas $n$ increases. \n\n"}
{"id": "1511.05539", "contents": "Title: Energy-Efficient Resource Allocation for Wireless Powered Communication\n  Networks Abstract: This paper considers a wireless powered communication network (WPCN), where\nmultiple users harvest energy from a dedicated power station and then\ncommunicate with an information receiving station. Our goal is to investigate\nthe maximum achievable energy efficiency (EE) of the network via joint time\nallocation and power control while taking into account the initial battery\nenergy of each user. We first study the EE maximization problem in the WPCN\nwithout any system throughput requirement. We show that the EE maximization\nproblem for the WPCN can be cast into EE maximization problems for two\nsimplified networks via exploiting its special structure. For each problem, we\nderive the optimal solution and provide the corresponding physical\ninterpretation, despite the non-convexity of the problems. Subsequently, we\nstudy the EE maximization problem under a minimum system throughput constraint.\nExploiting fractional programming theory, we transform the resulting non-convex\nproblem into a standard convex optimization problem. This allows us to\ncharacterize the optimal solution structure of joint time allocation and power\ncontrol and to derive an efficient iterative algorithm for obtaining the\noptimal solution. Simulation results verify our theoretical findings and\ndemonstrate the effectiveness of the proposed joint time and power\noptimization. \n\n"}
{"id": "1511.06034", "contents": "Title: Binary Locally Repairable Codes ---Sequential Repair for Multiple\n  Erasures Abstract: Locally repairable codes (LRC) for distribute storage allow two approaches to\nlocally repair multiple failed nodes: 1) parallel approach, by which each\nnewcomer access a set of $r$ live nodes $(r$ is the repair locality$)$ to\ndownload data and recover the lost packet; and 2) sequential approach, by which\nthe newcomers are properly ordered and each newcomer access a set of $r$ other\nnodes, which can be either a live node or a newcomer ordered before it. An\n$[n,k]$ linear code with locality $r$ and allows local repair for up to $t$\nfailed nodes by sequential approach is called an $(n,k,r,t)$-exact locally\nrepairable code (ELRC).\n  In this paper, we present a family of binary codes which is equivalent to the\ndirect product of $m$ copies of the $[r+1,r]$ single-parity-check code. We\nprove that such codes are $(n,k,r,t)$-ELRC with $n=(r+1)^m,k=r^m$ and\n$t=2^m-1$, which implies that they permit local repair for up to $2^m-1$\nerasures by sequential approach. Our result shows that the sequential approach\nhas much bigger advantage than parallel approach. \n\n"}
{"id": "1511.06230", "contents": "Title: Refined analysis of RGHWs of code pairs coming from Garcia-Stichtenoth's\n  second tower Abstract: Asymptotically good sequences of ramp secret sharing schemes were given in\n[Asymptotically good ramp secret sharing schemes, arXiv:1502.05507] by using\none-point algebraic geometric codes defined from asymptotically good towers of\nfunction fields. Their security is given by the relative generalized Hamming\nweights of the corresponding codes. In this paper we demonstrate how to obtain\nrefined information on the RGHWs when the codimension of the codes is small.\nFor general codimension, we give an improved estimate for the highest RGHW. \n\n"}
{"id": "1511.07499", "contents": "Title: On the Optimal Feedback Rate in Interference-Limited Multi-Antenna\n  Cellular Systems Abstract: We consider a downlink cellular network where multi-antenna base stations\n(BSs) transmit data to single-antenna users by using one of two linear\nprecoding methods with limited feedback: (i) maximum ratio transmission (MRT)\nfor serving a single user or (ii) zero forcing (ZF) for serving multiple users.\nThe BS and user locations are drawn from a Poisson point process, allowing\nexpressions for the signal- to-interference coverage probability and the\nergodic spectral efficiency to be derived as a function of system parameters\nsuch as the number of BS antennas and feedback bits, and the pathloss exponent.\nWe find a tight lower bound on the optimum number of feedback bits to maximize\nthe net spectral efficiency, which captures the overall system gain by\nconsidering both of downlink and uplink spectral efficiency using limited\nfeedback. Our main finding is that, when using MRT, the optimum number of\nfeedback bits scales linearly with the number of antennas, and logarithmically\nwith the channel coherence time. When using ZF, the feedback scales in the same\nways as MRT, but also linearly with the pathloss exponent. The derived results\nprovide system-level insights into the preferred channel codebook size by\naveraging the effects of short-term fading and long-term pathloss. \n\n"}
{"id": "1511.07910", "contents": "Title: Asynchronous Performance of Circularly Pulse-Shaped Waveforms for 5G Abstract: The fifth generation of wireless networks (5G) necessitates the use of\nwaveforms with loose constraints on synchronization in multiuser scenarios.\nAlso, carrier aggregation, as a way to better utilize the spectrum in 5G, needs\na waveform with low out-of-band (OOB) emission. Generalized frequency division\nmultiplexing (GFDM) and circular filter bank multicarrier (C-FBMC) are two\ncandidate waveforms that fulfill these requirements. Both GFDM and C-FBMC\noperate based on circular convolution, and use cyclic prefix to combat channel\nresponse. In this paper, we develop an analytical technique for examining the\nOOB emission and multiuser interference (MUI) in circularly shaped waveforms,\nlike GFDM and C-FBMC. To stay focused, the study in this paper is limited to\nC-FBMC modulation. However, the approach we take is trivially extendable to\nother waveforms as well. We derive equations that quantify OOB emission and\nMUI. Our analysis allows us to identify the source of OOB emission and MUI.\nThis leads us to quantify the methods proposed by other researchers to decrease\nOOB emission and MUI. Moreover, we quantify the impact of signal windowing at\nthe transmitter and receiver in reducing OOB emission and MUI, respectively. \n\n"}
{"id": "1512.03032", "contents": "Title: Hybrid MIMO Architectures for Millimeter Wave Communications: Phase\n  Shifters or Switches? Abstract: Hybrid analog/digital MIMO architectures were recently proposed as an\nalternative for fully-digitalprecoding in millimeter wave (mmWave) wireless\ncommunication systems. This is motivated by the possible reduction in the\nnumber of RF chains and analog-to-digital converters. In these architectures,\nthe analog processing network is usually based on variable phase shifters. In\nthis paper, we propose hybrid architectures based on switching networks to\nreduce the complexity and the power consumption of the structures based on\nphase shifters. We define a power consumption model and use it to evaluate the\nenergy efficiency of both structures. To estimate the complete MIMO channel, we\npropose an open loop compressive channel estimation technique which is\nindependent of the hardware used in the analog processing stage. We analyze the\nperformance of the new estimation algorithm for hybrid architectures based on\nphase shifters and switches. Using the estimated, we develop two algorithms for\nthe design of the hybrid combiner based on switches and analyze the achieved\nspectral efficiency. Finally, we study the trade-offs between power\nconsumption, hardware complexity, and spectral efficiency for hybrid\narchitectures based on phase shifting networks and switching networks.\nNumerical results show that architectures based on switches obtain equal or\nbetter channel estimation performance to that obtained using phase shifters,\nwhile reducing hardware complexity and power consumption. For equal power\nconsumption, all the hybrid architectures provide similar spectral\nefficiencies. \n\n"}
{"id": "1512.03878", "contents": "Title: Coding for classical-quantum channels with rate limited side information\n  at the encoder: An information-spectrum approach Abstract: We study the hybrid classical-quantum version of the channel coding problem\nfor the famous Gel'fand-Pinsker channel. In the classical setting for this\nchannel the conditional distribution of the channel output given the channel\ninput is a function of a random parameter called the channel state. We study\nthis problem when a rate limited version of the channel state is available at\nthe encoder for the classical-quantum Gel'fand-Pinsker channel. We establish\nthe capacity region for this problem in the information-spectrum setting. The\ncapacity region is quantified in terms of spectral-sup classical mutual\ninformation rate and spectral-inf quantum mutual information rate. \n\n"}
{"id": "1512.04833", "contents": "Title: Generalized Turbo Signal Recovery for Nonlinear Measurements and\n  Orthogonal Sensing Matrices Abstract: In this study, we propose a generalized turbo signal recovery algorithm to\nestimate a signal from quantized measurements, in which the sensing matrix is a\nrow-orthogonal matrix, such as the partial discrete Fourier transform matrix.\nThe state evolution of the proposed algorithm is derived and is shown to be\nconsistent with that obtained with the replica method. Numerical experiments\nillustrate the excellent agreement of the proposed algorithm with theoretical\nstate evolution. \n\n"}
{"id": "1512.08220", "contents": "Title: New bounds and constructions for multiply constant-weight codes Abstract: Multiply constant-weight codes (MCWCs) were introduced recently to improve\nthe reliability of certain physically unclonable function response. In this\npaper, the bounds of MCWCs and the constructions of optimal MCWCs are studied.\nFirstly, we derive three different types of upper bounds which improve the\nJohnson-type bounds given by Chee {\\sl et al.} in some parameters. The\nasymptotic lower bound of MCWCs is also examined. Then we obtain the asymptotic\nexistence of two classes of optimal MCWCs, which shows that the Johnson-type\nbounds for MCWCs with distances $2\\sum_{i=1}^mw_i-2$ or $2mw-w$ are\nasymptotically exact. Finally, we construct a class of optimal MCWCs with total\nweight four and distance six by establishing the connection between such MCWCs\nand a new kind of combinatorial structures. As a consequence, the maximum sizes\nof MCWCs with total weight less than or equal to four are determined almost\ncompletely. \n\n"}
{"id": "1512.08269", "contents": "Title: Statistical and Computational Guarantees for the Baum-Welch Algorithm Abstract: The Hidden Markov Model (HMM) is one of the mainstays of statistical modeling\nof discrete time series, with applications including speech recognition,\ncomputational biology, computer vision and econometrics. Estimating an HMM from\nits observation process is often addressed via the Baum-Welch algorithm, which\nis known to be susceptible to local optima. In this paper, we first give a\ngeneral characterization of the basin of attraction associated with any global\noptimum of the population likelihood. By exploiting this characterization, we\nprovide non-asymptotic finite sample guarantees on the Baum-Welch updates,\nguaranteeing geometric convergence to a small ball of radius on the order of\nthe minimax rate around a global optimum. As a concrete example, we prove a\nlinear rate of convergence for a hidden Markov mixture of two isotropic\nGaussians given a suitable mean separation and an initialization within a ball\nof large radius around (one of) the true parameters. To our knowledge, these\nare the first rigorous local convergence guarantees to global optima for the\nBaum-Welch algorithm in a setting where the likelihood function is nonconvex.\nWe complement our theoretical results with thorough numerical simulations\nstudying the convergence of the Baum-Welch algorithm and illustrating the\naccuracy of our predictions. \n\n"}
{"id": "1601.02391", "contents": "Title: Almost universal codes for fading wiretap channels Abstract: We consider a fading wiretap channel model where the transmitter has only\nstatistical channel state information, and the legitimate receiver and\neavesdropper have perfect channel state information. We propose a sequence of\nnon-random lattice codes which achieve strong secrecy and semantic security\nover ergodic fading channels. The construction is almost universal in the sense\nthat it achieves the same constant gap to secrecy capacity over Gaussian and\nergodic fading models. \n\n"}
{"id": "1601.02864", "contents": "Title: Tables of subspace codes Abstract: One of the main problems of subspace coding asks for the maximum possible\ncardinality of a subspace code with minimum distance at least $d$ over\n$\\mathbb{F}_q^n$, where the dimensions of the codewords, which are vector\nspaces, are contained in $K\\subseteq\\{0,1,\\dots,n\\}$. In the special case of\n$K=\\{k\\}$ one speaks of constant dimension codes. Since this (still) emerging\nfield is very prosperous on the one hand side and there are a lot of\nconnections to classical objects from Galois geometry it is a bit difficult to\nkeep or to obtain an overview about the current state of knowledge. To this end\nwe have implemented an on-line database of the (at least to us) known results\nat \\url{subspacecodes.uni-bayreuth.de}. The aim of this recurrently updated\ntechnical report is to provide a user guide how this technical tool can be used\nin research projects and to describe the so far implemented theoretic and\nalgorithmic knowledge. \n\n"}
{"id": "1601.02882", "contents": "Title: On Hidden States in Quantum Random Walks Abstract: It was recently pointed out that identifiability of quantum random walks and\nhidden Markov processes underlie the same principles. This analogy immediately\nraises questions on the existence of hidden states also in quantum random walks\nand their relationship with earlier debates on hidden states in quantum\nmechanics. The overarching insight was that not only hidden Markov processes,\nbut also quantum random walks are finitary processes. Since finitary processes\nenjoy nice asymptotic properties, this also encourages to further investigate\nthe asymptotic properties of quantum random walks. Here, answers to all these\nquestions are given. Quantum random walks, hidden Markov processes and finitary\nprocesses are put into a unifying model context. In this context, quantum\nrandom walks are seen to not only enjoy nice ergodic properties in general, but\nalso intuitive quantum-style asymptotic properties. It is also pointed out how\nhidden states arising from our framework relate to hidden states in earlier,\nprominent treatments on topics such as the EPR paradoxon or Bell's\ninequalities. \n\n"}
{"id": "1601.04485", "contents": "Title: TDOA Matrices: Algebraic Properties and their Application to Robust\n  Denoising with Missing Data Abstract: Measuring the Time delay of Arrival (TDOA) between a set of sensors is the\nbasic setup for many applications, such as localization or signal beamforming.\nThis paper presents the set of TDOA matrices, which are built from noise-free\nTDOA measurements, not requiring knowledge of the sensor array geometry. We\nprove that TDOA matrices are rank-two and have a special SVD decomposition that\nleads to a compact linear parametric representation. Properties of TDOA\nmatrices are applied in this paper to perform denoising, by finding the TDOA\nmatrix closest to the matrix composed with noisy measurements. The paper shows\nthat this problem admits a closed-form solution for TDOA measurements\ncontaminated with Gaussian noise which extends to the case of having missing\ndata. The paper also proposes a novel robust denoising method resistant to\noutliers, missing data and inspired in recent advances in robust low-rank\nestimation. Experiments in synthetic and real datasets show TDOA-based\nlocalization, both in terms of TDOA accuracy estimation and localization error. \n\n"}
{"id": "1601.04500", "contents": "Title: Second-Order and Moderate Deviation Asymptotics for Successive\n  Refinement Abstract: We derive the optimal second-order coding region and moderate deviations\nconstant for successive refinement source coding with a joint excess-distortion\nprobability constraint. We consider two scenarios: (i) a discrete memoryless\nsource (DMS) and arbitrary distortion measures at the decoders and (ii) a\nGaussian memoryless source (GMS) and quadratic distortion measures at the\ndecoders. For a DMS with arbitrary distortion measures, we prove an achievable\nsecond-order coding region, using type covering lemmas by Kanlis and Narayan\nand by No, Ingber and Weissman. We prove the converse using the perturbation\napproach by Gu and Effros. When the DMS is successively refinable, the\nexpressions for the second-order coding region and the moderate deviations\nconstant are simplified and easily computable. For this case, we also obtain\nnew insights on the second-order behavior compared to the scenario where\nseparate excess-distortion proabilities are considered. For example, we\ndescribe a DMS, for which the optimal second-order region transitions from\nbeing characterizable by a bivariate Gaussian to a univariate Gaussian, as the\ndistortion levels are varied. We then consider a GMS with quadratic distortion\nmeasures. To prove the direct part, we make use of the sphere covering theorem\nby Verger-Gaugry, together with appropriately-defined Gaussian type classes. To\nprove the converse, we generalize Kostina and Verd\\'u's one-shot converse bound\nfor point-to-point lossy source coding. We remark that this proof is applicable\nto general successively refinable sources. In the proofs of the moderate\ndeviations results for both scenarios, we follow a strategy similar to that for\nthe second-order asymptotics and use the moderate deviations principle. \n\n"}
{"id": "1601.04829", "contents": "Title: Spectral-Efficiency Analysis of Massive MIMO Systems in Centralized and\n  Distributed Schemes Abstract: This paper analyzes the spectral efficiency of massive multiple-input\nmultiple-output (MIMO) systems in both centralized and distributed\nconfigurations, referred to as C-MIMO and D-MIMO, respectively. By accounting\nfor real environmental parameters and antenna characteristics, namely, path\nloss, shadowing effect, multi-path fading and antenna correlation, a novel\ncomprehensive channel model is first proposed in closed-form, which is\napplicable to both types of MIMO schemes. Then, based on the proposed model,\nthe asymptotic behavior of the spectral efficiency of the MIMO channel under\nboth the centralized and distributed configurations is analyzed and compared in\nexact forms, by exploiting the theory of very long random vectors. Afterwards,\na case study is performed by applying the obtained results into MIMO networks\nwith circular coverage. In such a case, it is attested that for the D-MIMO of\ncell radius $r_{\\mathrm{c}}$ and circular antenna array of\nradius~$r_{\\mathrm{a}}$, the optimal value of~$r_{\\mathrm{a}}$ that maximizes\nthe average spectral efficiency is accurately established by\n$r_{\\mathrm{a}}^{\\mathrm{opt}}=r_{\\mathrm{c}}/1.31$. Monte Carlo simulation\nresults corroborate the developed spectral-efficiency analysis. \n\n"}
{"id": "1601.05563", "contents": "Title: Unconstrained distillation capacities of a pure-loss bosonic broadcast\n  channel Abstract: Bosonic channels are important in practice as they form a simple model for\nfree-space or fiber-optic communication. Here we consider a single-sender\ntwo-receiver pure-loss bosonic broadcast channel and determine the\nunconstrained capacity region for the distillation of bipartite entanglement\nand secret key between the sender and each receiver, whenever they are allowed\narbitrary public classical communication. We show how the state merging\nprotocol leads to achievable rates in this setting, giving an inner bound on\nthe capacity region. We also evaluate an outer bound on the region by using the\nrelative entropy of entanglement and a `reduction by teleportation' technique.\nThe outer bounds match the inner bounds in the infinite-energy limit, thereby\nestablishing the unconstrained capacity region for such channels. Our result\ncould provide a useful benchmark for implementing a broadcasting of\nentanglement and secret key through such channels. An important open question\nrelevant to practice is to determine the capacity region in both this setting\nand the single-sender single-receiver case when there is an energy constraint\non the transmitter. \n\n"}
{"id": "1601.05879", "contents": "Title: Construction of a Channel Code from an Arbitrary Source Code with\n  Decoder Side Information Abstract: The construction of a channel code by using a source code with decoder side\ninformation is introduced. For the construction, any pair of encoder and\ndecoder is available for a source code with decoder side information. A\nconstrained-random-number generator, which generates random numbers satisfying\na condition specified by a function and its value, is used to construct a\nstochastic channel encoder. The result suggests that we can divide the channel\ncoding problem into the problems of channel encoding and source decoding with\nside information. \n\n"}
{"id": "1601.05921", "contents": "Title: Edge Agreement of Second-order Multi-agent System with Dynamic\n  Quantization via Directed Edge Laplacian Abstract: This work explores the edge agreement problem of second-order multi-agent\nsystem with dynamic quantization under directed communication. To begin with,\nby virtue of the directed edge laplacian, we derive a model reduction\nrepresentation of the closed-loop multi-agent system depended on the spanning\ntree subgraph. Considering the limitations of the finite bandwidth channels,\nthe quantization effects of second-order multi-agent system under directed\ngraph are considered. Motivated by the observation that the static quantizer\nalways lead to the practical stability rather than the asymptotic stability,\nthe dynamic quantized communication strategy referring to the rooming\nin-rooming out scheme is employed. Based on the reduced model associated with\nthe essential edge Laplacian, the asymptotic stability of second-order\nmulti-agent system under dynamic quantized effects with only finite\nquantization level can be guaranteed. Finally, simulation results are provided\nto verify the theoretical analysis. \n\n"}
{"id": "1601.06280", "contents": "Title: Sub-Quadratic Decoding of Gabidulin Codes Abstract: This paper shows how to decode errors and erasures with Gabidulin codes in\nsub-quadratic time in the code length, improving previous algorithms which had\nat least quadratic complexity. The complexity reduction is achieved by\naccelerating operations on linearized polynomials. In particular, we present\nfast algorithms for division, multi-point evaluation and interpolation of\nlinearized polynomials and show how to efficiently compute minimal subspace\npolynomials. \n\n"}
{"id": "1601.06396", "contents": "Title: On detecting and quantification of randomness for one-sided sequences Abstract: The paper studies discrete time processes and their predictability and\nrandomness in deterministic pathwise setting, without using probabilistic\nassumptions on the ensemble. We suggest some approaches to quantification of\nrandomness based on frequency analysis of two-sided and one-sided sequences. In\naddition, the paper suggests an extension of the notion of bandlimitiness on\none-sided sequences and a procedure allowing to represent an one-sided sequence\nas a sum of left-bandlimited and predictable sequences and a non-reducible\nnoise. \n\n"}
{"id": "1601.06578", "contents": "Title: Throughput Analysis of Wireless Powered Cognitive Radio Networks with\n  Compressive Sensing and Matrix Completion Abstract: In this paper, we consider a cognitive radio network in which energy\nconstrained secondary users (SUs) can harvest energy from the randomly deployed\npower beacons (PBs). A new frame structure is proposed for the considered\nnetwork. A wireless power transfer (WPT) model and a compressive spectrum\nsensing model are introduced. In the WPT model, a new WPT scheme is proposed,\nand the closed-form expressions for the power outage probability are derived.\nIn compressive spectrum sensing model, two scenarios are considered: 1) Single\nSU, and 2) Multiple SUs. In the single SU scenario, in order to reduce the\nenergy consumption at the SU, compressive sensing technique which enables\nsub-Nyquist sampling is utilized. In the multiple SUs scenario, cooperative\nspectrum sensing (CSS) is performed with adopting low-rank matrix completion\ntechnique to obtain the complete matrix at the fusion center. Throughput\noptimizations of the secondary network are formulated into two linear\nconstrained problems, which aim to maximize the throughput of single SU and the\nCSS networks, respectively. Three methods are provided to obtain the maximal\nthroughput of secondary network by optimizing the time slots allocation and the\ntransmit power. Simulation results show that: 1) Multiple SUs scenario can\nachieve lower power outage probability than single SU scenario; and 2) The\noptimal throughput can be improved by implementing compressive spectrum sensing\nin the proposed frame structure design. \n\n"}
{"id": "1601.06873", "contents": "Title: Chernoff Information of Bottleneck Gaussian Trees Abstract: In this paper, our objective is to find out the determining factors of\nChernoff information in distinguishing a set of Gaussian trees. In this set,\neach tree can be attained via an edge removal and grafting operation from\nanother tree. This is equivalent to asking for the Chernoff information between\nthe most-likely confused, i.e. \"bottleneck\", Gaussian trees, as shown to be the\ncase in ML estimated Gaussian tree graphs lately. We prove that the Chernoff\ninformation between two Gaussian trees related through an edge removal and a\ngrafting operation is the same as that between two three-node Gaussian trees,\nwhose topologies and edge weights are subject to the underlying graph\noperation. In addition, such Chernoff information is shown to be determined\nonly by the maximum generalized eigenvalue of the two Gaussian covariance\nmatrices. The Chernoff information of scalar Gaussian variables as a result of\nlinear transformation (LT) of the original Gaussian vectors is also uniquely\ndetermined by the same maximum generalized eigenvalue. What is even more\ninteresting is that after incorporating the cost of measurements into a\nnormalized Chernoff information, Gaussian variables from LT have larger\nnormalized Chernoff information than the one based on the original Gaussian\nvectors, as shown in our proved bounds \n\n"}
{"id": "1601.07865", "contents": "Title: Grid Energy Consumption and QoS Tradeoff in Hybrid Energy Supply\n  Wireless Networks Abstract: Hybrid energy supply (HES) wireless networks have recently emerged as a new\nparadigm to enable green networks, which are powered by both the electric grid\nand harvested renewable energy. In this paper, we will investigate two critical\nbut conflicting design objectives of HES networks, i.e., the grid energy\nconsumption and quality of service (QoS). Minimizing grid energy consumption by\nutilizing the harvested energy will make the network environmentally friendly,\nbut the achievable QoS may be degraded due to the intermittent nature of energy\nharvesting. To investigate the tradeoff between these two aspects, we introduce\nthe total service cost as the performance metric, which is the weighted sum of\nthe grid energy cost and the QoS degradation cost. Base station assignment and\npower control is adopted as the main strategy to minimize the total service\ncost, while both cases with non-causal and causal side information are\nconsidered. With non-causal side information, a Greedy Assignment algorithm\nwith low complexity and near-optimal performance is proposed. With causal side\ninformation, the design problem is formulated as a discrete Markov decision\nproblem. Interesting solution structures are derived, which shall help to\ndevelop an efficient monotone backward induction algorithm. To further reduce\ncomplexity, a Look-Ahead policy and a Threshold-based Heuristic policy are also\nproposed. Simulation results shall validate the effectiveness of the proposed\nalgorithms and demonstrate the unique grid energy consumption and QoS tradeoff\nin HES networks. \n\n"}
{"id": "1601.07985", "contents": "Title: Online (and Offline) Robust PCA: Novel Algorithms and Performance\n  Guarantees Abstract: In this work, we study the online robust principal components' analysis\n(RPCA) problem. In recent work, RPCA has been defined as a problem of\nseparating a low-rank matrix (true data), $L$, and a sparse matrix (outliers),\n$S$, from their sum, $M:=L + S$. A more general version of this problem is to\nrecover $L$ and $S$ from $M:=L + S + W$ where $W$ is the matrix of unstructured\nsmall noise/corruptions. An important application where this problem occurs is\nin video analytics in trying to separate sparse foregrounds (e.g., moving\nobjects) from slowly changing backgrounds. While there has been a large amount\nof recent work on solutions and guarantees for the batch RPCA problem, the\nonline problem is largely open.\"Online\" RPCA is the problem of doing the above\non-the-fly with the extra assumptions that the initial subspace is accurately\nknown and that the subspace from which $l_t$ is generated changes slowly over\ntime. We develop and study a novel \"online\" RPCA algorithm based on the\nrecently introduced Recursive Projected Compressive Sensing (ReProCS)\nframework. Our algorithm improves upon the original ReProCS algorithm and it\nalso returns even more accurate offline estimates. The key contribution of this\nwork is a correctness result (complete performance guarantee) for this\nalgorithm under reasonably mild assumptions. By using extra assumptions --\naccurate initial subspace knowledge, slow subspace change, and clustered\neigenvalues -- we are able to remove one important limitation of batch RPCA\nresults and two key limitations of a recent result for ReProCS for online RPCA.\nTo our knowledge, this work is among the first few correctness results for\nonline RPCA. Most earlier results were only partial results, i.e., they\nrequired an assumption on intermediate algorithm estimates. \n\n"}
{"id": "1602.00095", "contents": "Title: Walsh Sampling with Incomplete Noisy Signals Abstract: With the advent of massive data outputs at a regular rate, admittedly, signal\nprocessing technology plays an increasingly key role. Nowadays, signals are not\nmerely restricted to physical sources, they have been extended to digital\nsources as well.\n  Under the general assumption of discrete statistical signal sources, we\npropose a practical problem of sampling incomplete noisy signals for which we\ndo not know a priori and the sampling size is bounded. We approach this\nsampling problem by Shannon's channel coding theorem. Our main results\ndemonstrate that it is the large Walsh coefficient(s) that characterize(s)\ndiscrete statistical signals, regardless of the signal sources. By the\nconnection of Shannon's theorem, we establish the necessary and sufficient\ncondition for our generic sampling problem for the first time. Our generic\nsampling results find practical and powerful applications in not only\nstatistical cryptanalysis, but software system performance optimization. \n\n"}
{"id": "1602.01149", "contents": "Title: Secure Index Coding: Existence and Construction Abstract: We investigate the construction of weakly-secure index codes for a sender to\nsend messages to multiple receivers with side information in the presence of an\neavesdropper. We derive a sufficient and necessary condition for the existence\nof index codes that are secure against an eavesdropper with access to any\nsubset of messages of cardinality $t$, for any fixed $t$. In contrast to the\nbenefits of using random keys in secure network coding, we prove that random\nkeys do not promote security in three classes of index-coding instances. \n\n"}
{"id": "1602.02415", "contents": "Title: On Cartesian line sampling with anisotropic total variation\n  regularization Abstract: This paper considers the use of the anisotropic total variation seminorm to\nrecover a two dimensional vector $x\\in \\mathbb{C}^{N\\times N}$ from its partial\nFourier coefficients, sampled along Cartesian lines. We prove that if $(x_{k,j}\n- x_{k-1,j})_{k,j}$ has at most $s_1$ nonzero coefficients in each column and\n$(x_{k,j} - x_{k,j-1})_{k,j}$ has at most $s_2$ nonzero coefficients in each\nrow, then, up to multiplication by $\\log$ factors, one can exactly recover $x$\nby sampling along $s_1$ horizontal lines of its Fourier coefficients and along\n$s_2$ vertical lines of its Fourier coefficients. Finally, unlike standard\ncompressed sensing estimates, the $\\log$ factors involved are dependent on the\nseparation distance between the nonzero entries in each row/column of the\ngradient of $x$ and not on $N^2$, the ambient dimension of $x$. \n\n"}
{"id": "1602.02648", "contents": "Title: Coding in the fork network in the framework of Kolmogorov complexity Abstract: Many statements from the classic information theory (the theory of Shannon's\nentropy) have natural counterparts in the algorithmic information theory (in\nthe framework of Kolmogorov complexity). In this paper we discuss one simple\ninstance of the parallelism between Shannon's and Kolmogorov's theories: we\nprove in the setting of Kolmogorov complexity a version of Wolf's\ncharacterization of admissible rates for the fork network. \n\n"}
{"id": "1602.03471", "contents": "Title: Improved group testing rates with constant column weight designs Abstract: We consider nonadaptive group testing where each item is placed in a constant\nnumber of tests. The tests are chosen uniformly at random with replacement, so\nthe testing matrix has (almost) constant column weights. We show that\nperformance is improved compared to Bernoulli designs, where each item is\nplaced in each test independently with a fixed probability. In particular, we\nshow that the rate of the practical COMP detection algorithm is increased by\n31% in all sparsity regimes. In dense cases, this beats the best possible\nalgorithm with Bernoulli tests, and in sparse cases is the best proven\nperformance of any practical algorithm. We also give an algorithm-independent\nupper bound for the constant column weight case; for dense cases this is again\na 31% increase over the analogous Bernoulli result. \n\n"}
{"id": "1602.03571", "contents": "Title: High Dimensional Inference with Random Maximum A-Posteriori\n  Perturbations Abstract: This paper presents a new approach, called perturb-max, for high-dimensional\nstatistical inference that is based on applying random perturbations followed\nby optimization. This framework injects randomness to maximum a-posteriori\n(MAP) predictors by randomly perturbing the potential function for the input. A\nclassic result from extreme value statistics asserts that perturb-max\noperations generate unbiased samples from the Gibbs distribution using\nhigh-dimensional perturbations. Unfortunately, the computational cost of\ngenerating so many high-dimensional random variables can be prohibitive.\nHowever, when the perturbations are of low dimension, sampling the perturb-max\nprediction is as efficient as MAP optimization. This paper shows that the\nexpected value of perturb-max inference with low dimensional perturbations can\nbe used sequentially to generate unbiased samples from the Gibbs distribution.\nFurthermore the expected value of the maximal perturbations is a natural bound\non the entropy of such perturb-max models. A measure concentration result for\nperturb-max values shows that the deviation of their sampled average from its\nexpectation decays exponentially in the number of samples, allowing effective\napproximation of the expectation. \n\n"}
{"id": "1602.03906", "contents": "Title: How to group wireless nodes together? Abstract: This report presents a survey on how to group together in a static way planar\nnodes, that may belong to a wireless network (ad hoc or cellular). The aim is\nto identify appropriate methods that could also be applied for Point Processes.\nSpecifically matching pairs and algorithms are initially discussed. Next,\nspecifically for Point Processes, the Nearest Neighbour and Lilypond models are\npresented. Properties and results for the two models are stated. Original\nbounds are given for the value of the so-called generation number, which is\nrelated to the size of the nearest neighbour cluster. Finally, a variation of\nthe nearest neighbour grouping is proposed and an original metric is\nintroduced, named here the ancestor number. This is used to facilitate the\nanalysis of the distribution of cluster size. Based on this certain related\nbounds are derived. The report and the analysis included show clearly the\ndifficulty of working in point processes with static clusters of size greater\nthan two, when these are defined by proximity criteria. \n\n"}
{"id": "1602.04207", "contents": "Title: Fundamental Limits of Cache-Aided Interference Management Abstract: We consider a system comprising a library of $N$ files (e.g., movies) and a\nwireless network with $K_T$ transmitters, each equipped with a local cache of\nsize of $M_T$ files, and $K_R$ receivers, each equipped with a local cache of\nsize of $M_R$ files. Each receiver will ask for one of the $N$ files in the\nlibrary, which needs to be delivered. The objective is to design the cache\nplacement (without prior knowledge of receivers' future requests) and the\ncommunication scheme to maximize the throughput of the delivery. In this\nsetting, we show that the sum degrees-of-freedom (sum-DoF) of\n$\\min\\left\\{\\frac{K_T M_T+K_R M_R}{N},K_R\\right\\}$ is achievable, and this is\nwithin a factor of 2 of the optimum, under one-shot linear schemes. This result\nshows that (i) the one-shot sum-DoF scales linearly with the aggregate cache\nsize in the network (i.e., the cumulative memory available at all nodes), (ii)\nthe transmitters' and receivers' caches contribute equally in the one-shot\nsum-DoF, and (iii) caching can offer a throughput gain that scales linearly\nwith the size of the network.\n  To prove the result, we propose an achievable scheme that exploits the\nredundancy of the content at transmitters' caches to cooperatively zero-force\nsome outgoing interference and availability of the unintended content at\nreceivers' caches to cancel (subtract) some of the incoming interference. We\ndevelop a particular pattern for cache placement that maximizes the overall\ngains of cache-aided transmit and receive interference cancellations. For the\nconverse, we present an integer optimization problem which minimizes the number\nof communication blocks needed to deliver any set of requested files to the\nreceivers. We then provide a lower bound on the value of this optimization\nproblem, hence leading to an upper bound on the linear one-shot sum-DoF of the\nnetwork, which is within a factor of 2 of the achievable sum-DoF. \n\n"}
{"id": "1602.04521", "contents": "Title: Quasi Linear Codes: Application to Point-to-Point and Multi-Terminal\n  Source Coding Abstract: A new ensemble of structured codes is introduced. These codes are called\nQuasi Linear Codes (QLC). The QLC's are constructed by taking subsets of linear\ncodes. They have a looser structure compared to linear codes and are not closed\nunder addition. We argue that these codes provide gains in terms of achievable\nRate-Distortions (RD) in different multi-terminal source coding problems. We\nderive the necessary covering bounds for analyzing the performance of QLC's. We\nthen consider the Multiple-Descriptions (MD) problem, and prove through an\nexample that the application of QLC's gives an improved achievable RD region\nfor this problem. Finally, we derive an inner bound to the achievable RD region\nfor the general MD problem which strictly contains all of the previous known\nachievable regions. \n\n"}
{"id": "1602.05072", "contents": "Title: Optimizing Transmission Lengths for Limited Feedback with Non-Binary\n  LDPC Examples Abstract: This paper presents a general approach for optimizing the number of symbols\nin increments (packets of incremental redundancy) in a feedback communication\nsystem with a limited number of increments. This approach is based on a tight\nnormal approximation on the rate for successful decoding. Applying this\napproach to a variety of feedback systems using non-binary (NB) low-density\nparity-check (LDPC) codes shows that greater than 90% of capacity can be\nachieved with average blocklengths fewer than 500 transmitted bits. One result\nis that the performance with ten increments closely approaches the performance\nwith an infinite number of increments. The paper focuses on binary- input\nadditive-white Gaussian noise (BI-AWGN) channels but also demonstrates that the\nnormal approximation works well on examples of fading channels as well as\nhigh-SNR AWGN channels that require larger QAM constellations. The paper\nexplores both variable-length feedback codes with termination (VLFT) and the\nmore practical variable length feedback (VLF) codes without termination that\nrequire no assumption of noiseless transmitter confirmation. For VLF we\nconsider both a two-phase scheme and CRC-based scheme. \n\n"}
{"id": "1602.06529", "contents": "Title: Robust Resource Allocation for Full-Duplex Cognitive Radio Systems Abstract: In this paper, we investigate resource allocation algorithm design for\nfull-duplex (FD) cognitive radio systems. The secondary network employs a FD\nbase station for serving multiple half-duplex downlink and uplink users\nsimultaneously. We study the resource allocation design for minimizing the\nmaximum interference leakage to primary users while providing quality of\nservice for secondary users. The imperfectness of the channel state information\nof the primary users is taken into account for robust resource allocation\nalgorithm design. The algorithm design is formulated as a non-convex\noptimization problem and solved optimally by applying semidefinite programming\n(SDP) relaxation. Simulation results not only show the significant reduction in\ninterference leakage compared to baseline schemes, but also confirm the\nrobustness of the proposed algorithm. \n\n"}
{"id": "1602.06847", "contents": "Title: Improving Wireless Physical Layer Security via Exploiting Co-Channel\n  Interference Abstract: This paper considers a scenario in which a source-destination pair needs to\nestablish a confidential connection against an external eavesdropper, aided by\nthe interference generated by another source-destination pair that exchanges\npublic messages. The goal is to compute the maximum achievable secrecy degrees\nof freedom (S.D.o.F) region of a MIMO two-user wiretap network. First, a\ncooperative secrecy transmission scheme is proposed, whose feasible set is\nshown to achieve all S.D.o.F. pairs on the S.D.o.F. region boundary. In this\nway, the determination of the S.D.o.F. region is reduced to a problem of\nmaximizing the S.D.o.F. pair over the proposed transmission scheme. The maximum\nachievable S.D.o.F. region boundary points are obtained in closed form, and the\nconstruction of the precoding matrices achieving the maximum S.D.o.F. region\nboundary is provided. The obtained analytical expressions clearly show the\nrelation between the maximum achievable S.D.o.F. region and the number of\nantennas at each terminal. \n\n"}
{"id": "1602.09001", "contents": "Title: Strong Coordination over Multi-hop Line Networks Abstract: We analyze the problem of strong coordination over a multi-hop line network\nin which the node initiating the coordination is a terminal network node. We\nassume that each node has access to a certain amount of randomness that is\nlocal to the node, and that the nodes share some common randomness, which are\nused together with explicit hop-by-hop communication to achieve strong\ncoordination. We derive the trade-offs among the required rates of\ncommunication on the network links, the rates of local randomness available to\nnetwork nodes, and the rate of common randomness to realize strong\ncoordination. We present an achievable coding scheme built using multiple\nlayers of channel resolvability codes, and establish several settings in which\nthis scheme is proven to offer the best possible trade-offs. \n\n"}
{"id": "1603.01566", "contents": "Title: Identifiability of an X-rank decomposition of polynomial maps Abstract: In this paper, we study a polynomial decomposition model that arises in\nproblems of system identification, signal processing and machine learning. We\nshow that this decomposition is a special case of the X-rank decomposition ---\na powerful novel concept in algebraic geometry that generalizes the tensor CP\ndecomposition. We prove new results on generic/maximal rank and on\nidentifiability of a particular polynomial decomposition model. In the paper,\nwe try to make results and basic tools accessible for general audience\n(assuming no knowledge of algebraic geometry or its prerequisites). \n\n"}
{"id": "1603.01651", "contents": "Title: Degrees of Freedom of the MIMO 2x2 Interference Network with General\n  Message Sets Abstract: We establish the DoF region for the MIMO 2x2 interference network with a\ngeneral message set, consisting of nine messages, one for each pair of a subset\nof transmitters at which that message is known and a subset of receivers where\nthat message is desired. An outer bound on the general nine-message network is\nobtained and then it is shown to be tight, establishing the DoF region for the\nmost general antenna setting wherein all four nodes have an arbitrary number of\nantennas each. The DoF-optimal scheme is applicable to the MIMO 2x2 network\nwith constant channel coefficients, and hence, a fortiori, to time/frequency\nvarying channel scenarios. In particular, a linear precoding scheme is proposed\nthat can achieve all the DoF tuples in the DoF region. In it, the precise roles\nplayed by transmit zero-forcing, interference alignment, random beamforming,\nsymbol extensions and asymmetric complex signaling are delineated. For\ninstance, we identify a class of antenna settings in which ACS is required to\nachieve the fractional-valued corner points. Evidently, the DoF regions of all\npreviously unknown cases of the 2x2 interference network with a subset of the\nnine-messages are established as special cases of the general result of this\npaper. In particular, the DoF region of the well-known four-message (and even\nthree-message) MIMO X channel is established. This problem had remained open\ndespite previous studies which had found inner and outer bounds that were not\ntight in general. Hence, the DoF regions of all special cases obtained from the\ngeneral DoF region of the nine-message 2x2 interference network of this work\nthat include at least three of the four X channel messages are new, among many\nothers. Our work sheds light on how the same physical 2x2 network could be used\nby a suitable choice of message sets to take most advantage of the channel\nresource in a flexible and efficient manner. \n\n"}
{"id": "1603.01681", "contents": "Title: A single-phase, proximal path-following framework Abstract: We propose a new proximal, path-following framework for a class of\nconstrained convex problems. We consider settings where the nonlinear---and\npossibly non-smooth---objective part is endowed with a proximity operator, and\nthe constraint set is equipped with a self-concordant barrier. Our approach\nrelies on the following two main ideas. First, we re-parameterize the\noptimality condition as an auxiliary problem, such that a good initial point is\navailable; by doing so, a family of alternative paths towards the optimum is\ngenerated. Second, we combine the proximal operator with path-following ideas\nto design a single-phase, proximal, path-following algorithm. Our method has\nseveral advantages. First, it allows handling non-smooth objectives via\nproximal operators; this avoids lifting the problem dimension in order to\naccommodate non-smooth components in optimization. Second, it consists of only\na \\emph{single phase}: While the overall convergence rate of classical\npath-following schemes for self-concordant objectives does not suffer from the\ninitialization phase, proximal path-following schemes undergo slow convergence,\nin order to obtain a good starting point \\cite{TranDinh2013e}. In this work, we\nshow how to overcome this limitation in the proximal setting and prove that our\nscheme has the same $\\mathcal{O}(\\sqrt{\\nu}\\log(1/\\varepsilon))$ worst-case\niteration-complexity with standard approaches \\cite{Nesterov2004,Nesterov1994}\nwithout requiring an initial phase, where $\\nu$ is the barrier parameter and\n$\\varepsilon$ is a desired accuracy. Finally, our framework allows errors in\nthe calculation of proximal-Newton directions, without sacrificing the\nworst-case iteration complexity. We demonstrate the merits of our algorithm via\nthree numerical examples, where proximal operators play a key role. \n\n"}
{"id": "1603.02365", "contents": "Title: On the Polar Code Encoding in Fading Channels Abstract: Besides the determined construction of polar codes in BEC channels, different\nconstruction techniques have been proposed for AWGN channels. The current\nstate-of-the-art algorithm starts with a design-SNR (or an operating SNR) and\nthen processing is carried out to approximate each individual bit channel.\nHowever, as found in this paper, for fading channels, an operating SNR can not\nbe directly used in approximating the bit channels. To achieve a better BER\nperformance, the input SNR for the polar code construction in fadding channels\nis derived. A selection of the design-SNR for both the AWGN and the fading\nchannels from an information theoretical point of view is studied. Also\npresented in this paper is the study of sacrificing a small data rate to gain\norders of magnitude increase in the BER performance. \n\n"}
{"id": "1603.04389", "contents": "Title: Linear and Nonlinear Frequency-Division Multiplexing Abstract: Two signal multiplexing schemes for optical fiber communication are\nconsidered: Wavelength-division multiplexing (WDM) and nonlinear\nfrequency-division multiplexing (NFDM), based on the nonlinear Fourier\ntransform (NFT). Achievable information rates (AIRs) of NFDM and WDM are\ncompared in a network scenario with an ideal lossless model of the optical\nfiber in the defocusing regime. It is shown that the NFDM AIR is greater than\nthe WDM AIR subject to a bandwidth and average power constraint, in a\nrepresentative system with one symbol per user. The improvement results from\nnonlinear signal multiplexing. \n\n"}
{"id": "1603.05846", "contents": "Title: A Connection Between Locally Repairable Codes and Exact Regenerating\n  Codes Abstract: Typically, locally repairable codes (LRCs) and regenerating codes have been\nstudied independently of each other, and it has not been clear how the\nparameters of one relate to those of the other. In this paper, a novel\nconnection between locally repairable codes and exact regenerating codes is\nestablished. Via this connection, locally repairable codes are interpreted as\nexact regenerating codes. Further, some of these codes are shown to perform\nbetter than time-sharing codes between minimum bandwidth regenerating and\nminimum storage regenerating codes. \n\n"}
{"id": "1603.07135", "contents": "Title: Simplicial Complex Entropy Abstract: We propose an entropy function for simplicial complices. Its value gives the\nexpected cost of the optimal encoding of sequences of vertices of the complex,\nwhen any two vertices belonging to the same simplex are indistinguishable. We\nshow that the proposed entropy function can be computed efficiently. By\ncomputing the entropy of several complices consisting of hundreds of simplices,\nwe show that the proposed entropy function can be used in the analysis of the\nlarge sequences of simplicial complices that often appear in computational\ntopology applications. \n\n"}
{"id": "1603.07181", "contents": "Title: Iterative Scaling Algorithm for Channels Abstract: Here we define a procedure for evaluating KL-projections (I- and\nrI-projections) of channels. These can be useful in the decomposition of mutual\ninformation between input and outputs, e.g. to quantify synergies and\ninteractions of different orders, as well as information integration and other\nrelated measures of complexity.\n  The algorithm is a generalization of the standard iterative scaling\nalgorithm, which we here extend from probability distributions to channels\n(also known as transition kernels). \n\n"}
{"id": "1603.07327", "contents": "Title: Constellation Shaping for WDM systems using 256QAM/1024QAM with\n  Probabilistic Optimization Abstract: In this paper, probabilistic shaping is numerically and experimentally\ninvestigated for increasing the transmission reach of wavelength division\nmultiplexed (WDM) optical communication system employing quadrature amplitude\nmodulation (QAM). An optimized probability mass function (PMF) of the QAM\nsymbols is first found from a modified Blahut-Arimoto algorithm for the optical\nchannel. A turbo coded bit interleaved coded modulation system is then applied,\nwhich relies on many-to-one labeling to achieve the desired PMF, thereby\nachieving shaping gain. Pilot symbols at rate at most 2% are used for\nsynchronization and equalization, making it possible to receive input\nconstellations as large as 1024QAM. The system is evaluated experimentally on a\n10 GBaud, 5 channels WDM setup. The maximum system reach is increased w.r.t.\nstandard 1024QAM by 20% at input data rate of 4.65 bits/symbol and up to 75% at\n5.46 bits/symbol. It is shown that rate adaptation does not require changing of\nthe modulation format. The performance of the proposed 1024QAM shaped system is\nvalidated on all 5 channels of the WDM signal for selected distances and rates.\nFinally, it was shown via EXIT charts and BER analysis that iterative\ndemapping, while generally beneficial to the system, is not a requirement for\nachieving the shaping gain. \n\n"}
{"id": "1603.07513", "contents": "Title: Achievable DoF Regions of MIMO Networks with Imperfect CSIT Abstract: We focus on a two-receiver Multiple-Input-Multiple-Output (MIMO) Broadcast\nChannel (BC) and Interference Channel (IC) with an arbitrary number of antennas\nat each node. We assume an imperfect knowledge of local Channel State\nInformation at the Transmitters (CSIT), whose error decays with the\nSignal-to-Noise-Ratio. With such configuration, we characterize the achievable\nDegrees-of-Freedom (DoF) regions in both BC and IC, by proposing a\nRate-Splitting approach, which divides each receiver's message into a common\npart and a private part. Compared to the RS scheme designed for the symmetric\nMIMO case, this scheme is suitable for the general asymmetric deployment with\nan arbitrary number of antennas at each node. In BC, the proposed block 1)\nemploys an unequal power allocation to the private messages of the two\nreceivers, 2) exploits the benefit of having an extra spatial dimension at one\nreceiver, and 3) is carried out with a Space-Time transmission. These features\nenable the scheme to yield a greater DoF region than trivially extending the\nscheme designed for the symmetric case. In IC, we modify the scheme proposed\nfor the BC case by applying a linear transformation to the channel matrices.\nSuch a linear transformation allows us to identify the signal space where the\ntwo transmitted signals interfere with each other and propose a proper power\nallocation policy. The achievable DoF regions are shown to be optimal for some\nantenna configurations. \n\n"}
{"id": "1603.07628", "contents": "Title: On Communication through a Gaussian Channel with an MMSE Disturbance\n  Constraint Abstract: This paper considers a Gaussian channel with one transmitter and two\nreceivers. The goal is to maximize the communication rate at the\nintended/primary receiver subject to a disturbance constraint at the\nunintended/secondary receiver. The disturbance is measured in terms of minimum\nmean square error (MMSE) of the interference that the transmission to the\nprimary receiver inflicts on the secondary receiver.\n  The paper presents a new upper bound for the problem of maximizing the mutual\ninformation subject to an MMSE constraint. The new bound holds for vector\ninputs of any length and recovers a previously known limiting (when the length\nof vector input tends to infinity) expression from the work of Bustin\n$\\textit{et al.}$ The key technical novelty is a new upper bound on the MMSE.\nThis bound allows one to bound the MMSE for all signal-to-noise ratio (SNR)\nvalues $\\textit{below}$ a certain SNR at which the MMSE is known (which\ncorresponds to the disturbance constraint). This bound complements the\n`single-crossing point property' of the MMSE that upper bounds the MMSE for all\nSNR values $\\textit{above}$ a certain value at which the MMSE value is known.\nThe MMSE upper bound provides a refined characterization of the\nphase-transition phenomenon which manifests, in the limit as the length of the\nvector input goes to infinity, as a discontinuity of the MMSE for the problem\nat hand.\n  For vector inputs of size $n=1$, a matching lower bound, to within an\nadditive gap of order $O \\left( \\log \\log \\frac{1}{\\sf MMSE} \\right)$ (where\n${\\sf MMSE}$ is the disturbance constraint), is shown by means of the mixed\ninputs technique recently introduced by Dytso $\\textit{et al.}$ \n\n"}
{"id": "1603.08236", "contents": "Title: Improving the Performance of Nested Lattice Codes Using Concatenation Abstract: A fundamental problem in coding theory is the design of an efficient coding\nscheme that achieves the capacity of the additive white Gaussian (AWGN)\nchannel. The main objective of this short note is to point out that by\nconcatenating a capacity-achieving nested lattice code with a suitable\nhigh-rate linear code over an appropriate finite field, we can achieve the\ncapacity of the AWGN channel with polynomial encoding and decoding complexity.\nSpecifically, we show that using inner Construction-A lattice codes and outer\nReed-Solomon codes, we can obtain capacity-achieving codes whose encoding and\ndecoding complexities grow as $O(N^2)$, while the probability of error decays\nexponentially in $N$, where $N$ denotes the blocklength. Replacing the outer\nReed-Solomon code by an expander code helps us further reduce the decoding\ncomplexity to $O(N\\log^2N)$. This also gives us a recipe for converting a\nhigh-complexity nested lattice code for a Gaussian channel to a low-complexity\nconcatenated code without any loss in the asymptotic rate. As examples, we\ndescribe polynomial-time coding schemes for the wiretap channel, and the\ncompute-and-forward scheme for computing integer linear combinations of\nmessages. \n\n"}
{"id": "1603.08817", "contents": "Title: Compressive Sensing Based Design of Sparse Tripole Arrays Abstract: This paper considers the problem of designing sparse linear tripole arrays.\nIn such arrays at each antenna location there are three orthogonal dipoles,\nallowing full measurement of both the horizontal and vertical components of the\nreceived waveform. We formulate this problem from the viewpoint of Compressive\nSensing (CS). However, unlike for isotropic array elements (single antenna), we\nnow have three complex valued weight coefficients associated with each\npotential location (due to the three dipoles), which have to be simultaneously\nminimised. If this is not done, we may only set the weight coefficients of\nindividual dipoles to be zero valued, rather than complete tripoles, meaning\nsome dipoles may remain at each location. Therefore, the contributions of this\npaper are to formulate the design of sparse tripole arrays as an optimisation\nproblem, and then we obtain a solution based on the minimisation of a modified\nl1 norm or a series of iteratively solved reweighted minimisations, which\nensure a truly sparse solution. Design examples are provided to verify the\neffectiveness of the proposed methods and show that a good approximation of a\nreference pattern can be achieved using fewer tripoles than a Uniform Linear\nArray (ULA) of equivalent length. \n\n"}
{"id": "1603.09263", "contents": "Title: Universal Lattice Codes for MIMO Channels Abstract: We propose a coding scheme that achieves the capacity of the compound MIMO\nchannel with algebraic lattices. Our lattice construction exploits the\nmultiplicative structure of number fields and their group of units to absorb\nill-conditioned channel realizations. To shape the constellation, a discrete\nGaussian distribution over the lattice points is applied. These techniques,\nalong with algebraic properties of the proposed lattices, are then used to\nconstruct a sub-optimal de-coupled coding schemes that achieves a gap to\ncompound capacity by decoding in a lattice that does not depend of the channel\nrealization. The gap is characterized in terms of algebraic invariants of the\ncodes, and shown to be significantly smaller than previous schemes in the\nliterature. We also exhibit alternative algebraic constructions that achieve\nthe capacity of ergodic fading channels. \n\n"}
{"id": "1604.00700", "contents": "Title: From compressed sensing to compressed bit-streams: practical encoders,\n  tractable decoders Abstract: Compressed sensing is now established as an effective method for dimension\nreduction when the underlying signals are sparse or compressible with respect\nto some suitable basis or frame. One important, yet under-addressed problem\nregarding the compressive acquisition of analog signals is how to perform\nquantization. This is directly related to the important issues of how\n\"compressed\" compressed sensing is (in terms of the total number of bits one\nends up using after acquiring the signal) and ultimately whether compressed\nsensing can be used to obtain compressed representations of suitable signals.\nBuilding on our recent work, we propose a concrete and practicable method for\nperforming \"analog-to-information conversion\". Following a compressive signal\nacquisition stage, the proposed method consists of a quantization stage, based\non $\\Sigma\\Delta$ (sigma-delta) quantization, and a subsequent encoding\n(compression) stage that fits within the framework of compressed sensing\nseamlessly. We prove that, using this method, we can convert analog compressive\nsamples to compressed digital bitstreams and decode using tractable algorithms\nbased on convex optimization. We prove that the proposed AIC provides a nearly\noptimal encoding of sparse and compressible signals. Finally, we present\nnumerical experiments illustrating the effectiveness of the proposed\nanalog-to-information converter. \n\n"}
{"id": "1604.01835", "contents": "Title: Exploiting Full-duplex Receivers for Achieving Secret Communications in\n  Multiuser MISO Networks Abstract: We consider a broadcast channel, in which a multi-antenna transmitter (Alice)\nsends $K$ confidential information signals to $K$ legitimate users (Bobs) in\nthe presence of $L$ eavesdroppers (Eves). Alice uses MIMO precoding to generate\nthe information signals along with her own (Tx-based) friendly jamming.\nInterference at each Bob is removed by MIMO zero-forcing. This, however, leaves\na \"vulnerability region\" around each Bob, which can be exploited by a nearby\nEve. We address this problem by augmenting Tx-based friendly jamming (TxFJ)\nwith Rx-based friendly jamming (RxFJ), generated by each Bob. Specifically,\neach Bob uses self-interference suppression (SIS) to transmit a friendly\njamming signal while simultaneously receiving an information signal over the\nsame channel. We minimize the powers allocated to the information, TxFJ, and\nRxFJ signals under given guarantees on the individual secrecy rate for each\nBob. The problem is solved for the cases when the eavesdropper's channel state\ninformation is known/unknown. Simulations show the effectiveness of the\nproposed solution. Furthermore, we discuss how to schedule transmissions when\nthe rate requirements need to be satisfied on average rather than\ninstantaneously. Under special cases, a scheduling algorithm that serves only\nthe strongest receivers is shown to outperform the one that schedules all\nreceivers. \n\n"}
{"id": "1604.02986", "contents": "Title: Stronger wireless signals appear more Poisson Abstract: Keeler, Ross and Xia (2016) recently derived approximation and convergence\nresults, which imply that the point process formed from the signal strengths\nreceived by an observer in a wireless network under a general statistical\npropagation model can be modelled by an inhomogeneous Poisson point process on\nthe positive real line. The basic requirement for the results to apply is that\nthere must be a large number of transmitters with different locations and\nrandom propagation effects.The aim of this note is to apply some of the main\nresults of Keeler, Ross and Xia (2016) in a less general but more easily\napplicable form to illustrate how the results can be applied in practice. New\nresults are derived that show that it is the strongest signals, after being\nweakened by random propagation effects, that behave like a Poisson process,\nwhich supports recent experimental work. \n\n"}
{"id": "1604.04826", "contents": "Title: On the Non-existence of certain classes of generalized bent functions Abstract: We obtain new non-existence results of generalized bent functions from\n\\ZZ^n_q to \\ZZ_q (called type [n,q]). The first case is a class of types where\nq=2p_1^{r_1}p_2^{r_2}. The second case contains two types [1 <= n <= 3, 2 *\n31^e]$ and [1 <= n <= 7,2 * 151^e]. \n\n"}
{"id": "1604.05908", "contents": "Title: 3D Massive MIMO Systems: Modeling and Performance Analysis Abstract: Multiple-input-multiple-output (MIMO) systems of current LTE releases are\ncapable of adaptation in the azimuth only. Recently, the trend is to enhance\nsystem performance by exploiting the channel's degrees of freedom in the\nelevation, which necessitates the characterization of 3D channels. We present\nan information-theoretic channel model for MIMO systems that supports the\nelevation dimension. The model is based on the principle of maximum entropy,\nwhich enables us to determine the distribution of the channel matrix consistent\nwith the prior information on the angles. Based on this model, we provide\nanalytical expression for the cumulative density function (CDF) of the mutual\ninformation (MI) for systems with a single receive and finite number of\ntransmit antennas in the general signal-to-interference-plus-noise-ratio (SINR)\nregime. The result is extended to systems with finite receive antennas in the\nlow SINR regime. A Gaussian approximation to the asymptotic behavior of MI\ndistribution is derived for the large number of transmit antennas and paths\nregime. We corroborate our analysis with simulations that study the performance\ngains realizable through meticulous selection of the transmit antenna downtilt\nangles, confirming the potential of elevation beamforming to enhance system\nperformance. The results are directly applicable to the analysis of 5G\n3D-Massive MIMO-systems. \n\n"}
{"id": "1604.06531", "contents": "Title: The Synergistic Gains of Coded Caching and Delayed Feedback Abstract: In this paper, we consider the $K$-user cache-aided wireless MISO broadcast\nchannel (BC) with random fading and delayed CSIT, and identify the optimal\ncache-aided degrees-of-freedom (DoF) performance within a factor of 4. The\nachieved performance is due to a scheme that combines basic coded-caching with\nMAT-type schemes, and which efficiently exploits the prospective-hindsight\nsimilarities between these two methods. This delivers a powerful synergy\nbetween coded caching and delayed feedback, in the sense that the total\nsynergistic DoF-gain can be much larger than the sum of the individual gains\nfrom delayed CSIT and from coded caching.\n  The derived performance interestingly reveals --- for the first time ---\nsubstantial DoF gains from coded caching, even when the (normalized) cache size\n$\\gamma$ (fraction of the library stored at each receiving device) is very\nsmall. Specifically, a microscopic $\\gamma \\approx e^{-G}$ can come within a\nfactor of $G$ from the interference-free optimal. For example, storing at each\ndevice only a \\emph{thousandth} of what is deemed as `popular' content\n($\\gamma\\approx 10^{-3}$), we approach the interference-free optimal within a\nfactor of $ln(10^3) \\approx 7$ (per user DoF of $1/7$), for any number of\nusers. This result carries an additional practical ramification as it reveals\nhow to use coded caching to essentially buffer CSI, thus partially ameliorating\nthe burden of having to acquire real-time CSIT. \n\n"}
{"id": "1604.06971", "contents": "Title: On principles of large deviation and selected data compression Abstract: The Shannon Noiseless coding theorem (the data-compression principle) asserts\nthat for an information source with an alphabet $\\mathcal X=\\{0,\\ldots ,\\ell\n-1\\}$ and an asymptotic equipartition property, one can reduce the number of\nstored strings $(x_0,\\ldots ,x_{n-1})\\in {\\mathcal X}^n$ to $\\ell^{nh}$ with an\narbitrary small error-probability. Here $h$ is the entropy rate of the source\n(calculated to the base $\\ell$). We consider further reduction based on the\nconcept of utility of a string measured in terms of a rate of a weight\nfunction. The novelty of the work is that the distribution of memory is\nanalyzed from a probabilistic point of view. A convenient tool for assessing\nthe degree of reduction is a probabilistic large deviation principle. Assuming\na Markov-type setting, we discuss some relevant formulas, including the case of\na general alphabet. \n\n"}
{"id": "1604.08178", "contents": "Title: Centralized Coded Caching for Heterogeneous Lossy Requests Abstract: Centralized coded caching of popular contents is studied for users with\nheterogeneous distortion requirements, corresponding to diverse processing and\ndisplay capabilities of mobile devices. Users' distortion requirements are\nassumed to be fixed and known, while their particular demands are revealed only\nafter the placement phase. Modeling each file in the database as an independent\nand identically distributed Gaussian vector, the minimum delivery rate that can\nsatisfy any demand combination within the corresponding distortion target is\nstudied. The optimal delivery rate is characterized for the special case of two\nusers and two files for any pair of distortion requirements. For the general\nsetting with multiple users and files, a layered caching and delivery scheme,\nwhich exploits the successive refinability of Gaussian sources, is proposed.\nThis scheme caches each content in multiple layers, and it is optimized by\nsolving two subproblems: lossless caching of each layer with heterogeneous\ncache capacities, and allocation of available caches among layers. The delivery\nrate minimization problem for each layer is solved numerically, while two\nschemes, called the proportional cache allocation (PCA) and ordered cache\nallocation (OCA), are proposed for cache allocation. These schemes are compared\nwith each other and the cut-set bound through numerical simulations. \n\n"}
{"id": "1604.08231", "contents": "Title: When Can Helper Node Selection Improve Regenerating Codes? Part I:\n  Graph-Based Analysis Abstract: Regenerating codes (RCs) can significantly reduce the repair-bandwidth of\ndistributed storage networks. Initially, the analysis of RCs was based on the\nassumption that during the repair process, the newcomer does not distinguish\n(among all surviving nodes) which nodes to access, i.e., the newcomer is\noblivious to the set of helpers being used. Such a scheme is termed the blind\nhelper selection (BHS) scheme. Nonetheless, it is intuitive in practice that\nthe newcomer should choose to access only those \"good\" helpers. In this\ntwo-part paper, a new characterization of the effect of choosing the helper\nnodes in terms of the storage-bandwidth tradeoff is given. Specifically, the\nanswer to the following fundamental question is provided: Under what condition\ndoes proactively choosing the helper nodes improve the storage-bandwidth\ntradeoff?\n  Through a graph-based analysis, this Part I paper answers this question by\nproviding a necessary and sufficient condition under which optimally choosing\ngood helpers strictly improves the storage-bandwidth tradeoff. A low-complexity\nhelper selection solution, termed the family helper selection (FHS) scheme, is\nproposed and the corresponding storage/repair-bandwidth curve is characterized.\nThis Part I paper also proves that under some design parameters, the FHS scheme\nis indeed optimal among all helper selection schemes. In the Part II paper, an\nexplicit construction of an exact-repair code is proposed that achieves the\nminimum-bandwidth-regenerating (MBR) point of the FHS scheme. The new\nexact-repair code can be viewed as a generalization of the existing fractional\nrepetition code. \n\n"}
{"id": "1605.01473", "contents": "Title: Topological Interference Management with Reconfigurable Antennas Abstract: We study the symmetric degrees-of-freedom (DoF) of partially connected\ninterference networks under linear coding strategies at transmitters without\nchannel state information beyond topology. We assume that the receivers are\nequipped with reconfigurable antennas that can switch among their preset modes.\nIn such a network setting, we characterize the class of network topologies in\nwhich half linear symmetric DoF is achievable. Moreover, we derive a general\nupper bound on the linear symmetric DoF for arbitrary network topologies. We\nalso show that this upper bound is tight if the transmitters have at most two\nco-interferers. \n\n"}
{"id": "1605.01829", "contents": "Title: Downlink Transmission of Short Packets: Framing and Control Information\n  Revisited Abstract: Cellular wireless systems rely on frame-based transmissions. The frame design\nis conventionally based on heuristics, consisting of a frame header and a data\npart. The frame header contains control information that provides pointers to\nthe messages within the data part. In this paper, we revisit the principles of\nframe design and show the impact of the new design in scenarios that feature\nshort data packets which are central to various 5G and Internet of Things\napplications. We treat framing for downlink transmission in an AWGN broadcast\nchannel with K users, where the sizes of the messages to the users are random\nvariables. Using approximations from finite blocklength information theory, we\nestablish a framework in which a message to a given user is not necessarily\nencoded as a single packet, but may be grouped with the messages to other users\nand benefit from the improved efficiency of longer codes. This requires changes\nin the way control information is sent, and it requires that the users need to\nspend power decoding other messages, thereby increasing the average power\nconsumption. We show that the common heuristic design is only one point on a\ncurve that represents the trade-off between latency and power consumption. \n\n"}
{"id": "1605.02233", "contents": "Title: On the Capacity of the Beta-Binomial Channel Model for Multi-Level Cell\n  Flash Memories Abstract: The beta-binomial (BBM) channel model was recently proposed to model the\noverdispersed statistics of empirically observed bit errors in multi-level cell\n(MLC) flash memories. In this paper, we study the capacity of the BBM channel\nmodel for MLC flash memories. Using the compound channel approach, we first\nshow that the BBM channel model capacity is zero. However, through empirical\nobservation, this appears to be a very pessimistic estimate of the flash memory\nchannel capacity. We propose a refined channel model called the\ntruncated-support beta-binomial (TS-BBM) channel model and derive its capacity.\nUsing empirical error statistics from 1X-nm and 2Y-nm MLC flash memories, we\nnumerically estimate the TS-BBM channel model capacity as a function of the\nprogram/erase (P/E) cycling stress. The capacity of the 2-TS-BBM channel model\nprovides an upper bound on the coding rates for the flash memory chip assuming\na single binary error correction code is used. \n\n"}
{"id": "1605.02423", "contents": "Title: On Deep Holes of Projective Reed-Solomon Codes Abstract: In this paper, we obtain new results on the covering radius and deep holes\nfor projective Reed-Solomon (PRS) codes. \n\n"}
{"id": "1605.02818", "contents": "Title: Brascamp-Lieb Inequality and Its Reverse: An Information Theoretic View Abstract: We generalize a result by Carlen and Cordero-Erausquin on the equivalence\nbetween the Brascamp-Lieb inequality and the subadditivity of relative entropy\nby allowing for random transformations (a broadcast channel). This leads to a\nunified perspective on several functional inequalities that have been gaining\npopularity in the context of proving impossibility results. We demonstrate that\nthe information theoretic dual of the Brascamp-Lieb inequality is a convenient\nsetting for proving properties such as data processing, tensorization,\nconvexity and Gaussian optimality. Consequences of the latter include an\nextension of the Brascamp-Lieb inequality allowing for Gaussian random\ntransformations, the determination of the multivariate Wyner common information\nfor Gaussian sources, and a multivariate version of Nelson's hypercontractivity\ntheorem. Finally we present an information theoretic characterization of a\nreverse Brascamp-Lieb inequality involving a random transformation (a multiple\naccess channel). \n\n"}
{"id": "1605.02894", "contents": "Title: Sharp Sufficient Conditions for Stable Recovery of Block Sparse Signals\n  by Block Orthogonal Matching Pursuit Abstract: In this paper, we use the block orthogonal matching pursuit (BOMP) algorithm\nto recover block sparse signals $\\x$ from measurements $\\y=\\A\\x+\\v$, where $\\v$\nis an $\\ell_2$-bounded noise vector (i.e., $\\|\\v\\|_2\\leq \\epsilon$ for some\nconstant $\\epsilon$). We investigate some sufficient conditions based on the\nblock restricted isometry property (block-RIP) for exact (when $\\v=\\0$) and\nstable (when $\\v\\neq\\0$) recovery of block sparse signals $\\x$. First, on the\none hand, we show that if $\\A$ satisfies the block-RIP with\n$\\delta_{K+1}<1/\\sqrt{K+1}$, then every block $K$-sparse signal $\\x$ can be\nexactly or stably recovered by BOMP in $K$ iterations. On the other hand, we\nshow that, for any $K\\geq 1$ and $1/\\sqrt{K+1}\\leq \\delta<1$, there exists a\nmatrix $\\A$ satisfying the block-RIP with $\\delta_{K+1}=\\delta$ and a block\n$K$-sparse signal $\\x$ such that BOMP may fail to recover $\\x$ in $K$\niterations. Then, we study some sufficient conditions for recovering block\n$\\alpha$-strongly-decaying $K$-sparse signals. We show that if $\\A$ satisfies\nthe block-RIP with $\\delta_{K+1}<\\sqrt{2}/2$, then every\n$\\alpha$-strongly-decaying block $K$-sparse signal can be exactly or stably\nrecovered by BOMP in $K$ iterations under some conditions on $\\alpha$. Our\nnewly found sufficient condition on the block-RIP of $\\A$ is less restrictive\nthan that for $\\ell_1$ minimization for this special class of sparse signals.\nFurthermore, for any $K\\geq 1$, $\\alpha>1$ and $\\sqrt{2}/2\\leq \\delta<1$, the\nrecovery of $\\x$ may fail in $K$ iterations for a sensing matrix $\\A$ which\nsatisfies the block-RIP with $\\delta_{K+1}=\\delta$. Finally, we study some\nsufficient conditions for partial recovery of block sparse signals.\nSpecifically, if $\\A$ satisfies the block-RIP with $\\delta_{K+1}<\\sqrt{2}/2$,\nthen BOMP is guaranteed to recover some blocks of $\\x$ if these blocks satisfy\na sufficient condition. \n\n"}
{"id": "1605.02899", "contents": "Title: Revisited Design Criteria For STBCs With Reduced Complexity ML Decoding Abstract: The design of linear STBCs offering a low-complexity ML decoding using the\nwell known Sphere Decoder (SD) has been extensively studied in last years. The\nfirst considered approach to derive design criteria for the construction of\nsuch codes is based on the Hurwitz-Radon (HR) Theory for mutual orthogonality\nbetween the weight matrices defining the linear code. This appproach served to\nconstruct new families of codes admitting fast sphere decoding such as\nmulti-group decodable, fast decodable, and fast-group decodable codes. In a\nsecond Quadratic Form approach, the Fast Sphere Decoding (FSD) complexity of\nlinear STBCs is captured by a Hurwitz Radon Quadratic Form (HRQF) matrix based\nin its essence on the HR Theory. In this work, we revisit the structure of\nweight matrices for STBCs to admit Fast Sphere decoding. We first propose novel\nsufficient conditions and design criteria for reduced-complexity ML decodable\nlinear STBCs considering an arbitrary number of antennas and linear STBCs of an\narbitrary coding rate. Then we apply the derived criteria to the three families\nof codes mentioned above and provide analytical proofs showing that the FSD\ncomplexity depends only on the weight matrices and their ordering and not on\nthe channel gains or the number of antennas and explain why the so far used HR\ntheory-based approaches are suboptimal. \n\n"}
{"id": "1605.04192", "contents": "Title: Robust On-line Matrix Completion on Graphs Abstract: We study online robust matrix completion on graphs. At each iteration a\nvector with some entries missing is revealed and our goal is to reconstruct it\nby identifying the underlying low-dimensional subspace from which the vectors\nare drawn. We assume there is an underlying graph structure to the data, that\nis, the components of each vector correspond to nodes of a certain (known)\ngraph, and their values are related accordingly. We give algorithms that\nexploit the graph to reconstruct the incomplete data, even in the presence of\noutlier noise. The theoretical properties of the algorithms are studied and\nnumerical experiments using both synthetic and real world datasets verify the\nimproved performance of the proposed technique compared to other state of the\nart algorithms. \n\n"}
{"id": "1605.05717", "contents": "Title: RADON: Repairable Atomic Data Object in Networks Abstract: Erasure codes offer an efficient way to decrease storage and communication\ncosts while implementing atomic memory service in asynchronous distributed\nstorage systems. In this paper, we provide erasure-code-based algorithms having\nthe additional ability to perform background repair of crashed nodes. A repair\noperation of a node in the crashed state is triggered externally, and is\ncarried out by the concerned node via message exchanges with other active nodes\nin the system. Upon completion of repair, the node re-enters active state, and\nresumes participation in ongoing and future read, write, and repair operations.\nTo guarantee liveness and atomicity simultaneously, existing works assume\neither the presence of nodes with stable storage, or presence of nodes that\nnever crash during the execution. We demand neither of these; instead we\nconsider a natural, yet practical network stability condition $N1$ that only\nrestricts the number of nodes in the crashed/repair state during broadcast of\nany message.\n  We present an erasure-code based algorithm $RADON_C$ that is always live, and\nguarantees atomicity as long as condition $N1$ holds. In situations when the\nnumber of concurrent writes is limited, $RADON_C$ has significantly improved\nstorage and communication cost over a replication-based algorithm $RADON_R$,\nwhich also works under $N1$. We further show how a slightly stronger network\nstability condition $N2$ can be used to construct algorithms that never violate\natomicity. The guarantee of atomicity comes at the expense of having an\nadditional phase during the read and write operations. \n\n"}
{"id": "1606.00933", "contents": "Title: Multipair Massive MIMO Relaying with Pilot-Data Transmission Overlay Abstract: We propose a pilot-data transmission overlay scheme for multipair massive\nmultiple-input multiple-output (MIMO) relaying systems employing either half-\nor full-duplex (HD or FD) communications at the relay station (RS). In the\nproposed scheme, pilots are transmitted in partial overlap with data to\ndecrease the channel estimation overhead. The RS can detect the source data\nwith minimal destination pilot interference by exploiting the asymptotic\northogonality of massive MIMO channels. Then pilot-data interference can be\neffectively suppressed with assistance of the detected source data in the\ndestination channel estimation. Due to the transmission overlay, the effective\ndata period is extended, hence improving system throughput. Both theoretical\nand simulation results confirm that the proposed pilot-data overlay scheme\noutperforms the conventional separate pilot-data design in the limited\ncoherence time interval scenario. Moreover, asymptotic analyses at high and low\nSNR regions demonstrate the superiority of the proposed scheme regardless of\nthe coherence interval length. Because of simultaneous transmission, the proper\nallocation of source data transmission and relay data forwarding power can\nfurther improve the system performance. Hence a power allocation problem is\nformulated and a successive convex approximation approach is proposed to solve\nthe non-convex optimization problem with the FD pilot-data transmission\noverlay. \n\n"}
{"id": "1606.03380", "contents": "Title: Low-Complexity MIMO Precoding for Finite-Alphabet Signals Abstract: This paper investigates the design of precoders for single-user\nmultiple-input multiple-output (MIMO) channels, and in particular for\nfinite-alphabet signals. Based on an asymptotic expression for the mutual\ninformation of channels exhibiting line-of-sight components and rather general\nantenna correlations, precoding structures that decompose the general channel\ninto a set of parallel subchannel pairs are proposed. Then, a low-complexity\niterative algorithm is devised to maximize the sum mutual information of all\npairs. The proposed algorithm significantly reduces the computational load of\nexisting approaches with only minimal loss in performance. The complexity\nsavings increase with the number of transmit antennas and with the cardinality\nof the signal alphabet, making it possible to support values thereof that were\nunmanageable with existing solutions. Most importantly, the proposed solution\ndoes not require instantaneous channel state information (CSI) at the\ntransmitter, but only statistical CSI. \n\n"}
{"id": "1606.03668", "contents": "Title: Spatial and Social Paradigms for Interference and Coverage Analysis in\n  Underlay D2D Network Abstract: The homogeneous Poisson point process (PPP) is widely used to model spatial\ndistribution of base stations and mobile terminals. The same process can be\nused to model underlay device-to-device (D2D) network, however, neglecting\nhomophilic relation for D2D pairing presents underestimated system insights. In\nthis paper, we model both spatial and social distributions of interfering D2D\nnodes as proximity based independently marked homogeneous Poisson point\nprocess. The proximity considers physical distance between D2D nodes whereas\nsocial relationship is modeled as Zipf based marks. We apply these two\nparadigms to analyze the effect of interference on coverage probability of\ndistance-proportional power-controlled cellular user. Effectively, we apply two\ntype of functional mappings (physical distance, social marks) to Laplace\nfunctional of PPP. The resulting coverage probability has no closed-form\nexpression, however for a subset of social marks, the mark summation converges\nto digamma and polygamma functions. This subset constitutes the upper and lower\nbounds on coverage probability. We present numerical evaluation of these bounds\non coverage probability by varying number of different parameters. The results\nshow that by imparting simple power control on cellular user, ultra-dense\nunderlay D2D network can be realized without compromising the coverage\nprobability of cellular user. \n\n"}
{"id": "1606.03878", "contents": "Title: Device-independent dimension tests in the prepare-and-measure scenario Abstract: Analyzing the dimension of an unknown quantum system in a device-independent\nmanner, i.e., using only the measurement statistics, is a fundamental task in\nquantum physics and quantum information theory. In this paper, we consider this\nproblem in the prepare-and-measure scenario. Specifically, we provide a lower\nbound on the dimension of the prepared quantum systems which is a function that\nonly depends on the measurement statistics. Furthermore, we show that our bound\nperforms well on several examples. {In particular}, we show that our bound\nprovides new insights into the notion of dimension witness, and we also use it\nto show that the sets of restricted-dimensional prepare-and-measure\ncorrelations are not always convex. \n\n"}
{"id": "1606.04073", "contents": "Title: On Probabilistic Shaping of Quadrature Amplitude Modulation for the\n  Nonlinear Fiber Channel Abstract: Different aspects of probabilistic shaping for a multi-span optical\ncommunication system are studied. First, a numerical analysis of the additive\nwhite Gaussian noise (AWGN) channel investigates the effect of using a small\nnumber of input probability mass functions (PMFs) for a range of\nsignal-to-noise ratios (SNRs), instead of optimizing the constellation shaping\nfor each SNR. It is shown that if a small penalty of at most 0.1 dB SNR to the\nfull shaping gain is acceptable, just two shaped PMFs are required per\nquadrature amplitude modulation (QAM) over a large SNR range. For a multi-span\nwavelength division multiplexing (WDM) optical fiber system with 64QAM input,\nit is shown that just one PMF is required to achieve large gains over uniform\ninput for distances from 1,400 km to 3,000 km. Using recently developed\ntheoretical models that extend the Gaussian noise (GN) model and full-field\nsplit-step simulations, we illustrate the ramifications of probabilistic\nshaping on the effective SNR after fiber propagation. Our results show that,\nfor a fixed average optical launch power, a shaping gain is obtained for the\nnoise contributions from fiber amplifiers and modulation-independent nonlinear\ninterference (NLI), whereas shaping simultaneously causes a penalty as it leads\nto an increased NLI. However, this nonlinear shaping loss is found to have a\nrelatively minor impact, and optimizing the shaped PMF with a\nmodulation-dependent GN model confirms that the PMF found for AWGN is also a\ngood choice for a multi-span fiber system. \n\n"}
{"id": "1606.04467", "contents": "Title: Outer Bounds on the Storage-Repair Bandwidth Tradeoff of Exact-Repair\n  Regenerating Codes Abstract: In this paper, three outer bounds on the normalized storage-repair bandwidth\n(S-RB) tradeoff of regenerating codes having parameter set\n$\\{(n,k,d),(\\alpha,\\beta)\\}$ under the exact-repair (ER) setting are presented.\nThe first outer bound is applicable for every parameter set $(n,k,d)$ and in\nconjunction with a code construction known as {\\em improved layered codes}, it\ncharacterizes the normalized ER tradeoff for the case $(n,k=3,d=n-1)$. It\nestablishes a non-vanishing gap between the ER and functional-repair (FR)\ntradeoffs for every $(n,k,d)$. The second bound is an improvement upon an\nexisting bound due to Mohajer et al. and is tighter than the first bound, in a\nregime away from the Minimum Storage Regeneraing (MSR) point. The third bound\nis for the case of $k=d$, under the linear setting. This outer bound matches\nwith the achievable region of {\\em layered codes} thereby characterizing the\nnormalized ER tradeoff of linear ER codes when $k=d=n-1$. \n\n"}
{"id": "1606.05025", "contents": "Title: Large Antenna Analysis of Multi-Cell Full-Duplex Networks Abstract: We study a multi-cell multi-user MIMO full-duplex network, where each base\nstation (BS) has multiple antennas with full-duplex capability supporting\nsingle-antenna users with either full-duplex or half-duplex radios. We\ncharacterize the up- and downlink ergodic achievable rates for the case of\nlinear precoders and receivers. The rate analysis includes practical\nconstraints such as imperfect self- interference cancellation, channel\nestimation error, training overhead and pilot contamination. We show that the\n2X gain of full-duplex over half-duplex system remains in the asymptotic regime\nwhere the number of BS antennas grows infinitely large. We numerically evaluate\nthe finite SNR and antenna performance, which reveals that full-duplex networks\ncan use significantly fewer antennas to achieve spectral efficiency gain over\nthe half-duplex counterparts. In addition, the overall full-duplex gains can be\nachieved under realistic 3GPP multi-cell network settings despite the increased\ninterference introduced in the full-duplex networks. \n\n"}
{"id": "1606.08587", "contents": "Title: Coordination and Antenna Domain Formation in Cloud-RAN systems Abstract: We study here the problem of Antenna Domain Formation (ADF) in cloud RAN\nsystems, whereby multiple remote radio-heads (RRHs) are each to be assigned to\na set of antenna domains (ADs), such that the total interference between the\nADs is minimized. We formulate the corresponding optimization problem, by\nintroducing the concept of \\emph{interference coupling coefficients} among\npairs of radio-heads. We then propose a low-overhead algorithm that allows the\nproblem to be solved in a distributed fashion, among the aggregation nodes\n(ANs), and establish basic convergence results. Moreover, we also propose a\nsimple relaxation to the problem, thus enabling us to characterize its maximum\nperformance. We follow a layered coordination structure: after the ADs are\nformed, radio-heads are clustered to perform coordinated beamforming using the\nwell known Weighted-MMSE algorithm. Finally, our simulations show that using\nthe proposed ADF mechanism would significantly increase the sum-rate of the\nsystem (with respect to random assignment of radio-heads). \n\n"}
{"id": "1606.09552", "contents": "Title: Proximity Operators of Discrete Information Divergences Abstract: Information divergences allow one to assess how close two distributions are\nfrom each other. Among the large panel of available measures, a special\nattention has been paid to convex $\\varphi$-divergences, such as\nKullback-Leibler, Jeffreys-Kullback, Hellinger, Chi-Square, Renyi, and\nI$_{\\alpha}$ divergences. While $\\varphi$-divergences have been extensively\nstudied in convex analysis, their use in optimization problems often remains\nchallenging. In this regard, one of the main shortcomings of existing methods\nis that the minimization of $\\varphi$-divergences is usually performed with\nrespect to one of their arguments, possibly within alternating optimization\ntechniques. In this paper, we overcome this limitation by deriving new\nclosed-form expressions for the proximity operator of such two-variable\nfunctions. This makes it possible to employ standard proximal methods for\nefficiently solving a wide range of convex optimization problems involving\n$\\varphi$-divergences. In addition, we show that these proximity operators are\nuseful to compute the epigraphical projection of several functions of practical\ninterest. The proposed proximal tools are numerically validated in the context\nof optimal query execution within database management systems, where the\nproblem of selectivity estimation plays a central role. Experiments are carried\nout on small to large scale scenarios. \n\n"}
{"id": "1607.00942", "contents": "Title: On Artificial-Noise Aided Transmit Design for Multi-User MISO Systems\n  with Integrated Services Abstract: This paper considers artificial noise (AN)-aided transmit designs for\nmulti-user MISO systems in the eyes of service integration. Specifically, we\ncombine two sorts of services, and serve them simultaneously: one multicast\nmessage intended for all receivers and one confidential message intended for\nonly one receiver. The confidential message is kept perfectly secure from all\nthe unauthorized receivers. Our goal is to jointly design the optimal input\ncovariances for the multicast message, confidential message and AN, such that\nthe achievable secrecy rate region is maximized subject to the sum power\nconstraint. This secrecy rate region maximization (SRRM) problem is a nonconvex\nvector maximization problem. To handle it, we reformulate the SRRM problem into\na provably equivalent scalar optimization problem and propose a searching\nmethod to find all of its Pareto optimal points. The equivalent scalar\noptimization problem is identified as a secrecy rate maximization (SRM) problem\nwith the quality of multicast service (QoMS) constraints. Further, we show that\nthis equivalent QoMS-constrained SRM problem, albeit nonconvex, can be\nefficiently handled based on a two-stage optimization approach, including\nsolving a sequence of semidefinite programs. Moreover, we also extend the SRRM\nproblem to an imperfect channel state information (CSI) case where a worst-case\nrobust formulation is considered. In particular, while transmit beamforming is\ngenerally a suboptimal technique to the SRRM problem, we prove that it is\noptimal for the confidential message transmission whether in the perfect CSI\nscenario or in the imperfect CSI scenario. Finally, numerical results\ndemonstrate that the AN-aided transmit designs are effective in expanding the\nachievable secrecy rate regions. \n\n"}
{"id": "1607.01048", "contents": "Title: Capacity of Gaussian Many-Access Channels Abstract: Classical multiuser information theory studies the fundamental limits of\nmodels with a fixed (often small) number of users as the coding blocklength\ngoes to infinity. This work proposes a new paradigm, referred to as {\\em\nmany-user information theory}, where the number of users is allowed to grow\nwith the blocklength. This paradigm is motivated by emerging systems with a\nmassive number of users in an area, such as machine-to-machine communication\nsystems and sensor networks. The focus of the current paper is the {\\em\nmany-access} channel model, which consists of a single receiver and many\ntransmitters, whose number increases unboundedly with the blocklength.\nMoreover, an unknown subset of transmitters may transmit in a given block and\nneed to be identified. A new notion of capacity is introduced and characterized\nfor the Gaussian many-access channel with random user activities. The capacity\ncan be achieved by first detecting the set of active users and then decoding\ntheir messages. \n\n"}
{"id": "1607.01116", "contents": "Title: Power-Efficient Resource Allocation for MC-NOMA with Statistical Channel\n  State Information Abstract: In this paper, we study the power-efficient resource allocation for\nmulticarrier non-orthogonal multiple access (MC-NOMA) systems. The resource\nallocation algorithm design is formulated as a non-convex optimization problem\nwhich takes into account the statistical channel state information at\ntransmitter and quality of service (QoS) constraints. To strike a balance\nbetween system performance and computational complexity, we propose a\nsuboptimal power allocation and user scheduling with low computational\ncomplexity to minimize the total power consumption. The proposed design\nexploits the heterogeneity of QoS requirement to determine the successive\ninterference cancellation decoding order. Simulation results demonstrate that\nthe proposed scheme achieves a close-to-optimal performance and significantly\noutperforms a conventional orthogonal multiple access (OMA) scheme. \n\n"}
{"id": "1607.01736", "contents": "Title: On Achievability of an $(r,l)$ Fractional Linear Network Code Abstract: It is known that there exists a network, called as the M-network, which is\nnot scalar linearly solvable but has a vector linear solution for message\ndimension two. Recently, a generalization of this result has been presented\nwhere it has been shown that for any integer $m\\geq 2$, there exists a network\nwhich has a $(m,m)$ vector linear solution, but does not have a $(w,w)$ vector\nlinear solution for $w<m$. This paper presents a further generalization.\nSpecifically, we show that for any positive integers $k,n,$ and $m\\geq 2$,\nthere exists a network which has a $(mk,mn)$ fractional linear solution, but\ndoes not have a $(wk,wn)$ fractional linear solution for $w<m$. \n\n"}
{"id": "1607.02699", "contents": "Title: At Every Corner: Determining Corner Points of Two-User Gaussian\n  Interference Channels Abstract: The corner points of the capacity region of the two-user Gaussian\ninterference channel under strong or weak interference are determined using the\nnotions of almost Gaussian random vectors, almost lossless addition of random\nvectors, and almost linearly dependent random vectors. In particular, the\n\"missing\" corner point problem is solved in a manner that differs from previous\nworks in that it avoids the use of integration over a continuum of SNR values\nor of Monge-Kantorovitch transportation problems. \n\n"}
{"id": "1607.02925", "contents": "Title: Faster Low-rank Approximation using Adaptive Gap-based Preconditioning Abstract: We propose a method for rank $k$ approximation to a given input matrix $X \\in\n\\mathbb{R}^{d \\times n}$ which runs in time \\[ \\tilde{O} \\left(d ~\\cdot~\n\\min\\left\\{n + \\tilde{sr}(X) \\,G^{-2}_{k,p+1}\\ ,\\ n^{3/4}\\, \\tilde{sr}(X)^{1/4}\n\\,G^{-1/2}_{k,p+1} \\right\\} ~\\cdot~ \\text{poly}(p)\\right) ~, \\] where $p>k$,\n$\\tilde{sr}(X)$ is related to stable rank of $X$, and $G_{k,p+1} =\n\\frac{\\sigma_k-\\sigma_p}{\\sigma_k}$ is the multiplicative gap between the\n$k$-th and the $(p+1)$-th singular values of $X$. In particular, this yields a\nlinear time algorithm if the gap is at least $1/\\sqrt{n}$ and\n$k,p,\\tilde{sr}(X)$ are constants. \n\n"}
{"id": "1607.04206", "contents": "Title: Reliable MIMO Optical Wireless Communications Through Super-Rectangular\n  Cover Abstract: In this paper, we consider an intensity modulated direct detection MIMO\noptical wireless communication (OWC) system. For such a system, a novel\nsuper-rectangular cover theory is developed to characterize both the unique\nidentifiability and full reliability. This theory states that a transmitted\nmatrix signal can be uniquely identified if and only if the cover order is\nequal to the transmitter aperture number, i.e., full cover. In addition, we\nprove that full reliability is guaranteed for space-time block coded MIMO-OWC\nover commonly used log-normal fading channels with an ML detector if and only\nif the STBC enables full cover. In addition, the diversity gain can be\ngeometrically interpreted as the cover order of the super-rectangle, which\nshould be maximized, and the volume of this super-rectangle, as the diversity\nloss, should be minimized. Using this established error performance criterion,\nthe optimal linear STBC for block fading channels is proved to be spatial\nrepetition code with an optimal power allocation. The design of the optimal\nnon-linear STBC is shown to be equivalent to constructing the optimal\nmulti-dimensional constellation. Specifically, a multi-dimensional\nconstellation from Diophantine equations is proposed and then, shown to be more\nenergy-efficient than the commonly used nonnegative pulse amplitude modulation\nconstellation. \n\n"}
{"id": "1607.04352", "contents": "Title: Ergodic Spectral Efficiency in MIMO Cellular Networks Abstract: This paper shows how the application of stochastic geometry to the analysis\nof wireless networks is greatly facilitated by (i) a clear separation of time\nscales, (ii) the abstraction of small-scale effects via ergodicity, and (iii)\nan interference model that reflects the receiver's lack of knowledge of how\neach individual interference term is faded. These procedures render the\nanalysis both more manageable and more precise, as well as more amenable to the\nincorporation of subsequent features. In particular, the paper presents\nanalytical characterizations of the ergodic spectral efficiency of cellular\nnetworks with single-user multiple-input multiple-output (MIMO) and\nsectorization. These characterizations, in the form of easy-to-evaluate\nexpressions, encompass the coverage, the distribution of spectral efficiency\nover the network locations, and the average thereof. \n\n"}
{"id": "1607.05459", "contents": "Title: Dynamic Joint Uplink and Downlink Optimization for Uplink and Downlink\n  Decoupling-Enabled 5G Heterogeneous Networks Abstract: The concept of user-centric and personalized service in the fifth generation\n(5G) mobile networks encourages technical solutions such as dynamic asymmetric\nuplink/downlink resource allocation and elastic association of cells to users\nwith decoupled uplink and downlink (DeUD) access. In this paper we develop a\njoint uplink and downlink optimization algorithm for DeUD-enabled wireless\nnetworks for adaptive joint uplink and downlink bandwidth allocation and power\ncontrol, under different link association policies. Based on a general model of\ninter-cell interference, we propose a three-step optimization algorithm to\njointly optimize the uplink and downlink bandwidth allocation and power\ncontrol, using the fixed point approach for nonlinear operators with or without\nmonotonicity, to maximize the minimum level of quality of service satisfaction\nper link, subjected to a general class of resource (power and bandwidth)\nconstraints. We present numerical results illustrating the theoretical findings\nfor network simulator in a real-world setting, and show the advantage of our\nsolution compared to the conventional proportional fairness resource allocation\nschemes in both the coupled uplink and downlink (CoUD) access and the novel\nlink association schemes in DeUD. \n\n"}
{"id": "1607.07252", "contents": "Title: Topological Interference Management with User Admission Control via\n  Riemannian Optimization Abstract: Topological interference management (TIM) provides a promising way to manage\ninterference only based on the network connectivity information. Previous works\non the TIM problem mainly focus on using the index coding approach and graph\ntheory to establish conditions of network topologies to achieve the feasibility\nof topological interference management. In this paper, we propose a novel user\nadmission control approach via sparse and low-rank optimization to maximize the\nnumber of admitted users for achieving the feasibility of topological\ninterference management. To assist efficient algorithms design for the\nformulated rank-constrained (i.e., degrees-of-freedom (DoF) allocation) l0-norm\nmaximization (i.e., user capacity maximization) problem, we propose a\nregularized smoothed l1- norm minimization approach to induce sparsity pattern,\nthereby guiding the user selection. We further develop a Riemannian\ntrust-region algorithm to solve the resulting rank-constrained smooth\noptimization problem via exploiting the quotient manifold of fixed-rank\nmatrices. Simulation results demonstrate the effectiveness and near-optimal\nperformance of the proposed Riemannian algorithm to maximize the number of\nadmitted users for topological interference management. \n\n"}
{"id": "1607.07484", "contents": "Title: Phase Retrieval by Linear Algebra Abstract: The null vector method, based on a simple linear algebraic concept, is\nproposed as a solution to the phase retrieval problem.\n  In the case with complex Gaussian random measurement matrices, a\nnon-asymptotic error bound is derived, yielding an asymptotic regime of\naccurate approximation comparable to that for the spectral vector method. \n\n"}
{"id": "1607.07815", "contents": "Title: Strong Secrecy on a Class of Degraded Broadcast Channels Using Polar\n  Codes Abstract: Different polar coding schemes are proposed for the memoryless degraded\nbroadcast channel under different reliability and secrecy requirements: layered\ndecoding and/or layered secrecy. In this setting, the transmitter wishes to\nsend multiple messages to a set of legitimate receivers keeping them masked\nfrom a set of eavesdroppers. The layered decoding structure requires receivers\nwith better channel quality to reliably decode more messages, while the layered\nsecrecy structure requires eavesdroppers with worse channel quality to be kept\nignorant of more messages. The implementation of the proposed polar coding\nschemes is discussed and their performance is evaluated by simulations for the\nsymmetric degraded broadcast channel. \n\n"}
{"id": "1607.08259", "contents": "Title: Adaptive Signal Detection and Parameter Estimation in Unknown Colored\n  Gaussian Noise Abstract: This paper considers the general signal detection and parameter estimation\nproblem in the presence of colored Gaussian noise disturbance. By modeling the\ndisturbance with an autoregressive process, we present three signal detectors\nwith different unknown parameters under the general framework of binary\nhypothesis testing. The closed form of parameter estimates and the asymptotic\ndistributions of these three tests are also given. Given two examples of\nfrequency modulated signal detection problem and time series moving object\ndetection problem, the simulation results demonstrate the effectiveness of\nthree presented detectors. \n\n"}
{"id": "1608.02670", "contents": "Title: Parameters of two classes of LCD BCH codes Abstract: Historically, LCD cyclic codes were referred to as reversible cyclic codes,\nwhich had application in data storage. Due to a newly discovered application in\ncryptography, there has been renewed interest on LCD codes. In this paper, we\nexplore two special families of LCD cyclic codes, which are both BCH codes. The\ndimensions and the minimum distances of these LCD BCH codes are investigated.\nAs a byproduct, the parameters of some primitive BCH codes are also obtained. \n\n"}
{"id": "1608.03628", "contents": "Title: Time Coupled Diffusion Maps Abstract: We consider a collection of $n$ points in $\\mathbb{R}^d$ measured at $m$\ntimes, which are encoded in an $n \\times d \\times m$ data tensor. Our objective\nis to define a single embedding of the $n$ points into Euclidean space which\nsummarizes the geometry as described by the data tensor. In the case of a fixed\ndata set, diffusion maps (and related graph Laplacian methods) define such an\nembedding via the eigenfunctions of a diffusion operator constructed on the\ndata. Given a sequence of $m$ measurements of $n$ points, we construct a\ncorresponding sequence of diffusion operators and study their product. Via this\nproduct, we introduce the notion of time coupled diffusion distance and time\ncoupled diffusion maps which have natural geometric and probabilistic\ninterpretations. To frame our method in the context of manifold learning, we\nmodel evolving data as samples from an underlying manifold with a time\ndependent metric, and we describe a connection of our method to the heat\nequation over a manifold with time dependent metric. \n\n"}
{"id": "1608.03640", "contents": "Title: MSE-based Precoding for MIMO Downlinks in Heterogeneous Networks Abstract: Considering a heterogeneous network (HetNet) system consisting of a macro\ntier overlaid with a second tier of small cells (SCs), this paper studies the\nmean square error (MSE) based precoding design to be employed by the macro base\nstation and the SC nodes for multiple-input multiple-output (MIMO) downlinks.\nFirst, a new sum-MSE of all users based minimization problem is proposed aiming\nto design a set of macro cell (MC) and SC transmit precoding matrices or\nvectors. To solve it, two different algorithms are presented. One is via a\nrelaxed-constraints based alternating optimization (RAO) realized by efficient\nalternating optimization and relaxing non-convex constraints to convex ones.\nThe other is via an unconstrained alternating optimization with normalization\n(UAON) implemented by introducing the constraints into the iterations with the\nnormalization operation. Second, a separate MSE minimization based precoding is\nproposed by considering the signal and interference terms corresponding to the\nmacro tier and the SCs separately. Simulation results show that the sum-MSE\nbased RAO algorithm provides the best MSE performance among the proposed\nschemes under a number of system configurations. When the number of antennas at\nthe macro-BS is sufficiently large, the MSE of the separate MSE-based precoding\nis found to approach that of RAO and surpass that of UAON. Together, this paper\nprovides a suite of three new precoding techniques that is expected to meet the\nneed in a broad range of HetNet environments with adequate balance between\nperformance and complexity. \n\n"}
{"id": "1608.03710", "contents": "Title: Joint 3D Positioning and Network Synchronization in 5G Ultra-Dense\n  Networks Using UKF and EKF Abstract: It is commonly expected that future fifth generation (5G) networks will be\ndeployed with a high spatial density of access nodes (ANs) in order to meet the\nenvisioned capacity requirements of the upcoming wireless networks.\nDensification is beneficial not only for communications but it also creates a\nconvenient infrastructure for highly accurate user node (UN) positioning.\nDespite the fact that positioning will play an important role in future\nnetworks, thus enabling a huge amount of location-based applications and\nservices, this great opportunity has not been widely explored in the existing\nliterature. Therefore, this paper proposes an unscented Kalman filter\n(UKF)-based method for estimating directions of arrival (DoAs) and times of\narrival (ToA) at ANs as well as performing joint 3D positioning and network\nsynchronization in a network-centric manner. In addition to the proposed\nUKF-based solution, the existing 2D extended Kalman filter (EKF)-based solution\nis extended to cover also realistic 3D positioning scenarios. Building on the\npremises of 5G ultra-dense networks (UDNs), the performance of both methods is\nevaluated and analysed in terms of DoA and ToA estimation as well as\npositioning and clock offset estimation accuracy, using the METIS map-based\nray-tracing channel model and 3D trajectories for vehicles and unmanned aerial\nvehicles (UAVs) through the Madrid grid. Based on the comprehensive numerical\nevaluations, both proposed methods can provide the envisioned one meter 3D\npositioning accuracy even in the case of unsynchronized 5G network while\nsimultaneously tracking the clock offsets of network elements with a\nnanosecond-scale accuracy. \n\n"}
{"id": "1608.03874", "contents": "Title: LDPC Lattice Codes for Full-Duplex Relay Channels Abstract: Low density parity check (LDPC) lattices are obtained from Construction D'\nand a family of nested binary LDPC codes. We consider an special case of these\nlattices with one binary LDPC code as underlying code. This special case of\nLDPC lattices can be obtained by lifting binary LDPC codes using Construction A\nlattices. The LDPC lattices were the first family of lattices which have\nefficient decoding in high dimensions. We employ the encoding and decoding of\nthe LDPC lattices in a cooperative transmission framework. We establish two\nefficient shaping methods based on hypercube shaping and Voronoi shaping, to\nobtain LDPC lattice codes. Then, we propose the implementation of block Markov\nencoding for one-way and two-way relay networks using LDPC lattice codes. This\nentails owning an efficient method for decomposing full-rate codebook into\nlower rate codebooks. We apply different decomposition schemes for one-way and\ntwo-way relay channels which are the altered versions of the decomposition\nmethods of low density lattice codes (LDLCs). Due to the lower complexity of\nthe decoding for LDPC lattices comparing to LDLCs, the complexity of our\nschemes are significantly lower than the ones proposed for LDLCs. The\nefficiency of the proposed schemes are presented using simulation results. \n\n"}
{"id": "1608.04165", "contents": "Title: Wireless Energy Harvesting Cooperative Communications with Direct Link\n  and Energy Accumulation Abstract: This paper investigates a wireless energy harvesting cooperative network\n(WEHCN) consisting of a source, a decode-and-forward (DF) relay and a\ndestination. We consider the relay as an energy harvesting (EH) node equipped\nwith EH circuit and a rechargeable battery. Moreover, the direct link between\nsource and destination is assumed to exist. The relay can thus harvest and\naccumulate energy from radio-frequency signals ejected by the source and assist\nits information transmission opportunistically. We develop an incremental\naccumulate-then-forward (IATF) relaying protocol for the considered WEHCN. In\nthe IATF protocol, the source sends its information to destination via the\ndirect link and requests the relay to cooperate only when it is necessary such\nthat the relay has more chances to accumulate the harvested energy. By modeling\nthe charging/discharging behaviors of the relay battery as a finite-state\nMarkov chain, we derive a closed-form expression for the outage probability of\nthe proposed IATF. Numerical results validate our theoretical analysis and show\nthat the IATF scheme can significantly outperform the direct transmission\nscheme without cooperation. \n\n"}
{"id": "1608.05094", "contents": "Title: Tolerant Compressed Sensing With Partially Coherent Sensing Matrices Abstract: Most of compressed sensing (CS) theory to date is focused on incoherent\nsensing, that is, columns from the sensing matrix are highly uncorrelated.\nHowever, sensing systems with naturally occurring correlations arise in many\napplications, such as signal detection, motion detection and radar. Moreover,\nin these applications it is often not necessary to know the support of the\nsignal exactly, but instead small errors in the support and signal are\ntolerable.\n  Despite the abundance of work utilizing incoherent sensing matrices, for this\ntype of tolerant recovery we suggest that coherence is actually beneficial. We\npromote the use of coherent sampling when tolerant support recovery is\nacceptable, and demonstrate its advantages empirically. In addition, we provide\na first step towards theoretical analysis by considering a specific\nreconstruction method for selected signal classes. \n\n"}
{"id": "1608.06272", "contents": "Title: ASIC Design of a Noisy Gradient Descent Bit Flip Decoder for 10GBASE-T\n  Ethernet Standard Abstract: In this paper, the NGDBF algorithm is implemented on a code that is deployed\nin the IEEE 802.3an Ethernet standard. The design employs a fully parallel\narchitecture and operates in two-phases: start-up phase and decoding phase. The\ntwo phase operation keeps the high latency operations off-line, thereby\nreducing the decoding latency during the decoding phase. The design is\nbench-marked with other state-of-the-art designs on the same code that employ\ndifferent algorithms and architectures. The results indicate that the NGDBF\ndecoder has a better area efficiency and a better energy efficiency compared to\nother state-of-art decoders. When the design is operated in medium to high\nsignal to noise ratios, the design is able to provide greater than the required\nminimum throughput of 10Gbps. The design consumes 0.81mm2 of area and has an\nenergy efficiency of 1.7pJ/bit, which are the lowest in the reported\nliterature. The design also provides better error performance compared to other\nsimplified decoder implementations and consumes lesser wire-length compared to\na recently proposed design. \n\n"}
{"id": "1609.00832", "contents": "Title: Information Measures, Inequalities and Performance Bounds for Parameter\n  Estimation in Impulsive Noise Environments Abstract: Recent studies found that many channels are affected by additive noise that\nis impulsive in nature and is best explained by heavy-tailed symmetric\nalpha-stable distributions. Dealing with impulsive noise environments comes\nwith an added complexity with respect to the standard Gaussian environment: the\nalpha-stable probability density functions have an infinite second moment and\nthe \"nice\" Hilbert space structure of the space of random variables having a\nfinite second moment is lost along with its tools and methodologies. This is\nindeed the case in estimation theory where classical tools to quantify\nperformance of an estimator are tightly related to the assumption of finite\nvariance variables. In alpha-stable environments, expressions such as the mean\nsquare error and the Cramer-Rao bound are hence problematic. In this work, we\ntackle the parameter estimation problem in impulsive noise environments and\ndevelop novel tools that are tailored to the alpha-stable and heavy-tailed\nnoise environments, tools that coincide with the standard ones adopted in the\nGaussian setup, namely a generalized \"power\" measure and a generalized Fisher\ninformation. We generalize known information inequalities commonly used in the\nGaussian context: the de Bruijn's identity, the data processing inequality, the\nFisher information inequality, the isoperimetric inequality for entropies and\nthe Cramer-Rao bound. Additionally, we derive upper bounds on the differential\nentropy of independent sums having a stable component. Finally, the new \"power\"\nmeasure is used to shed some light on the additive alpha-stable noise channel\ncapacity in a setup that generalizes the linear average power constrained AWGN\nchannel. Our theoretical findings are paralleled with numerical evaluations of\nvarious quantities and bounds using developed {\\em Matlab} packages. \n\n"}
{"id": "1609.02411", "contents": "Title: Velocity-Aware Handover Management in Two-Tier Cellular Networks Abstract: While network densification is considered an important solution to cater the\never-increasing capacity demand, its effect on the handover (HO) rate is\noverlooked. In dense 5G networks, HO delays may neutralize or even negate the\ngains offered by network densification. Hence, user mobility imposes a\nnontrivial challenge to harvest capacity gains via network densification. In\nthis paper, we propose a velocity-aware HO management scheme for two-tier\ndownlink cellular network to mitigate the HO effect on the foreseen\ndensification throughput gains. The proposed HO scheme sacrifices the best BS\nconnectivity, by skipping HO to some BSs along the user's trajectory, to\nmaintain longer connection durations and reduce HO rates. Furthermore, the\nproposed scheme enables cooperative BS service and strongest interference\ncancellation to compensate for skipping the best connectivity. To this end, we\nconsider different HO skipping scenarios and develop a velocity-aware\nmathematical model, via stochastic geometry, to quantify the performance of the\nproposed HO scheme in terms of the coverage probability and user throughput.\nThe results highlight the HO rate problem in dense cellular environments and\nshow the importance of the proposed HO schemes. Finally, the value of BS\ncooperation along with handover skipping is quantified for different user\nmobility profiles. \n\n"}
{"id": "1609.03142", "contents": "Title: Exact Dimensionality Reduction for Partial Line Spectra Estimation\n  Problems Abstract: Line spectral estimation theory aims to estimate the off-the-grid spectral\ncomponents of a time signal with optimal precision. Recent results have shown\nthat it is possible to recover signals having sparse line spectra from few\ntemporal observations via the use of convex programming. However, the\ncomputational cost of such approaches remains the major flaw to their\napplication to practical systems. This work investigates the recovery of\nspectrally sparse signal from low-dimensional partial measurements. It is shown\nin the first part of this paper that, under a light assumption on the\nsub-sampling matrix, the partial line spectral estimation problems can be\nrelaxed into a low-dimensional semidefinite program. The proof technique relies\non a novel extension of the Gram parametrization to subspaces of trigonometric\npolynomials.\n  The second part of this work focuses on the analysis of two particular\nsub-sampling patterns: multirate sampling and random selection sampling. It is\nshown that those sampling patterns guarantee perfect recovery of the line\nspectra, and that the reconstruction can be achieved in a poly-logarithmic time\nwith respect to the full observation case. Moreover, the sub-Nyquist recovery\ncapabilities of such sampling patterns are highlighted. The atomic soft\nthresholding method is adapted in the presented framework to estimate sparse\nspectra in noisy environments, and a scalable algorithm for its resolution is\nproposed. \n\n"}
{"id": "1609.08137", "contents": "Title: Nearest-Neighbor and Contact Distance Distributions for Thomas Cluster\n  Process Abstract: We characterize the statistics of nearest-neighbor and contact distance\ndistributions for Thomas cluster process (TCP), which is a special case of\nPoisson cluster process. In particular, we derive the cumulative distribution\nfunction (CDF) of the distance to the nearest point of TCP from a reference\npoint for three different cases: (i) reference point is not a part of the point\nprocess, (ii) it is chosen uniformly at random from the TCP, and (iii) it is a\nrandomly chosen point from a cluster chosen uniformly at random from the TCP.\nWhile the first corresponds to the contact distance distribution, the other two\nprovide two different viewpoints for the nearest-neighbor distance\ndistribution. \n\n"}
{"id": "1609.08878", "contents": "Title: Graph-Theoretic Approaches to Two-Sender Index Coding Abstract: Consider a communication scenario over a noiseless channel where a sender is\nrequired to broadcast messages to multiple receivers, each having side\ninformation about some messages. In this scenario, the sender can leverage the\nreceivers' side information during the encoding of messages in order to reduce\nthe required transmissions. This type of encoding is called index coding. In\nthis paper, we study index coding with two cooperative senders, each with some\nsubset of messages, and multiple receivers, each requesting one unique message.\nThe index coding in this setup is called two-sender unicast index coding\n(TSUIC). The main aim of TSUIC is to minimize the total number of transmissions\nrequired by the two senders. Based on graph-theoretic approaches, we prove that\nTSUIC is equivalent to single-sender unicast index coding (SSUIC) for some\nspecial cases. Moreover, we extend the existing schemes for SSUIC, viz., the\ncycle-cover scheme, the clique-cover scheme, and the local-chromatic scheme to\nthe corresponding schemes for TSUIC. \n\n"}
{"id": "1609.09696", "contents": "Title: A Comprehensive Analysis of 5G Heterogeneous Cellular Systems operating\n  over $\\kappa$-$\\mu$ Shadowed Fading Channels Abstract: Emerging cellular technologies such as those proposed for use in 5G\ncommunications will accommodate a wide range of usage scenarios with diverse\nlink requirements. This will include the necessity to operate over a versatile\nset of wireless channels ranging from indoor to outdoor, from line-of-sight\n(LOS) to non-LOS, and from circularly symmetric scattering to environments\nwhich promote the clustering of scattered multipath waves. Unfortunately, many\nof the conventional fading models adopted in the literature to develop network\nmodels lack the flexibility to account for such disparate signal propagation\nmechanisms. To bridge the gap between theory and practical channels, we\nconsider $\\kappa$-$\\mu$ shadowed fading, which contains as special cases, the\nmajority of the linear fading models proposed in the open literature, including\nRayleigh, Rician, Nakagami-m, Nakagami-q, One-sided Gaussian, $\\kappa$-$\\mu$,\n$\\eta$-$\\mu$, and Rician shadowed to name but a few. In particular, we apply an\northogonal expansion to represent the $\\kappa$-$\\mu$ shadowed fading\ndistribution as a simplified series expression. Then using the series\nexpressions with stochastic geometry, we propose an analytic framework to\nevaluate the average of an arbitrary function of the SINR over $\\kappa$-$\\mu$\nshadowed fading channels. Using the proposed method, we evaluate the spectral\nefficiency, moments of the SINR, bit error probability and outage probability\nof a $K$-tier HetNet with $K$ classes of BSs, differing in terms of the\ntransmit power, BS density, shadowing characteristics and small-scale fading.\nBuilding upon these results, we provide important new insights into the network\nperformance of these emerging wireless applications while considering a diverse\nrange of fading conditions and link qualities. \n\n"}
{"id": "1610.01723", "contents": "Title: Learning with Finite Memory for Machine Type Communication Abstract: Machine-type devices (MTDs) will lie at the heart of the Internet of Things\n(IoT) system. A key challenge in such a system is sharing network resources\nbetween small MTDs, which have limited memory and computational capabilities.\nIn this paper, a novel learning \\emph{with finite memory} framework is proposed\nto enable MTDs to effectively learn about each others message state, so as to\nproperly adapt their transmission parameters. In particular, an IoT system in\nwhich MTDs can transmit both delay tolerant, periodic messages and critical\nalarm messages is studied. For this model, the characterization of the\nexponentially growing delay for critical alarm messages and the convergence of\nthe proposed learning framework in an IoT are analyzed. Simulation results show\nthat the delay of critical alarm messages is significantly reduced up to $94\\%$\nwith very minimal memory requirements. The results also show that the proposed\nlearning with finite memory framework is very effective in mitigating the\nlimiting factors of learning that prevent proper learning procedures. \n\n"}
{"id": "1610.02512", "contents": "Title: Location-Aided Pilot Contamination Avoidance for Massive MIMO Systems Abstract: Pilot contamination, defined as the interference during the channel\nestimation process due to reusing the same pilot sequences in neighboring\ncells, can severely degrade the performance of massive multiple-input\nmultiple-output systems. In this paper, we propose a location-based approach to\nmitigating the pilot contamination problem for uplink multiple-input\nmultiple-output systems. Our approach makes use of the approximate locations of\nmobile devices to provide good estimates of the channel statistics between the\nmobile devices and their corresponding base stations. Specifically, we aim at\navoiding pilot contamination even when the number of base station antennas is\nnot very large, and when multiple users from different cells, or even in the\nsame cell, are assigned the same pilot sequence. First, we characterize a\ndesired angular region of the target user at the serving base station based on\nthe number of base station antennas and the location of the target user, and\nmake the observation that in this region the interference is close to zero due\nto the spatial separability. Second, based on this observation, we propose\npilot coordination methods for multi-user multi-cell scenarios to avoid pilot\ncontamination. The numerical results indicate that the proposed pilot\ncontamination avoidance schemes enhance the quality of the channel estimation\nand thereby improve the per-cell sum rate offered by target base stations. \n\n"}
{"id": "1610.02680", "contents": "Title: Minimax Optimality of Shiryaev-Roberts Procedure for Quickest Drift\n  Change Detection of a Brownian motion Abstract: The problem of detecting a change in the drift of a Brownian motion is\nconsidered. The change point is assumed to have a modified exponential prior\ndistribution with unknown parameters. A worst-case analysis with respect to\nthese parameters is adopted leading to a min-max problem formulation.\nAnalytical and numerical justifications are provided towards establishing that\nthe Shiryaev-Roberts procedure with a specially designed starting point is\nexactly optimal for the proposed mathematical setup. \n\n"}
{"id": "1610.04273", "contents": "Title: Generalized and Extended Product Codes Abstract: Generalized Product (GPC) Codes, an unification of Product Codes and\nIntegrated Interleaved (II) Codes, are presented. Applications for approaches\nrequiring local and global parities are described. The more general problem of\nextending product codes by adding global parities is studied and an upper bound\non the minimum distance of such codes is obtained. Codes with one, two and\nthree global parities whose minimum distances meet the bound are presented.\nTradeoffs between optimality and field size are discussed. \n\n"}
{"id": "1610.04924", "contents": "Title: An interleaver design for polar codes over slow fading channels Abstract: We consider the problem of using polar codes over slow fading wireless\nchannels. For design, we focus on a parallel slow fading channel with 2 blocks,\nand polar codes with rate <= 1/2. Motivated by Arikan's systematic polar code\nconstruction, we propose an interleaver design for a general polar code. The\ninterleaver comprises of using the bit reversal of the order of polarized bit\nchannels. This interleaver is called a diversity interleaver. In addition to\nthe diversity interleaver, a diversity polar code is proposed to further\nincrease the diversity gain.\n  The proposed designs are evaluated via link simulations for AWGN and fading\nchannels. The simulation results show a performance close to the outage\nprobability (within 2 dB) and significant gains over using a random\ninterleaver. \n\n"}
{"id": "1610.05617", "contents": "Title: A Tractable Framework for the Analysis of Dense Heterogeneous Cellular\n  Networks Abstract: This paper investigates the downlink performance of K-tier heteregeneous\ncellular networks (HCNs) under general settings. First, Gaussian approximation\nbounds for the standardized aggregate wireless interference (AWI) in dense\nK-tier HCNs are obtained for when base stations (BSs) in each tier are\ndistributed over the plane according to a spatial and general Poisson point\nprocess. The Kolmogorov-Smirnov (KS) distance is used to measure deviations of\nthe distribution of the standardized AWI from the standard normal distribution.\nAn explicit and analytical expression bounding the KS distance between these\ntwo distributions is obtained as a function of a broad range of network\nparameters such as per-tier transmission power levels, per-tier BS intensity,\nBS locations, general fading statistics, and general bounded path-loss models.\nBounds achieve a good statistical match between the standardized AWI\ndistribution and its normal approximation even for moderately dense HCNs.\nSecond, various spatial performance metrics of interest such as outage\ncapacity, ergodic capacity and area spectral efficiency in the downlink of\nK-tier HCNs for general signal propogation models are investigated by making\nuse of the derived distribution approximation results. Considering two specific\nBS association policies, it is shown that the derived performance bounds track\nthe actual performance metrics reasonably well for a wide range of BS\nintensities, with the gap among them becoming negligibly small for denser HCN\ndeployments. \n\n"}
{"id": "1610.06974", "contents": "Title: Optimal Control for Network Coding Broadcast Abstract: Random linear network coding (RLNC) has been shown to efficiently improve the\nnetwork performance in terms of reducing transmission delays and increasing the\nthroughput in broadcast and multicast communications. However, it can result in\nincreased storage and computational complexity at the receivers end. In our\nprevious work we considered the broadcast transmission of large file to N\nreceivers. We showed that the storage and complexity requirements at the\nreceivers end can be greatly reduced when segmenting the file into smaller\nblocks and applying RLNC to these blocks. To that purpose, we proposed a packet\nscheduling policy, namely the Least Received. In this work we will prove the\noptimality of our previously proposed policy, in terms of file transfer\ncompletion time, when N = 2. We will model our system as a Markov Decision\nProcess and prove the optimality of the policy using Dynamic Programming. Our\nintuition is that the Least Received policy may be optimal regardless of the\nnumber of receivers. Towards that end, we will provide experimental results\nthat verify that ntuition. \n\n"}
{"id": "1610.07284", "contents": "Title: Decentralized Transmission Policies for Energy Harvesting Devices Abstract: The problem of finding decentralized transmission policies in a wireless\ncommunication network with energy harvesting constraints is formulated and\nsolved using the decentralized Markov decision process framework. The proposed\npolicy defines the transmission probabilities of all devices so as to correctly\nbalance the collision probabilities with the energy constraints. After an\ninitial coordination phase, in which the network parameters are initialized for\nall devices, every node proceeds in a fully decentralized fashion. We\nnumerically show that, because of the harvesting, a fully orthogonal scheme\n(e.g., TDMA-like) is sub-optimal in this scenario, and that the optimal\ntrade-off lies between an orthogonal and a completely symmetric system. \n\n"}
{"id": "1610.07297", "contents": "Title: Channel capacity of polar coding with a given polar mismatched\n  successive cancellation decoder Abstract: Ar{\\i}kan's polar coding, is by now a well studied technique that allows\nachieving the symmetric capacity of binary input memoryless channels with low\ncomplexity encoding and decoding, provided that the polar decoding architecture\nis used and the decoding metric is matched to the true channel. In this paper,\nwe analyze communication rates that are achievable when the polar\ncoding/decoding architecture is used with the decoder using an incorrect model\nof the channel. We define the `polar mismatched capacity' as an analogue of the\nclassical mismatched capacity, give an expression for it, and derive bounds on\nit. \n\n"}
{"id": "1610.07578", "contents": "Title: On capacity of optical communications over a lossy bosonic channel with\n  a receiver employing the most general coherent electro-optic feedback control Abstract: We study the problem of designing optical receivers to discriminate between\nmultiple coherent states using coherent processing receivers---i.e., one that\nuses arbitrary coherent feedback control and quantum-noise-limited direct\ndetection---which was shown by Dolinar to achieve the minimum error probability\nin discriminating any two coherent states. We first derive and re-interpret\nDolinar's binary-hypothesis minimum-probability-of-error receiver as the one\nthat optimizes the information efficiency at each time instant, based on\nrecursive Bayesian updates within the receiver. Using this viewpoint, we\npropose a natural generalization of Dolinar's receiver design to discriminate\n$M$ coherent states each of which could now be a codeword, i.e., a sequence of\n$N$ coherent states each drawn from a modulation alphabet. We analyze the\nchannel capacity of the pure-loss optical channel with a general\ncoherent-processing receiver in the low-photon number regime and compare it\nwith the capacity achievable with direct detection and the Holevo limit\n(achieving the latter would require a quantum joint-detection receiver). We\nshow compelling evidence that despite the optimal performance of Dolinar's\nreceiver for the binary coherent-state hypothesis test (either in error\nprobability or mutual information), the asymptotic communication rate\nachievable by such a coherent-processing receiver is only as good as direct\ndetection. This suggests that in the infinitely-long codeword limit, all\npotential benefits of coherent processing at the receiver can be obtained by\ndesigning a good code and direct detection, with no feedback within the\nreceiver. \n\n"}
{"id": "1610.07693", "contents": "Title: Supervised-Learning-Aided Communication Framework for MIMO Systems with\n  Low-Resolution ADCs Abstract: This paper considers a multiple-input-multiple-output (MIMO) system with\nlow-resolution analog-to-digital converters (ADCs). In this system, we propose\na novel communication framework that is inspired by supervised learning. The\nkey idea of the proposed framework is to learn the non-linear input-output\nsystem, formed by the concatenation of a wireless channel and a quantization\nfunction used at the ADCs, for data detection. In this framework, a\nconventional channel estimation process is replaced by a system learning\nprocess, in which the conditional probability mass functions (PMFs) of the\nnonlinear system are empirically learned by sending the repetitions of all\npossible data signals as pilot signals. Then the subsequent data detection\nprocess is performed based on the empirical conditional PMFs obtained during\nthe system learning. To reduce both the training overhead and the detection\ncomplexity, we also develop a supervised-learning-aided\nsuccessive-interference-cancellation method. In this method, a data signal\nvector is divided into two subvectors with reduced dimensions. Then these two\nsubvectors are successively detected based on the conditional PMFs that are\nlearned using artificial noise signals and an estimated channel. For the case\nof one-bit ADCs, we derive an analytical expression for vector-error-rate of\nthe proposed framework under perfect channel knowledge at the receiver.\nSimulations demonstrate the detection error reduction of the proposed framework\ncompared to conventional detection techniques that are based on channel\nestimation. \n\n"}
{"id": "1610.07736", "contents": "Title: Construction of MDS self-dual codes from orthogonal matrices Abstract: In this paper, we give algorithms and methods of construction of self-dual\ncodes over finite fields using orthogonal matrices. Randomization in the\northogonal group, and code extension are the main tools. Some optimal, almost\nMDS, and MDS self-dual codes over both small and large prime fields are\nconstructed. \n\n"}
{"id": "1610.08070", "contents": "Title: Low rank matrix recovery from Clifford orbits Abstract: We prove that low-rank matrices can be recovered efficiently from a small\nnumber of measurements that are sampled from orbits of a certain matrix group.\nAs a special case, our theory makes statements about the phase retrieval\nproblem. Here, the task is to recover a vector given only the amplitudes of its\ninner product with a small number of vectors from an orbit. Variants of the\ngroup in question have appeared under different names in many areas of\nmathematics. In coding theory and quantum information, it is the complex\nClifford group; in time-frequency analysis the oscillator group; and in\nmathematical physics the metaplectic group. It affords one particularly small\nand highly structured orbit that includes and generalizes the discrete Fourier\nbasis: While the Fourier vectors have coefficients of constant modulus and\nphases that depend linearly on their index, the vectors in said orbit have\nphases with a quadratic dependence. In quantum information, the orbit is used\nextensively and is known as the set of stabilizer states. We argue that due to\ntheir rich geometric structure and their near-optimal recovery properties,\nstabilizer states form an ideal model for structured measurements for phase\nretrieval. Our results hold for $m\\geq C \\kappa_r r d \\log(d)$ measurements,\nwhere the oversampling factor k varies between $\\kappa_r=1$ and $\\kappa_r =\nr^2$ depending on the orbit. The reconstruction is stable towards both additive\nnoise and deviations from the assumption of low rank. If the matrices of\ninterest are in addition positive semidefinite, reconstruction may be performed\nby a simple constrained least squares regression. Our proof methods could be\nadapted to cover orbits of other groups. \n\n"}
{"id": "1610.09028", "contents": "Title: Through the Haze: a Non-Convex Approach to Blind Gain Calibration for\n  Linear Random Sensing Models Abstract: Computational sensing strategies often suffer from calibration errors in the\nphysical implementation of their ideal sensing models. Such uncertainties are\ntypically addressed by using multiple, accurately chosen training signals to\nrecover the missing information on the sensing model, an approach that can be\nresource-consuming and cumbersome. Conversely, blind calibration does not\nemploy any training signal, but corresponds to a bilinear inverse problem whose\nalgorithmic solution is an open issue. We here address blind calibration as a\nnon-convex problem for linear random sensing models, in which we aim to recover\nan unknown signal from its projections on sub-Gaussian random vectors, each\nsubject to an unknown positive multiplicative factor (or gain). To solve this\noptimisation problem we resort to projected gradient descent starting from a\nsuitable, carefully chosen initialisation point. An analysis of this algorithm\nallows us to show that it converges to the exact solution provided a sample\ncomplexity requirement is met, i.e., relating convergence to the amount of\ninformation collected during the sensing process. Interestingly, we show that\nthis requirement grows linearly (up to log factors) in the number of unknowns\nof the problem. This sample complexity is found both in absence of prior\ninformation, as well as when subspace priors are available for both the signal\nand gains, allowing a further reduction of the number of observations required\nfor our recovery guarantees to hold. Moreover, in the presence of noise we show\nhow our descent algorithm yields a solution whose accuracy degrades gracefully\nwith the amount of noise affecting the measurements. Finally, we present some\nnumerical experiments in an imaging context, where our algorithm allows for a\nsimple solution to blind calibration of the gains in a sensor array. \n\n"}
{"id": "1610.09247", "contents": "Title: Generalized I-MMSE for K-User Gaussian Channels Abstract: In this paper, we generalize the fundamental relation between the mutual\ninformation and the minimum mean squared error (MMSE) by Guo, Shamai, and Verdu\n[1] to K-User Gaussian channels. We prove that the derivative of the multiuser\nmutual information with respect to the signal to noise ratio (SNR) is equal to\nthe total MMSE plus a covariance term with respect to the cross correlation of\nthe multiuser input estimates, the channels and the precoding matrices. We shed\nlight that such relation is a generalized I-MMSE with one step lookahead and\nlookback, applied to the Successive Interference Cancellation (SIC) in the\ndecoding process. \n\n"}
{"id": "1611.00297", "contents": "Title: Generalized Entropy Concentration for Counts Abstract: The phenomenon of entropy concentration provides strong support for the\nmaximum entropy method, MaxEnt, for inferring a probability vector from\ninformation in the form of constraints. Here we extend this phenomenon, in a\ndiscrete setting, to non-negative integral vectors not necessarily summing to\n1. We show that linear constraints that simply bound the allowable sums suffice\nfor concentration to occur even in this setting. This requires a new,\n`generalized' entropy measure in which the sum of the vector plays a role. We\nmeasure the concentration in terms of deviation from the maximum generalized\nentropy value, or in terms of the distance from the maximum generalized entropy\nvector. We provide non-asymptotic bounds on the concentration in terms of\nvarious parameters, including a tolerance on the constraints which ensures that\nthey are always satisfied by an integral vector. Generalized entropy\nmaximization is not only compatible with ordinary MaxEnt, but can also be\nconsidered an extension of it, as it allows us to address problems that cannot\nbe formulated as MaxEnt problems. \n\n"}
{"id": "1611.01278", "contents": "Title: Topological Interference Management: Linear Cooperation is not useful\n  for Wyner's Networks Abstract: In this work, we study the value of cooperative transmission in wireless\nnetworks if no channel state information is available at the transmitters (no\nCSIT). Our focus is on large locally connected networks, where each transmitter\nis connected to the receiver that has the same index as well as L succeeding\nreceivers. The cases of L=1 and L=2 represent Wyner's asymmetric and symmetric\nnetwork models, respectively. The considered rate criterion is the per user\nDegrees of Freedom (puDoF) as the number of transmitter-receiver pairs goes to\ninfinity. For the case when L=1, it was shown in previous work that linear\ncooperation schemes do not increases the puDoF value, and that the optimal\nscheme relies on assigning each message to a single transmitter and using\northogonal access (TDMA). Here, we extend this conclusion to the case where\nL=2, by proving optimality of TDMA in this case as well. We conclude by\ndiscussing whether increasing the value of L can create a value for linear\ncooperation schemes from a DoF perspective. \n\n"}
{"id": "1611.01579", "contents": "Title: Decentralized Caching and Coded Delivery with Distinct Cache Capacities Abstract: Decentralized proactive caching and coded delivery is studied in a content\ndelivery network, where each user is equipped with a cache memory, not\nnecessarily of equal capacity. Cache memories are filled in advance during the\noff-peak traffic period in a decentralized manner, i.e., without the knowledge\nof the number of active users, their identities, or their particular demands.\nUser demands are revealed during the peak traffic period, and are served\nsimultaneously through an error-free shared link. The goal is to find the\nminimum delivery rate during the peak traffic period that is sufficient to\nsatisfy all possible demand combinations. A group-based decentralized caching\nand coded delivery scheme is proposed, and it is shown to improve upon the\nstate-of-the-art in terms of the minimum required delivery rate when there are\nmore users in the system than files. Numerical results indicate that the\nimprovement is more significant as the cache capacities of the users become\nmore skewed. A new lower bound on the delivery rate is also presented, which\nprovides a tighter bound than the classical cut-set bound. \n\n"}
{"id": "1611.02380", "contents": "Title: Policy Optimization for Content Push via Energy Harvesting Small Cells\n  in Heterogeneous Networks Abstract: Motivated by the rapid development of energy harvesting technology and\ncontent-aware communication in access networks, this paper considers the push\nmechanism design in small-cell base stations (SBSs) powered by renewable\nenergy. A user request can be satisfied by either push or unicast from the SBS.\nIf the SBS cannot handle the request, the user is blocked by the SBS and is\nserved by the macro-cell BS (MBS) instead, which typically consumes more\nenergy. We aim to minimize the ratio of user requests blocked by the SBS. With\nfinite battery capacity, Markov decision process based problem is formulated,\nand the optimal policy is found by dynamic programming (DP). Two\nthreshold-based policies are proposed: the push-only threshold-based (POTB)\npolicy and the energy-efficient threshold-based (EETB) policy, and the\nclosed-form blocking probabilities with infinite battery capacity are derived.\nNumerical results show that the proposed policies outperform the conventional\nnon-push policy if the content popularity changes slowly or the content request\ngenerating rate is high, and can achieve the performance of the greedy optimal\nthreshold-based (GOTB) policy. In addition, the performance gap between the\nthreshold-based policies and the DP optimal policy is small when the energy\narrival rate is low or the request generating rate is high. \n\n"}
{"id": "1611.02733", "contents": "Title: Minimum node degree in inhomogeneous random key graphs with unreliable\n  links Abstract: We consider wireless sensor networks under a heterogeneous random key\npredistribution scheme and an on-off channel model. The heterogeneous key\npredistribution scheme has recently been introduced by Ya\\u{g}an - as an\nextension to the Eschenauer and Gligor scheme - for the cases when the network\nconsists of sensor nodes with varying level of resources and/or connectivity\nrequirements, e.g., regular nodes vs. cluster heads. The network is modeled by\nthe intersection of the inhomogeneous random key graph (induced by the\nheterogeneous scheme) with an Erd\\H{o}s-R\\'enyi graph (induced by the on/off\nchannel model). We present conditions (in the form of zero-one laws) on how to\nscale the parameters of the intersection model so that with high probability\nall of its nodes are connected to at least $k$ other nodes; i.e., the minimum\nnode degree of the graph is no less than $k$. We also present numerical results\nto support our results in the finite-node regime. The numerical results suggest\nthat the conditions that ensure $k$-connectivity coincide with those ensuring\nthe minimum node degree being no less than $k$. \n\n"}
{"id": "1611.02989", "contents": "Title: Bayesian data assimilation based on a family of outer measures Abstract: A flexible representation of uncertainty that remains within the standard\nframework of probabilistic measure theory is presented along with a study of\nits properties. This representation relies on a specific type of outer measure\nthat is based on the measure of a supremum, hence combining additive and highly\nsub-additive components. It is shown that this type of outer measure enables\nthe introduction of intuitive concepts such as pullback and general data\nassimilation operations. \n\n"}
{"id": "1611.05992", "contents": "Title: Secure and Energy-Efficient Beamforming for Simultaneous Information and\n  Energy Transfer Abstract: Next-generation communication networks will likely involve the\nenergy-efficient transfer of information and energy over the same wireless\nchannel, for which the physical layer will become more vulnerable to cyber\nattacks by potential multi-antenna eavesdroppers. To address this issue, this\npaper considers transmit time-switching (TS) mode, in which energy and\ninformation signals are transmitted separately in time by the BS. This protocol\nis not only easy to implement but also delivers the opportunity of\nmulti-purpose beamforming, in which energy beamformers during wireless power\ntransfer are useful in jamming the eavesdropper. In the presence of imperfect\nchannel estimation and multi-antenna eavesdroppers, the energy and information\nbeamformers and the transmit TS ratio are jointly optimized to maximize the\nworst-case user secrecy rate subject to UEs' harvested energy thresholds and a\nBS transmit power budget. New robust path-following algorithms, which involve\none simple convex quadratic program at each iteration are proposed for\ncomputational solutions of this difficult optimization problem and also the\nproblem of secure energy efficiency maximization. The latter is further complex\ndue to additional optimization variables appearing in the denominator of the\nsecrecy rate function. Numerical results confirm that the performance of the\nproposed computational solutions is robust against the channel uncertainties. \n\n"}
{"id": "1611.06443", "contents": "Title: Spectrum Sharing Radar: Coexistence via Xampling Abstract: This paper presents a spectrum sharing technology enabling interference-free\noperation of a surveillance radar and communication transmissions over a common\nspectrum. A cognitive radio receiver senses the spectrum using low sampling and\nprocessing rates. The radar is a cognitive system that employs a Xampling-based\nreceiver and transmits in several narrow bands. Our main contribution is the\nalliance of two previous ideas, CRo and cognitive radar (CRr), and their\nadaptation to solve the spectrum sharing problem. \n\n"}
{"id": "1611.07164", "contents": "Title: Distance verification for classical and quantum LDPC codes Abstract: The techniques of distance verification known for general linear codes are\nre-applied to quantum stabilizer codes. Then distance verification is addressed\nfor classical and quantum LDPC codes. New complexity bounds for distance\nverification with provable performance are derived using the average weight\nspectra of the ensembles of LDPC codes. These bounds are expressed in terms of\nthe erasure-correcting capacity of the corresponding ensemble. We also present\na new irreducible-cluster technique that can be applied to any LDPC code and\ntakes advantage of parity-checks' sparsity for both classical and quantum LDPC\ncodes. This technique reduces complexity exponents of all existing\ndeterministic techniques designed for generic stabilizer codes with small\nrelative distances, which also include all known families of quantum LDPC\ncodes. \n\n"}
{"id": "1611.07216", "contents": "Title: What to Expect When You Are Expecting on the Grassmannian Abstract: Consider an incoming sequence of vectors, all belonging to an unknown\nsubspace $\\operatorname{S}$, and each with many missing entries. In order to\nestimate $\\operatorname{S}$, it is common to partition the data into blocks and\niteratively update the estimate of $\\operatorname{S}$ with each new incoming\nmeasurement block.\n  In this paper, we investigate a rather basic question: Is it possible to\nidentify $\\operatorname{S}$ by averaging the column span of the partially\nobserved incoming measurement blocks on the Grassmannian?\n  We show that in general the span of the incoming blocks is in fact a biased\nestimator of $\\operatorname{S}$ when data suffers from erasures, and we find an\nupper bound for this bias. We reach this conclusion by examining the defining\noptimization program for the Fr\\'{e}chet expectation on the Grassmannian, and\nwith the aid of a sharp perturbation bound and standard large deviation\nresults. \n\n"}
{"id": "1611.09073", "contents": "Title: On Unique Decoding from Insertions and Deletions Abstract: In this paper, we study how often unique decoding from $t$ insertions or $t$\ndeletions occurs for error correcting codes. Insertions and deletions\nfrequently occur in synchronization problems and DNA, a medium which is\nbeginning to be used for long term data storage.\n  We define natural probabilistic channels that make $t$ insertions or $t$\ndeletions, and study the probability of unique decoding. Our most substantial\ncontribution is the derivation of tight upper bounds on the probability of\nunique decoding for messages passed though these channels. We also consider\nother aspects of the problem, and derive improved upper bounds for linear codes\nand VT-codes. \n\n"}
{"id": "1611.09981", "contents": "Title: Decoding from Pooled Data: Sharp Information-Theoretic Bounds Abstract: Consider a population consisting of n individuals, each of whom has one of d\ntypes (e.g. their blood type, in which case d=4). We are allowed to query this\ndatabase by specifying a subset of the population, and in response we observe a\nnoiseless histogram (a d-dimensional vector of counts) of types of the pooled\nindividuals. This measurement model arises in practical situations such as\npooling of genetic data and may also be motivated by privacy considerations. We\nare interested in the number of queries one needs to unambiguously determine\nthe type of each individual. In this paper, we study this information-theoretic\nquestion under the random, dense setting where in each query, a random subset\nof individuals of size proportional to n is chosen. This makes the problem a\nparticular example of a random constraint satisfaction problem (CSP) with a\n\"planted\" solution. We establish almost matching upper and lower bounds on the\nminimum number of queries m such that there is no solution other than the\nplanted one with probability tending to 1 as n tends to infinity. Our proof\nrelies on the computation of the exact \"annealed free energy\" of this model in\nthe thermodynamic limit, which corresponds to the exponential rate of decay of\nthe expected number of solution to this planted CSP. As a by-product of the\nanalysis, we show an identity of independent interest relating the Gaussian\nintegral over the space of Eulerian flows of a graph to its spanning tree\npolynomial. \n\n"}
{"id": "1612.00130", "contents": "Title: Secure Polar Coding for the Two-Way Wiretap Channel Abstract: We consider the problem of polar coding for secure communications over the\ntwo-way wiretap channel, where two legitimate users communicate with each other\nsimultaneously while a passive eavesdropper overhears a combination of their\nexchanged signals. The legitimate users wish to design a cooperative jamming\ncode such that the interference between their codewords can jam the\neavesdropper. In this paper, we design a polar coded cooperative jamming scheme\nthat achieves the whole secrecy rate region of the general two-way wiretap\nchannel under the strong secrecy criterion. The chaining method is used to make\nproper alignment of polar indices. The randomness required to be shared between\ntwo legitimate users is treated as a limited resource and we show that its rate\ncan be made negligible by increasing the blocklength and the number of chained\nblocks. For the special case when the eavesdropper channel is degraded with\nrespect to the legitimate ones, a simplified scheme is proposed which can\nsimultaneously ensure reliability and weak secrecy within a single transmission\nblock. An example of the binary erasure channel case is given to demonstrate\nthe performance of our scheme. \n\n"}
{"id": "1612.01186", "contents": "Title: Vector Approximate Message Passing for the Generalized Linear Model Abstract: The generalized linear model (GLM), where a random vector $\\boldsymbol{x}$ is\nobserved through a noisy, possibly nonlinear, function of a linear transform\noutput $\\boldsymbol{z}=\\boldsymbol{Ax}$, arises in a range of applications such\nas robust regression, binary classification, quantized compressed sensing,\nphase retrieval, photon-limited imaging, and inference from neural spike\ntrains. When $\\boldsymbol{A}$ is large and i.i.d. Gaussian, the generalized\napproximate message passing (GAMP) algorithm is an efficient means of MAP or\nmarginal inference, and its performance can be rigorously characterized by a\nscalar state evolution. For general $\\boldsymbol{A}$, though, GAMP can\nmisbehave. Damping and sequential-updating help to robustify GAMP, but their\neffects are limited. Recently, a \"vector AMP\" (VAMP) algorithm was proposed for\nadditive white Gaussian noise channels. VAMP extends AMP's guarantees from\ni.i.d. Gaussian $\\boldsymbol{A}$ to the larger class of rotationally invariant\n$\\boldsymbol{A}$. In this paper, we show how VAMP can be extended to the GLM.\nNumerical experiments show that the proposed GLM-VAMP is much more robust to\nill-conditioning in $\\boldsymbol{A}$ than damped GAMP. \n\n"}
{"id": "1612.01459", "contents": "Title: Approximate Support Recovery of Atomic Line Spectral Estimation: A Tale\n  of Resolution and Precision Abstract: This work investigates the parameter estimation performance of\nsuper-resolution line spectral estimation using atomic norm minimization. The\nfocus is on analyzing the algorithm's accuracy of inferring the frequencies and\ncomplex magnitudes from noisy observations. When the Signal-to-Noise Ratio is\nreasonably high and the true frequencies are separated by $O(\\frac{1}{n})$, the\natomic norm estimator is shown to localize the correct number of frequencies,\neach within a neighborhood of size $O(\\sqrt{{\\log n}/{n^3}} \\sigma)$ of one of\nthe true frequencies. Here $n$ is half the number of temporal samples and\n$\\sigma^2$ is the Gaussian noise variance. The analysis is based on a\nprimal-dual witness construction procedure. The obtained error bound matches\nthe Cram\\'er-Rao lower bound up to a logarithmic factor. The relationship\nbetween resolution (separation of frequencies) and precision or accuracy of the\nestimator is highlighted. Our analysis also reveals that the atomic norm\nminimization can be viewed as a convex way to solve a $\\ell_1$-norm\nregularized, nonlinear and nonconvex least-squares problem to global\noptimality. \n\n"}
{"id": "1612.03164", "contents": "Title: Square Hellinger Subadditivity for Bayesian Networks and its\n  Applications to Identity Testing Abstract: We show that the square Hellinger distance between two Bayesian networks on\nthe same directed graph, $G$, is subadditive with respect to the neighborhoods\nof $G$. Namely, if $P$ and $Q$ are the probability distributions defined by two\nBayesian networks on the same DAG, our inequality states that the square\nHellinger distance, $H^2(P,Q)$, between $P$ and $Q$ is upper bounded by the\nsum, $\\sum_v H^2(P_{\\{v\\} \\cup \\Pi_v}, Q_{\\{v\\} \\cup \\Pi_v})$, of the square\nHellinger distances between the marginals of $P$ and $Q$ on every node $v$ and\nits parents $\\Pi_v$ in the DAG. Importantly, our bound does not involve the\nconditionals but the marginals of $P$ and $Q$. We derive a similar inequality\nfor more general Markov Random Fields.\n  As an application of our inequality, we show that distinguishing whether two\nBayesian networks $P$ and $Q$ on the same (but potentially unknown) DAG satisfy\n$P=Q$ vs $d_{\\rm TV}(P,Q)>\\epsilon$ can be performed from\n$\\tilde{O}(|\\Sigma|^{3/4(d+1)} \\cdot n/\\epsilon^2)$ samples, where $d$ is the\nmaximum in-degree of the DAG and $\\Sigma$ the domain of each variable of the\nBayesian networks. If $P$ and $Q$ are defined on potentially different and\npotentially unknown trees, the sample complexity becomes\n$\\tilde{O}(|\\Sigma|^{4.5} n/\\epsilon^2)$, whose dependence on $n, \\epsilon$ is\noptimal up to logarithmic factors. Lastly, if $P$ and $Q$ are product\ndistributions over $\\{0,1\\}^n$ and $Q$ is known, the sample complexity becomes\n$O(\\sqrt{n}/\\epsilon^2)$, which is optimal up to constant factors. \n\n"}
{"id": "1612.04268", "contents": "Title: On dually almost MRD codes Abstract: In this paper we define and study a family of codes which come close to be\nMRD codes, so we call them AMRD codes (almost MRD). An AMRD code is a code with\nrank defect equal to 1. AMRD codes whose duals are AMRD are called dually AMRD.\nDually AMRD codes are the closest to the MRD codes given that both they and\ntheir dual codes are almost optimal. Necessary and sufficient conditions for\nthe codes to be dually AMRD are given. Furthermore we show that dually AMRD\ncodes and codes of rank defect one and maximum 2-generalized weight coincide\nwhen the size of the matrix divides the dimension. \n\n"}
{"id": "1612.05461", "contents": "Title: Least reliable messages based early termination method for LT soft\n  decoder Abstract: In this paper, we propose a new early termination method (ETM) for Luby\ntransform (LT) belief propagation (BP) decoder. The proposed ETM, which we call\nleast reliable messages (LRM), observes only sign alterations of a small\ncluster in log-likelihood ratio (LLR) messages passing between nodes in BP\ndecoder. Simulation results and complexity analyzes show that LRM significantly\nlower computational complexity of early termination section in decoder without\nany performance degradation and decreases the average decoding iteration\namounts compared to conventional ETMs in literature. The method can be easily\napplied to code families which can be decoded by BP such as low density parity\ncheck (LDPC) codes, polar codes and Raptor codes. \n\n"}
{"id": "1612.05943", "contents": "Title: Distributed Computing with Channel Noise Abstract: A group of $n$ users want to run a distributed protocol $\\pi$ over a network\nwhere communication occurs via private point-to-point channels. Unfortunately,\nan adversary, who knows $\\pi$, is able to maliciously flip bits on the\nchannels. Can we efficiently simulate $\\pi$ in the presence of such an\nadversary? We show that this is possible, even when $L$, the number of bits\nsent in $\\pi$, and $T$, the number of bits flipped by the adversary are not\nknown in advance. In particular, we show how to create a robust version of\n$\\pi$ that 1) fails with probability at most $\\delta$, for any $\\delta>0$; and\n2) sends $\\tilde{O}(L + T)$ bits, where the $\\tilde{O}$ notation hides a $\\log\n(nL/ \\delta)$ term multiplying $L$. Additionally, we show how to improve this\nresult when the average message size $\\alpha$ is not constant. In particular,\nwe give an algorithm that sends $O( L (1 + (1/\\alpha) \\log (n L/\\delta) + T)$\nbits. This algorithm is adaptive in that it does not require a priori knowledge\nof $\\alpha$. We note that if $\\alpha$ is $\\Omega\\left( \\log (n L/\\delta)\n\\right)$, then this improved algorithm sends only $O(L+T)$ bits, and is\ntherefore within a constant factor of optimal. \n\n"}
{"id": "1612.06835", "contents": "Title: Box constrained $\\ell_1$ optimization in random linear systems --\n  asymptotics Abstract: In this paper we consider box constrained adaptations of $\\ell_1$\noptimization heuristic when applied for solving random linear systems. These\nare typically employed when on top of being sparse the systems' solutions are\nalso known to be confined in a specific way to an interval on the real axis.\nTwo particular $\\ell_1$ adaptations (to which we will refer as the\n\\emph{binary} $\\ell_1$ and \\emph{box} $\\ell_1$) will be discussed in great\ndetail. Many of their properties will be addressed with a special emphasis on\nthe so-called phase transitions (PT) phenomena and the large deviation\nprinciples (LDP). We will fully characterize these through two different\nmathematical approaches, the first one that is purely probabilistic in nature\nand the second one that connects to high-dimensional geometry. Of particular\ninterest we will find that for many fairly hard mathematical problems a\ncollection of pretty elegant characterizations of their final solutions will\nturn out to exist. \n\n"}
{"id": "1612.07163", "contents": "Title: Transmission and Storage Rates for Sequential Massive Random Access Abstract: This paper introduces a new source coding paradigm called Sequential Massive\nRandom Access (SMRA). In SMRA, a set of correlated sources is encoded once for\nall and stored on a server, and clients want to successively access to only a\nsubset of the sources. Since the number of simultaneous clients can be huge,\nthe server is only allowed to extract a bitstream from the stored data: no\nre-encoding can be performed before the transmission of the specific client's\nrequest. In this paper, we formally define the SMRA framework and introduce\nboth storage and transmission rates to characterize the performance of SMRA. We\nderive achievable transmission and storage rates for lossless source coding of\ni.i.d. and non i.i.d. sources, and transmission and storage rates-distortion\nregions for Gaussian sources. We also show two practical implementations of\nSMRA systems based on rate-compatible LDPC codes. Both theoretical and\nexperimental results demonstrate that SMRA systems can reach the same\ntransmission rates as in traditional point to point source coding schemes,\nwhile having a reasonable overhead in terms of storage rate. These results\nconstitute a breakthrough for many recent data transmission applications in\nwhich different parts of the data are requested by the clients. \n\n"}
{"id": "1612.08549", "contents": "Title: Rank-One NMF-Based Initialization for NMF and Relative Error Bounds\n  under a Geometric Assumption Abstract: We propose a geometric assumption on nonnegative data matrices such that\nunder this assumption, we are able to provide upper bounds (both deterministic\nand probabilistic) on the relative error of nonnegative matrix factorization\n(NMF). The algorithm we propose first uses the geometric assumption to obtain\nan exact clustering of the columns of the data matrix; subsequently, it employs\nseveral rank-one NMFs to obtain the final decomposition. When applied to data\nmatrices generated from our statistical model, we observe that our proposed\nalgorithm produces factor matrices with comparable relative errors vis-\\`a-vis\nclassical NMF algorithms but with much faster speeds. On face image and\nhyperspectral imaging datasets, we demonstrate that our algorithm provides an\nexcellent initialization for applying other NMF algorithms at a low\ncomputational cost. Finally, we show on face and text datasets that the\ncombinations of our algorithm and several classical NMF algorithms outperform\nother algorithms in terms of clustering performance. \n\n"}
{"id": "1701.01103", "contents": "Title: Minimax R\\'enyi Redundancy Abstract: The redundancy for universal lossless compression of discrete memoryless\nsources in Campbell's setting is characterized as a minimax R\\'enyi divergence,\nwhich is shown to be equal to the maximal $\\alpha$-mutual information via a\ngeneralized redundancy-capacity theorem. Special attention is placed on the\nanalysis of the asymptotics of minimax R\\'enyi divergence, which is determined\nup to a term vanishing in blocklength. \n\n"}
{"id": "1701.02911", "contents": "Title: Quantum Stabilizer Codes Can Realize Access Structures Impossible by\n  Classical Secret Sharing Abstract: We show a simple example of a secret sharing scheme encoding classical secret\nto quantum shares that can realize an access structure impossible by classical\ninformation processing with limitation on the size of each share. The example\nis based on quantum stabilizer codes. \n\n"}
{"id": "1701.03207", "contents": "Title: Extended Gray-Wyner System with Complementary Causal Side Information Abstract: We establish the rate region of an extended Gray-Wyner system for 2-DMS\n$(X,Y)$ with two additional decoders having complementary causal side\ninformation. This extension is interesting because in addition to the\noperationally significant extreme points of the Gray-Wyner rate region, which\ninclude Wyner's common information, G{\\'a}cs-K{\\\"o}rner common information and\ninformation bottleneck, the rate region for the extended system also includes\nthe K{\\\"o}rner graph entropy, the privacy funnel and excess functional\ninformation, as well as three new quantities of potential interest, as extreme\npoints. To simplify the investigation of the 5-dimensional rate region of the\nextended Gray-Wyner system, we establish an equivalence of this region to a\n3-dimensional mutual information region that consists of the set of all triples\nof the form $(I(X;U),\\,I(Y;U),\\,I(X,Y;U))$ for some $p_{U|X,Y}$. We further\nshow that projections of this mutual information region yield the rate regions\nfor many settings involving a 2-DMS, including lossless source coding with\ncausal side information, distributed channel synthesis, and lossless source\ncoding with a helper. \n\n"}
{"id": "1701.03342", "contents": "Title: A Study on Arbitrarily Varying Channels with Causal Side Information at\n  the Encoder Abstract: In this work, we study two models of arbitrarily varying channels, when\ncausal side information is available at the encoder in a causal manner. First,\nwe study the arbitrarily varying channel (AVC) with input and state\nconstraints, when the encoder has state information in a causal manner. Lower\nand upper bounds on the random code capacity are developed. A lower bound on\nthe deterministic code capacity is established in the case of a\nmessage-averaged input constraint. In the setting where a state constraint is\nimposed on the jammer, while the user is under no constraints, the random code\nbounds coincide, and the random code capacity is determined. Furthermore, for\nthis scenario, a generalized non-symmetrizability condition is stated, under\nwhich the deterministic code capacity coincides with the random code capacity.\n  A second model considered in our work is the arbitrarily varying degraded\nbroadcast channel with causal side information at the encoder (without\nconstraints). We establish inner and outer bounds on both the random code\ncapacity region and the deterministic code capacity region. The capacity region\nis then determined for a class of channels satisfying a condition on the mutual\ninformations between the strategy variables and the channel outputs. As an\nexample, we show that the condition holds for the arbitrarily varying binary\nsymmetric broadcast channel, and we find the corresponding capacity region. \n\n"}
{"id": "1701.04371", "contents": "Title: On the Achievable Secrecy Diversity of Cooperative Networks with\n  Untrusted Relays Abstract: Cooperative relaying is often deployed to enhance the communication\nreliability (i.e., diversity order) and consequently the end-to-end achievable\nrate. However, this raises several security concerns when the relays are\nuntrusted since they may have access to the relayed message. In this paper, we\nstudy the achievable secrecy diversity order of cooperative networks with\nuntrusted relays. In particular, we consider a network with an N-antenna\ntransmitter (Alice), K single-antenna relays, and a single-antenna destination\n(Bob). We consider the general scenario where there is no relation between N\nand K, and therefore K can be larger than N. Alice and Bob are assumed to be\nfar away from each other, and all communication is done through the relays,\ni.e., there is no direct link. Providing secure communication while enhancing\nthe diversity order has been shown to be very challenging. In fact, it has been\nshown in the literature that the maximum achievable secrecy diversity order for\nthe adopted system model is one (while using artificial noise jamming). In this\npaper, we adopt a nonlinear interference alignment scheme that we have proposed\nrecently to transmit the signals from Alice to Bob. We analyze the proposed\nscheme in terms of the achievable secrecy rate and secrecy diversity order.\nAssuming Gaussian inputs, we derive an explicit expression for the achievable\nsecrecy rate and show analytically that a secrecy diversity order of up to\nmin(N,K)-1 can be achieved using the proposed technique. We provide several\nnumerical examples to validate the obtained analytical results and demonstrate\nthe superiority of the proposed technique to its counterparts that exist in the\nliterature. \n\n"}
{"id": "1701.05392", "contents": "Title: On Optimal Online Algorithms for Energy Harvesting Systems with\n  Continuous Energy and Data Arrivals Abstract: Energy harvesting (EH) has been developed to extend the lifetimes of\nenergy-limited communication systems. In this letter, we consider a single-user\nEH communication system, in which both of the arrival data and the harvested\nenergy curves are modeled as general functions. Unlike most of the works in the\nfield, we investigate the online algorithms which only acquire the causal\ninformation of the arrival data and the harvested energy processes. We study\nhow well the optimal online algorithm works compared with the optimal offline\nalgorithm, and thus our goal is to find the lower and upper bounds for the\nratio of the completion time in the optimal online algorithm to the optimal\noffline algorithm. We propose two online algorithms which achieve the upper\nbound of 2 on this ratio. Also, we show that this ratio is 2 for the optimal\nonline algorithm. \n\n"}
{"id": "1701.05653", "contents": "Title: Rigorous Dynamics of Expectation-Propagation-Based Signal Recovery from\n  Unitarily Invariant Measurements Abstract: This paper investigates sparse signal recovery based on expectation\npropagation (EP) from unitarily invariant measurements. A rigorous analysis is\npresented for the state evolution (SE) of an EP-based message-passing algorithm\nin the large system limit, where both input and output dimensions tend to\ninfinity at an identical speed. The main result is the justification of an SE\nformula conjectured by Ma and Ping. \n\n"}
{"id": "1701.06678", "contents": "Title: Variable-length codes for channels with memory and feedback:\n  error-exponent upper bounds Abstract: The reliability function of memoryless channels with noiseless feedback and\nvariable-length coding has been found to be a linear function of the average\nrate in the classic work of Burnashev. In this work we consider unifilar\nchannels with noiseless feedback and study upper bounds for the channel\nreliability function with variable length codes. In unifilar channels the\nchannel state is known to the transmitter but is unknown to the receiver. We\ngeneralize Burnashev's analysis and derive a similar expression which is linear\nin average rate and depends on the channel capacity, as well as an additional\nparameter which relates to a sequential binary hypothesis testing problem over\nthis channel. This parameter is evaluated by setting up an appropriate Markov\ndecision process (MDP). Furthermore, an upper bound for this parameter is\nderived using a simplified MDP. Numerical evaluation of the parameter for\nseveral binary input/state/output unifilar channels hints at the optimal\ntransmission strategies. Such strategies are studied in a companion paper to\nprovide lower (achievable) bounds on the channel reliability function. \n\n"}
{"id": "1701.07007", "contents": "Title: A New Wiretap Channel Model and its Strong Secrecy Capacity Abstract: In this paper, a new wiretap channel model is proposed, where the legitimate\ntransmitter and receiver communicate over a discrete memoryless channel. The\nwiretapper has perfect access to a fixed-length subset of the transmitted\ncodeword symbols of her choosing. Additionally, she observes the remainder of\nthe transmitted symbols through a discrete memoryless channel. This new model\nsubsumes the classical wiretap channel and wiretap channel II with noisy main\nchannel as its special cases. The strong secrecy capacity of the proposed\nchannel model is identified. Achievability is established by solving a dual\nsecret key agreement problem in the source model, and converting the solution\nto the original channel model using probability distribution approximation\narguments. In the dual problem, a source encoder and decoder, who observe\nrandom sequences independent and identically distributed according to the input\nand output distributions of the legitimate channel in the original problem,\ncommunicate a confidential key over a public error-free channel using a single\nforward transmission, in the presence of a compound wiretapping source who has\nperfect access to the public discussion. The security of the key is guaranteed\nfor the exponentially many possibilities of the subset chosen at wiretapper by\nderiving a lemma which provides a doubly-exponential convergence rate for the\nprobability that, for a fixed choice of the subset, the key is uniform and\nindependent from the public discussion and the wiretapping source's\nobservation. The converse is derived by using Sanov's theorem to upper bound\nthe secrecy capacity of the new wiretap channel model by the secrecy capacity\nwhen the tapped subset is randomly chosen by nature. \n\n"}
{"id": "1701.07115", "contents": "Title: Coded Caching with Linear Subpacketization is Possible using\n  Ruzsa-Szem\\'eredi Graphs Abstract: Coded caching is a problem where encoded broadcasts are used to satisfy users\nrequesting popular files and having caching capabilities. Recent work by\nMaddah-Ali and Niesen showed that it is possible to satisfy a scaling number of\nusers with only a constant number of broadcast transmissions by exploiting\ncoding and caching. Unfortunately, all previous schemes required the splitting\nof files into an exponential number of packets before the significant coding\ngains of caching appeared. The question of what can be achieved with polynomial\nsubpacketization (in the number of users) has been a central open problem in\nthis area. We resolve this problem and present the first coded caching scheme\nwith polynomial (in fact, linear) subpacketization. We obtain a number of\ntransmissions that is not constant, but can be any polynomial in the number of\nusers with an exponent arbitrarily close to zero. Our central technical tool is\na novel connection between Ruzsa-Szem\\'eredi graphs and coded caching. \n\n"}
{"id": "1701.07363", "contents": "Title: E2M2: Energy Efficient Mobility Management in Dense Small Cells with\n  Mobile Edge Computing Abstract: Merging mobile edge computing with the dense deployment of small cell base\nstations promises enormous benefits such as a real proximity, ultra-low latency\naccess to cloud functionalities. However, the envisioned integration creates\nmany new challenges and one of the most significant is mobility management,\nwhich is becoming a key bottleneck to the overall system performance. Simply\napplying existing solutions leads to poor performance due to the highly\noverlapped coverage areas of multiple base stations in the proximity of the\nuser and the co-provisioning of radio access and computing services. In this\npaper, we develop a novel user-centric mobility management scheme, leveraging\nLyapunov optimization and multi-armed bandits theories, in order to maximize\nthe edge computation performance for the user while keeping the user's\ncommunication energy consumption below a constraint. The proposed scheme\neffectively handles the uncertainties present at multiple levels in the system\nand provides both short-term and long-term performance guarantee. Simulation\nresults show that our proposed scheme can significantly improve the computation\nperformance (compared to state of the art) while satisfying the communication\nenergy constraint. \n\n"}
{"id": "1701.07668", "contents": "Title: Low Rank Magnetic Resonance Fingerprinting Abstract: Purpose: Magnetic Resonance Fingerprinting (MRF) is a relatively new approach\nthat provides quantitative MRI measures using randomized acquisition.\nExtraction of physical quantitative tissue parameters is performed off-line,\nwithout the need of patient presence, based on acquisition with varying\nparameters and a dictionary generated according to the Bloch equation\nsimulations. MRF uses hundreds of radio frequency (RF) excitation pulses for\nacquisition, and therefore a high undersampling ratio in the sampling domain\n(k-space) is required for reasonable scanning time. This undersampling causes\nspatial artifacts that hamper the ability to accurately estimate the tissue's\nquantitative values. In this work, we introduce a new approach for quantitative\nMRI using MRF, called magnetic resonance Fingerprinting with LOw Rank (FLOR).\n  Methods: We exploit the low rank property of the concatenated temporal\nimaging contrasts, on top of the fact that the MRF signal is sparsely\nrepresented in the generated dictionary domain. We present an iterative scheme\nthat consists of a gradient step followed by a low rank projection using the\nsingular value decomposition.\n  Results: Experimental results consist of retrospective sampling, that allows\ncomparison to a well defined reference, and prospective sampling that shows the\nperformance of FLOR for a real-data sampling scenario. Both experiments\ndemonstrate improved parameter accuracy compared to other compressed-sensing\nand low-rank based methods for MRF at 5% and 9% sampling ratios, for the\nretrospective and prospective experiments, respectively.\n  Conclusions: We have shown through retrospective and prospective experiments\nthat by exploiting the low rank nature of the MRF signal, FLOR recovers the MRF\ntemporal undersampled images and provides more accurate parameter maps compared\nto previous iterative methods. \n\n"}
{"id": "1702.00153", "contents": "Title: Structure and Performance of Generalized Quasi-Cyclic Codes Abstract: Generalized quasi-cyclic (GQC) codes form a natural generalization of\nquasi-cyclic (QC) codes. They are viewed here as mixed alphabet codes over a\nfamily of ring alphabets. Decomposing these rings into local rings by the\nChinese Remainder Theorem yields a decomposition of GQC codes into a sum of\nconcatenated codes. This decomposition leads to a trace formula, a minimum\ndistance bound, and to a criteria for the GQC code to be self-dual or to be\nlinear complementary dual (LCD). Explicit long GQC codes that are LCD, but not\nQC, are exhibited. \n\n"}
{"id": "1702.01203", "contents": "Title: Intrinsic entropies of log-concave distributions Abstract: The entropy of a random variable is well-known to equal the exponential\ngrowth rate of the volumes of its typical sets. In this paper, we show that for\nany log-concave random variable $X$, the sequence of the $\\lfloor n\\theta\n\\rfloor^{\\text{th}}$ intrinsic volumes of the typical sets of $X$ in dimensions\n$n \\geq 1$ grows exponentially with a well-defined rate. We denote this rate by\n$h_X(\\theta)$, and call it the $\\theta^{\\text{th}}$ intrinsic entropy of $X$.\nWe show that $h_X(\\theta)$ is a continuous function of $\\theta$ over the range\n$[0,1]$, thereby providing a smooth interpolation between the values 0 and\n$h(X)$ at the endpoints 0 and 1, respectively. \n\n"}
{"id": "1702.03446", "contents": "Title: On the Global-Local Dichotomy in Sparsity Modeling Abstract: The traditional sparse modeling approach, when applied to inverse problems\nwith large data such as images, essentially assumes a sparse model for small\noverlapping data patches. While producing state-of-the-art results, this\nmethodology is suboptimal, as it does not attempt to model the entire global\nsignal in any meaningful way - a nontrivial task by itself. In this paper we\npropose a way to bridge this theoretical gap by constructing a global model\nfrom the bottom up. Given local sparsity assumptions in a dictionary, we show\nthat the global signal representation must satisfy a constrained\nunderdetermined system of linear equations, which can be solved efficiently by\nmodern optimization methods such as Alternating Direction Method of Multipliers\n(ADMM). We investigate conditions for unique and stable recovery, and provide\nnumerical evidence corroborating the theory. \n\n"}
{"id": "1702.04707", "contents": "Title: Comparison of Polar Decoders with Existing Low-Density Parity-Check and\n  Turbo Decoders Abstract: Polar codes are a recently proposed family of provably capacity-achieving\nerror-correction codes that received a lot of attention. While their\ntheoretical properties render them interesting, their practicality compared to\nother types of codes has not been thoroughly studied. Towards this end, in this\npaper, we perform a comparison of polar decoders against LDPC and Turbo\ndecoders that are used in existing communications standards. More specifically,\nwe compare both the error-correction performance and the hardware efficiency of\nthe corresponding hardware implementations. This comparison enables us to\nidentify applications where polar codes are superior to existing\nerror-correction coding solutions as well as to determine the most promising\nresearch direction in terms of the hardware implementation of polar decoders. \n\n"}
{"id": "1702.04822", "contents": "Title: ns-3 Implementation of the 3GPP MIMO Channel Model for Frequency\n  Spectrum above 6 GHz Abstract: Communications at mmWave frequencies will be a key enabler of the next\ngeneration of cellular networks, due to the multi-Gbps rate that can be\nachieved. However, there are still several problems that must be solved before\nthis technology can be widely adopted, primarily associated with the interplay\nbetween the variability of mmWave links and the complexity of mobile networks.\nAn end-to-end network simulator represents a great tool to assess the\nperformance of any proposed solution to meet the stringent 5G requirements.\nGiven the criticality of channel propagation characteristics at higher\nfrequencies, we present our implementation of the 3GPP channel model for the\n6-100 GHz band for the ns-3 end-to-end 5G mmWave module, and detail its\nassociated MIMO beamforming architecture. \n\n"}
{"id": "1702.05202", "contents": "Title: A Correlation-Breaking Interleaving of Polar Codes in Concatenated\n  Systems Abstract: It is known that the bit errors of polar codes with successive cancellation\n(SC) decoding are coupled. However, existing concatenation schemes of polar\ncodes with other error correction codes rarely take this coupling effect into\nconsideration. To achieve a better error performance of concatenated systems\nwith polar codes as inner codes, one can divide all bits in an outer block into\ndifferent polar blocks to completely de-correlate the possible coupled errors\nin the transmitter side. We call this interleaving a blind interleaving (BI)\nwhich serves as a benchmark. Two BI schemes, termed BI-DP and BI-CDP, are\nproposed in the paper. To better balance performance, memory size, and the\ndecoding delay from the de-interleaving, a novel interleaving scheme, named the\ncorrelation-breaking interleaving (CBI), is proposed. The CBI breaks the\ncorrelated information bits based on the error correlation pattern proposed and\nproven in this paper. The proposed CBI scheme is general in the sense that any\nerror correction code can serve as the outer code. In this paper, Low-Density\nParity-Check (LDPC) codes and BCH codes are used as two examples of the outer\ncodes of the interleaving scheme. The CBI scheme 1) can keep the simple SC\npolar decoding while achieving a better error performance than the\nstate-of-the-art (SOA) direct concatenation of polar codes with LDPC codes and\nBCH codes; 2) achieves a comparable error performance as the BI-DP scheme with\na smaller memory size and a shorter decoding delay. Numerical results are\nprovided to verify the performance of the BI schemes and the CBI scheme. \n\n"}
{"id": "1702.05722", "contents": "Title: From rate distortion theory to metric mean dimension: variational\n  principle Abstract: The purpose of this paper is to point out a new connection between\ninformation theory and dynamical systems. In the information theory side, we\nconsider rate distortion theory, which studies lossy data compression of\nstochastic processes under distortion constraints. In the dynamical systems\nside, we consider mean dimension theory, which studies how many parameters per\nsecond we need to describe a dynamical system. The main results are new\nvariational principles connecting rate distortion function to metric mean\ndimension. \n\n"}
{"id": "1702.05833", "contents": "Title: IEEE 802.11ad-based Radar: An Approach to Joint Vehicular\n  Communication-Radar System Abstract: Millimeter-wave (mmWave) radar is widely used in vehicles for applications\nsuch as adaptive cruise control and collision avoidance. In this paper, we\npropose an IEEE 802.11ad-based radar for long-range radar (LRR) applications at\nthe 60 GHz unlicensed band. We exploit the preamble of a single-carrier (SC)\nphysical layer (PHY) frame, which consists of Golay complementary sequences\nwith good correlation properties, as a radar waveform. This system enables a\njoint waveform for automotive radar and a potential mmWave vehicular\ncommunication system based on IEEE 802.11ad, allowing hardware reuse. To\nformulate an integrated framework of vehicle-to-vehicle (V2V) communication and\nLRR based on a mmWave consumer wireless local area network (WLAN) standard, we\nmake typical assumptions for LRR applications and incorporate the full duplex\nradar assumption due to the possibility of sufficient isolation and\nself-interference cancellation. We develop single- and multi-frame radar\nreceiver algorithms for target detection as well as range and velocity\nestimation within a coherent processing interval. Our proposed radar processing\nalgorithms leverage channel estimation and time-frequency synchronization\ntechniques used in a conventional IEEE 802.11ad receiver with minimal\nmodifications. Analysis and simulations show that in a single target scenario,\na Gbps data rate is achieved simultaneously with cm-level range accuracy and\ncm/s-level velocity accuracy. The target vehicle is detected with a high\nprobability of detection ($>$99.9$\\%$) at a low false alarm of 10$^{-6}$ for an\nequivalent isotropically radiated power (EIRP) of 43 dBm up to a vehicle\nseparation distance of 200 m. \n\n"}
{"id": "1702.06226", "contents": "Title: Noise Models in the Nonlinear Spectral Domain for Optical Fibre\n  Communications Abstract: Existing works on building a soliton transmission system only encode\ninformation using the imaginary part of the eigenvalue, which fails to make\nfull use of the signal degree-of-freedoms. Motivated by this observation, we\nmake the first step of encoding information using (discrete) spectral\namplitudes by proposing analytical noise models for the spectral amplitudes of\n$N$-solitons ($N\\geq 1$). To our best knowledge, this is the first work in\nbuilding an analytical noise model for spectral amplitudes, which leads to many\ninteresting information theoretic questions, such as channel capacity analysis,\nand has a potential of increasing the transmission rate. The noise statistics\nof the spectral amplitude of a soliton are also obtained without the Gaussian\napproximation. \n\n"}
{"id": "1702.07160", "contents": "Title: Space-Time Channel Modulation Abstract: In this paper, we introduce the concept of space-time channel modulation\n(STCM), which extends the classical space-time block codes into a new third\ndimension: channel states (transmission media) dimension. Three novel STCM\nschemes, which provide interesting trade-offs among decoding complexity, error\nperformance and data rate, are proposed. It is shown via computer simulations\nthat the proposed STCM schemes achieve considerably better error performance\nthan the existing media-based modulation (MBM) and classical systems. \n\n"}
{"id": "1702.07409", "contents": "Title: Founsure 1.0: An Erasure Code Library with Efficient Repair and Update\n  Features Abstract: Founsure is an open-source software library that implements a\nmulti-dimensional graph-based erasure coding entirely based on fast exclusive\nOR (XOR) logic. Its implementation utilizes compiler optimizations and\nmulti-threading to generate the right assembly code for the given multi-core\nCPU architecture with vector processing capabilities. Founsure possesses\nimportant features that shall find various applications in modern data storage,\ncommunication, and networked computer systems, in which the data needs\nprotection against device, hardware, and node failures. As data size reached\nunprecedented levels, these systems have become hungry for network bandwidth,\ncomputational resources, and average consumed power. To address that, the\nproposed library provides a three-dimensional design space that trades off the\ncomputational complexity, coding overhead, and data/node repair bandwidth to\nmeet different requirements of modern distributed data storage and processing\nsystems. Founsure library enables efficient encoding, decoding,\nrepairs/rebuilds, and updates while all the required data storage and\ncomputations are distributed across the network nodes. \n\n"}
{"id": "1702.07803", "contents": "Title: Nonparanormal Information Estimation Abstract: We study the problem of using i.i.d. samples from an unknown multivariate\nprobability distribution $p$ to estimate the mutual information of $p$. This\nproblem has recently received attention in two settings: (1) where $p$ is\nassumed to be Gaussian and (2) where $p$ is assumed only to lie in a large\nnonparametric smoothness class. Estimators proposed for the Gaussian case\nconverge in high dimensions when the Gaussian assumption holds, but are\nbrittle, failing dramatically when $p$ is not Gaussian. Estimators proposed for\nthe nonparametric case fail to converge with realistic sample sizes except in\nvery low dimensions. As a result, there is a lack of robust mutual information\nestimators for many realistic data. To address this, we propose estimators for\nmutual information when $p$ is assumed to be a nonparanormal (a.k.a., Gaussian\ncopula) model, a semiparametric compromise between Gaussian and nonparametric\nextremes. Using theoretical bounds and experiments, we show these estimators\nstrike a practical balance between robustness and scaling with dimensionality. \n\n"}
{"id": "1702.07939", "contents": "Title: Upper bounds on the smallest size of a saturating set in projective\n  planes and spaces of even dimension Abstract: In a projective plane $\\Pi_{q}$ (not necessarily Desarguesian) of order $q$,\na point subset $\\mathcal{S}$ is saturating (or dense) if any point of\n$\\Pi_{q}\\setminus \\mathcal{S}$ is collinear with two points in $\\mathcal{S}$.\nModifying an approach of [31], we proved the following upper bound on the\nsmallest size $s(2,q)$ of a saturating set in $\\Pi_{q}$: \\begin{equation*}\ns(2,q)\\leq \\sqrt{(q+1)\\left(3\\ln q+\\ln\\ln q\n+\\ln\\frac{3}{4}\\right)}+\\sqrt{\\frac{q}{3\\ln q}}+3. \\end{equation*} The bound\nholds for all q, not necessarily large.\n  By using inductive constructions, upper bounds on the smallest size of a\nsaturating set in the projective space $\\mathrm{PG}(N,q)$ with even dimension\n$N$ are obtained.\n  All the results are also stated in terms of linear covering codes. \n\n"}
{"id": "1702.08079", "contents": "Title: Topological Interference Management with Decoded Message Passing Abstract: The topological interference management (TIM) problem studies\npartially-connected interference networks with no channel state information\nexcept for the network topology (i.e., connectivity graph) at the transmitters.\nIn this paper, we consider a similar problem in the uplink cellular networks,\nwhile message passing is enabled at the receivers (e.g., base stations), so\nthat the decoded messages can be routed to other receivers via backhaul links\nto help further improve network performance. For this TIM problem with decoded\nmessage passing (TIM-MP), we model the interference pattern by conflict\ndigraphs, connect orthogonal access to the acyclic set coloring on conflict\ndigraphs, and show that one-to-one interference alignment boils down to\northogonal access because of message passing. With the aid of polyhedral\ncombinatorics, we identify the structural properties of certain classes of\nnetwork topologies where orthogonal access achieves the optimal\ndegrees-of-freedom (DoF) region in the information-theoretic sense. The\nrelation to the conventional index coding with simultaneous decoding is also\ninvestigated by formulating a generalized index coding problem with successive\ndecoding as a result of decoded message passing. The properties of reducibility\nand criticality are also studied, by which we are able to prove the linear\noptimality of orthogonal access in terms of symmetric DoF for the networks up\nto four users with all possible network topologies (218 instances). Practical\nissues of the tradeoff between the overhead of message passing and the\nachievable symmetric DoF are also discussed, in the hope of facilitating\nefficient backhaul utilization. \n\n"}
{"id": "1702.08531", "contents": "Title: Practical issues in decoy-state quantum key distribution based on the\n  central limit theorem Abstract: Decoy-state quantum key distribution is a standard tool for long-distance\nquantum communications. An important issue in this field is processing the\ndecoy-state statistics taking into account statistical fluctuations (or\n\"finite-key effects\"). In this work, we propose and analyze an option for decoy\nstatistics processing, which is based on the central limit theorem. We discuss\nsuch practical issues as an inclusion of the failure probability of the\ndecoy-states statistical estimates in the total failure probability of a QKD\nprotocol and also taking into account the deviations of the binomially\ndistributed random variables used in the estimations from the Gaussian\ndistribution. The results of numerical simulations show that the obtained\nestimations are quite tight. The proposed technique can be used as a part of\npost-processing procedures for industrial quantum key distribution systems. \n\n"}
{"id": "1702.08565", "contents": "Title: Nearly Maximally Predictive Features and Their Dimensions Abstract: Scientific explanation often requires inferring maximally predictive features\nfrom a given data set. Unfortunately, the collection of minimal maximally\npredictive features for most stochastic processes is uncountably infinite. In\nsuch cases, one compromises and instead seeks nearly maximally predictive\nfeatures. Here, we derive upper-bounds on the rates at which the number and the\ncoding cost of nearly maximally predictive features scales with desired\npredictive power. The rates are determined by the fractal dimensions of a\nprocess' mixed-state distribution. These results, in turn, show how widely-used\nfinite-order Markov models can fail as predictors and that mixed-state\npredictive features offer a substantial improvement. \n\n"}
{"id": "1702.08800", "contents": "Title: Jamming-Resistant Receivers for the Massive MIMO Uplink Abstract: We design a jamming-resistant receiver scheme to enhance the robustness of a\nmassive MIMO uplink system against jamming. We assume that a jammer attacks the\nsystem both in the pilot and data transmission phases. The key feature of the\nproposed scheme is that, in the pilot phase, we estimate not only the\nlegitimate channel, but also the jamming channel by exploiting a purposely\nunused pilot sequence. The jamming channel estimate is used to constructed\nlinear receive filters that reject the impact of the jamming signal. The\nperformance of the proposed scheme is analytically evaluated using asymptotic\nproperties of massive MIMO. The optimal regularized zero-forcing receiver and\nthe optimal power allocation are also studied. Numerical results are provided\nto verify our analysis and show that the proposed scheme greatly improves the\nachievable rates, as compared to conventional receivers. Interestingly, the\nproposed scheme works particularly well under strong jamming attacks, since the\nimproved estimate of the jamming channel outweighs the extra jamming power. \n\n"}
{"id": "1703.00428", "contents": "Title: Repair Strategies for Storage on Mobile Clouds Abstract: We study the data reliability problem for a community of devices forming a\nmobile cloud storage system. We consider the application of regenerating codes\nfor file maintenance within a geographically-limited area. Such codes require\nlower bandwidth to regenerate lost data fragments compared to file replication\nor reconstruction. We investigate threshold-based repair strategies where data\nrepair is initiated after a threshold number of data fragments have been lost\ndue to node mobility. We show that at a low departure-to-repair rate regime, a\nlazy repair strategy in which repairs are initiated after several nodes have\nleft the system outperforms eager repair in which repairs are initiated after a\nsingle departure. This optimality is reversed when nodes are highly mobile. We\nfurther compare distributed and centralized repair strategies and derive the\noptimal repair threshold for minimizing the average repair cost per unit of\ntime, as a function of underlying code parameters. In addition, we examine\ncooperative repair strategies and show performance improvements compared to\nnon-cooperative codes. We investigate several models for the time needed for\nnode repair including a simple fixed time model that allows for the computation\nof closed-form expressions and a more realistic model that takes into account\nthe number of repaired nodes. We derive the conditions under which the former\nmodel approximates the latter. Finally, an extended model where additional\nfailures are allowed during the repair process is investigated. Overall, our\nresults establish the joint effect of code design and repair algorithms on the\nmaintenance cost of distributed storage systems. \n\n"}
{"id": "1703.01038", "contents": "Title: Ultra-Dense Edge Caching under Spatio-Temporal Demand and Network\n  Dynamics Abstract: This paper investigates a cellular edge caching design under an extremely\nlarge number of small base stations (SBSs) and users. In this ultra-dense edge\ncaching network (UDCN), SBS-user distances shrink, and each user can request a\ncached content from multiple SBSs. Unfortunately, the complexity of existing\ncaching controls' mechanisms increases with the number of SBSs, making them\ninapplicable for solving the fundamental caching problem: How to maximize local\ncaching gain while minimizing the replicated content caching? Furthermore,\nspatial dynamics of interference is no longer negligible in UDCNs due to the\nsurge in interference. In addition, the caching control should consider\ntemporal dynamics of user demands. To overcome such difficulties, we propose a\nnovel caching algorithm weaving together notions of mean-field game theory and\nstochastic geometry. These enable our caching algorithm to become independent\nof the number of SBSs and users, while incorporating spatial interference\ndynamics as well as temporal dynamics of content popularity and storage\nconstraints. Numerical evaluation validates the fact that the proposed\nalgorithm reduces not only the long run average cost by at least 24% but also\nthe number of replicated content by 56% compared to a popularity-based\nalgorithm. \n\n"}
{"id": "1703.01142", "contents": "Title: Symmetric Laplacians, Quantum Density Matrices and their Von-Neumann\n  Entropy Abstract: We show that the (normalized) symmetric Laplacian of a simple graph can be\nobtained from the partial trace over a pure bipartite quantum state that\nresides in a bipartite Hilbert space (one part corresponding to the vertices,\nthe other corresponding to the edges). This suggests an interpretation of the\nsymmetric Laplacian's Von Neumann entropy as a measure of bipartite\nentanglement present between the two parts of the state. We then study extreme\nvalues for a connected graph's generalized R\\'enyi-$p$ entropy. Specifically,\nwe show that\n  (1) the complete graph achieves maximum entropy,\n  (2) the $2$-regular graph: a) achieves minimum R\\'enyi-$2$ entropy among all\n$k$-regular graphs, b) is within $\\log 4/3$ of the minimum R\\'enyi-$2$ entropy\nand $\\log4\\sqrt{2}/3$ of the minimum Von Neumann entropy among all connected\ngraphs, c) achieves a Von Neumann entropy less than the star graph.\n  Point $(2)$ contrasts sharply with similar work applied to (normalized)\ncombinatorial Laplacians, where it has been shown that the star graph almost\nalways achieves minimum Von Neumann entropy. In this work we find that the star\ngraph achieves maximum entropy in the limit as the number of vertices grows\nwithout bound.\n  Keywords: Symmetric; Laplacian; Quantum; Entropy; Bounds; R\\'enyi. \n\n"}
{"id": "1703.01733", "contents": "Title: Position-based coding and convex splitting for private communication\n  over quantum channels Abstract: The classical-input quantum-output (cq) wiretap channel is a communication\nmodel involving a classical sender $X$, a legitimate quantum receiver $B$, and\na quantum eavesdropper $E$. The goal of a private communication protocol that\nuses such a channel is for the sender $X$ to transmit a message in such a way\nthat the legitimate receiver $B$ can decode it reliably, while the eavesdropper\n$E$ learns essentially nothing about which message was transmitted. The\n$\\varepsilon $-one-shot private capacity of a cq wiretap channel is equal to\nthe maximum number of bits that can be transmitted over the channel, such that\nthe privacy error is no larger than $\\varepsilon\\in(0,1)$. The present paper\nprovides a lower bound on the $\\varepsilon$-one-shot private classical\ncapacity, by exploiting the recently developed techniques of Anshu,\nDevabathini, Jain, and Warsi, called position-based coding and convex\nsplitting. The lower bound is equal to a difference of the hypothesis testing\nmutual information between $X$ and $B$ and the \"alternate\" smooth\nmax-information between $X$ and $E$. The one-shot lower bound then leads to a\nnon-trivial lower bound on the second-order coding rate for private classical\ncommunication over a memoryless cq wiretap channel. \n\n"}
{"id": "1703.02324", "contents": "Title: Gaussian Multiple Access Channels with One-Bit Quantizer at the Receiver Abstract: The capacity region of a two-transmitter Gaussian multiple access channel\n(MAC) under average input power constraints is studied, when the receiver\nemploys a zero-threshold one-bit analog-to-digital converter (ADC). It is\nproved that the input distributions of the two transmitters that achieve the\nboundary points of the capacity region are discrete. Based on the position of a\nboundary point, upper bounds on the number of the mass points of the\ncorresponding distributions are derived. \n\n"}
{"id": "1703.03141", "contents": "Title: Orthogonal Transform Multiplexing with Memoryless Nonlinearity: a\n  Possible Alternative to Traditional Coded-Modulation Schemes Abstract: In this paper, we propose a novel joint coding-modulation technique based on\nserial concatenation of orthogonal linear transform, such as discrete Fourier\ntransform (DFT) or Walsh-Hadamard transform (WHT), with memoryless\nnonlinearity. We demonstrate that such a simple signal construction may exhibit\nproperties of a random code ensemble, as a result approaching channel capacity.\nOur computer simulations confirm that if the decoder relies on a modified\napproximate message passing algorithm, the proposed modulation technique\nexhibits performance on par with state-of-the-art coded modulation schemes that\nuse capacity-approaching component codes. The proposed modulation scheme could\nbe used directly or as a pre-coder for a conventional orthogonal frequency\ndivision multiplexing (OFDM) transmitter, resulting in a system possessing all\nbenefits of OFDM along with reduced peak-to-average power ratio (PAPR). \n\n"}
{"id": "1703.04064", "contents": "Title: An Improved Diversity Combining Receiver for Layered ACO-FOFDM in IM/DD\n  Systems Abstract: In this paper, an improved receiver based on diversity combining is proposed\nto improve the bit error rate (BER) performance of layered asymmetrically\nclipped optical fast orthogonal frequency division multiplexing (ACO-FOFDM) for\nintensity-modulated and direct-detected (IM/DD) optical transmission systems.\nLayered ACO-FOFDM can compensate the weakness of traditional ACO-FOFDM in low\nspectral efficiency, the utilization of discrete cosine transform in FOFDM\nsystem instead of fast Fourier transform in OFDM system can reduce the\ncomputational complexity without any influence on BER performance. The BER\nperformances of layered ACO-FOFDM system with improved receiver based on\ndiversity combining and DC-offset FOFDM (DCO-FOFDM) system with optimal DC-bias\nare compared at the same spectral efficiency. Simulation results show that\nunder different optical bit energy to noise power ratios, layered ACO-FOFDM\nsystem with improved receiver has 2.86dB, 5.26dB and 5.72dB BER performance\nadvantages at forward error correction limit over DCO-FOFDM system when the\nspectral efficiencies are 1 bit/s/Hz, 2 bits/s/Hz and 3 bits/s/Hz,\nrespectively. Layered ACO-FOFDM system with improved receiver based on\ndiversity combining is suitable for application in the adaptive IM/DD systems\nwith zero DC-bias. \n\n"}
{"id": "1703.04886", "contents": "Title: Information Theoretic Optimal Learning of Gaussian Graphical Models Abstract: What is the optimal number of independent observations from which a sparse\nGaussian Graphical Model can be correctly recovered? Information-theoretic\narguments provide a lower bound on the minimum number of samples necessary to\nperfectly identify the support of any multivariate normal distribution as a\nfunction of model parameters. For a model defined on a sparse graph with $p$\nnodes, a maximum degree $d$ and minimum normalized edge strength $\\kappa$, this\nnecessary number of samples scales at least as $d \\log p/\\kappa^2$. The sample\ncomplexity requirements of existing methods for perfect graph reconstruction\nexhibit dependency on additional parameters that do not enter in the lower\nbound. The question of whether the lower bound is tight and achievable by a\npolynomial time algorithm remains open. In this paper, we constructively answer\nthis question and propose an algorithm, termed DICE, whose sample complexity\nmatches the information-theoretic lower bound up to a universal constant\nfactor. We also propose a related algorithm SLICE that has a slightly higher\nsample complexity, but can be implemented as a mixed integer quadratic program\nwhich makes it attractive in practice. Importantly, SLICE retains a critical\nadvantage of DICE in that its sample complexity only depends on quantities\npresent in the information theoretic lower bound. We anticipate that this\nresult will stimulate future search of computationally efficient sample-optimal\nalgorithms. \n\n"}
{"id": "1703.05038", "contents": "Title: Harmonic Mean Iteratively Reweighted Least Squares for Low-Rank Matrix\n  Recovery Abstract: We propose a new iteratively reweighted least squares (IRLS) algorithm for\nthe recovery of a matrix $X \\in \\mathbb{C}^{d_1\\times d_2}$ of rank $r\n\\ll\\min(d_1,d_2)$ from incomplete linear observations, solving a sequence of\nlow complexity linear problems. The easily implementable algorithm, which we\ncall harmonic mean iteratively reweighted least squares (HM-IRLS), optimizes a\nnon-convex Schatten-$p$ quasi-norm penalization to promote low-rankness and\ncarries three major strengths, in particular for the matrix completion setting.\nFirst, we observe a remarkable global convergence behavior of the algorithm's\niterates to the low-rank matrix for relevant, interesting cases, for which any\nother state-of-the-art optimization approach fails the recovery. Secondly,\nHM-IRLS exhibits an empirical recovery probability close to $1$ even for a\nnumber of measurements very close to the theoretical lower bound $r (d_1 +d_2\n-r)$, i.e., already for significantly fewer linear observations than any other\ntractable approach in the literature. Thirdly, HM-IRLS exhibits a locally\nsuperlinear rate of convergence (of order $2-p$) if the linear observations\nfulfill a suitable null space property. While for the first two properties we\nhave so far only strong empirical evidence, we prove the third property as our\nmain theoretical result. \n\n"}
{"id": "1703.05307", "contents": "Title: On decoding algorithms for polar codes Abstract: We survey the known list decoding algorithms for polar codes and compare\ntheir complexity.\n  Index terms: Polar codes; Reed-Muller codes; successive cancellation\ndecoding. \n\n"}
{"id": "1703.06538", "contents": "Title: Scalable Content Delivery with Coded Caching in Multi-Antenna Fading\n  Channels Abstract: We consider the content delivery problem in a fading multi-input\nsingle-output channel with cache-aided users. We are interested in the\nscalability of the equivalent content delivery rate when the number of users,\n$K$, is large. Analytical results show that, using coded caching and wireless\nmulticasting, without channel state information at the transmitter (CSIT),\nlinear scaling of the content delivery rate with respect to $K$ can be achieved\nin some different ways. First, if the multicast transmission spans over $L$\nindependent sub-channels, e.g., in quasi-static fading if $L = 1$, and in block\nfading or multi-carrier systems if $L>1$, linear scaling can be obtained when\nthe product of the number of transmit antennas and the number of sub-channels\nscales logarithmically with $K$. Second, even with a fixed number of antennas,\nwe can achieve the linear scaling with a threshold-based user selection\nrequiring only one-bit feedbacks from the users. When CSIT is available, we\npropose a mixed strategy that combines spatial multiplexing and multicasting.\nNumerical results show that, by optimizing the power split between spatial\nmultiplexing and multicasting, we can achieve a significant gain of the content\ndelivery rate with moderate cache size. \n\n"}
{"id": "1703.06714", "contents": "Title: Generalized Compute-Compress-and-Forward Abstract: Compute-and-forward (CF) harnesses interference in wireless communications by\nexploiting structured coding. The key idea of CF is to compute integer\ncombinations of codewords from multiple source nodes, rather than to decode\nindividual codewords by treating others as noise. Compute-compress-and-forward\n(CCF) can further enhance the network performance by introducing compression\noperations at receivers. In this paper, we develop a more general compression\nframework, termed generalized compute-compress-and-forward (GCCF), where the\ncompression function involves multiple quantization-and-modulo lattice\noperations. We show that GCCF achieves a broader compression rate region than\nCCF. We also compare our compression rate region with the fundamental\nSlepian-Wolf (SW) region. We show that GCCF is optimal in the sense of\nachieving the minimum total compression rate. We also establish the criteria\nunder which GCCF achieves the SW region. In addition, we consider a two-hop\nrelay network employing the GCCF scheme. We formulate a sum-rate maximization\nproblem and develop an approximate algorithm to solve the problem. Numerical\nresults are presented to demonstrate the performance superiority of GCCF over\nCCF and other schemes. \n\n"}
{"id": "1703.07035", "contents": "Title: Pattern Division Multiple Access with Large-scale Antenna Array Abstract: In this paper, pattern division multiple access with large-scale antenna\narray (LSA-PDMA) is proposed as a novel non-orthogonal multiple access (NOMA)\nscheme. In the proposed scheme, pattern is designed in both beam domain and\npower domain in a joint manner. At the transmitter, pattern mapping utilizes\npower allocation to improve the system sum rate and beam allocation to enhance\nthe access connectivity and realize the integration of LSA into multiple access\nspontaneously. At the receiver, hybrid detection of spatial filter (SF) and\nsuccessive interference cancellation (SIC) is employed to separate the\nsuperposed multiple-domain signals. Furthermore, we formulate the sum rate\nmaximization problem to obtain the optimal pattern mapping policy, and the\noptimization problem is proved to be convex through proper mathematical\nmanipulations. Simulation results show that the proposed LSA-PDMA scheme\nachieves significant performance gain on system sum rate compared to both the\northogonal multiple access scheme and the power-domain NOMA scheme. \n\n"}
{"id": "1703.08642", "contents": "Title: Regularized Gradient Descent: A Nonconvex Recipe for Fast Joint Blind\n  Deconvolution and Demixing Abstract: We study the question of extracting a sequence of functions\n$\\{\\boldsymbol{f}_i, \\boldsymbol{g}_i\\}_{i=1}^s$ from observing only the sum of\ntheir convolutions, i.e., from $\\boldsymbol{y} = \\sum_{i=1}^s\n\\boldsymbol{f}_i\\ast \\boldsymbol{g}_i$. While convex optimization techniques\nare able to solve this joint blind deconvolution-demixing problem provably and\nrobustly under certain conditions, for medium-size or large-size problems we\nneed computationally faster methods without sacrificing the benefits of\nmathematical rigor that come with convex methods. In this paper, we present a\nnon-convex algorithm which guarantees exact recovery under conditions that are\ncompetitive with convex optimization methods, with the additional advantage of\nbeing computationally much more efficient. Our two-step algorithm converges to\nthe global minimum linearly and is also robust in the presence of additive\nnoise. While the derived performance bounds are suboptimal in terms of the\ninformation-theoretic limit, numerical simulations show remarkable performance\neven if the number of measurements is close to the number of degrees of\nfreedom. We discuss an application of the proposed framework in wireless\ncommunications in connection with the Internet-of-Things. \n\n"}
{"id": "1703.09848", "contents": "Title: Painless Breakups -- Efficient Demixing of Low Rank Matrices Abstract: Assume we are given a sum of linear measurements of $s$ different rank-$r$\nmatrices of the form $y = \\sum_{k=1}^{s} \\mathcal{A}_k ({X}_k)$. When and under\nwhich conditions is it possible to extract (demix) the individual matrices\n${X}_k$ from the single measurement vector ${y}$? And can we do the demixing\nnumerically efficiently? We present two computationally efficient algorithms\nbased on hard thresholding to solve this low rank demixing problem. We prove\nthat under suitable conditions these algorithms are guaranteed to converge to\nthe correct solution at a linear rate. We discuss applications in connection\nwith quantum tomography and the Internet-of-Things. Numerical simulations\ndemonstrate empirically the performance of the proposed algorithms. \n\n"}
{"id": "1704.00399", "contents": "Title: Ultra-Dense Networks: Is There a Limit to Spatial Spectrum Reuse? Abstract: The aggressive spatial spectrum reuse (SSR) by network densification using\nsmaller cells has successfully driven the wireless communication industry\nonward in the past decades. In our future journey toward ultra-dense networks\n(UDNs), a fundamental question needs to be answered. Is there a limit to SSR?\nIn other words, when we deploy thousands or millions of small cell base\nstations (BSs) per square kilometer, is activating all BSs on the same\ntime/frequency resource the best strategy? In this paper, we present\ntheoretical analyses to answer such question. In particular, we find that both\nthe signal and interference powers become bounded in practical UDNs with a\nnon-zero BS-to-UE antenna height difference and a finite UE density, which\nleads to a constant capacity scaling law. As a result, there exists an optimal\nSSR density that can maximize the network capacity. Hence, the limit to SSR\nshould be considered in the operation of future UDNs. \n\n"}
{"id": "1704.00436", "contents": "Title: Sparse Bayesian learning with uncertainty models and multiple\n  dictionaries Abstract: Sparse Bayesian learning (SBL) has emerged as a fast and competitive method\nto perform sparse processing. The SBL algorithm, which is developed using a\nBayesian framework, approximately solves a non-convex optimization problem\nusing fixed point updates. It provides comparable performance and is\nsignificantly faster than convex optimization techniques used in sparse\nprocessing. We propose a signal model which accounts for dictionary mismatch\nand the presence of errors in the weight vector at low signal-to-noise ratios.\nA fixed point update equation is derived which incorporates the statistics of\nmismatch and weight errors. We also process observations from multiple\ndictionaries. Noise variances are estimated using stochastic maximum\nlikelihood. The derived update equations are studied quantitatively using\nbeamforming simulations applied to direction-of-arrival (DoA). Performance of\nSBL using single- and multi-frequency observations, and in the presence of\naliasing, is evaluated. SwellEx-96 experimental data demonstrates qualitatively\nthe advantages of SBL. \n\n"}
{"id": "1704.00715", "contents": "Title: Convolutional Polar Codes Abstract: Arikan's Polar codes attracted much attention as the first efficiently\ndecodable and capacity achieving codes. Furthermore, Polar codes exhibit an\nexponentially decreasing block error probability with an asymptotic error\nexponent upper bounded by 1/2. Since their discovery, many attempts have been\nmade to improve the error exponent and the finite block-length performance,\nwhile keeping the bloc-structured kernel. Recently, two of us introduced a new\nfamily of efficiently decodable error-correction codes based on a recently\ndiscovered efficiently-contractible tensor network family in quantum many-body\nphysics, called branching MERA. These codes, called branching MERA codes,\ninclude Polar codes and also extend them in a non-trivial way by substituting\nthe bloc-structured kernel by a convolutional structure. Here, we perform an\nin-depth study of a particular example that can be thought of as a direct\nextension to Arikan's Polar code, which we therefore name Convolutional Polar\ncodes. We prove that these codes polarize and exponentially suppress the\nchannel's error probability, with an asymptotic error exponent log_2(3)/2 which\nis provably better than for Polar codes under successive cancellation decoding.\nWe also perform finite block-size numerical simulations which display improved\nerror-correcting capability with only a minor impact on decoding complexity. \n\n"}
{"id": "1704.00766", "contents": "Title: Active Anomaly Detection in Heterogeneous Processes Abstract: An active inference problem of detecting anomalies among heterogeneous\nprocesses is considered. At each time, a subset of processes can be probed. The\nobjective is to design a sequential probing strategy that dynamically\ndetermines which processes to observe at each time and when to terminate the\nsearch so that the expected detection time is minimized under a constraint on\nthe probability of misclassifying any process. This problem falls into the\ngeneral setting of sequential design of experiments pioneered by Chernoff in\n1959, in which a randomized strategy, referred to as the Chernoff test, was\nproposed and shown to be asymptotically optimal as the error probability\napproaches zero. For the problem considered in this paper, a low-complexity\ndeterministic test is shown to enjoy the same asymptotic optimality while\noffering significantly better performance in the finite regime and faster\nconvergence to the optimal rate function, especially when the number of\nprocesses is large. The computational complexity of the proposed test is also\nof a significantly lower order. \n\n"}
{"id": "1704.01891", "contents": "Title: On Multi-source Networks: Enumeration, Rate Region Computation, and\n  Hierarchy Abstract: Recent algorithmic developments have enabled computers to automatically\ndetermine and prove the capacity regions of small hypergraph networks under\nnetwork coding. A structural theory relating network coding problems of\ndifferent sizes is developed to make best use of this newfound computational\ncapability. A formal notion of network minimality is developed which removes\ncomponents of a network coding problem that are inessential to its core\ncomplexity. Equivalence between different network coding problems under\nrelabeling is formalized via group actions, an algorithm which can directly\nlist single representatives from each equivalence class of minimal networks up\nto a prescribed network size is presented. This algorithm, together with rate\nregion software, is leveraged to create a database containing the rate regions\nfor all minimal network coding problems with five or fewer sources and edges, a\ncollection of 744119 equivalence classes representing more than 9 million\nnetworks. In order to best learn from this database, and to leverage it to\ninfer rate regions and their characteristics of networks at scale, a hierarchy\nbetween different network coding problems is created with a new theory of\ncombinations and embedding operators. \n\n"}
{"id": "1704.01893", "contents": "Title: Improved Decoding and Error Floor Analysis of Staircase Codes Abstract: Staircase codes play an important role as error-correcting codes in optical\ncommunications. In this paper, a low-complexity method for resolving stall\npatterns when decoding staircase codes is described. Stall patterns are the\ndominating contributor to the error floor in the original decoding method. Our\nimprovement is based on locating stall patterns by intersecting non-zero\nsyndromes and flipping the corresponding bits. The approach effectively lowers\nthe error floor and allows for a new range of block sizes to be considered for\noptical communications at a certain rate or, alternatively, a significantly\ndecreased error floor for the same block size. Further, an improved error floor\nanalysis is introduced which provides a more accurate estimation of the\ncontributions to the error floor. \n\n"}
{"id": "1704.03137", "contents": "Title: Resolution-Adaptive Hybrid MIMO Architectures for Millimeter Wave\n  Communications Abstract: In this paper, we propose a hybrid analog-digital beamforming architecture\nwith resolution-adaptive ADCs for millimeter wave (mmWave) receivers with large\nantenna arrays. We adopt array response vectors for the analog combiners and\nderive ADC bit-allocation (BA) solutions in closed form. The BA solutions\nreveal that the optimal number of ADC bits is logarithmically proportional to\nthe RF chain's signal-to-noise ratio raised to the 1/3 power. Using the\nsolutions, two proposed BA algorithms minimize the mean square quantization\nerror of received analog signals under a total ADC power constraint.\nContributions of this paper include 1) ADC bit-allocation algorithms to improve\ncommunication performance of a hybrid MIMO receiver, 2) approximation of the\ncapacity with the BA algorithm as a function of channels, and 3) a worst-case\nanalysis of the ergodic rate of the proposed MIMO receiver that quantifies\nsystem tradeoffs and serves as the lower bound. Simulation results demonstrate\nthat the BA algorithms outperform a fixed-ADC approach in both spectral and\nenergy efficiency, and validate the capacity and ergodic rate formula. For a\npower constraint equivalent to that of fixed 4-bit ADCs, the revised BA\nalgorithm makes the quantization error negligible while achieving 22% better\nenergy efficiency. Having negligible quantization error allows existing\nstate-of-the-art digital beamformers to be readily applied to the proposed\nsystem. \n\n"}
{"id": "1704.03287", "contents": "Title: Uplink Multiuser Massive MIMO Systems with Low-Resolution ADCs: A\n  Coding-Theoretic Approach Abstract: This paper considers an uplink multiuser massive\nmultiple-input-multiple-output (MIMO) system with low-resolution\nanalog-to-digital converters (ADCs), in which K users with a single-antenna\ncommunicate with one base station (BS) with Nr antennas. In this system, we\npresent a novel multiuser MIMO detection framework that is inspired by coding\ntheory. The key idea of the proposed framework is to create a code C of length\n2Nr over a spatial domain. This code is constructed by a so-called\nauto-encoding function that is not designable but is completely described by a\nchannel transformation followed by a quantization function of the ADCs. From\nthis point of view, we convert a multiuser MIMO detection problem into an\nequivalent channel coding problem, in which a codeword of C corresponding to\nusers' messages is sent over 2Nr parallel channels, each with different channel\nreliability. To the resulting problem, we propose a novel weighted minimum\ndistance decoding (wMDD) that appropriately exploits the unequal channel\nreliabilities. It is shown that the proposed wMDD yields a non-trivial gain\nover the conventional minimum distance decoding (MDD). From coding-theoretic\nviewpoint, we identify that bit-error-rate (BER) exponentially decreases with\nthe minimum distance of the code C, which plays a similar role with a condition\nnumber in conventional MIMO systems. Furthermore, we develop the communication\nmethod that uses the wMDD for practical scenarios where the BS has no knowledge\nof channel state information. Finally, numerical results are provided to verify\nthe superiority of the proposed method. \n\n"}
{"id": "1704.04083", "contents": "Title: Constructions of optimal LCD codes over large finite fields Abstract: In this paper, we prove existence of optimal complementary dual codes (LCD\ncodes) over large finite fields. We also give methods to generate orthogonal\nmatrices over finite fields and then apply them to construct LCD codes.\nConstruction methods include random sampling in the orthogonal group, code\nextension, matrix product codes and projection over a self-dual basis. \n\n"}
{"id": "1704.04194", "contents": "Title: Ultrametrics in the genetic code and the genome Abstract: Ultrametric approach to the genetic code and the genome is considered and\ndeveloped. $p$-Adic degeneracy of the genetic code is pointed out. Ultrametric\ntree of the codon space is presented. It is shown that codons and amino acids\ncan be treated as $p$-adic ultrametric networks. Ultrametric modification of\nthe Hamming distance is defined and noted how it can be useful. Ultrametric\napproach with $p$-adic distance is an attractive and promising trend towards\ninvestigation of bioinformation. \n\n"}
{"id": "1704.06124", "contents": "Title: An Achievable Rate for an Optical Channel with Finite Memory Abstract: A fiber optic channel is modeled in a variety of ways; from the simple\nadditive white complex Gaussian noise model, to models that incorporate memory\nin the channel. Because of Kerr nonlinearity, a simple model is not a good\napproximation to an optical fiber. Hence we study a fiber optic channel with\nfinite memory and provide an achievable bound on channel capacity that improves\nupon a previously known bound. \n\n"}
{"id": "1704.06785", "contents": "Title: A general private information retrieval scheme for MDS coded databases\n  with colluding servers Abstract: The problem of private information retrieval gets renewed attentions in\nrecent years due to its information-theoretic reformulation and applications in\ndistributed storage systems. PIR capacity is the maximal number of bits\nprivately retrieved per one bit of downloaded bit. The capacity has been fully\nsolved for some degenerating cases. For a general case where the database is\nboth coded and colluded, the exact capacity remains unknown. We build a general\nprivate information retrieval scheme for MDS coded databases with colluding\nservers. Our scheme achieves the rate $(1+R+R^2+\\cdots+R^{M-1})$, where\n$R=1-\\frac{{{N-T}\\choose K}}{{N\\choose K}}$. Compared to existing PIR schemes,\nour scheme performs better for a certain range of parameters and is suitable\nfor any underlying MDS code used in the distributed storage system. \n\n"}
{"id": "1704.07611", "contents": "Title: A Survey on MIMO Transmission with Discrete Input Signals: Technical\n  Challenges, Advances, and Future Trends Abstract: Multiple antennas have been exploited for spatial multiplexing and diversity\ntransmission in a wide range of communication applications. However, most of\nthe advances in the design of high speed wireless multiple-input multiple\noutput (MIMO) systems are based on information-theoretic principles that\ndemonstrate how to efficiently transmit signals conforming to Gaussian\ndistribution. Although the Gaussian signal is capacity-achieving, signals\nconforming to discrete constellations are transmitted in practical\ncommunication systems. As a result, this paper is motivated to provide a\ncomprehensive overview on MIMO transmission design with discrete input signals.\nWe first summarize the existing fundamental results for MIMO systems with\ndiscrete input signals. Then, focusing on the basic point-to-point MIMO\nsystems, we examine transmission schemes based on three most important criteria\nfor communication systems: the mutual information driven designs, the mean\nsquare error driven designs, and the diversity driven designs. Particularly, a\nunified framework which designs low complexity transmission schemes applicable\nto massive MIMO systems in upcoming 5G wireless networks is provided in the\nfirst time. Moreover, adaptive transmission designs which switch among these\ncriteria based on the channel conditions to formulate the best transmission\nstrategy are discussed. Then, we provide a survey of the transmission designs\nwith discrete input signals for multiuser MIMO scenarios, including MIMO uplink\ntransmission, MIMO downlink transmission, MIMO interference channel, and MIMO\nwiretap channel. Additionally, we discuss the transmission designs with\ndiscrete input signals for other systems using MIMO technology. Finally,\ntechnical challenges which remain unresolved at the time of writing are\nsummarized and the future trends of transmission designs with discrete input\nsignals are addressed. \n\n"}
{"id": "1704.07766", "contents": "Title: A lower bound on the differential entropy of log-concave random vectors\n  with applications Abstract: We derive a lower bound on the differential entropy of a log-concave random\nvariable $X$ in terms of the $p$-th absolute moment of $X$. The new bound leads\nto a reverse entropy power inequality with an explicit constant, and to new\nbounds on the rate-distortion function and the channel capacity.\n  Specifically, we study the rate-distortion function for log-concave sources\nand distortion measure $| x - \\hat x|^r$, and we establish that the difference\nbetween the rate distortion function and the Shannon lower bound is at most\n$\\log(\\sqrt{\\pi e}) \\approx 1.5$ bits, independently of $r$ and the target\ndistortion $d$. For mean-square error distortion, the difference is at most\n$\\log (\\sqrt{\\frac{\\pi e}{2}}) \\approx 1$ bits, regardless of $d$.\n  We also provide bounds on the capacity of memoryless additive noise channels\nwhen the noise is log-concave. We show that the difference between the capacity\nof such channels and the capacity of the Gaussian channel with the same noise\npower is at most $\\log (\\sqrt{\\frac{\\pi e}{2}}) \\approx 1$ bits.\n  Our results generalize to the case of vector $X$ with possibly dependent\ncoordinates, and to $\\gamma$-concave random variables. Our proof technique\nleverages tools from convex geometry. \n\n"}
{"id": "1705.01576", "contents": "Title: Fourth-order Tensors with Multidimensional Discrete Transforms Abstract: The big data era is swamping areas including data analysis, machine/deep\nlearning, signal processing, statistics, scientific computing, and cloud\ncomputing. The multidimensional feature and huge volume of big data put urgent\nrequirements to the development of multilinear modeling tools and efficient\nalgorithms. In this paper, we build a novel multilinear tensor space that\nsupports useful algorithms such as SVD and QR, while generalizing the matrix\nspace to fourth-order tensors was believed to be challenging. Specifically,\ngiven any multidimensional discrete transform, we show that fourth-order\ntensors are bilinear operators on a space of matrices. First, we take a\ntransform-based approach to construct a new tensor space by defining a new\nmultiplication operation and tensor products, and accordingly the analogous\nconcepts: identity, inverse, transpose, linear combinations, and orthogonality.\nSecondly, we define the $\\mathcal{L}$-SVD for fourth-order tensors and present\nan efficient algorithm, where the tensor case requires a stronger condition for\nunique decomposition than the matrix case. Thirdly, we define the tensor\n$\\mathcal{L}$-QR decomposition and propose a Householder QR algorithm to avoid\nthe catastrophic cancellation problem associated with the conventional\nGram-Schmidt process. Finally, we validate our schemes on video compression and\none-shot face recognition. For video compression, compared with the existing\ntSVD, the proposed $\\mathcal{L}$-SVD achieves $3\\sim 10$dB gains in RSE, while\nthe running time is reduced by about $50\\%$ and $87.5\\%$, respectively. For\none-shot face recognition, the recognition rate is increased by about $10\\%\n\\sim 20\\%$. \n\n"}
{"id": "1705.03064", "contents": "Title: Optimal User Scheduling and Power Allocation for Millimeter Wave NOMA\n  Systems Abstract: This paper investigates the application of non-orthogonal multiple access\n(NOMA) in millimeter wave (mmWave) communications by exploiting beamforming,\nuser scheduling and power allocation. Random beamforming is invoked for\nreducing the feedback overhead of considered systems. A nonconvex optimization\nproblem for maximizing the sum rate is formulated, which is proved to be\nNP-hard. The branch and bound (BB) approach is invoked to obtain the optimal\npower allocation policy, which is proved to converge to a global optimal\nsolution. To elaborate further, low complexity suboptimal approach is developed\nfor striking a good computational complexity-optimality tradeoff, where\nmatching theory and successive convex approximation (SCA) techniques are\ninvoked for tackling the user scheduling and power allocation problems,\nrespectively. Simulation results reveal that: i) the proposed low complexity\nsolution achieves a near-optimal performance; and ii) the proposed mmWave NOMA\nsystems is capable of outperforming conventional mmWave orthogonal multiple\naccess (OMA) systems in terms of sum rate and the number of served users. \n\n"}
{"id": "1705.03280", "contents": "Title: Fast Approximate Construction of Best Complex Antipodal Spherical Codes Abstract: Compressive Sensing (CS) theory states that real-world signals can often be\nrecovered from much fewer measurements than those suggested by the Shannon\nsampling theorem. Nevertheless, recoverability does not only depend on the\nsignal, but also on the measurement scheme. The measurement matrix should\nbehave as close as possible to an isometry for the signals of interest.\nTherefore the search for optimal CS measurement matrices of size $m\\times n$\ntranslates into the search for a set of $n$ $m$-dimensional vectors with\nminimal coherence. Best Complex Antipodal Spherical Codes (BCASCs) are known to\nbe optimal in terms of coherence. An iterative algorithm for BCASC generation\nhas been recently proposed that tightly approaches the theoretical lower bound\non coherence. Unfortunately, the complexity of each iteration depends\nquadratically on $m$ and $n$. In this work we propose a modification of the\nalgorithm that allows reducing the quadratic complexity to linear on both $m$\nand $n$. Numerical evaluation showed that the proposed approach does not worsen\nthe coherence of the resulting BCASCs. On the contrary, an improvement was\nobserved for large $n$. The reduction of the computational complexity paves the\nway for using the BCASCs as CS measurement matrices in problems with large $n$.\nWe evaluate the CS performance of the BCASCs for recovering sparse signals. The\nBCASCs are shown to outperform both complex random matrices and Fourier\nensembles as CS measurement matrices, both in terms of coherence and sparse\nrecovery performance, especially for low $m/n$, which is the case of interest\nin CS. \n\n"}
{"id": "1705.03325", "contents": "Title: Non-orthogonal Multiple Access in Large-Scale Heterogeneous Networks Abstract: In this paper, the potential benefits of applying non-orthogonal multiple\naccess (NOMA) technique in $K$-tier hybrid heterogeneous networks (HetNets) is\nexplored. A promising new transmission framework is proposed, in which NOMA is\nadopted in small cells and massive multiple-input multiple-output (MIMO) is\nemployed in macro cells. For maximizing the biased average received power for\nmobile users, a NOMA and massive MIMO based user association scheme is\ndeveloped. To evaluate the performance of the proposed framework, we first\nderive the analytical expressions for the coverage probability of NOMA enhanced\nsmall cells. We then examine the spectrum efficiency of the whole network, by\nderiving exact analytical expressions for NOMA enhanced small cells and a\ntractable lower bound for massive MIMO enabled macro cells. Lastly, we\ninvestigate the energy efficiency of the hybrid HetNets. Our results\ndemonstrate that: 1) The coverage probability of NOMA enhanced small cells is\naffected to a large extent by the targeted transmit rates and power sharing\ncoefficients of two NOMA users; 2) Massive MIMO enabled macro cells are capable\nof significantly enhancing the spectrum efficiency by increasing the number of\nantennas; 3) The energy efficiency of the whole network can be greatly improved\nby densely deploying NOMA enhanced small cell base stations (BSs); and 4) The\nproposed NOMA enhanced HetNets transmission scheme has superior performance\ncompared to the orthogonal multiple access~(OMA) based HetNets. \n\n"}
{"id": "1705.03577", "contents": "Title: On the Ergodic Rate Lower Bounds with Applications to Massive MIMO Abstract: A well-known lower bound widely used in the massive MIMO literature hinges on\nchannel hardening, i.e., the phenomenon for which, thanks to the large number\nof antennas, the effective channel coefficients resulting from beamforming tend\nto deterministic quantities. If the channel hardening effect does not hold\nsufficiently well, this bound may be quite far from the actual achievable rate.\nIn recent developments of massive MIMO, several scenarios where channel\nhardening is not sufficiently pronounced have emerged. These settings include,\nfor example, the case of small scattering angular spread, yielding highly\ncorrelated channel vectors, and the case of cell-free massive MIMO. In this\nshort contribution, we present two new bounds on the achievable ergodic rate\nthat offer a complementary behavior with respect to the classical bound: while\nthe former performs well in the case of channel hardening and/or when the\nsystem is interference-limited (notably, in the case of finite number of\nantennas and conjugate beamforming transmission), the new bounds perform well\nwhen the useful signal coefficient does not harden but the channel coherence\nblock length is large with respect to the number of users, and in the case\nwhere interference is nearly entirely eliminated by zero-forcing beamforming.\nOverall, using the most appropriate bound depending on the system operating\nconditions yields a better understanding of the actual performance of systems\nwhere channel hardening may not occur, even in the presence of a very large\nnumber of antennas. \n\n"}
{"id": "1705.05005", "contents": "Title: Irregular Recovery and Unequal Locality for Locally Recoverable Codes\n  with Availability Abstract: A code is said to be a Locally Recoverable Code (LRC) with availability if\nevery coordinate can be recovered from multiple disjoint sets of other\ncoordinates called recovering sets. The vector of sizes of recovering sets of a\ncoordinate is called its recovery profile. In this work, we consider LRCs with\navailability under two different settings: (1) irregular recovery: non-constant\nrecovery profile that remains fixed for all coordinates, (2) unequal locality:\nregular recovery profile that can vary with coordinates. For each setting, we\nderive bounds for the minimum distance that generalize previously known bounds\nto the cases of irregular or varying recovery profiles. For the case of regular\nand fixed recovery profile, we show that a specific Tamo-Barg\npolynomial-evaluation construction is optimal for all-symbol locality, and we\nprovide parity-check matrix constructions for information locality with\navailability. \n\n"}
{"id": "1705.06670", "contents": "Title: Multilayer Codes for Synchronization from Deletions and Insertions Abstract: Consider two remote nodes (encoder and decoder), each with a binary sequence.\nThe encoder's sequence $X$ differs from the decoder's sequence $Y$ by a small\nnumber of edits (deletions and insertions). The goal is to construct a message\n$M$, to be sent via a one-way error free link, such that the decoder can\nreconstruct $X$ using $M$ and $Y$. In this paper, we devise a coding scheme for\nthis one-way synchronization model. The scheme is based on multiple layers of\nVarshamov-Tenengolts (VT) codes combined with off-the-shelf linear\nerror-correcting codes, and uses a list decoder. We bound the expected list\nsize of the decoder under certain assumptions, and validate its performance via\nnumerical simulations. We also consider an alternative decoder that uses only\nthe constraints from the VT codes (i.e., does not require a linear code), and\nhas a smaller redundancy at the expense of a slightly larger average list size. \n\n"}
{"id": "1705.06799", "contents": "Title: Joint Uplink and Downlink Coverage Analysis of Cellular-based RF-powered\n  IoT Network Abstract: Ambient radio frequency (RF) energy harvesting has emerged as a promising\nsolution for powering small devices and sensors in massive Internet of Things\n(IoT) ecosystem due to its ubiquity and cost efficiency. In this paper, we\nstudy joint uplink and downlink coverage of cellular-based ambient RF energy\nharvesting IoT where the cellular network is assumed to be the only source of\nRF energy. We consider a time division-based approach for power and information\ntransmission where each time-slot is partitioned into three sub-slots: (i)\ncharging sub-slot during which the cellular base stations (BSs) act as RF\nchargers for the IoT devices, which then use the energy harvested in this\nsub-slot for information transmission and/or reception during the remaining two\nsub-slots, (ii) downlink sub-slot during which the IoT device receives\ninformation from the associated BS, and (iii) uplink sub-slot during which the\nIoT device transmits information to the associated BS. For this setup, we\ncharacterize the joint coverage probability, which is the joint probability of\nthe events that the typical device harvests sufficient energy in the given time\nslot and is under both uplink and downlink signal-to-interference-plus-noise\nratio (SINR) coverage with respect to its associated BS. This metric\nsignificantly generalizes the prior art on energy harvesting communications,\nwhich usually focused on downlink or uplink coverage separately. The key\ntechnical challenge is in handling the correlation between the amount of energy\nharvested in the charging sub-slot and the information signal quality (SINR) in\nthe downlink and uplink sub-slots. Dominant BS-based approach is developed to\nderive tight approximation for this joint coverage probability. Several system\ndesign insights including comparison with regularly powered IoT network and\nthroughput-optimal slot partitioning are also provided. \n\n"}
{"id": "1705.07081", "contents": "Title: Secure Computation of Randomized Functions: Further Results Abstract: We consider secure computation of randomized functions between two users,\nwhere both the users (Alice and Bob) have inputs, Alice sends a message to Bob\nover a rate-limited, noise-free link, and then Bob produces the output. We\nstudy two cases: (i) when privacy condition is required only against Bob, who\ntries to learn more about Alice's input from the message than what can be\ninferred by his own input and output, and (ii) when there is no privacy\nrequirement. For both the problems, we give single-letter expressions for the\noptimal rates. For the first problem, we also explicitly characterize securely\ncomputable randomized functions when input has full support, which leads to a\nmuch simpler expression for the optimal rate. Recently, Data (ISIT 2016)\nstudied the remaining two cases (first, when privacy conditions are against\nboth the users; and second, when privacy condition is only against Alice) and\nobtained single-letter expressions for optimal rates in both the scenarios. \n\n"}
{"id": "1705.07237", "contents": "Title: Coexistence of RF-powered IoT and a Primary Wireless Network with\n  Secrecy Guard Zones Abstract: This paper studies the secrecy performance of a wireless network (primary\nnetwork) overlaid with an ambient RF energy harvesting IoT network (secondary\nnetwork). The nodes in the secondary network are assumed to be solely powered\nby ambient RF energy harvested from the transmissions of the primary network.\nWe assume that the secondary nodes can eavesdrop on the primary transmissions\ndue to which the primary network uses secrecy guard zones. The primary\ntransmitter goes silent if any secondary receiver is detected within its guard\nzone. Using tools from stochastic geometry, we derive the probability of\nsuccessful connection of the primary network as well as the probability of\nsecure communication. Two conditions must be jointly satisfied in order to\nensure successful connection: (i) the SINR at the primary receiver is above a\npredefined threshold, and (ii) the primary transmitter is not silent. In order\nto ensure secure communication, the SINR value at each of the secondary nodes\nshould be less than a predefined threshold. Clearly, when more secondary nodes\nare deployed, more primary transmitters will remain silent for a given guard\nzone radius, thus impacting the amount of energy harvested by the secondary\nnetwork. Our results concretely show the existence of an optimal deployment\ndensity for the secondary network that maximizes the density of nodes that are\nable to harvest sufficient amount of energy. Furthermore, we show the\ndependence of this optimal deployment density on the guard zone radius of the\nprimary network. In addition, we show that the optimal guard zone radius\nselected by the primary network is a function of the deployment density of the\nsecondary network. This interesting coupling between the two networks is\nstudied using tools from game theory. Overall, this work is one of the few\nconcrete works that symbiotically merge tools from stochastic geometry and game\ntheory. \n\n"}
{"id": "1705.08148", "contents": "Title: Capacity Outer Bound and Degrees of Freedom of Wiener Phase Noise\n  Channels with Oversampling Abstract: The discrete-time Wiener phase noise channel with an integrate-and-dump\nmulti-sample receiver is studied.\n  A novel outer bound on the capacity with an average input power constraint is\nderived as a function of the oversampling factor.\n  This outer bound yields the degrees of freedom for the scenario in which the\noversampling factor grows with the transmit power $P$ as $P^{\\alpha}$.\n  The result shows, perhaps surprisingly, that the largest pre-log that can be\nattained with phase modulation at high signal-to-noise ratio is at most $1/4$. \n\n"}
{"id": "1705.09024", "contents": "Title: UAV-Aided Offloading for Cellular Hotspot Abstract: In conventional terrestrial cellular networks, mobile terminals (MTs) at the\ncell edge often pose a performance bottleneck due to their long distances from\nthe serving ground base station (GBS), especially in hotspot period when the\nGBS is heavily loaded. This paper proposes a new hybrid network architecture by\nleveraging the use of unmanned aerial vehicle (UAV) as an aerial mobile base\nstation, which flies cyclically along the cell edge to offload data traffic for\ncell-edge MTs. We aim to maximize the minimum throughput of all MTs by jointly\noptimizing the UAV's trajectory, bandwidth allocation and user partitioning. We\nfirst consider orthogonal spectrum sharing between the UAV and GBS, and then\nextend to spectrum reuse where the total bandwidth is shared by both the GBS\nand UAV with their mutual interference effectively avoided. Numerical results\nshow that the proposed hybrid network with optimized spectrum sharing and\ncyclical multiple access design significantly improves the spatial throughput\nover the conventional GBS-only network; while the spectrum reuse scheme\nprovides further throughput gains at the cost of slightly higher complexity for\ninterference control. Moreover, compared to the conventional small-cell\noffloading scheme, the proposed UAV offloading scheme is shown to outperform in\nterms of throughput, besides saving the infrastructure cost. \n\n"}
{"id": "1705.09258", "contents": "Title: Quantum-secured blockchain Abstract: Blockchain is a distributed database which is cryptographically protected\nagainst malicious modifications. While promising for a wide range of\napplications, current blockchain platforms rely on digital signatures, which\nare vulnerable to attacks by means of quantum computers. The same, albeit to a\nlesser extent, applies to cryptographic hash functions that are used in\npreparing new blocks, so parties with access to quantum computation would have\nunfair advantage in procuring mining rewards. Here we propose a possible\nsolution to the quantum era blockchain challenge and report an experimental\nrealization of a quantum-safe blockchain platform that utilizes quantum key\ndistribution across an urban fiber network for information-theoretically secure\nauthentication. These results address important questions about realizability\nand scalability of quantum-safe blockchains for commercial and governmental\napplications. \n\n"}
{"id": "1705.09769", "contents": "Title: Efficient 3D Placement of a UAV Using Particle Swarm Optimization Abstract: Unmanned aerial vehicles (UAVs) can be used as aerial wireless base stations\nwhen cellular networks go down. Prior studies on UAV-based wireless coverage\ntypically consider an Air-to-Ground path loss model, which assumes that the\nusers are outdoor and they are located on a 2D plane. In this paper, we propose\nusing a single UAV to provide wireless coverage for indoor users inside a\nhigh-rise building under disaster situations (such as earthquakes or floods),\nwhen cellular networks are down. We assume that the locations of indoor users\nare uniformly distributed in each floor and we propose a particle swarm\noptimization algorithm to find an efficient 3D placement of a UAV that\nminimizes the total transmit power required to cover the indoor users. \n\n"}
{"id": "1705.10091", "contents": "Title: Rate $(n-1)/n$ Systematic MDS Convolutional Codes over $GF(2^m)$ Abstract: A systematic convolutional encoder of rate $(n-1)/n$ and maximum degree $D$\ngenerates a code of free distance at most ${\\cal D} = D+2$ and, at best, a\ncolumn distance profile (CDP) of $[2,3,\\ldots,{\\cal D}]$. A code is\n\\emph{Maximum Distance Separable} (MDS) if it possesses this CDP. Applied on a\ncommunication channel over which packets are transmitted sequentially and which\nloses (erases) packets randomly, such a code allows the recovery from any\npattern of $j$ erasures in the first $j$ $n$-packet blocks for $j<{\\cal D}$,\nwith a delay of at most $j$ blocks counting from the first erasure. This paper\naddresses the problem of finding the largest ${\\cal D}$ for which a systematic\nrate $(n-1)/n$ code over $GF(2^m)$ exists, for given $n$ and $m$. In\nparticular, constructions for rates $(2^m-1)/2^m$ and $(2^{m-1}-1)/2^{m-1}$ are\npresented which provide optimum values of ${\\cal D}$ equal to 3 and 4,\nrespectively. A search algorithm is also developed, which produces new codes\nfor ${\\cal D}$ for field sizes $2^m \\leq 2^{14}$. Using a complete search\nversion of the algorithm, the maximum value of ${\\cal D}$, and codes that\nachieve it, are determined for all code rates $\\geq 1/2$ and every field size\n$GF(2^m)$ for $m\\leq 5$ (and for some rates for $m=6$). \n\n"}
{"id": "1706.00800", "contents": "Title: Two-Point Codes for the Generalized GK curve Abstract: We improve previously known lower bounds for the minimum distance of certain\ntwo-point AG codes constructed using a Generalized Giulietti-Korchmaros curve\n(GGK). Castellanos and Tizziotti recently described such bounds for two-point\ncodes coming from the Giulietti-Korchmaros curve (GK). Our results completely\ncover and in many cases improve on their results, using different techniques,\nwhile also supporting any GGK curve. Our method builds on the order bound for\nAG codes: to enable this, we study certain Weierstrass semigroups. This allows\nan efficient algorithm for computing our improved bounds. We find several new\nimprovements upon the MinT minimum distance tables. \n\n"}
{"id": "1706.00904", "contents": "Title: X-TCP: A Cross Layer Approach for TCP Uplink Flows in mmWave Networks Abstract: Millimeter wave frequencies will likely be part of the fifth generation of\nmobile networks and of the 3GPP New Radio (NR) standard. MmWave communication\nindeed provides a very large bandwidth, thus an increased cell throughput, but\nhow to exploit these resources at the higher layers is still an open research\nquestion. A very relevant issue is the high variability of the channel, caused\nby the blockage from obstacles and the human body. This affects the design of\ncongestion control mechanisms at the transport layer, and state-of-the-art TCP\nschemes such as TCP CUBIC present suboptimal performance. In this paper, we\npresent a cross layer approach for uplink flows that adjusts the congestion\nwindow of TCP at the mobile equipment side using an estimation of the available\ndata rate at the mmWave physical layer, based on the actual resource allocation\nand on the Signal to Interference plus Noise Ratio. We show that this approach\nreduces the latency, avoiding to fill the buffers in the cellular stack, and\nhas a quicker recovery time after RTO events than several other TCP congestion\ncontrol algorithms. \n\n"}
{"id": "1706.01191", "contents": "Title: The Likelihood Ratio Test in High-Dimensional Logistic Regression Is\n  Asymptotically a Rescaled Chi-Square Abstract: Logistic regression is used thousands of times a day to fit data, predict\nfuture outcomes, and assess the statistical significance of explanatory\nvariables. When used for the purpose of statistical inference, logistic models\nproduce p-values for the regression coefficients by using an approximation to\nthe distribution of the likelihood-ratio test. Indeed, Wilks' theorem asserts\nthat whenever we have a fixed number $p$ of variables, twice the log-likelihood\nratio (LLR) $2\\Lambda$ is distributed as a $\\chi^2_k$ variable in the limit of\nlarge sample sizes $n$; here, $k$ is the number of variables being tested. In\nthis paper, we prove that when $p$ is not negligible compared to $n$, Wilks'\ntheorem does not hold and that the chi-square approximation is grossly\nincorrect; in fact, this approximation produces p-values that are far too small\n(under the null hypothesis). Assume that $n$ and $p$ grow large in such a way\nthat $p/n\\rightarrow\\kappa$ for some constant $\\kappa < 1/2$. We prove that for\na class of logistic models, the LLR converges to a rescaled chi-square, namely,\n$2\\Lambda~\\stackrel{\\mathrm{d}}{\\rightarrow}~\\alpha(\\kappa)\\chi_k^2$, where the\nscaling factor $\\alpha(\\kappa)$ is greater than one as soon as the\ndimensionality ratio $\\kappa$ is positive. Hence, the LLR is larger than\nclassically assumed. For instance, when $\\kappa=0.3$,\n$\\alpha(\\kappa)\\approx1.5$. In general, we show how to compute the scaling\nfactor by solving a nonlinear system of two equations with two unknowns. Our\nmathematical arguments are involved and use techniques from approximate message\npassing theory, non-asymptotic random matrix theory and convex geometry. We\nalso complement our mathematical study by showing that the new limiting\ndistribution is accurate for finite sample sizes. Finally, all the results from\nthis paper extend to some other regression models such as the probit regression\nmodel. \n\n"}
{"id": "1706.02171", "contents": "Title: SCW Codes for Maximum Likelihood Detection in Diffusive Molecular\n  Communications without Channel State Information Abstract: Instantaneous or statistical channel state information (CSI) is needed for\nmost detection schemes developed for molecular communication (MC) systems.\nSince the MC channel changes over time, e.g., due to variations in the velocity\nof flow, the temperature, or the distance between transmitter and receiver, CSI\nacquisition has to be conducted repeatedly to keep track of CSI variations.\nFrequent CSI acquisition may entail a large overhead whereas infrequent CSI\nacquisition may result in a low CSI estimation accuracy. To overcome these\nchallenges, we design codes which enable maximum likelihood sequence detection\nat the receiver without instantaneous or statistical CSI. In particular,\nassuming concentration shift keying modulation, we show that a class of codes,\nreferred to as strongly constant-weight (SCW) codes, enables optimal CSI-free\nsequence detection at the expense of a decrease in data rate. For the proposed\nSCW codes, we analyze the code rate, the error rate, and the average number of\nreleased molecules. In addition, we study the properties of binary SCW codes\nand balanced SCW codes in further detail. Simulation results verify our\nanalytical derivations and reveal that SCW codes with CSI-free detection\noutperform uncoded transmission with optimal coherent and non-coherent\ndetection. \n\n"}
{"id": "1706.05091", "contents": "Title: Spatial Coding Techniques for Molecular MIMO Abstract: This paper studies spatial diversity techniques applied to multiple-input\nmultiple-output (MIMO) diffusion-based molecular communications (DBMC). Two\ntypes of spatial coding techniques, namely Alamouti-type coding and repetition\nMIMO coding are suggested and analyzed. In addition, we consider receiver-side\nequal-gain combining, which is equivalent to maximum-ratio combining in\nsymmetrical scenarios. For numerical analysis, the channel impulse responses of\na symmetrical $2 \\times 2$ MIMO-DBMC system are acquired by a trained\nartificial neural network. It is demonstrated that spatial diversity has the\npotential to improve the system performance and that repetition MIMO coding\noutperforms Alamouti-type coding. \n\n"}
{"id": "1706.05295", "contents": "Title: Nonbacktracking Bounds on the Influence in Independent Cascade Models Abstract: This paper develops upper and lower bounds on the influence measure in a\nnetwork, more precisely, the expected number of nodes that a seed set can\ninfluence in the independent cascade model. In particular, our bounds exploit\nnonbacktracking walks, Fortuin-Kasteleyn-Ginibre (FKG) type inequalities, and\nare computed by message passing implementation. Nonbacktracking walks have\nrecently allowed for headways in community detection, and this paper shows that\ntheir use can also impact the influence computation. Further, we provide a knob\nto control the trade-off between the efficiency and the accuracy of the bounds.\nFinally, the tightness of the bounds is illustrated with simulations on various\nnetwork models. \n\n"}
{"id": "1706.05431", "contents": "Title: Centralized Multi-Node Repair Regenerating Codes Abstract: In a distributed storage system, recovering from multiple failures is a\ncritical and frequent task that is crucial for maintaining the system's\nreliability and fault-tolerance. In this work, we focus on the problem of\nrepairing multiple failures in a centralized way, which can be desirable in\nmany data storage configurations, and we show that a significant repair traffic\nreduction is possible. First, the fundamental tradeoff between the repair\nbandwidth and the storage size for functional repair is established. Using a\ngraph-theoretic formulation, the optimal tradeoff is identified as the solution\nto an integer optimization problem, for which a closed-form expression is\nderived. Expressions of the extreme points, namely the minimum storage\nmulti-node repair (MSMR) and minimum bandwidth multi-node repair (MBMR) points,\nare obtained. Second, we describe a general framework for converting single\nerasure minimum storage regenerating codes to MSMR codes. The repair strategy\nfor $e$ failures is similar to that for single failure, however certain extra\nrequirements need to be satisfied by the repairing functions for single\nfailure. For illustration, the framework is applied to product-matrix codes and\ninterference alignment codes. Furthermore, we prove that the functional MBMR\npoint is not achievable for linear exact repair codes. We also show that\nexact-repair minimum bandwidth cooperative repair (MBCR) codes achieve an\ninterior point, that lies near the MBMR point, when $k \\equiv 1 \\mod e$, $k$\nbeing the minimum number of nodes needed to reconstruct the entire data.\nFinally, for $k> 2e, e\\mid k$ and $e \\mid d$, where $d$ is the number of helper\nnodes during repair, we show that the functional repair tradeoff is not\nachievable under exact repair, except for maybe a small portion near the MSMR\npoint, which parallels the results for single erasure repair by Shah et al. \n\n"}
{"id": "1706.07531", "contents": "Title: High Performance Non-Binary Spatially-Coupled Codes for Flash Memories Abstract: Modern dense Flash memory devices operate at very low error rates, which\nrequire powerful error correcting coding (ECC) techniques. An emerging class of\ngraph-based ECC techniques that has broad applications is the class of\nspatially-coupled (SC) codes, where a block code is partitioned into components\nthat are then rewired multiple times to construct an SC code. Here, our focus\nis on SC codes with the underlying circulant-based structure. In this paper, we\npresent a three-stage approach for the design of high performance non-binary SC\n(NB-SC) codes optimized for practical Flash channels; we aim at minimizing the\nnumber of detrimental general absorbing sets of type two (GASTs) in the graph\nof the designed NB-SC code. In the first stage, we deploy a novel partitioning\nmechanism, called the optimal overlap partitioning, which acts on the\nprotograph of the SC code to produce optimal partitioning corresponding to the\nsmallest number of detrimental objects. In the second stage, we apply a new\ncirculant power optimizer to further reduce the number of detrimental GASTs. In\nthe third stage, we use the weight consistency matrix framework to manipulate\nedge weights to eliminate as many as possible of the GASTs that remain in the\nNB-SC code after the first two stages (that operate on the unlabeled graph of\nthe code). Simulation results reveal that NB-SC codes designed using our\napproach outperform state-of-the-art NB-SC codes when used over Flash channels. \n\n"}
{"id": "1706.08286", "contents": "Title: A hypothesis testing approach for communication over entanglement\n  assisted compound quantum channel Abstract: We study the problem of communication over a compound quantum channel in the\npresence of entanglement. Classically such channels are modeled as a collection\nof conditional probability distributions wherein neither the sender nor the\nreceiver is aware of the channel being used for transmission, except for the\nfact that it belongs to this collection. We provide near optimal achievability\nand converse bounds for this problem in the one-shot quantum setting in terms\nof quantum hypothesis testing divergence. We also consider the case of informed\nsender, showing a one-shot achievability result that converges appropriately in\nthe asymptotic and i.i.d. setting. Our achievability proof is similar in spirit\nto its classical counterpart. To arrive at our result, we use the technique of\nposition-based decoding along with a new approach for constructing a union of\ntwo projectors, which can be of independent interest. We give another\napplication of the union of projectors to the problem of testing composite\nquantum hypotheses. \n\n"}
{"id": "1706.09434", "contents": "Title: Approximate Quantum Error Correction Revisited: Introducing the\n  Alpha-bit Abstract: We establish that, in an appropriate limit, qubits of communication should be\nregarded as composite resources, decomposing cleanly into independent\ncorrelation and transmission components. Because qubits of communication can\nestablish ebits of entanglement, qubits are more powerful resources than ebits.\nWe identify a new communications resource, the zero-bit, which is precisely\nhalf the gap between them, replacing classical bits by zero-bits makes\nteleportation asymptotically reversible. The decomposition of a qubit into an\nebit and two zero-bits has wide-ranging consequences including applications to\nstate merging, the quantum channel capacity, entanglement distillation, quantum\nidentification and remote state preparation. The source of these results is the\ntheory of approximate quantum error correction. The action of a quantum channel\nis reversible if and only if no information is leaked to the environment, a\ncharacterization that is useful even in approximate form. However, different\nnotions of approximation lead to qualitatively different forms of quantum error\ncorrection in the limit of large dimension. We study the effect of a constraint\non the dimension of the reference system when considering information leakage.\nWhile the resulting condition fails to ensure that the entire input can be\ncorrected, it does ensure that all subspaces of dimension matching that of the\nreference are correctable. The size of the reference can be characterized by a\nparameter $\\alpha$, we call the associated resource an $\\alpha$-bit. Changing\n$\\alpha$ interpolates between standard quantum error correction and quantum\nidentification, a form of equality testing for quantum states. We develop the\ntheory of $\\alpha$-bits, including the applications above, and determine the\n$\\alpha$-bit capacity of general quantum channels, finding single-letter\nformulas for the entanglement-assisted and amortised variants. \n\n"}
{"id": "1707.00227", "contents": "Title: Relationship between Cross-Polarization Discrimination (XPD) and Spatial\n  Correlation in Indoor Small-Cell MIMO Systems Abstract: In this letter, we present a correlated channel model for a dual-polarization\nantenna to omnidirectional antennas in indoor small-cell multiple-input\nmultiple-output (MIMO) systems. In an indoor environment, we confirm that the\ncross-polarization discrimination (XPD) in the direction of angle-of-departure\ncan be represented as the spatial correlation of the MIMO channel. We also\nevaluate a dual-polarization antenna-based MIMO channel model and a spatially\ncorrelated channel model using a three-dimensional (3D) ray-tracing simulator.\nFurthermore, we provide the equivalent distance between adjacent antennas\naccording to the XPD, providing insights into designing a dual-polarization\nantenna and its arrays. \n\n"}
{"id": "1707.00475", "contents": "Title: Reconstruction Error Bounds for Compressed Sensing under Poisson or\n  Poisson-Gaussian Noise Using Variance Stabilization Transforms Abstract: Most existing bounds for signal reconstruction from compressive measurements\nmake the assumption of additive signal-independent noise. However in many\ncompressive imaging systems, the noise statistics are more accurately\nrepresented by Poisson or Poisson-Gaussian noise models. In this paper, we\nderive upper bounds for signal reconstruction error from compressive\nmeasurements which are corrupted by Poisson or Poisson-Gaussian noise. The\nfeatures of our bounds are as follows: (1) The bounds are derived for a\nprobabilistically motivated, computationally tractable convex estimator with\nprincipled parameter selection. The estimator penalizes signal sparsity subject\nto a constraint that imposes an upper bound on a term based on variance\nstabilization transforms to approximate the Poisson or Poisson-Gaussian\nnegative log-likelihoods. (2) They are applicable to signals that are sparse as\nwell as compressible in any orthonormal basis, and are derived for compressive\nsystems obeying realistic constraints such as non-negativity and\nflux-preservation. We present extensive numerical results for signal\nreconstruction under varying number of measurements and varying signal\nintensity levels. \n\n"}
{"id": "1707.01064", "contents": "Title: Physical Layer Service Integration in 5G: Potentials and Challenges Abstract: High transmission rate and secure communication have been identified as the\nkey targets that need to be effectively addressed by fifth generation (5G)\nwireless systems. In this context, the concept of physical-layer security\nbecomes attractive, as it can establish perfect security using only the\ncharacteristics of wireless medium. Nonetheless, to further increase the\nspectral efficiency, an emerging concept, termed physical-layer service\nintegration (PHY-SI), has been recognized as an effective means. Its basic idea\nis to combine multiple coexisting services, i.e., multicast/broadcast service\nand confidential service, into one integral service for one-time transmission\nat the transmitter side. This article first provides a tutorial on typical\nPHY-SI models. Furthermore, we propose some state-of-the-art solutions to\nimprove the overall performance of PHY-SI in certain important communication\nscenarios. In particular, we highlight the extension of several concepts\nborrowed from conventional single-service communications, such as artificial\nnoise (AN), eigenmode transmission etc., to the scenario of PHY-SI. These\ntechniques are shown to be effective in the design of reliable and robust\nPHY-SI schemes. Finally, several potential research directions are identified\nfor future work. \n\n"}
{"id": "1707.03495", "contents": "Title: Lengthening and Extending Binary Private Information Retrieval Codes Abstract: It was recently shown by Fazeli et al. that the storage overhead of a\ntraditional $t$-server private information retrieval (PIR) protocol can be\nsignificantly reduced using the concept of a $t$-server PIR code. In this work,\nwe show that a family of $t$-server PIR codes (with increasing dimensions and\nblocklengths) can be constructed from an existing $t$-server PIR code through\nlengthening by a single information symbol and code extension by at most\n$\\bigl\\lceil t/2\\bigr\\rceil$ code symbols. Furthermore, by extending a code\nconstruction notion from Steiner systems by Fazeli et al., we obtain a specific\nfamily of $t$-server PIR codes. Based on a code construction technique that\nlengthens and extends a $t$-server PIR code simultaneously, a basic algorithm\nto find good (i.e., small blocklength) $t$-server PIR codes is proposed. For\nthe special case of $t=5$, we find provably optimal PIR codes for code\ndimensions $k\\leq 6$, while for all $7\\leq k\\leq 32$ we find codes of smaller\nblocklength than the best known codes from the literature. Furthermore, in the\ncase of $t = 8$, we also find better codes for $k = 5, 6, 11, 12$. Numerical\nresults show that most of the best found $5$-server PIR codes can be\nconstructed from the proposed family of codes connected to Steiner systems. \n\n"}
{"id": "1707.03571", "contents": "Title: Enhancing massive MIMO: A new approach for Uplink training based on\n  heterogeneous coherence time Abstract: Massive multiple-input multiple-output (MIMO) is one of the key technologies\nin future generation networks. Owing to their considerable spectral and energy\nefficiency gains, massive MIMO systems provide the needed performance to cope\nwith the ever increasing wireless capacity demand. Nevertheless, the number of\nscheduled users stays limited in massive MIMO both in time division duplexing\n(TDD) and frequency division duplexing (FDD) systems. This is due to the\nlimited coherence time, in TDD systems, and to limited feedback capacity, in\nFDD mode. In current systems, the time slot duration in TDD mode is the same\nfor all users. This is a suboptimal approach since users are subject to\nheterogeneous Doppler spreads and, consequently, different coherence times. In\nthis paper, we investigate a massive MIMO system operating in TDD mode in\nwhich, the frequency of uplink training differs among users based on their\nactual channel coherence times. We argue that optimizing uplink training by\nexploiting this diversity can lead to considerable spectral efficiency gain. We\nthen provide a user scheduling algorithm that exploits a coherence interval\nbased grouping in order to maximize the achievable weighted sum rate. \n\n"}
{"id": "1707.03962", "contents": "Title: Prediction and Power in Molecular Sensors: Uncertainty and Dissipation\n  When Conditionally Markovian Channels Are Driven by Semi-Markov Environments Abstract: Sensors often serve at least two purposes: predicting their input and\nminimizing dissipated heat. However, determining whether or not a particular\nsensor is evolved or designed to be accurate and efficient is difficult. This\narises partly from the functional constraints being at cross purposes and\npartly since quantifying the predictive performance of even in silico sensors\ncan require prohibitively long simulations. To circumvent these difficulties,\nwe develop expressions for the predictive accuracy and thermodynamic costs of\nthe broad class of conditionally Markovian sensors subject to unifilar hidden\nsemi-Markov (memoryful) environmental inputs. Predictive metrics include the\ninstantaneous memory and the mutual information between present sensor state\nand input future, while dissipative metrics include power consumption and the\nnonpredictive information rate. Success in deriving these formulae relies\nheavily on identifying the environment's causal states, the input's minimal\nsufficient statistics for prediction. Using these formulae, we study the\nsimplest nontrivial biological sensor model---that of a Hill molecule,\ncharacterized by the number of ligands that bind simultaneously, the sensor's\ncooperativity. When energetic rewards are proportional to total predictable\ninformation, the closest cooperativity that optimizes the total energy budget\ngenerally depends on the environment's past hysteretically. In this way, the\nsensor gains robustness to environmental fluctuations. Given the simplicity of\nthe Hill molecule, such hysteresis will likely be found in more complex\npredictive sensors as well. That is, adaptations that only locally optimize\nbiochemical parameters for prediction and dissipation can lead to sensors that\n\"remember\" the past environment. \n\n"}
{"id": "1707.05128", "contents": "Title: Differentially Private Testing of Identity and Closeness of Discrete\n  Distributions Abstract: We study the fundamental problems of identity testing (goodness of fit), and\ncloseness testing (two sample test) of distributions over $k$ elements, under\ndifferential privacy. While the problems have a long history in statistics,\nfinite sample bounds for these problems have only been established recently.\n  In this work, we derive upper and lower bounds on the sample complexity of\nboth the problems under $(\\varepsilon, \\delta)$-differential privacy. We\nprovide optimal sample complexity algorithms for identity testing problem for\nall parameter ranges, and the first results for closeness testing. Our\ncloseness testing bounds are optimal in the sparse regime where the number of\nsamples is at most $k$.\n  Our upper bounds are obtained by privatizing non-private estimators for these\nproblems. The non-private estimators are chosen to have small sensitivity. We\npropose a general framework to establish lower bounds on the sample complexity\nof statistical tasks under differential privacy. We show a bound on\ndifferentially private algorithms in terms of a coupling between the two\nhypothesis classes we aim to test. By constructing carefully chosen priors over\nthe hypothesis classes, and using Le Cam's two point theorem we provide a\ngeneral mechanism for proving lower bounds. We believe that the framework can\nbe used to obtain strong lower bounds for other statistical tasks under\nprivacy. \n\n"}
{"id": "1707.05932", "contents": "Title: Effects of Feedback on the One-sided Secrecy of Two-way Wiretap through\n  Multiple Transmissions Abstract: In this paper, the one-sided secrecy of two-way wiretap channel with feedback\nis investigated, where the confidential messages of one user through multiple\ntransmissions is guaranteed secure against an external eavesdropper. For one\nthing, one-sided secrecy satisfies the secure demand of many practical\nscenarios. For another, the secrecy is measured over many blocks since the\ncorrelation between eavesdropper's observation and the confidential messages in\nsuccessive blocks, instead of secrecy measurement of one block in previous\nworks. Thus, firstly, an achievable secrecy rate region is derived for the\ngeneral two-way wiretap channel with feedback through multiple transmissions\nunder one-sided secrecy. Secondly, outer bounds on the secrecy capacity region\nare also obtained. The gap between inner and outer bounds on the secrecy\ncapacity region is explored via the binary input two-way wiretap channels. Most\nnotably, the secrecy capacity regions are established for the XOR channel.\nFurthermore, the result shows that the achievable rate region with feedback is\nlarger than that without feedback. Therefore, the benefit role of feedback is\nprecisely characterized for two-way wiretap channel with feedback under\none-sided secrecy. \n\n"}
{"id": "1707.09441", "contents": "Title: A compressive channel estimation technique robust to synchronization\n  impairments Abstract: Initial access at millimeter wave frequencies is a challenging problem due to\nhardware non-idealities and low SNR measurements prior to beamforming. Prior\nwork has exploited the observation that mmWave MIMO channels are sparse in the\nspatial angle domain and has used compressed sensing based algorithms for\nchannel estimation. Most of them, however, ignore hardware impairments like\ncarrier frequency offset and phase noise, and fail to perform well when such\nimpairments are considered. In this paper, we develop a compressive channel\nestimation algorithm for narrowband mmWave systems, which is robust to such non\nidealities. We address this problem by constructing a tensor that models both\nthe mmWave channel and CFO, and estimate the tensor while still exploiting the\nsparsity of the mmWave channel. Simulation results show that under the same\nsettings, our method performs better than comparable algorithms that are robust\nto phase errors. \n\n"}
{"id": "1707.09445", "contents": "Title: Joint CFO and Channel Estimation in Millimeter Wave Systems with One-Bit\n  ADCs Abstract: We develop a method to jointly estimate the carrier frequency offset (CFO)\nand the narrowband channel in millimeter wave (mmWave) MIMO systems operating\nwith one-bit analog-to-digital converters (ADCs). We assume perfect timing\nsynchronization and transform the underlying CFO-channel optimization problem\nto a higher dimensional space using lifting techniques. Exploiting the sparsity\nof mmWave MIMO channels in the angle domain, we perform joint estimation by\nsolving a noisy quantized compressed sensing problem of the lifted version,\nusing generalized approximate message passing. Simulation results show that our\nmethod is able to recover both the channel and the CFO using one-bit\nmeasurements. \n\n"}
{"id": "1708.00905", "contents": "Title: Covert Communication Achieved by A Greedy Relay in Wireless Networks Abstract: Covert communication aims to hide the very existence of wireless\ntransmissions in order to guarantee a strong security in wireless networks. In\nthis work, we examine the possibility and achievable performance of covert\ncommunication in one-way relay networks. Specifically, the relay is greedy and\nopportunistically transmits its own information to the destination covertly on\ntop of forwarding the source's message, while the source tries to detect this\ncovert transmission to discover the illegitimate usage of the resource (e.g.,\npower, spectrum) allocated only for the purpose of forwarding source's\ninformation. We propose two strategies for the relay to transmit its covert\ninformation, namely fixed-rate and fixed-power transmission schemes, for which\nthe source's detection limits are analysed in terms of the false alarm and miss\ndetection rates and the achievable effective covert rates from the relay to\ndestination are derived. Our examination determines the conditions under which\nthe fixed-rate transmission scheme outperforms the fixed-power transmission\nscheme, and vice versa, which enables the relay to achieve the maximum\neffective covert rate. Our analysis indicates that the relay has to forward the\nsource's message to shield its covert transmission and the effective covert\nrate increases with its forwarding ability (e.g., its maximum transmit power). \n\n"}
{"id": "1708.03131", "contents": "Title: Hypotheses testing on infinite random graphs Abstract: Drawing on some recent results that provide the formalism necessary to\ndefinite stationarity for infinite random graphs, this paper initiates the\nstudy of statistical and learning questions pertaining to these objects.\nSpecifically, a criterion for the existence of a consistent test for complex\nhypotheses is presented, generalizing the corresponding results on time series.\nAs an application, it is shown how one can test that a tree has the Markov\nproperty, or, more generally, to estimate its memory. \n\n"}
{"id": "1708.03808", "contents": "Title: Dimension Reduction for Polynomials over Gaussian Space and Applications Abstract: We introduce a new technique for reducing the dimension of the ambient space\nof low-degree polynomials in the Gaussian space while preserving their relative\ncorrelation structure, analogous to the Johnson-Lindenstrauss lemma. As\napplications, we address the following problems:\n  1. Computability of Approximately Optimal Noise Stable function over Gaussian\nspace: The goal is to find a partition of $\\mathbb{R}^n$ into $k$ parts, that\nmaximizes the noise stability. An $\\delta$-optimal partition is one which is\nwithin additive $\\delta$ of the optimal noise stability.\n  De, Mossel & Neeman (CCC 2017) raised the question of proving a computable\nbound on the dimension $n_0(\\delta)$ in which we can find an $\\delta$-optimal\npartition. While De et al. provide such a bound, using our new technique, we\nobtain improved explicit bounds on the dimension $n_0(\\delta)$.\n  2. Decidability of Non-Interactive Simulation of Joint Distributions: A\n\"non-interactive simulation\" problem is specified by two distributions $P(x,y)$\nand $Q(u,v)$: The goal is to determine if two players that observe sequences\n$X^n$ and $Y^n$ respectively where $\\{(X_i, Y_i)\\}_{i=1}^n$ are drawn i.i.d.\nfrom $P(x,y)$ can generate pairs $U$ and $V$ respectively (without\ncommunicating with each other) with a joint distribution that is arbitrarily\nclose in total variation to $Q(u,v)$. Even when $P$ and $Q$ are extremely\nsimple, it is open in several cases if $P$ can simulate $Q$.\n  In the special where $Q$ is a joint distribution over $\\{0,1\\} \\times\n\\{0,1\\}$, Ghazi, Kamath and Sudan (FOCS 2016) proved a computable bound on the\nnumber of samples $n_0(\\delta)$ that can be drawn from $P(x,y)$ to get\n$\\delta$-close to $Q$ (if it is possible at all). Recently De, Mossel & Neeman\nobtained such bounds when $Q$ is a distribution over $[k] \\times [k]$ for any\n$k \\ge 2$. We recover this result with improved explicit bounds on\n$n_0(\\delta)$. \n\n"}
{"id": "1708.04444", "contents": "Title: Efficient Downlink Channel Probing and Uplink Feedback in FDD Massive\n  MIMO Systems Abstract: Massive Multiple-Input Multiple-Output (massive MIMO) is a variant of\nmulti-user MIMO in which the number of antennas at each Base Station (BS) is\nvery large and typically much larger than the number of users simultaneously\nserved. Massive MIMO can be implemented with Time Division Duplexing (TDD) or\nFrequency Division Duplexing (FDD) operation. FDD massive MIMO systems are\nparticularly desirable due to their implementation in current wireless networks\nand their efficiency in situations with symmetric traffic and delay-sensitive\napplications. However, implementing FDD massive MIMO systems is known to be\nchallenging since it imposes a large feedback overhead in the Uplink (UL) to\nobtain channel state information for the Downlink (DL). In recent years, a\nconsiderable amount of research is dedicated to developing methods to reduce\nthe feedback overhead in such systems. In this paper, we use the sparse spatial\nscattering properties of the environment to achieve this goal. The idea is to\nestimate the support of the continuous, frequency-invariant scattering function\nfrom UL channel observations and use this estimate to obtain the support of the\nDL channel vector via appropriate interpolation. We use the resulting support\nestimate to design an efficient DL probing and UL feedback scheme in which the\nfeedback dimension scales proportionally with the sparsity order of DL channel\nvectors. Since the sparsity order is much less than the number of BS antennas\nin almost all practically relevant scenarios, our method incurs much less\nfeedback overhead compared with the currently proposed methods in the\nliterature, such as those based on compressed-sensing. We use numerical\nsimulations to assess the performance of our probing-feedback algorithm and\ncompare it with these methods. \n\n"}
{"id": "1708.05575", "contents": "Title: Massive MIMO Unlicensed for High-Performance Indoor Networks Abstract: We propose massive MIMO unlicensed (mMIMO-U) as a high-capacity solution for\nfuture indoor wireless networks operating in the unlicensed spectrum. Building\nupon massive MIMO (mMIMO), mMIMO-U incorporates additional key features, such\nas the capability of placing accurate radiation nulls towards coexisting nodes\nduring the channel access and data transmission phases. We demonstrate the\nspectrum reuse and data rate improvements attained by mMIMO-U by comparing\nthree practical deployments: single-antenna Wi-Fi, where an indoor operator\ndeploys three single-antenna Wi-Fi access points (APs), and two other scenarios\nwhere the central AP is replaced by either a mMIMO AP or the proposed mMIMO-U\nAP. We show that upgrading the central AP with mMIMO-U provides increased\nchannel access opportunities for all of them. Moreover, mMIMO-U achieves\nfour-fold and seven-fold gains in median throughput when compared to\ntraditional mMIMO and single-antenna setups, respectively. \n\n"}
{"id": "1708.06235", "contents": "Title: Deep Convolutional Neural Networks for Massive MIMO Fingerprint-Based\n  Positioning Abstract: This paper provides an initial investigation on the application of\nconvolutional neural networks (CNNs) for fingerprint-based positioning using\nmeasured massive MIMO channels. When represented in appropriate domains,\nmassive MIMO channels have a sparse structure which can be efficiently learned\nby CNNs for positioning purposes. We evaluate the positioning accuracy of\nstate-of-the-art CNNs with channel fingerprints generated from a channel model\nwith a rich clustered structure: the COST 2100 channel model. We find that\nmoderately deep CNNs can achieve fractional-wavelength positioning accuracies,\nprovided that an enough representative data set is available for training. \n\n"}
{"id": "1708.06336", "contents": "Title: Analysis of Optimal Combining in Rician Fading with Co-channel\n  Interference Abstract: Approximate Symbol error rate (SER), outage probability and rate expressions\nare derived for receive diversity system employing optimum combining when both\nthe desired and the interfering signals are subjected to Rician fading, for the\ncases of a) equal power uncorrelated interferers b) unequal power interferers\nc) interferer correlation. The derived expressions are applicable for an\narbitrary number of receive antennas and interferers and for any quadrature\namplitude modulation (QAM) constellation. Furthermore, we derive a simple\nclosed form expression for SER in the interference-limited regime, for the\nspecial case of Rayleigh faded interferers. A close match is observed between\nthe SER, outage probability and rate results obtained through the derived\nanalytical expressions and the ones obtained from Monte-Carlo simulations. \n\n"}
{"id": "1708.06650", "contents": "Title: Constructions of Coded Caching Schemes with Flexible Memory Size Abstract: Coded caching scheme recently has become quite popular in the wireless\nnetwork due to its effectively reducing the transmission amount (denote such an\namount by $R$) during peak traffic times. However to realize a coded caching\nscheme, each file must be divided into $F$ packets which usually increases the\ncomputation complexity of a coded caching scheme. So we prefer to construct a\ncaching scheme that decreases the order of $F$ for practical implementations.\n  In this paper, we construct four classes of new schemes where two classes can\nsignificantly reduce the value of $F$ by increasing a little $R$ comparing with\nthe well known scheme proposed by Maddah-Ali and Niesen, and $F$ in the other\ntwo classes grows sub-exponentially with $K$ by sacrificing more $R$. It is\nworth noting that a tradeoff between $R$ and $F$, which is a hot topic in the\nfield of caching scheme, is proposed by our constructions. In addition, our\nconstructions include all the results constructed by Yan et al., (IEEE Trans.\nInf. Theory 63, 5821-5833, 2017) and some main results obtained by Shangguan et\nal., (arXiv preprint arXiv:1608.03989v1) as the special cases. \n\n"}
{"id": "1708.07811", "contents": "Title: Channel reciprocity calibration in TDD hybrid beamforming massive MIMO\n  systems Abstract: Hybrid analog-digital (AD) beamforming structure is a very attractive\nsolution to build low cost massive multiple-input multiple-output (MIMO)\nsystems. Typically these systems use a set of fixed beams for transmission and\nreception to avoid the need to obtain channel state information at transmitter\n(CSIT) for each antenna element individually. However, such a method can not\nfully exploit the potential of hybrid AD beamforming systems. Alternatively,\nCSIT can be estimated by assuming a model for the propagation channel, whereas\nthis model is only validated in millimeter-wave (mmWave) band thanks to its\npoor scattering nature. In this paper, we focus on time division duplex (TDD)\nsystems with hybrid beamforming structure and propose a reciprocity calibration\nscheme that allows to acquire full CSIT. Different to existing CSIT acquisition\nmethods, our approach does not require any assumption on the channel model and\ncan, in theory, estimate the CSIT up to an arbitrary small error. \n\n"}
{"id": "1708.09272", "contents": "Title: Inhomogeneous perturbation and error bounds for the stationary\n  performance of random walks in the quarter plane Abstract: A continuous-time random walk in the quarter plane with homogeneous\ntransition rates is considered. Given a non-negative reward function on the\nstate space, we are interested in the expected stationary performance. Since a\ndirect derivation of the stationary probability distribution is not available\nin general, the performance is approximated by a perturbed random walk, whose\ntransition rates on the boundaries are changed such that its stationary\nprobability distribution is known in closed form.\n  A perturbed random walk for which the stationary distribution is a sum of\ngeometric terms is considered and the perturbed transition rates are allowed to\nbe inhomogeneous. It is demonstrated that such rates can be constructed for any\nsum of geometric terms that satisfies the balance equations in the interior of\nthe state space. The inhomogeneous transitions relax the pairwise-coupled\nstructure on these geometric terms that would be imposed if only homogeneous\ntransitions are used.\n  An explicit expression for the approximation error bound is obtained using\nthe Markov reward approach, which does not depend on the values of the\ninhomogeneous rates but only on the parameters of the geometric terms.\nNumerical experiments indicate that inhomogeneous perturbation can give smaller\nerror bounds than homogeneous perturbation. \n\n"}
{"id": "1708.09354", "contents": "Title: Quantum-enhanced reinforcement learning for finite-episode games with\n  discrete state spaces Abstract: Quantum annealing algorithms belong to the class of metaheuristic tools,\napplicable for solving binary optimization problems. Hardware implementations\nof quantum annealing, such as the quantum annealing machines produced by D-Wave\nSystems, have been subject to multiple analyses in research, with the aim of\ncharacterizing the technology's usefulness for optimization and sampling tasks.\nHere, we present a way to partially embed both Monte Carlo policy iteration for\nfinding an optimal policy on random observations, as well as how to embed (n)\nsub-optimal state-value functions for approximating an improved state-value\nfunction given a policy for finite horizon games with discrete state spaces on\na D-Wave 2000Q quantum processing unit (QPU). We explain how both problems can\nbe expressed as a quadratic unconstrained binary optimization (QUBO) problem,\nand show that quantum-enhanced Monte Carlo policy evaluation allows for finding\nequivalent or better state-value functions for a given policy with the same\nnumber episodes compared to a purely classical Monte Carlo algorithm.\nAdditionally, we describe a quantum-classical policy learning algorithm. Our\nfirst and foremost aim is to explain how to represent and solve parts of these\nproblems with the help of the QPU, and not to prove supremacy over every\nexisting classical policy evaluation algorithm. \n\n"}
{"id": "1708.09517", "contents": "Title: Upper and Lower Bounds on the Capacity of Amplitude-Constrained MIMO\n  Channels Abstract: In this work, novel upper and lower bounds for the capacity of channels with\narbitrary constraints on the support of the channel input symbols are derived.\nAs an immediate practical application, the case of multiple-input\nmultiple-output channels with amplitude constraints is considered. The bounds\nare shown to be within a constant gap if the channel matrix is invertible and\nare tight in the high amplitude regime for arbitrary channel matrices.\nMoreover, in the high amplitude regime, it is shown that the capacity scales\nlinearly with the minimum between the number of transmit and receive antennas,\nsimilarly to the case of average power-constrained inputs. \n\n"}
{"id": "1709.00779", "contents": "Title: Directional Cell Search Delay Analysis for Cellular Networks with Static\n  Users Abstract: Cell search is the process for a user to detect its neighboring base stations\n(BSs) and make a cell selection decision. Due to the importance of beamforming\ngain in millimeter wave (mmWave) and massive MIMO cellular networks, the\ndirectional cell search delay performance is investigated. A cellular network\nwith fixed BS and user locations is considered, so that strong temporal\ncorrelations exist for the SINR experienced at each BS and user. For Poisson\ncellular networks with Rayleigh fading channels, a closed-form expression for\nthe spatially averaged mean cell search delay of all users is derived. This\nmean cell search delay for a noise-limited network (e.g., mmWave network) is\nproved to be infinite whenever the non-line-of-sight (NLOS) path loss exponent\nis larger than 2. For interference-limited networks, a phase transition for the\nmean cell search delay is shown to exist in terms of the number of BS\nantennas/beams $M$: the mean cell search delay is infinite when $M$ is smaller\nthan a threshold and finite otherwise. Beam-sweeping is also demonstrated to be\neffective in decreasing the cell search delay, especially for the cell edge\nusers. \n\n"}
{"id": "1709.01307", "contents": "Title: Distributed second order methods with increasing number of working nodes Abstract: Recently, an idling mechanism has been introduced in the context of\ndistributed \\emph{first order} methods for minimization of a sum of nodes'\nlocal convex costs over a generic, connected network. With the idling\nmechanism, each node $i$, at each iteration $k$, is active -- updates its\nsolution estimate and exchanges messages with its network neighborhood -- with\nprobability $p_k$, and it stays idle with probability $1-p_k$, while the\nactivations are independent both across nodes and across iterations. In this\npaper, we demonstrate that the idling mechanism can be successfully\nincorporated in \\emph{distributed second order methods} also. Specifically, we\napply the idling mechanism to the recently proposed Distributed Quasi Newton\nmethod (DQN). We first show theoretically that, when $p_k$ grows to one across\niterations in a controlled manner, DQN with idling exhibits very similar\ntheoretical convergence and convergence rates properties as the standard DQN\nmethod, thus achieving the same order of convergence rate (R-linear) as the\nstandard DQN, but with significantly cheaper updates. Simulation examples\nconfirm the benefits of incorporating the idling mechanism, demonstrate the\nmethod's flexibility with respect to the choice of the $p_k$'s, and compare the\nproposed idling method with related algorithms from the literature. \n\n"}
{"id": "1709.01629", "contents": "Title: Antenna Selection in MIMO Cognitive Radio-Inspired NOMA Systems Abstract: This letter investigates a joint antenna selection (AS) problem for a MIMO\ncognitive radio-inspired non-orthogonal multiple access (CR-NOMA) network. In\nparticular, a new computationally efficient joint AS algorithm, namely\nsubset-based joint AS (SJ-AS), is proposed to maximize the signal-to-noise\nratio of the secondary user under the condition that the quality of service\n(QoS) of the primary user is satisfied. The asymptotic closed-form expression\nof the outage performance for SJ-AS is derived, and the minimal outage\nprobability achieved by SJ-AS among all possible joint AS schemes is proved.\nThe provided numerical results demonstrate the superior performance of the\nproposed scheme. \n\n"}
{"id": "1709.02625", "contents": "Title: Decentralized Robust Transceiver Designs for MISO SWIPT Interference\n  Channel Abstract: This paper considers a $K$-user multiple-input single-output (MISO)\ninterference channels for simultaneous wireless information and power transfer\n(SWIPT), where each multi-antenna transmitter serves a single-antenna receiver\nper user pair. All receivers perform simultaneously information processing and\nenergy harvesting (EH) based on the receive power-splitting (PS) architectures.\nAssuming imperfect channel state information (CSI) at the transmitters, we\ndevelop an optimal robust transceiver design scheme that minimizes the total\ntransmission power under the worst-case signal-to-interference-plus-noise ratio\n(SINR) and energy harvesting (EH) constraints at the receivers, by jointly\noptimizing transmit beamforming and receive PS ratio per receiver. When the CSI\nuncertainties are bounded by ellipsoidal regions, it is shown that the\nworst-case SINR and EH constraints per receiver can be recast into quadratic\nmatrix inequality forms. Leveraging semidefinite relaxation technique, the\nintended robust beamforming and PS (BFPS) problem can be relaxed as a tractable\n(centralized) semidefinite program (SDP). More importantly, relying on the\nstate-of-the-art alternating direction method of multipliers (ADMM) in convex\noptimization, we propose a {\\em decentralized} algorithm capable of computing\nthe optimal robust BFPS scheme with local CSI and limited information exchange\namong the transmitters. It is shown the proposed decentralized algorithm is\nguaranteed to converge to the optimal centralized solution. Numerical results\nare provided to demonstrate the merits of the proposed approaches. \n\n"}
{"id": "1709.02884", "contents": "Title: Degrees of Freedom of the Broadcast Channel with Hybrid CSI at\n  Transmitter and Receivers Abstract: In general, the different links of a broadcast channel may experience\ndifferent fading dynamics and, potentially, unequal or hybrid channel state\ninformation (CSI) conditions. The faster the fading and the shorter the fading\nblock length, the more often the link needs to be trained and estimated at the\nreceiver, and the more likely that CSI is stale or unavailable at the\ntransmitter. Disparity of link fading dynamics in the presence of CSI\nlimitations can be modeled by a multi-user broadcast channel with both\nnon-identical link fading block lengths as well as dissimilar link CSIR/CSIT\nconditions. This paper investigates a MISO broadcast channel where some\nreceivers experience longer coherence intervals (static receivers) and have\nCSIR, while some other receivers experience shorter coherence intervals\n(dynamic receivers) and do not enjoy free CSIR. We consider a variety of CSIT\nconditions for the above mentioned model, including no CSIT, delayed CSIT, or\nhybrid CSIT. To investigate the degrees of freedom region, we employ\ninterference alignment and beamforming along with a product superposition that\nallows simultaneous but non-contaminating transmission of pilots and data to\ndifferent receivers. Outer bounds employ the extremal entropy inequality as\nwell as a bounding of the performance of a discrete memoryless multiuser\nmultilevel broadcast channel. For several cases, inner and outer bounds are\nestablished that either partially meet, or the gap diminishes with increasing\ncoherence times. \n\n"}
{"id": "1709.07487", "contents": "Title: Computing the Unique Information Abstract: Given a pair of predictor variables and a response variable, how much\ninformation do the predictors have about the response, and how is this\ninformation distributed between unique, redundant, and synergistic components?\nRecent work has proposed to quantify the unique component of the decomposition\nas the minimum value of the conditional mutual information over a constrained\nset of information channels. We present an efficient iterative divergence\nminimization algorithm to solve this optimization problem with convergence\nguarantees and evaluate its performance against other techniques. \n\n"}
{"id": "1709.10371", "contents": "Title: Multi-Kernel Polar Codes: Proof of Polarization and Error Exponents Abstract: In this paper, we investigate a novel family of polar codes based on\nmulti-kernel constructions, proving that this construction actually polarizes.\nTo this end, we derive a new and more general proof of polarization, which\ngives sufficient conditions for kernels to polarize. Finally, we derive the\nconvergence rate of the multi-kernel construction and relate it to the\nconvergence rate of each of the constituent kernels. \n\n"}
{"id": "1709.10393", "contents": "Title: Achievable Information Rates for Fiber Optics: Applications and\n  Computations Abstract: In this paper, achievable information rates (AIR) for fiber optical\ncommunications are discussed. It is shown that AIRs such as the mutual\ninformation and generalized mutual information are good design metrics for\ncoded optical systems. The theoretical predictions of AIRs are compared to the\nperformance of modern codes including low-parity density check (LDPC) and polar\ncodes. Two different computation methods for these AIRs are also discussed:\nMonte-Carlo integration and Gauss-Hermite quadrature. Closed-form ready-to-use\napproximations for such computations are provided for arbitrary constellations\nand the multidimensional AWGN channel. The computation of AIRs in optical\nexperiments and simulations is also discussed. \n\n"}
{"id": "1710.02977", "contents": "Title: Linear Prediction based Data Detection of Convolutional Coded DQPSK in\n  SIMO-OFDM Abstract: Data detection of convolutional coded differential quaternary phase shift\nkeyed (DQPSK) signals using a predictive Viterbi algorithm (VA) based receiver,\nis presented for single input, multiple output - orthogonal frequency division\nmultiplexed (OFDM) systems. The receiver has both error correcting capability\nand also the ability to perform channel estimation (prediction). The predictive\nVA operates on a supertrellis with just $S_{\\mathrm{ST}}=S_{\\mathrm{E}}\\times\n2^{P-1}$ states instead of $S_{\\mathrm{ST}}=S_{\\mathrm{E}}\\times 2^{P}$ states,\nwhere the complexity reduction is achieved by using the concept of isometry\n(here $S_{\\mathrm{E}}$ denotes the number of states in the encoder trellis and\n$P$ denotes the prediction order). Though the linear prediction based data\ndetection in turbo coded OFDM and the bit interleaved coded (BIC) OFDM systems\nperform better than the proposed approach in terms of bit error rate (BER) for\na given signal to noise ratio (SNR), the decoding delay of the proposed\napproach is significantly lower than that of the BIC and the turbo coded OFDM\nsystems. \n\n"}
{"id": "1710.04971", "contents": "Title: Average Age of Information with Hybrid ARQ under a Resource Constraint Abstract: Scheduling of the transmission of status updates over an error-prone\ncommunication channel is studied in order to minimize the long-term average age\nof information (AoI) at the destination, under an average resource constraint\nat the source node, which limits the average number of transmissions. After\neach transmission, the source receives an instantaneous ACK/NACK feedback, and\ndecides on the next update, without a priori knowledge on the success of the\nfuture transmissions. The optimal scheduling policy is studied under different\nfeedback mechanisms; in particular, standard automatic repeat request (ARQ) and\nhybrid ARQ (HARQ) protocols are considered. Average-cost reinforcement learning\nalgorithms are proposed when the error probabilities for the HARQ system are\nunknown. \n\n"}
{"id": "1710.04999", "contents": "Title: Matrix-Product Constructions for Hermitian Self-Orthogonal Codes Abstract: Self-orthogonal codes have been of interest due to there rich algebraic\nstructures and wide applications. Euclidean self-orthogonal codes have been\nquite well studied in literature. Here, we have focused on Hermitian\nself-orthogonal codes. Constructions of such codes have been given based on the\nwell-known matrix-product construction for linear codes. Criterion for the\nunderlying matrix and the input codes required in such constructions have been\ndetermined. In many cases, the Hermitian self-orthogonality of the input codes\nand the assumption that the underlying matrix is unitary can be relaxed. Some\nspecial matrices used in the constructions and illustrative examples of good\nHermitian self-orthogonal codes have been provided as well. \n\n"}
{"id": "1710.05602", "contents": "Title: On Fast-Decodable Algebraic Space--Time Codes Abstract: In the near future, the $5^{th}$ generation (5G) wireless systems will be\nestablished. They will consist of an integration of different techniques,\nincluding distributed antenna systems and massive multiple-input\nmultiple-output systems, and the overall performance will highly depend on the\nchannel coding techniques employed. Due to the nature of future wireless\nnetworks, space--time codes are no longer merely an object of choice, but will\noften appear naturally in the communications setting. However, as the involved\ncommunication devices often exhibit a modest computational power, the\ncomplexity of the codes to be utilised should be reasonably low for possible\npractical implementation.\n  Fast-decodable codes enjoy reduced complexity of maximum-likelihood (ML)\ndecoding due to a smart inner structure allowing for parallelisation in the ML\nsearch. The complexity reductions considered in this chapter are entirely owing\nto the algebraic structure of the considered codes, and could be further\nimproved by employing non-ML decoding methods, however yielding suboptimal\nperformance.\n  The aim of this chapter is twofold. First, we provide a tutorial introduction\nto space--time coding and study powerful algebraic tools for their design and\nconstruction. Secondly, we revisit algebraic techniques used for reducing the\nworst-case decoding complexity of both single-user and multiuser space-time\ncodes, alongside with general code families and illustrative examples. \n\n"}
{"id": "1710.08379", "contents": "Title: Performance Bounds of Concatenated Polar Coding Schemes Abstract: A concatenated coding scheme over binary memoryless symmetric (BMS) channels\nusing a polarization transformation followed by outer sub-codes is analyzed.\nAchievable error exponents and upper bounds on the error rate are derived. The\nfirst bound is obtained using outer codes which are typical linear codes from\nthe ensemble of parity check matrices whose elements are chosen independently\nand uniformly. As a byproduct of this bound, it determines the required rate\nsplit of the total rate to the rates of the outer codes. A lower bound on the\nerror exponent that holds for all BMS channels with a given capacity is then\nderived. Improved bounds and approximations for finite blocklength codes using\nchannel dispersions (normal approximation), as well as converse and approximate\nconverse results, are also obtained. The bounds are compared to actual\nsimulation results from the literature. For the cases considered, when\ntransmitting over the binary input additive white Gaussian noise channel, there\nwas only a small gap between the normal approximation prediction and the actual\nerror rate of concatenated BCH-polar codes. \n\n"}
{"id": "1710.10654", "contents": "Title: Delivery Time Minimization in Edge Caching: Synergistic Benefits of\n  Subspace Alignment and Zero Forcing Abstract: An emerging trend of next generation communication systems is to provide\nnetwork edges with additional capabilities such as additional storage resources\nin the form of caches to reduce file delivery latency. To investigate this\naspect, we study the fundamental limits of a cache-aided wireless network\nconsisting of one central base station, $M$ transceivers and $K$ receivers from\na latency-centric perspective. We use the normalized delivery time (NDT) to\ncapture the per-bit latency for the worst-case file request pattern at high\nsignal-to-noise ratios (SNR), normalized with respect to a reference\ninterference-free system with unlimited transceiver cache capabilities. For\nvarious special cases with $M=\\{1,2\\}$ and $K=\\{1,2,3\\}$ that satisfy $M+K\\leq\n4$, we establish the optimal tradeoff between cache storage and latency. This\nis facilitated through establishing a novel converse (for arbitrary $M$ and\n$K$) and an achievability scheme on the NDT. Our achievability scheme is a\nsynergistic combination of multicasting, zero-forcing beamforming and\ninterference alignment. \n\n"}
{"id": "1710.10754", "contents": "Title: Stationarity Region of Mm-Wave Channel Based on Outdoor Microcellular\n  Measurements at 28 GHz Abstract: The stationarity region, i.e., the area in which the statistics of a\npropagation channel remain constant, is an important measure of the propagation\nchannel, and essential for efficient system design. This paper presents what is\nto our knowledge the first extensive measurement campaign for measuring the\nstationarity region of MIMO mm-wave channels. Using a novel 28 GHz phased-array\nsounder with high phase stability, we present results in an urban microcell\nLoS, and LOS to NLOS transition region scenario, for the stationarity region of\nshadowing, power delay profile, and the angular power spectrum. A comparison to\nresults at cm-waves shows considerably reduced stationarity region size, which\nhas an important impact on system design. \n\n"}
{"id": "1711.01007", "contents": "Title: Wireless Network Simplification: The Performance of Routing Abstract: Consider a wireless Gaussian network where a source wishes to communicate\nwith a destination with the help of N full-duplex relay nodes. Most practical\nsystems today route information from the source to the destination using the\nbest path that connects them. In this paper, we show that routing can in the\nworst case result in an unbounded gap from the network capacity - or reversely,\nphysical layer cooperation can offer unbounded gains over routing. More\nspecifically, we show that for $N$-relay Gaussian networks with an arbitrary\ntopology, routing can in the worst case guarantee an approximate fraction\n$\\frac{1}{\\left\\lfloor N/2 \\right\\rfloor + 1}$ of the capacity of the full\nnetwork, independently of the SNR regime. We prove that this guarantee is\nfundamental, i.e., it is the highest worst-case guarantee that we can provide\nfor routing in relay networks. Next, we consider how these guarantees are\nrefined for Gaussian layered relay networks with $L$ layers and $N_L$ relays\nper layer. We prove that for arbitrary $L$ and $N_L$, there always exists a\nroute in the network that approximately achieves at least $\\frac{2}{(L-1)N_L +\n4}$ $\\left(\\mbox{resp.}\\frac{2}{LN_L+2}\\right)$ of the network capacity for odd\n$L$ (resp. even $L$), and there exist networks where the best routes exactly\nachieve these fractions. These results are formulated within the network\nsimplification framework, that asks what fraction of the capacity we can\nachieve by using a subnetwork (in our case, a single path). A fundamental step\nin our proof is a simplification result for MIMO antenna selection that may\nalso be of independent interest. To the best of our knowledge, this is the\nfirst result that characterizes, for general wireless network topologies, what\nis the performance of routing with respect to physical layer cooperation\ntechniques that approximately achieve the network capacity. \n\n"}
{"id": "1711.01082", "contents": "Title: On the Capacity of SWIPT Systems with a Nonlinear Energy Harvesting\n  Circuit Abstract: In this paper, we study information-theoretic limits for simultaneous\nwireless information and power transfer (SWIPT) systems employing a practical\nnonlinear radio frequency (RF) energy harvesting (EH) receiver. In particular,\nwe consider a three-node system with one transmitter that broadcasts a common\nsignal to separated information decoding (ID) and EH receivers. Owing to the\nnonlinearity of the EH receiver circuit, the efficiency of wireless power\ntransfer depends significantly on the waveform of the transmitted signal. In\nthis paper, we aim to answer the following fundamental question: What is the\noptimal input distribution of the transmit waveform that maximizes the rate of\nthe ID receiver for a given required harvested power at the EH receiver? In\nparticular, we study the capacity of a SWIPT system impaired by additive white\nGaussian noise (AWGN) under average-power (AP) and peak-power (PP) constraints\nat the transmitter and an EH constraint at the EH receiver. Using Hermite\npolynomial bases, we prove that the optimal capacity-achieving input\ndistribution that maximizes the rate-energy region is unique and discrete with\na finite number of mass points. Furthermore, we show that the optimal input\ndistribution for the same problem without PP constraint is discrete whenever\nthe EH constraint is active and continuous zero-mean Gaussian, otherwise. Our\nnumerical results show that the rate-energy region is enlarged for a larger PP\nconstraint and that the rate loss of the considered SWIPT system compared to\nthe AWGN channel without EH receiver is reduced by increasing the AP budget. \n\n"}
{"id": "1711.03684", "contents": "Title: Covert Communications with A Full-Duplex Receiver over Wireless Fading\n  Channels Abstract: In this work, we propose a covert communication scheme where the transmitter\nattempts to hide its transmission to a full-duplex receiver, from a warden that\nis to detect this covert transmission using a radiometer. Specifically, we\nfirst derive the detection error rate at the warden, based on which the optimal\ndetection threshold for its radiometer is analytically determined and its\nexpected detection error rate over wireless fading channels is achieved in a\nclosed-form expression. Our analysis indicates that the artificial noise\ndeliberately produced by the receiver with a random transmit power, although\ncauses self-interference, offers the capability of achieving a positive\neffective covert rate for any transmit power (can be infinity) subject to any\ngiven covertness requirement on the expected detection error rate. This work is\nthe first study on the use of the full-duplex receiver with controlled\nartificial noise for achieving covert communications and invites further\ninvestigation in this regard. \n\n"}
{"id": "1711.04449", "contents": "Title: Unified Framework of KKT Conditions Based Matrix Optimizations for MIMO\n  Communications Abstract: For multi-input multi-output (MIMO) communication systems, many transceiver\ndesign problems involve the optimization of the covariance matrices of the\ntransmitted signals. The derivation of the optimal solutions based on\nKarush-Kuhn-Tucker (KKT) conditions is a most popular method, and many results\nhave been reported for different scenarios of MIMO systems. In this overview\npaper, we propose a unified framework in formulating the KKT conditions for\ngeneral MIMO systems. Based on this framework, the optimal water-filling\nstructures of the transmission covariance matrices are derived rigorously,\nwhich are applicable to a wide range of MIMO systems. Our results show that for\nseemingly different MIMO systems with various power constraints and objective\nfunctions, the derivations and water-filling structures for the optimal\ncovariance matrix solutions are fundamentally the same. Thus, our unified\nframework and solution reveal the underlying relationships among the different\nwater-filling structures of the covariance matrices. Furthermore, our results\nprovide new solutions to the covariance matrix optimization of many complicated\nMIMO systems with multiple users and imperfect channel state information which\nwere unknown before. \n\n"}
{"id": "1711.05219", "contents": "Title: LAA LTE and WiFi based Smart Grid Metering Infrastructure in 3.5 GHz\n  Band Abstract: Advanced metering infrastructure (AMI) of smart grid requires bidirectional\ncommunication for transferring data to billing center, for which WiFi is an\nattractive choice. However, WiFi operates in the unlicensed bands and LTE needs\nto offload data in the same unlicensed band. Recent release of 3.5 GHz (also\ntermed as citizen broadband radio service (CBRS)) can be an attractive shared\nband where LTE and WiFi can coexist. In our study, we propose a fixed duty\ncycled LTE-U and WiFi based smart grid metering infrastructure where smart\nmeter uses WiFi and data collector (termed as Access Point (AP)) of smart\nmeters uses LTE for transferring data. We investigate the coexistence\nperformance of LTE-WiFi in the 3.5 GHz band using a time division duplexing\n(TDD) LTE confederated by WiFi along with FTP traffic model for system level\nsimulation. The simulation results demonstrate a good neighboring coexistence\nbetween LTE and WiFi resulting a candidate AMI architecture for smart grid in\nthe 3.5 GHz band. \n\n"}
{"id": "1711.07277", "contents": "Title: Backscatter Communications for the Internet of Things: A Stochastic\n  Geometry Approach Abstract: Motivated by the recent advances in the Internet of Things (IoT) and in\nWireless Power Transfer (WPT), we study a network architecture that consists of\npower beacons (PBs) and passive backscatter nodes (BNs). The PBs transmit a\nsinusoidal continuous wave (CW) and the BNs reflect back a portion of this\nsignal while harvesting the remaining part. A BN harvests energy from multiple\nnearby PBs and modulates its information bits on the composite CW through\nbackscatter modulation. The analysis poses real challenges due to the double\nfading channel, and its dependence on the PPPs of both the BNs and PBs.\nHowever, with the help of stochastic geometry, we derive the coverage\nprobability and the capacity of the network in tractable and easily computable\nexpressions, which depend on different system parameters. We observe that the\ncoverage probability decreases with an increase in the density of the BNs,\nwhile the capacity of the network improves. We further compare the performance\nof this network with a regular powered network in which the BNs have a reliable\npower source and show that for a very high density of the PBs, the coverage\nprobability of the former network approaches that of the regular powered\nnetwork. \n\n"}
{"id": "1711.07324", "contents": "Title: On DNA Codes using the Ring Z4 + wZ4 Abstract: In this work, we study the DNA codes from the ring R = Z4 + wZ4, where w^2 =\n2+2w with 16 elements. We establish a one to one correspondence between the\nelements of the ring R and all the DNA codewords of length 2 by defining a\ndistance-preserving Gau map phi. Using this map, we give several new classes of\nthe DNA codes which satisfies reverse and reverse complement constraints. Some\nof the constructed DNA codes are optimal. \n\n"}
{"id": "1711.07680", "contents": "Title: Asymptotically Minimax Robust Hypothesis Testing Abstract: The design of asymptotically minimax robust hypothesis testing is formalized\nfor the Bayesian and Neyman-Pearson tests of Type-I and Type-II. The\nuncertainty classes based on the KL-divergence, $\\alpha$-divergence,\nsymmetrized $\\alpha$-divergence, total variation distance, as well as the band\nmodel, moment classes and p-point classes are considered. Implications between\nsingle-sample-, all-sample- and asymptotic minimax robustness are derived.\nExistence and uniqueness of asymptotically minimax robust tests are proven\nusing Sion's minimax theorem and the Karush-Kuhn-Tucker multipliers. The least\nfavorable distributions and the corresponding robust likelihood ratio functions\nare derived in parametric forms, which can then be determined by solving a\nsystem of equations. The proposed theory proves that Dabak's design does not\nproduce any asymptotically minimax robust test. Furthermore, it also\ngeneralizes the earlier works by Huber and Kassam by allowing analytical\nderivations, hence, providing answers to the questions 'how?', which were left\nunanswered. Simulations are provided to exemplify and evaluate the theoretical\nderivations. \n\n"}
{"id": "1711.11193", "contents": "Title: Design of Non-orthogonal Multiple Access Enhanced Backscatter\n  Communication Abstract: Backscatter communication (BackCom), which allows a backscatter node (BN) to\ncommunicate with the reader by modulating and reflecting the incident\ncontinuous wave from the reader, is considered as a promising solution to power\nthe future Internet-of-Things. In this paper, we consider a single BackCom\nsystem, where multiple BNs are served by a reader. We propose to use the\npower-domain non-orthogonal multiple access (NOMA), i.e., multiplexing the BNs\nin different regions or with different backscattered power levels, to enhance\nthe spectrum efficiency of the BackCom system. To better exploit power-domain\nNOMA, we propose to set the reflection coefficients for multiplexed BNs to be\ndifferent. Based on this considered model, we develop the reflection\ncoefficient selection criteria. To illustrate the enhanced system with the\nproposed criteria, we analyze the performance of BackCom system in terms of the\naverage number of bits that can be successfully decoded by the reader for\ntwo-node pairing case and the average number of successful BNs for the general\nmultiplexing case. Our results shows that NOMA achieves much better performance\ngain in the BackCom system as compared to its performance gain in the\nconventional system, which highlights the importance of applying NOMA to the\nBackCom system. \n\n"}
{"id": "1712.00256", "contents": "Title: Fast-SSC-Flip Decoding of Polar Codes Abstract: Polar codes are widely considered as one of the most exciting recent\ndiscoveries in channel coding. For short to moderate block lengths, their\nerror-correction performance under list decoding can outperform that of other\nmodern error-correcting codes. However, high-speed list-based decoders with\nmoderate complexity are challenging to implement. Successive-cancellation\n(SC)-flip decoding was shown to be capable of a competitive error-correction\nperformance compared to that of list decoding with a small list size, at a\nfraction of the complexity, but suffers from a variable execution time and a\nhigher worst-case latency. In this work, we show how to modify the\nstate-of-the-art high-speed SC decoding algorithm to incorporate the SC-flip\nideas. The algorithmic improvements are presented as well as average\nexecution-time results tailored to a hardware implementation. The results show\nthat the proposed fast-SSC-flip algorithm has a decoding speed close to an\norder of magnitude better than the previous works while retaining a comparable\nerror-correction performance. \n\n"}
{"id": "1712.00764", "contents": "Title: Arbitrarily Varying Wiretap Channel with State Sequence Known or Unknown\n  at the Receiver Abstract: The secrecy capacity problems over the general arbitrarily varying wiretap\nchannel (AVWC), with respect to the maximal decoding error probability and\nstrong secrecy criterion, are considered, where the channel state sequence may\nbe known or unknown at the receiver. In the mean time, it is always assumed\nthat the channel state sequence is known at the eavesdropper and unknown at the\ntransmitter. Capacity results of both stochastic code (with random encoder and\ndeterministic decoder) and random code (with random encoder and decoder) are\ndiscussed. This model includes the previous models of classic AVWC as special\ncases. Single-letter lower bounds on the secrecy capacities are given, which\nare proved to be the secrecy capacities when the main channel is less noisy\nthan the wiretap channel. The coding scheme is based on Csiszar's almost\nindependent coloring scheme and Ahlswede's elimination technique. Moreover, a\nnew kind of typical sequence with respect to states is defined for this coding\nscheme. It is concluded that the secrecy capacity of stochastic code is\nidentical to that of random code when the receiver knows the state sequence.\nMeanwhile, random code may achieve larger secrecy capacity when the state\nsequence is unknown by the receiver. \n\n"}
{"id": "1712.01249", "contents": "Title: On Out-of-Band Emissions of Quantized Precoding in Massive MU-MIMO-OFDM Abstract: We analyze out-of-band (OOB) emissions in the massive multi-user (MU)\nmultiple-input multiple-output (MIMO) downlink. We focus on systems in which\nthe base station (BS) is equipped with low-resolution digital-to-analog\nconverters (DACs) and orthogonal frequency-division multiplexing (OFDM) is used\nto communicate to the user equipments (UEs) over frequency-selective channels.\nWe demonstrate that analog filtering in combination with simple\nfrequency-domain digital predistortion (DPD) at the BS enables a significant\nreduction of OOB emissions, but degrades the\nsignal-to-interference-noise-and-distortion ratio (SINDR) at the UEs and\nincreases the peak-to-average power ratio (PAR) at the BS. We use Bussgang's\ntheorem to characterize the tradeoffs between OOB emissions, SINDR, and PAR,\nand to study the impact of analog filters and DPD on the error-rate performance\nof the massive MU-MIMO-OFDM downlink. Our results show that by carefully tuning\nthe parameters of the analog filters, one can achieve a significant reduction\nin OOB emissions with only a moderate degradation of error-rate performance and\nPAR. \n\n"}
{"id": "1712.03314", "contents": "Title: Efficient Data Collection Over Multiple Access Wireless Sensors Network Abstract: Data collection in Wireless Sensor Networks (WSN) draws significant\nattention, due to emerging interest in technologies raging from Internet of\nThings (IoT) networks to simple \"Presence\" applications, which identify the\nstatus of the devices (active or inactive). Numerous Medium Access Control\n(MAC) protocols for WSN, which can address the challenge of data collection in\ndense networks, were suggested over the years. Most of these protocols utilize\nthe traditional layering approach, in which the MAC layer is unaware of the\nencapsulated packet payload, and therefore there is no connection between the\ndata collected, the physical layer and the signaling mechanisms. Nonetheless,\nin many of the applications that intend to utilize such protocols, nodes may\nneed to exchange very little information, and do so only sporadically, that is,\nwhile the number of devices in the network can be very large, only a subset\nwishes to transmit at any given time. Thus, a tailored protocol, which matches\nthe signaling, physical layer and access control to traffic patterns is\nrequired.\n  In this work, we design and analyze a data collection protocol based on\ninformation theoretic principles. In the suggested protocol, the sink collects\nmessages from up to K sensors simultaneously, out of a large population of\nsensors, without knowing in advance which sensors will transmit, and without\nrequiring any synchronization, coordination or management overhead. In other\nwords, neither the sink nor the other sensors need to know who are the actively\ntransmitting sensors, and this data is decoded directly from the channel\noutput. We provide a simple codebook construction with very simple encoding and\ndecoding procedures. We further design a secure version of the protocol. \n\n"}
{"id": "1712.03399", "contents": "Title: A Characterization of Antidegradable Qubit Channels Abstract: This paper provides a characterization for the set of antidegradable qubit\nchannels. The characterization arises from the correspondence between the\nantidegradability of a channel and the symmetric extendibility of its Choi\noperator. Using an inequality derived to describe the set of bipartite qubit\nstates which admit symmetric extension, we are able to characterize the set of\nall antidegradable qubit channels. Using the characterization we investigate\nthe antidegradability of unital qubit channels and arbitrary qubit channels\nwith respect to the dimension of the environment. We additionally provide a\ncondition which describes qubit channels which are simultaneously degradable\nand antidegradable along with a classification of self-complementary qubit\nchannels. \n\n"}
{"id": "1712.04266", "contents": "Title: Fundamental Limits of Cloud and Cache-Aided Interference Management with\n  Multi-Antenna Edge Nodes Abstract: In fog-aided cellular systems, content delivery latency can be minimized by\njointly optimizing edge caching and transmission strategies. In order to\naccount for the cache capacity limitations at the Edge Nodes (ENs),\ntransmission generally involves both fronthaul transfer from a cloud processor\nwith access to the content library to the ENs, as well as wireless delivery\nfrom the ENs to the users. In this paper, the resulting problem is studied from\nan information-theoretic viewpoint by making the following practically relevant\nassumptions: 1) the ENs have multiple antennas; 2) only uncoded fractional\ncaching is allowed; 3) the fronthaul links are used to send fractions of\ncontents; and 4) the ENs are constrained to use one-shot linear precoding on\nthe wireless channel. Assuming offline proactive caching and focusing on a high\nsignal-to-noise ratio (SNR) latency metric, the optimal information-theoretic\nperformance is investigated under both serial and pipelined fronthaul-edge\ntransmission modes. The analysis characterizes the minimum high-SNR latency in\nterms of Normalized Delivery Time (NDT) for worst-case users' demands. The\ncharacterization is exact for a subset of system parameters, and is generally\noptimal within a multiplicative factor of 3/2 for the serial case and of 2 for\nthe pipelined case. The results bring insights into the optimal interplay\nbetween edge and cloud processing in fog-aided wireless networks as a function\nof system resources, including the number of antennas at the ENs, the ENs'\ncache capacity and the fronthaul capacity. \n\n"}
{"id": "1712.04767", "contents": "Title: Penalty Dual Decomposition Method For Nonsmooth Nonconvex Optimization Abstract: Many contemporary signal processing, machine learning and wireless\ncommunication applications can be formulated as nonconvex nonsmooth\noptimization problems. Often there is a lack of efficient algorithms for these\nproblems, especially when the optimization variables are nonlinearly coupled in\nsome nonconvex constraints. In this work, we propose an algorithm named penalty\ndual decomposition (PDD) for these difficult problems and discuss its various\napplications. The PDD is a double-loop iterative algorithm. Its inner\niterations is used to inexactly solve a nonconvex nonsmooth augmented\nLagrangian problem via block-coordinate-descenttype methods, while its outer\niteration updates the dual variables and/or a penalty parameter. In Part I of\nthis work, we describe the PDD algorithm and rigorously establish its\nconvergence to KKT solutions. In Part II we evaluate the performance of PDD by\ncustomizing it to three applications arising from signal processing and\nwireless communications. \n\n"}
{"id": "1712.06387", "contents": "Title: Short Packets over Block-Memoryless Fading Channels: Pilot-Assisted or\n  Noncoherent Transmission? Abstract: We present nonasymptotic upper and lower bounds on the maximum coding rate\nachievable when transmitting short packets over a Rician memoryless\nblock-fading channel for a given requirement on the packet error probability.\nWe focus on the practically relevant scenario in which there is no \\emph{a\npriori} channel state information available at the transmitter and at the\nreceiver. An upper bound built upon the min-max converse is compared to two\nlower bounds: the first one relies on a noncoherent transmission strategy in\nwhich the fading channel is not estimated explicitly at the receiver; the\nsecond one employs pilot-assisted transmission (PAT) followed by\nmaximum-likelihood channel estimation and scaled mismatched nearest-neighbor\ndecoding at the receiver. Our bounds are tight enough to unveil the optimum\nnumber of diversity branches that a packet should span so that the energy per\nbit required to achieve a target packet error probability is minimized, for a\ngiven constraint on the code rate and the packet size. Furthermore, the bounds\nreveal that noncoherent transmission is more energy efficient than PAT, even\nwhen the number of pilot symbols and their power is optimized. For example, for\nthe case when a coded packet of $168$ symbols is transmitted using a channel\ncode of rate $0.48$ bits/channel use, over a block-fading channel with block\nsize equal to $8$ symbols, PAT requires an additional $1.2$ dB of energy per\ninformation bit to achieve a packet error probability of $10^{-3}$ compared to\na suitably designed noncoherent transmission scheme. Finally, we devise a PAT\nscheme based on punctured tail-biting quasi-cyclic codes and ordered statistics\ndecoding, whose performance are close ($1$ dB gap at $10^{-3}$ packet error\nprobability) to the ones predicted by our PAT lower bound. This shows that the\nPAT lower bound provides useful guidelines on the design of actual PAT schemes. \n\n"}
{"id": "1712.07062", "contents": "Title: Covert Wireless Communication with a Poisson Field of Interferers Abstract: In this paper, we study covert communication in wireless networks consisting\nof a transmitter, Alice, an intended receiver, Bob, a warden, Willie, and a\nPoisson field of interferers. Bob and Willie are subject to uncertain shot\nnoise due to the ambient signals from interferers in the network. With the aid\nof stochastic geometry, we analyze the throughput of the covert communication\nbetween Alice and Bob subject to given requirements on the covertness against\nWillie and the reliability of decoding at Bob. We consider non-fading and\nfading channels. We analytically obtain interesting findings on the impacts of\nthe density and the transmit power of the concurrent interferers on the covert\nthroughput. That is, the density and the transmit power of the interferers have\nno impact on the covert throughput as long as the network stays in the\ninterference-limited regime, for both the non-fading and the fading cases. When\nthe interference is sufficiently small and comparable with the receiver noise,\nthe covert throughput increases as the density or the transmit power of the\nconcurrent interferers increases. \n\n"}
{"id": "1801.02010", "contents": "Title: On decoding procedures of intertwining codes Abstract: One of the main weakness of the family of centralizer codes is that its\nlength is always $n^2$. Thus we have taken a new matrix equation code called\nintertwining code. Specialty of this code is the length of it, which is of the\nform $nk$. We establish two decoding methods which can be fitted to\nintertwining codes as well as for any linear codes. We also show an inclusion\nof linear codes into a special class of intertwining codes. \n\n"}
{"id": "1801.02781", "contents": "Title: Minimum Throughput Maximization in UAV-Aided Wireless Powered\n  Communication Networks Abstract: This paper investigates unmanned aerial vehicle (UAV)-aided wireless powered\ncommunication network (WPCN) systems where a mobile access point (AP) at the\nUAV serves multiple energy-constrained ground terminals (GTs). Specifically,\nthe UAVs first charge the GTs by transmitting the wireless energy transfer\n(WET) signals in the downlink. Then, by utilizing the harvested wireless energy\nfrom the UAVs, the GTs send their uplink wireless information transmission\n(WIT) signals to the UAVs. In this paper, depending on the operations of the\nUAVs, we adopt two different scenarios, namely integrated UAV and separated UAV\nWPCNs. First, in the integrated UAV WPCN, a UAV acts as a hybrid AP in which\nboth energy transfer and information reception are processed at a single UAV.\nIn contrast, for the separated UAV WPCN, we consider two UAVs each of which\nbehaves as an energy AP and an information AP independently, and thus the\nenergy transfer and the information decoding are separately performed at two\ndifferent UAVs. For both systems, we jointly optimize the trajectories of the\nUAVs, the uplink power control, and the time resource allocation for the WET\nand the WIT to maximize the minimum throughput of the GTs. Since the formulated\nproblems are non-convex, we apply the concave-convex procedure by deriving\nappropriate convex bounds for non-convex constraints. As a result, we propose\niterative algorithms which efficiently identify a local optimal solution for\nthe minimum throughput maximization problems. Simulation results verify the\nefficiency of the proposed algorithms compared to conventional schemes. \n\n"}
{"id": "1801.03668", "contents": "Title: Asynchronous Mobile-Edge Computation Offloading: Energy-Efficient\n  Resource Management Abstract: Mobile-edge computation offloading (MECO) is an emerging technology for\nenhancing mobiles' computation capabilities and prolonging their battery lives,\nby offloading intensive computation from mobiles to nearby servers such as base\nstations. In this paper, we study the energy-efficient resource-management\npolicy for the asynchronous MECO system, where the mobiles have heterogeneous\ninput-data arrival time instants and computation deadlines. First, we consider\nthe general case with arbitrary arrival-deadline orders. Based on the monomial\nenergy-consumption model for data transmission, an optimization problem is\nformulated to minimize the total mobile-energy consumption under the\ntime-sharing and computation-deadline constraints. The optimal\nresource-management policy for data partitioning (for offloading and local\ncomputing) and time division (for transmissions) is shown to be computed by\nusing the block coordinate decent method. To gain further insights, we study\nthe optimal resource-management design for two special cases. First, consider\nthe case of identical arrival-deadline orders, i.e., a mobile with input data\narriving earlier also needs to complete computation earlier. The optimization\nproblem is reduced to two sequential problems corresponding to the optimal\nscheduling order and joint data-partitioning and time-division given the\noptimal order. It is found that the optimal time-division policy tends to\nbalance the defined effective computing power among offloading mobiles via time\nsharing. Furthermore, this solution approach is extended to the case of reverse\narrival-deadline orders. The corresponding time-division policy is derived by a\nproposed transformation-and-scheduling approach, which first determines the\ntotal offloading duration and data size for each mobile in the transformation\nphase and then specifies the offloading intervals for each mobile in the\nscheduling phase. \n\n"}
{"id": "1801.04033", "contents": "Title: A Simplified Coding Scheme for the Broadcast Channel With Complementary\n  Receiver Side Information Under Individual Secrecy Constraints Abstract: This paper simplifies an existing coding scheme for the two-receiver discrete\nmemoryless broadcast channel with complementary receiver side information where\nthere is a passive eavesdropper and individual secrecy is required. The\nexisting coding scheme is simplified in two steps by replacing Wyner secrecy\ncoding with Carleial-Hellman secrecy coding. The resulting simplified scheme is\nfree from redundant message splits and random components. Not least, the\nsimplified scheme retains the existing achievable individual secrecy rate\nregion. Finally, its construction simplicity helps us gain additional insight\non the integration of secrecy techniques into error-correcting coding schemes. \n\n"}
{"id": "1801.04803", "contents": "Title: New LMRD bounds for constant dimension codes and improved constructions Abstract: We generalize upper bounds for constant dimension codes containing a lifted\nmaximum rank distance code first studied by Etzion and Silberstein. The proof\nallows to construct several improved codes. \n\n"}
{"id": "1801.05112", "contents": "Title: Exact Error and Erasure Exponents for the Asymmetric Broadcast Channel Abstract: Consider the asymmetric broadcast channel with a random superposition\ncodebook, which may be comprised of constant composition or \\iid codewords. By\napplying Forney's optimal decoder for individual messages and the message pair\nfor the receiver that decodes both messages, exact (ensemble-tight) error and\nerasure exponents are derived. It is shown that the optimal decoder designed to\ndecode the pair of messages achieves the optimal trade-off between the total\nand undetected exponents associated with the optimal decoder for the private\nmessage. Convex optimization-based procedures to evaluate the exponents\nefficiently are proposed. Finally, numerical examples are presented to\nillustrate the results. \n\n"}
{"id": "1801.05227", "contents": "Title: A Survey of Physical Layer Security Techniques for 5G Wireless Networks\n  and Challenges Ahead Abstract: Physical layer security which safeguards data confidentiality based on the\ninformation-theoretic approaches has received significant research interest\nrecently. The key idea behind physical layer security is to utilize the\nintrinsic randomness of the transmission channel to guarantee the security in\nphysical layer. The evolution towards 5G wireless communications poses new\nchallenges for physical layer security research. This paper provides a latest\nsurvey of the physical layer security research on various promising 5G\ntechnologies, including physical layer security coding, massive multiple-input\nmultiple-output, millimeter wave communications, heterogeneous networks,\nnon-orthogonal multiple access, full duplex technology, etc. Technical\nchallenges which remain unresolved at the time of writing are summarized and\nthe future trends of physical layer security in 5G and beyond are discussed. \n\n"}
{"id": "1801.05483", "contents": "Title: Pilot Contamination Mitigation with Reduced RF Chains Abstract: Massive multiple-input multiple-output (MIMO) communication is a promising\ntechnology for increasing spectral efficiency in wireless networks. Two of the\nmain challenges massive MIMO systems face are degraded channel estimation\naccuracy due to pilot contamination and increase in computational load and\nhardware complexity due to the massive amount of antennas. In this paper, we\nfocus on the problem of channel estimation in massive MIMO systems, while\naddressing these two challenges: We jointly design the pilot sequences to\nmitigate the effect of pilot contamination and propose an analog combiner which\nmaps the high number of sensors to a low number of RF chains, thus reducing the\ncomputational and hardware cost. We consider a statistical model in which the\nchannel covariance obeys a Kronecker structure. In particular, we treat two\nsuch cases, corresponding to fully- and partially-separable correlations. We\nprove that with these models, the analog combiner design can be done\nindependently of the pilot sequences. Given the resulting combiner, we derive a\nclosed-form expression for the optimal pilot sequences in the fully-separable\ncase and suggest a greedy sum of ratio traces maximization (GSRTM) method for\ndesigning sub-optimal pilots in the partially-separable scenario. We\ndemonstrate via simulations that our pilot design framework achieves lower mean\nsquared error than the common pilot allocation framework previously considered\nfor pilot contamination mitigation. \n\n"}
{"id": "1801.05522", "contents": "Title: Coded Computing for Distributed Graph Analytics Abstract: Performance of distributed graph processing systems significantly suffers\nfrom 'communication bottleneck' as a large number of messages are exchanged\namong servers at each step of the computation. Motivated by graph based\nMapReduce, we propose a coded computing framework that leverages computation\nredundancy to alleviate the communication bottleneck in distributed graph\nprocessing. We develop a novel 'coding' scheme that systematically injects\nstructured redundancy in computation phase to enable 'coded' multicasting\nopportunities during message exchange between servers, reducing communication\nload substantially in large-scale graph processing. For theoretical analysis,\nwe consider random graph models, and prove that our proposed scheme enables an\n(asymptotically) inverse-linear trade-off between 'computation load' and\n'average communication load' for two popular random graph models -- Erdos-Renyi\nmodel, and power law model. Particularly, for a given computation load r, (i.e.\nwhen each graph vertex is carefully stored at r servers), the proposed scheme\nslashes the average communication load by (nearly) a multiplicative factor of\nr. For the Erdos-Renyi model, our proposed scheme is optimal asymptotically as\nthe graph size increases by providing an information-theoretic converse. To\nillustrate the benefits of our scheme in practice, we implement PageRank over\nAmazon EC2, using artificial as well as real-world datasets, demonstrating\nsignificant gains over conventional PageRank. We also specialize our scheme and\nextend our theoretical results to two other random graph models -- random\nbi-partite model, and stochastic block model. They asymptotically enable\ninverse-linear trade-offs between computation and communication loads in\ndistributed graph processing for these popular random graph models as well. We\ncomplement the achievability results with converse bounds for both of these\nmodels. \n\n"}
{"id": "1801.06022", "contents": "Title: Reconstruction Codes for DNA Sequences with Uniform Tandem-Duplication\n  Errors Abstract: DNA as a data storage medium has several advantages, including far greater\ndata density compared to electronic media. We propose that schemes for data\nstorage in the DNA of living organisms may benefit from studying the\nreconstruction problem, which is applicable whenever multiple reads of noisy\ndata are available. This strategy is uniquely suited to the medium, which\ninherently replicates stored data in multiple distinct ways, caused by\nmutations. We consider noise introduced solely by uniform tandem-duplication,\nand utilize the relation to constant-weight integer codes in the Manhattan\nmetric. By bounding the intersection of the cross-polytope with hyperplanes, we\nprove the existence of reconstruction codes with greater capacity than known\nerror-correcting codes, which we can determine analytically for any set of\nparameters. \n\n"}
{"id": "1801.06623", "contents": "Title: Promises and Caveats of Uplink IoT Ultra-Dense Networks Abstract: In this paper, by means of simulations, we evaluate the uplink (UL)\nperformance of an Internet of Things (IoT) capable ultra-dense network (UDN) in\nterms of the coverage probability and the density of reliably working user\nequipments (UEs). From our study, we show the benefits and challenges that UL\nIoT UDNs will bring about in the future. In more detail, for a low-reliability\ncriterion, such as achieving a UL signal-to-interference-plus-noise ratio\n(SINR) above 0 dB, the density of reliably working UEs grows quickly with the\nnetwork densification, showing the potential of UL IoT UDNs. In contrast, for a\nhigh-reliability criterion, such as achieving a UL SINR above 10 dB, the\ndensity of reliably working UEs remains to be low in UDNs due to excessive\ninter-cell interference, which should be considered when operating UL IoT UDNs.\nMoreover, considering the existence of a non-zero antenna height difference\nbetween base stations (BSs) and UEs, the density of reliably working UEs could\neven decrease as we deploy more BSs. This calls for the usage of sophisticated\ninterference management schemes and/or beam steering/shaping technologies in UL\nIoT UDNs. \n\n"}
{"id": "1801.10484", "contents": "Title: Cache-Aided Non-Orthogonal Multiple Access: The Two-User Case Abstract: In this paper, we propose a cache-aided non-orthogonal multiple access (NOMA)\nscheme for spectrally efficient downlink transmission. The proposed scheme not\nonly reaps the benefits associated with NOMA and caching, but also exploits the\ndata cached at the users for interference cancellation. As a consequence,\ncaching can help to reduce the residual interference power, making multiple\ndecoding orders at the users feasible. The resulting flexibility in decoding\ncan be exploited for improved NOMA detection. We characterize the achievable\nrate region of cache-aided NOMA and derive the Pareto optimal rate tuples\nforming the boundary of the rate region. Moreover, we optimize cache-aided NOMA\nfor minimization of the time required for completing file delivery. The optimal\ndecoding order and the optimal transmit power and rate allocation are derived\nas functions of the cache status, the file sizes, and the channel conditions.\nSimulation results confirm that, compared to several baseline schemes, the\nproposed cache-aided NOMA scheme significantly expands the achievable rate\nregion and increases the sum rate for downlink transmission, which translates\ninto substantially reduced file delivery times. \n\n"}
{"id": "1802.00157", "contents": "Title: Optimal LRC codes for all lenghts n <= q Abstract: A family of distance-optimal LRC codes from certain subcodes of $q$-ary\nReed-Solomon codes, proposed by I.~Tamo and A.~Barg in 2014, assumes that the\ncode length $n$ is a multiple of $r+1.$ By shortening codes from this family,\nwe show that it is possible to lift this assumption, still obtaining\ndistance-optimal codes. \n\n"}
{"id": "1802.00263", "contents": "Title: Robust Sequential Detection in Distributed Sensor Networks Abstract: We consider the problem of sequential binary hypothesis testing with a\ndistributed sensor network in a non-Gaussian noise environment. To this end, we\npresent a general formulation of the Consensus + Innovations Sequential\nProbability Ratio Test (CISPRT). Furthermore, we introduce two different\nconcepts for robustifying the CISPRT and propose four different algorithms,\nnamely, the Least-Favorable-Density-CISPRT, the Median-CISPRT, the M-CISPRT,\nand the Myriad-CISPRT. Subsequently, we analyze their suitability for different\nbinary hypothesis tests before verifying and evaluating their performance in a\nshift-in-mean and a shift-in-variance scenario. \n\n"}
{"id": "1802.01513", "contents": "Title: Covariance Matrix Estimation for Massive MIMO Abstract: We propose a novel pilot structure for covariance matrix estimation in\nmassive multiple-input multiple-output (MIMO) systems in which each user\ntransmits two pilot sequences, with the second pilot sequence multiplied by a\nrandom phase-shift. The covariance matrix of a particular user is obtained by\ncomputing the sample cross-correlation of the channel estimates obtained from\nthe two pilot sequences. This approach relaxes the requirement that all the\nusers transmit their uplink pilots over the same set of symbols. We derive\nexpressions for the achievable rate and the mean-squared error of the\ncovariance matrix estimate when the proposed method is used with staggered\npilots. The performance of the proposed method is compared with existing\nmethods through simulations. \n\n"}
{"id": "1802.02667", "contents": "Title: Generalized Degrees of Freedom of Noncoherent Diamond Networks Abstract: We study the generalized degrees of freedom (gDoF) of the block-fading\nnoncoherent diamond (parallel relay) wireless network with asymmetric\ndistributions of link strengths, and a coherence time of T symbol duration. We\nfirst derive an outer bound for this channel and then derive the optimal\nsignaling structure for this outer bound. Using the optimal signaling structure\nwe solve the outer bound optimization problem in terms of its gDoF. Using\ninsights from our outer bound signaling solution, we devise an achievability\nstrategy based on a novel scheme that we call train-scale quantize-map-forward\n(TS-QMF). This uses training in the links from the source to the relays,\nscaling and quantizing at the relays combined with nontraining-based schemes.\nWe show the optimality of this scheme with respect to the outer bound in terms\nof the gDoF. In noncoherent point-to-point multiple-input-multiple-output\n(MIMO) channels, where the fading channel is unknown to transmitter and\nreceiver, an important tradeoff between communication and channel learning was\nrevealed by Zheng and Tse, by demonstrating that not all the available antennas\nmight be used, as it is suboptimal to learn all their channel parameters. Our\nresults in this paper for the diamond network demonstrates that in certain\nregimes the optimal scheme uses a subnetwork, demonstrating a tradeoff between\nchannel learning and communications. In some regimes, it is gDoF optimal to do\nrelay selection, i.e, use a part of the network. In the other regimes, even\nwhen it is essential to use the entire network, it is suboptimal to learn the\nchannel states for all the links in the network, i.e, traditional\ntraining-based schemes are suboptimal in these regimes. \n\n"}
{"id": "1802.03720", "contents": "Title: Double Minimum Variance Beamforming Method to Enhance Photoacoustic\n  Imaging Abstract: One of the common algorithms used to reconstruct photoacoustic (PA) images is\nthe non-adaptive Delay-and-Sum (DAS) beamformer. However, the quality of the\nreconstructed PA images obtained by DAS is not satisfying due to its high level\nof sidelobes and wide mainlobe. In contrast, adaptive beamformers, such as\nminimum variance (MV), result in an improved image compared to DAS. In this\npaper, a novel beamforming method, called Double MV (D-MV) is proposed to\nenhance the image quality compared to the MV. It is shown that there is a\nsummation procedure between the weighted subarrays in the output of the MV\nbeamformer. This summation can be interpreted as the non-adaptive DAS\nbeamformer. It is proposed to replace the existing DAS with the MV algorithm to\nreduce the contribution of the off-axis signals caused by the DAS beamformer\nbetween the weighted subarrays. The numerical results show that the proposed\ntechnique improves the full-width-half-maximum (FWHM) and signal-to-noise ratio\n(SNR) for about 28.83 \\mu m and 4.8 dB in average, respectively, compared to MV\nbeamformer. Also, quantitative evaluation of the experimental results indicates\nthat the proposed D-MV leads to 0.15 mm and 1.96 dB improvement in FWHM and\nSNR, in comparison with MV beamformer. \n\n"}
{"id": "1802.04838", "contents": "Title: Network Estimation from Point Process Data Abstract: Consider observing a collection of discrete events within a network that\nreflect how network nodes influence one another. Such data are common in spike\ntrains recorded from biological neural networks, interactions within a social\nnetwork, and a variety of other settings. Data of this form may be modeled as\nself-exciting point processes, in which the likelihood of future events depends\non the past events. This paper addresses the problem of estimating\nself-excitation parameters and inferring the underlying functional network\nstructure from self-exciting point process data. Past work in this area was\nlimited by strong assumptions which are addressed by the novel approach here.\nSpecifically, in this paper we (1) incorporate saturation in a point process\nmodel which both ensures stability and models non-linear thresholding effects;\n(2) impose general low-dimensional structural assumptions that include\nsparsity, group sparsity and low-rankness that allows bounds to be developed in\nthe high-dimensional setting; and (3) incorporate long-range memory effects\nthrough moving average and higher-order auto-regressive components. Using our\ngeneral framework, we provide a number of novel theoretical guarantees for\nhigh-dimensional self-exciting point processes that reflect the role played by\nthe underlying network structure and long-term memory. We also provide\nsimulations and real data examples to support our methodology and main results. \n\n"}
{"id": "1802.05209", "contents": "Title: Sum Secrecy Rate Maximization in a Multi-Carrier MIMO Wiretap Channel\n  with Full-Duplex Jamming Abstract: In this paper we address a sum secrecy rate maximization problem for a\nmulti-carrier and MIMO communication system. We consider the case that the\nreceiver is capable of full-duplex (FD) operation and simultaneously sends\njamming signal to a potential eavesdropper. In particular, we simultaneously\ntake advantage of the spatial and frequency diversity in the system in order to\nobtain a higher level of security in the physical layer. Due to the non-convex\nnature of the resulting mathematical problem, we propose an iterative solution\nwith a guaranteed convergence, based on block coordinate descent method, by\nre-structuring our problem as a separately convex program. Moreover, for the\nspecial case that the transmitter is equipped with a single antenna, an optimal\ntransmit power allocation strategy is obtained analytically, assuming a known\njamming strategy. We also study a FD bidirectional secure communication system,\nwhere the jamming power can be reused to enhance the sum secrecy rate. The\nperformance of the proposed design is then numerically evaluated compared to\nthe other design strategies, and under different system assumptions. \n\n"}
{"id": "1802.05856", "contents": "Title: Algorithmic Complexity and Reprogrammability of Chemical Structure\n  Networks Abstract: Here we address the challenge of profiling causal properties and tracking the\ntransformation of chemical compounds from an algorithmic perspective. We\nexplore the potential of applying a computational interventional calculus based\non the principles of algorithmic probability to chemical structure networks. We\nprofile the sensitivity of the elements and covalent bonds in a chemical\nstructure network algorithmically, asking whether reprogrammability affords\ninformation about thermodynamic and chemical processes involved in the\ntransformation of different compound classes. We arrive at numerical results\nsuggesting a correspondence between some physical, structural and functional\nproperties. Our methods are capable of separating chemical classes that reflect\nfunctional and natural differences without considering any information about\natomic and molecular properties. We conclude that these methods, with their\nlinks to chemoinformatics via algorithmic, probability hold promise for future\nresearch. \n\n"}
{"id": "1802.07458", "contents": "Title: Non-Asymptotic Bounds and a General Formula for the Rate-Distortion\n  Region of the Successive Refinement Problem Abstract: In the successive refinement problem, a fixed-length sequence emitted from an\ninformation source is encoded into two codewords by two encoders in order to\ngive two reconstructions of the sequence. One of two reconstructions is\nobtained by one of two codewords, and the other reconstruction is obtained by\nall two codewords. For this coding problem, we give non-asymptotic inner and\nouter bounds on pairs of numbers of codewords of two encoders such that each\nprobability that a distortion exceeds a given distortion level is less than a\ngiven probability level. We also give a general formula for the rate-distortion\nregion for general sources, where the rate-distortion region is the set of rate\npairs of two encoders such that each maximum value of possible distortions is\nless than a given distortion level. \n\n"}
{"id": "1802.07990", "contents": "Title: Joint Antenna Selection and Phase-Only Beamforming Using Mixed-Integer\n  Nonlinear Programming Abstract: In this paper, we consider the problem of joint antenna selection and analog\nbeamformer design in downlink single-group multicast networks. Our objective is\nto reduce the hardware costs by minimizing the number of required phase\nshifters at the transmitter while fulfilling given distortion limits at the\nreceivers. We formulate the problem as an L0 minimization problem and devise a\nnovel branch-and-cut based algorithm to solve the resulting mixed-integer\nnonlinear program to optimality. We also propose a suboptimal heuristic\nalgorithm to solve the above problem approximately with a low computational\ncomplexity. Computational results illustrate that the solutions produced by the\nproposed heuristic algorithm are optimal in most cases. The results also\nindicate that the performance of the optimal methods can be significantly\nimproved by initializing with the result of the suboptimal method. \n\n"}
{"id": "1802.08223", "contents": "Title: Achievable Rate of Private Function Retrieval from MDS Coded Databases Abstract: We study the problem of private function retrieval (PFR) in a distributed\nstorage system. In PFR the user wishes to retrieve a linear combination of $M$\nmessages stored in non-colluding $(N,K)$ MDS coded databases while revealing no\ninformation about the coefficients of the intended linear combination to any of\nthe individual databases. We present an achievable scheme for MDS coded PFR\nwith a rate that matches the capacity for coded private information retrieval\nderived recently, $R=(1+R_c+R_c^2+\\dots+R_c^{M-1})^{-1}=\\frac{1-R_c}{1-R_c^M}$,\nwhere $R_c=\\frac{K}{N}$ is the rate of the MDS code. This achievable rate is\ntight in some special cases. \n\n"}
{"id": "1803.00983", "contents": "Title: Power Control and Channel Allocation for D2D Underlaid Cellular Networks Abstract: Device-to-Device (D2D) communications underlaying cellular networks is a\nviable network technology that can potentially increase spectral utilization\nand improve power efficiency for proximitybased wireless applications and\nservices. However, a major challenge in such deployment scenarios is the\ninterference caused by D2D links when sharing the same resources with cellular\nusers. In this work, we propose a channel allocation (CA) scheme together with\na set of three power control (PC) schemes to mitigate interference in a D2D\nunderlaid cellular system modeled as a random network using the mathematical\ntool of stochastic geometry. The novel aspect of the proposed CA scheme is that\nit enables D2D links to share resources with multiple cellular users as opposed\nto one as previously considered in the literature. Moreover, the accompanying\ndistributed PC schemes further manage interference during link establishment\nand maintenance. The first two PC schemes compensate for large-scale path-loss\neffects and maximize the D2D sum rate by employing distance-dependent pathloss\nparameters of the D2D link and the base station, including an error estimation\nmargin. The third scheme is an adaptive PC scheme based on a variable target\nsignal-to-interference-plus-noise ratio, which limits the interference caused\nby D2D users and provides sufficient coverage probability for cellular users.\nClosed-form expressions for the coverage probability of cellular links, D2D\nlinks, and sum rate of D2D links are derived in terms of the allocated power,\ndensity of D2D links, and path-loss exponent. The impact of these key system\nparameters on network performance is analyzed and compared with previous work.\nSimulation results demonstrate an enhancement in cellular and D2D coverage\nprobabilities, and an increase in spectral and power efficiency. \n\n"}
{"id": "1803.01819", "contents": "Title: Sub-Nyquist Radar: Principles and Prototypes Abstract: In the past few years, new approaches to radar signal processing have been\nintroduced which allow the radar to perform signal detection and parameter\nestimation from much fewer measurements than that required by Nyquist sampling.\nThese systems - referred to as sub-Nyquist radars - model the received signal\nas having finite rate of innovation and employ the Xampling framework to obtain\nlow-rate samples of the signal. Sub-Nyquist radars exploit the fact that the\ntarget scene is sparse facilitating the use of compressed sensing (CS) methods\nin signal recovery. In this chapter, we review several pulse-Doppler radar\nsystems based on these principles. Contrary to other CS-based designs, our\nformulations directly address the reduced-rate analog sampling in space and\ntime, avoid a prohibitive dictionary size, and are robust to noise and clutter.\nWe begin by introducing temporal sub-Nyquist processing for estimating the\ntarget locations using less bandwidth than conventional systems. This paves the\nway to cognitive radars which share their transmit spectrum with other\ncommunication services, thereby providing a robust solution for coexistence in\nspectrally crowded environments. Next, without impairing Doppler resolution, we\nreduce the dwell time by transmitting interleaved radar pulses in a scarce\nmanner within a coherent processing interval or \"slow time\". Then, we consider\nmultiple-input-multiple-output array radars and demonstrate spatial sub-Nyquist\nprocessing which allows the use of few antenna elements without degradation in\nangular resolution. Finally, we demonstrate application of sub-Nyquist and\ncognitive radars to imaging systems such as synthetic aperture radar. For each\nsetting, we present a state-of-the-art hardware prototype designed to\ndemonstrate the real-time feasibility of sub-Nyquist radars. \n\n"}
{"id": "1803.02078", "contents": "Title: Finite sample improvement of Akaike's Information Criterion Abstract: We emphasize that it is possible to improve the principle of unbiased risk\nestimation for model selection by addressing excess risk deviations in the\ndesign of penalization procedures. Indeed, we propose a modification of\nAkaike's Information Criterion that avoids overfitting, even when the sample\nsize is small. We call this correction an over-penalization procedure. As proof\nof concept, we show the nonasymptotic optimality of our histogram selection\nprocedure in density estimation by establishing sharp oracle inequalities for\nthe Kullback-Leibler divergence. One of the main features of our theoretical\nresults is that they include the estimation of unbounded logdensities. To do\nso, we prove several analytical and probabilistic lemmas that are of\nindependent interest. In an experimental study, we also demonstrate\nstate-of-the-art performance of our over-penalization criterion for bin size\nselection, in particular outperforming AICc procedure. \n\n"}
{"id": "1803.02288", "contents": "Title: A New Scaling Law for Activity Detection in Massive MIMO Systems Abstract: In this paper, we study the problem of \\textit{activity detection} (AD) in a\nmassive MIMO setup, where the Base Station (BS) has $M \\gg 1$ antennas. We\nconsider a block fading channel model where the $M$-dim channel vector of each\nuser remains almost constant over a \\textit{coherence block} (CB) containing\n$D_c$ signal dimensions. We study a setting in which the number of potential\nusers $K_c$ assigned to a specific CB is much larger than the dimension of the\nCB $D_c$ ($K_c \\gg D_c$) but at each time slot only $A_c \\ll K_c$ of them are\nactive. Most of the previous results, based on compressed sensing, require that\n$A_c\\le D_c$, which is a bottleneck in massive deployment scenarios such as\nInternet-of-Things (IoT) and Device-to-Device (D2D) communication. In this\npaper, we show that one can overcome this fundamental limitation when the\nnumber of BS antennas $M$ is sufficiently large. More specifically, we derive a\n\\textit{scaling law} on the parameters $(M, D_c, K_c, A_c)$ and also\n\\textit{Signal-to-Noise Ratio} (SNR) under which our proposed AD scheme\nsucceeds. Our analysis indicates that with a CB of dimension $D_c$, and a\nsufficient number of BS antennas $M$ with $A_c/M=o(1)$, one can identify the\nactivity of $A_c=O(D_c^2/\\log^2(\\frac{K_c}{A_c}))$ active users, which is much\nlarger than the previous bound $A_c=O(D_c)$ obtained via traditional compressed\nsensing techniques. In particular, in our proposed scheme one needs to pay only\na poly-logarithmic penalty $O(\\log^2(\\frac{K_c}{A_c}))$ for increasing the\nnumber of potential users $K_c$, which makes it ideally suited for AD in IoT\nsetups. We propose low-complexity algorithms for AD and provide numerical\nsimulations to illustrate our results. We also compare the performance of our\nproposed AD algorithms with that of other competitive algorithms in the\nliterature. \n\n"}
{"id": "1803.04725", "contents": "Title: Storage and Repair Bandwidth Tradeoff for Distributed Storage Systems\n  with Clusters and Separate Nodes Abstract: The optimal tradeoff between node storage and repair bandwidth is an\nimportant issue for distributed storage systems (DSSs). As for realistic DSSs\nwith clusters, when repairing a failed node, it is more efficient to download\nmore data from intra-cluster nodes than from cross-cluster nodes. Therefore, it\nis meaningful to differentiate the repair bandwidth from intra-cluster and\ncross-cluster. For cluster DSSs the tradeoff has been considered with special\nrepair assumptions where all the alive nodes are utilized to repair a failed\nnode. In this paper, we investigate the optimal tradeoff for cluster DSSs under\nmore general storage/repair parameters. Furthermore, a regenerating code\nconstruction strategy achieving the points in the optimal tradeoff curve is\nproposed for cluster DSSs with specific parameters as a numerical example.\nMoreover, the influence of separate nodes for the tradeoff is also considered\nfor DSSs with clusters and separated nodes. \n\n"}
{"id": "1803.05844", "contents": "Title: Iterative Turbo Receiver for LDPC-Coded MIMO Systems Based on\n  Semi-definite Relaxation Abstract: In this work, we develop a new iterative turbo receiver for LDPC-coded\nmulti-antenna systems based on semidefinite relaxation (SDR). For a classical\nturbo receiver, forward error correction (FEC) code is only used at decoder.\nNonetheless, by taking advantage of FEC code in the detection stage, our\nproposed SDR detector can output extrinsic information with much improved\nreliability to the decoder. We also propose a simplified SDR turbo receiver\nthat solves only one SDR problem per codeword instead of solving multiple SDR\nproblems in the iterative turbo processing. This scheme significantly reduces\nthe time complexity of SDR turbo receiver, while the error performance remains\nsimilar as before. In fact, our simplified scheme is generic in the sense that\nit is applicable to any list-based iterative receivers. \n\n"}
{"id": "1803.06982", "contents": "Title: Quantifying coherence with quantum addition Abstract: Quantum addition channels have been recently introduced in the context of\nderiving entropic power inequalities for finite dimensional quantum systems. We\nprove a reverse entropy power equality which can be used to analytically prove\nan inequality conjectured recently for arbitrary dimension and arbitrary\naddition weight. We show that the relative entropic difference between the\noutput of such a quantum additon channel and the corresponding classical\nmixture quantitatively captures the amount of coherence present in a quantum\nsystem. This new coherence measure admits an upper bound in terms of the\nrelative entropy of coherence and is utilized to formulate a state-dependent\nuncertainty relation for two observables. Our results may provide deep insights\nto the origin of quantum coherence for mixed states that truly come from the\ndiscrepancy between quantum addition and the classical mixture. \n\n"}
{"id": "1803.07505", "contents": "Title: Non-Asymptotic Classical Data Compression with Quantum Side Information Abstract: In this paper, we analyze classical data compression with quantum side\ninformation (also known as the classical-quantum Slepian-Wolf protocol) in the\nso-called large and moderate deviation regimes. In the non-asymptotic setting,\nthe protocol involves compressing classical sequences of finite length $n$ and\ndecoding them with the assistance of quantum side information. In the large\ndeviation regime, the compression rate is fixed, and we obtain bounds on the\nerror exponent function, which characterizes the minimal probability of error\nas a function of the rate. Devetak and Winter showed that the asymptotic data\ncompression limit for this protocol is given by a conditional entropy. For any\nprotocol with a rate below this quantity, the probability of error converges to\none asymptotically and its speed of convergence is given by the strong converse\nexponent function. We obtain finite blocklength bounds on this function, and\ndetermine exactly its asymptotic value. In the moderate deviation regime for\nthe compression rate, the latter is no longer considered to be fixed. It is\nallowed to depend on the blocklength $n$, but assumed to decay slowly to the\nasymptotic data compression limit. Starting from a rate above this limit, we\ndetermine the speed of convergence of the error probability to zero and show\nthat it is given in terms of the conditional information variance. Our results\ncomplement earlier results obtained by Tomamichel and Hayashi, in which they\nanalyzed the so-called small deviation regime of this protocol. \n\n"}
{"id": "1803.08404", "contents": "Title: Sequence pairs with asymptotically optimal aperiodic correlation Abstract: The Pursley-Sarwate criterion of a pair of finite complex-valued sequences\nmeasures the collective smallness of the aperiodic autocorrelations and the\naperiodic crosscorrelations of the two sequences. It is known that this\nquantity is always at least 1 with equality if and only if the sequence pair is\na Golay pair. We exhibit pairs of complex-valued sequences whose entries have\nunit magnitude for which the Pursley-Sarwate criterion tends to 1 as the\nsequence length tends to infinity. Our constructions use different carefully\nchosen Chu sequences. \n\n"}
{"id": "1803.09012", "contents": "Title: Message passing-based joint CFO and channel estimation in millimeter\n  wave systems with one-bit ADCs Abstract: Channel estimation at millimeter wave (mmWave) is challenging when large\nantenna arrays are used. Prior work has leveraged the sparse nature of mmWave\nchannels via compressed sensing based algorithms for channel estimation. Most\nof these algorithms, though, assume perfect synchronization and are vulnerable\nto phase errors that arise due to carrier frequency offset (CFO) and phase\nnoise. Recently sparsity-aware, non-coherent beamforming algorithms that are\nrobust to phase errors were proposed for narrowband phased array systems with\nfull resolution analog-to-digital converters (ADCs). Such energy based\nalgorithms, however, are not robust to heavy quantization at the receiver. In\nthis paper, we develop a joint CFO and wideband channel estimation algorithm\nthat is scalable across different mmWave architectures. Our method exploits the\nsparsity of mmWave MIMO channel in the angle-delay domain, in addition to\ncompressibility of the phase error vector. We formulate the joint estimation as\na sparse bilinear optimization problem and then use message passing for\nrecovery. We also give an efficient implementation of a generalized bilinear\nmessage passing algorithm for the joint estimation in mmWave systems with\none-bit ADCs. Simulation results show that our method is able to recover the\nCFO and the channel compressively, even in the presence of phase noise. \n\n"}
{"id": "1804.03295", "contents": "Title: MmWave MU-MIMO for Aerial Networks Abstract: Millimeter wave offers high bandwidth for air-to-air (A2A) communication. In\nthis paper, we evaluate the rate performance of a multiuser MIMO (MU-MIMO)\nconfiguration where several aircraft communicate with a central hub. We\nconsider a hybrid subarray architecture, single path channels, and realistic\natmospheric attenuation effects. We propose a mathematical framework for the\nanalysis of millimeter wave (mmWave) MU-MIMO networks. Via Monte Carlo\nsimulation, we demonstrate that mmWave is a promising technology for delivering\ngigabit connectivity in next-generation aerial networks. \n\n"}
{"id": "1804.05814", "contents": "Title: Multidimensional Constellations for Uplink SCMA Systems --- A\n  Comparative Study Abstract: Sparse code multiple access (SCMA) is a class of non-orthogonal multiple\naccess (NOMA) that is proposed to support uplink machine-type communication\nservices. In an SCMA system, designing multidimensional constellation plays an\nimportant role in the performance of the system. Since the behaviour of\nmultidimensional constellations highly depends on the type of the channel, it\nis crucial to employ a constellation that is suitable for a certain\napplication. In this paper, we first highlight and review the key performance\nindicators (KPIs) of multidimensional constellations that should be considered\nin their design process for various channel scenarios. We then provide a survey\non the known multidimensional constellations in the context of SCMA systems\nwith their design criteria. The performance of some of those constellations are\nevaluated for uncoded, high-rate, and low-rate LTE turbo-coded SCMA systems\nunder different channel conditions through extensive simulations. All\nturbo-coded comparisons are performed for bit-interleaved coded modulation,\nwith a concatenated detection and decoding scheme. Simulation results confirm\nthat multidimensional constellations that satisfy KPIs of a certain channel\nscenario outperform others. Moreover, the bit error rate performance of uncoded\nsystems, and the performance of the coded systems are coupled to their\nbit-labeling. The performance of the systems also remarkably depends on the\nbehavior of the multi-user detector at different signal-to-noise ratio regions. \n\n"}
{"id": "1804.07675", "contents": "Title: Achievable Information Rates for Nonlinear Fiber Communication via\n  End-to-end Autoencoder Learning Abstract: Machine learning is used to compute achievable information rates (AIRs) for a\nsimplified fiber channel. The approach jointly optimizes the input distribution\n(constellation shaping) and the auxiliary channel distribution to compute AIRs\nwithout explicit channel knowledge in an end-to-end fashion. \n\n"}
{"id": "1804.07756", "contents": "Title: Mobile Edge Computing-Enabled Heterogeneous Networks Abstract: The mobile edge computing (MEC) has been introduced for providing computing\ncapabilities at the edge of networks to improve the latency performance of\nwireless networks. In this paper, we provide the novel framework for\nMEC-enabled heterogeneous networks (HetNets), composed of the multi-tier\nnetworks with access points (APs) (i.e., MEC servers), which have different\ntransmission power and different computing capabilities. In this framework, we\nalso consider multiple-type mobile users with different sizes of computation\ntasks, and they offload the tasks to a MEC server, and receive the computation\nresulting data from the server. We derive the successful edge computing\nprobability (SECP), defined as the probability that a user offloads and\nfinishes its computation task at the MEC server within the target latency. We\nprovide a closed-form expression of the approximated SECP for general case, and\nclosed-form expressions of the exact SECP for special cases. This paper then\nprovides the design insights for the optimal configuration of MEC-enabled\nHetNets by analyzing the effects of network parameters and bias factors, used\nin MEC server association, on the SECP. Specifically, it shows how the optimal\nbias factors in terms of SECP can be changed according to the numbers of user\ntypes and tiers of MEC servers, and how they are different to the conventional\nones that did not consider the computing capabilities and task sizes. \n\n"}
{"id": "1804.07985", "contents": "Title: Capacity of Multiple One-Bit Transceivers in a Rayleigh Environment Abstract: We analyze the channel capacity of a system with a large number of one-bit\ntransceivers in a classical Rayleigh environment with perfect channel\ninformation at the receiver. With $M$ transmitters and $N=\\alpha M$ receivers,\nwe derive an expression of the capacity per transmitter $\\mathcal{C}$, where\n$\\mathcal{C}\\leq\\min(1,\\alpha)$, as a function of $\\alpha$ and signal-to-noise\nratio (SNR) $\\rho$, when $M\\to\\infty$. We show that our expression is a good\napproximation for small $M$, and provide simple approximations of $\\mathcal{C}$\nfor various ranges of $\\alpha$ and SNR $\\rho$. We conclude that at high SNR,\n$\\mathcal{C}$ reaches its upper limit of one only if the ratio $\\alpha>1.24$.\nExpressions for determining when $\\mathcal{C}$ \"saturates\" as a function of\n$\\alpha$ and $\\rho$ are given. \n\n"}
{"id": "1804.08595", "contents": "Title: Single-User mmWave Massive MIMO: SVD-based ADC Bit Allocation and\n  Combiner Design Abstract: In this paper, we propose a Singular-Value-Decomposition-based\nvariable-resolution Analog to Digital Converter (ADC) bit allocation design for\na single-user Millimeter wave massive Multiple-Input Multiple-Output receiver.\nWe derive the optimality condition for bit allocation under a power constraint.\nThis condition ensures optimal receiver performance in the Mean Squared Error\n(MSE) sense. We derive the MSE expression and show that it approaches the\nCramer-Rao Lower Bound (CRLB). The CRLB is seen to be a function of the analog\ncombiner, the digital combiner, and the bit allocation matrix. We attempt to\nminimize the CRLB with respect to the bit allocation matrix by making suitable\nassumptions regarding the structure of the combiners. In doing so, the bit\nallocation design reduces to a set of simple inequalities consisting of ADC\nbits, channel singular values and covariance of the quantization noise along\neach RF path. This results in a simple and computationally efficient bit\nallocation algorithm. Using simulations, we show that the MSE performance of\nour proposed bit allocation is very close to that of the Full Search (FS) bit\nallocation. We also show that the computational complexity of our proposed\nmethod has an order of magnitude improvement compared to FS and Genetic\nAlgorithm based bit allocation of $\\cite{Zakir1}$ \n\n"}
{"id": "1804.08980", "contents": "Title: Rate-Distortion Theory for General Sets and Measures Abstract: This paper is concerned with a rate-distortion theory for sequences of i.i.d.\nrandom variables with general distribution supported on general sets including\nmanifolds and fractal sets. Manifold structures are prevalent in data science,\ne.g., in compressed sensing, machine learning, image processing, and\nhandwritten digit recognition. Fractal sets find application in image\ncompression and in modeling of Ethernet traffic. We derive a lower bound on the\n(single-letter) rate-distortion function that applies to random variables X of\ngeneral distribution and for continuous X reduces to the classical Shannon\nlower bound. Moreover, our lower bound is explicit up to a parameter obtained\nby solving a convex optimization problem in a nonnegative real variable. The\nonly requirement for the bound to apply is the existence of a sigma-finite\nreference measure for X satisfying a certain subregularity condition. This\ncondition is very general and prevents the reference measure from being highly\nconcentrated on balls of small radii. To illustrate the wide applicability of\nour result, we evaluate the lower bound for a random variable distributed\nuniformly on a manifold, namely, the unit circle, and a random variable\ndistributed uniformly on a self-similar set, namely, the middle third Cantor\nset. \n\n"}
{"id": "1804.09212", "contents": "Title: On the construction of sparse matrices from expander graphs Abstract: We revisit the asymptotic analysis of probabilistic construction of adjacency\nmatrices of expander graphs proposed in [4]. With better bounds we derived a\nnew reduced sample complexity for the number of nonzeros per column of these\nmatrices, precisely $d = \\mathcal{O}\\left(\\log_s(N/s) \\right)$; as opposed to\nthe standard $d = \\mathcal{O}\\left(\\log(N/s) \\right)$. This gives insights into\nwhy using small $d$ performed well in numerical experiments involving such\nmatrices. Furthermore, we derive quantitative sampling theorems for our\nconstructions which show our construction outperforming the existing\nstate-of-the-art. We also used our results to compare performance of sparse\nrecovery algorithms where these matrices are used for linear sketching. \n\n"}
{"id": "1804.10181", "contents": "Title: Beam Training and Data Transmission Optimization in Millimeter-Wave\n  Vehicular Networks Abstract: Future vehicular communication networks call for new solutions to support\ntheir capacity demands, by leveraging the potential of the millimeter-wave\n(mm-wave) spectrum. Mobility, in particular, poses severe challenges in their\ndesign, and as such shall be accounted for. A key question in mm-wave vehicular\nnetworks is how to optimize the trade-off between directive Data Transmission\n(DT) and directional Beam Training (BT), which enables it. In this paper,\nlearning tools are investigated to optimize this trade-off. In the proposed\nscenario, a Base Station (BS) uses BT to establish a mm-wave directive link\ntowards a Mobile User (MU) moving along a road. To control the BT/DT trade-off,\na Partially Observable (PO) Markov Decision Process (MDP) is formulated, where\nthe system state corresponds to the position of the MU within the road link.\nThe goal is to maximize the number of bits delivered by the BS to the MU over\nthe communication session, under a power constraint. The resulting optimal\npolicies reveal that adaptive BT/DT procedures significantly outperform\ncommon-sense heuristic schemes, and that specific mobility features, such as\nuser position estimates, can be effectively used to enhance the overall system\nperformance and optimize the available system resources. \n\n"}
{"id": "1804.10335", "contents": "Title: Communication, Computing and Caching for Mobile VR Delivery: Modeling\n  and Trade-off Abstract: Mobile virtual reality (VR) delivery is gaining increasing attention from\nboth industry and academia due to its ability to provide an immersive\nexperience. However, achieving mobile VR delivery requires ultra-high\ntransmission rate, deemed as a first killer application for 5G wireless\nnetworks. In this paper, in order to alleviate the traffic burden over wireless\nnetworks, we develop an implementation framework for mobile VR delivery by\nutilizing caching and computing capabilities of mobile VR device. We then\njointly optimize the caching and computation offloading policy for minimizing\nthe required average transmission rate under the latency and local average\nenergy consumption constraints. In a symmetric scenario, we obtain the optimal\njoint policy and the closed-form expression of the minimum average transmission\nrate. Accordingly, we analyze the tradeoff among communication, computing and\ncaching, and then reveal analytically the fact that the communication overhead\ncan be traded by the computing and caching capabilities of mobile VR device,\nand also what conditions must be met for it to happen. Finally, we discuss the\noptimization problem in a heterogeneous scenario, and propose an efficient\nsuboptimal algorithm with low computation complexity, which is shown to achieve\ngood performance in the numerical results. \n\n"}
{"id": "1805.03367", "contents": "Title: Dispersion Bound for the Wyner-Ahlswede-K\\\"orner Network via Reverse\n  Hypercontractivity on Types Abstract: This paper introduces a new converse machinery for a challenging class of\ndistributed source-type problems (e.g.\\ distributed source coding, common\nrandomness generation, or hypothesis testing with communication constraints),\nthrough the example of the Wyner-Ahlswede-K\\\"orner network. Using the\nfunctional-entropic duality and the reverse hypercontractivity of the\ntransposition semigroup, we lower bound the error probability for each joint\ntype. Then by averaging the error probability over types, we lower bound the\n$c$-dispersion (which characterizes the second-order behavior of the weighted\nsum of the rates of the two compressors when a nonvanishing error probability\nis small) as the variance of the gradient of $\\inf_{P_{U|X}}\\{cH(Y|U)+I(U;X)\\}$\nwith respect to $Q_{XY}$, the per-letter side information and source\ndistribution. In comparison, using standard achievability arguments based on\nthe method of types, we upper-bound the $c$-dispersion as the variance of\n$c\\imath_{Y|U}(Y|U)+\\imath_{U;X}(U;X)$, which improves the existing upper\nbounds but has a gap to the aforementioned lower bound. \n\n"}
{"id": "1805.03785", "contents": "Title: Deep Learning of Geometric Constellation Shaping including Fiber\n  Nonlinearities Abstract: A new geometric shaping method is proposed, leveraging unsupervised machine\nlearning to optimize the constellation design. The learned constellation\nmitigates nonlinear effects with gains up to 0.13 bit/4D when trained with a\nsimplified fiber channel model. \n\n"}
{"id": "1805.07132", "contents": "Title: Cooperative Multi-Bitrate Video Caching and Transcoding in Multicarrier\n  NOMA-Assisted Heterogeneous Virtualized MEC Networks Abstract: Cooperative video caching and transcoding in mobile edge computing (MEC)\nnetworks is a new paradigm for future wireless networks, e.g., 5G and 5G\nbeyond, to reduce scarce and expensive backhaul resource usage by prefetching\nvideo files within radio access networks (RANs). Integration of this technique\nwith other advent technologies, such as wireless network virtualization and\nmulticarrier non-orthogonal multiple access (MC-NOMA), provides more flexible\nvideo delivery opportunities, which leads to enhancements both for the\nnetwork's revenue and for the end-users' service experience. In this regard, we\npropose a two-phase RAF for a parallel cooperative joint multi-bitrate video\ncaching and transcoding in heterogeneous virtualized MEC networks. In the cache\nplacement phase, we propose novel proactive delivery-aware cache placement\nstrategies (DACPSs) by jointly allocating physical and radio resources based on\nnetwork stochastic information to exploit flexible delivery opportunities.\nThen, for the delivery phase, we propose a delivery policy based on the user\nrequests and network channel conditions. The optimization problems\ncorresponding to both phases aim to maximize the total revenue of network\nslices, i.e., virtual networks. Both problems are non-convex and suffer from\nhigh-computational complexities. For each phase, we show how the problem can be\nsolved efficiently. We also propose a low-complexity RAF in which the\ncomplexity of the delivery algorithm is significantly reduced. A Delivery-aware\ncache refreshment strategy (DACRS) in the delivery phase is also proposed to\ntackle the dynamically changes of network stochastic information. Extensive\nnumerical assessments demonstrate a performance improvement of up to 30% for\nour proposed DACPSs and DACRS over traditional approaches. \n\n"}
{"id": "1805.08026", "contents": "Title: A Correlation Measure Based on Vector-Valued $L_p$-Norms Abstract: In this paper, we introduce a new measure of correlation for bipartite\nquantum states. This measure depends on a parameter $\\alpha$, and is defined in\nterms of vector-valued $L_p$-norms. The measure is within a constant of the\nexponential of $\\alpha$-R\\'enyi mutual information, and reduces to the trace\nnorm (total variation distance) for $\\alpha=1$. We will prove some decoupling\ntype theorems in terms of this measure of correlation, and present some\napplications in privacy amplification as well as in bounding the random coding\nexponents. In particular, we establish a bound on the secrecy exponent of the\nwiretap channel (under the total variation metric) in terms of the\n$\\alpha$-R\\'enyi mutual information according to \\emph{Csisz\\'ar's proposal}. \n\n"}
{"id": "1805.08321", "contents": "Title: Bandit-Based Monte Carlo Optimization for Nearest Neighbors Abstract: The celebrated Monte Carlo method estimates an expensive-to-compute quantity\nby random sampling. Bandit-based Monte Carlo optimization is a general\ntechnique for computing the minimum of many such expensive-to-compute\nquantities by adaptive random sampling. The technique converts an optimization\nproblem into a statistical estimation problem which is then solved via\nmulti-armed bandits. We apply this technique to solve the problem of\nhigh-dimensional $k$-nearest neighbors, developing an algorithm which we prove\nis able to identify exact nearest neighbors with high probability. We show that\nunder regularity assumptions on a dataset of $n$ points in $d$-dimensional\nspace, the complexity of our algorithm scales logarithmically with the\ndimension of the data as $O\\left((n+d)\\log^2\n\\left(\\frac{nd}{\\delta}\\right)\\right)$ for error probability $\\delta$, rather\nthan linearly as in exact computation requiring $O(nd)$. We corroborate our\ntheoretical results with numerical simulations, showing that our algorithm\noutperforms both exact computation and state-of-the-art algorithms such as\nkGraph, NGT, and LSH on real datasets. \n\n"}
{"id": "1805.09378", "contents": "Title: Convolutional Polar Codes on Channels with Memory using Tensor Networks Abstract: Arikan's recursive code construction is designed to polarize a collection of\nmemoryless channels into a set of good and a set of bad channels, and it can be\nefficiently decoded using successive cancellation. It was recently shown that\nthe same construction also polarizes channels with memory, and a generalization\nof successive cancellation decoder was proposed with a complexity that scales\nlike the third power of the channel's memory size. In another line of work, the\npolar code construction was extended by replacing the block polarization kernel\nby a convoluted kernel. Here, we present an efficient decoding algorithm for\nfinite-state memory channels that can be applied to polar codes and\nconvolutional polar codes. This generalization is most effectively described\nusing the tensor network formalism, and the manuscript presents a\nself-contained description of the required basic concepts. We use numerical\nsimulations to study the performance of these algorithms for practically\nrelevant code sizes and find that the convolutional structure outperforms the\nstandard polar codes on a variety of channels with memory. \n\n"}
{"id": "1805.09409", "contents": "Title: Non-Gaussian Hyperplane Tessellations and Robust One-Bit Compressed\n  Sensing Abstract: We show that a tessellation generated by a small number of random affine\nhyperplanes can be used to approximate Euclidean distances between any two\npoints in an arbitrary bounded set $T$, where the random hyperplanes are\ngenerated by subgaussian or heavy-tailed normal vectors and uniformly\ndistributed shifts. We derive quantitative bounds on the number of hyperplanes\nneeded for constructing such tessellations in terms of natural metric\ncomplexity measures of $T$ and the desired approximation error. Our work\nextends significantly prior results in this direction, which were restricted to\nGaussian hyperplane tessellations of subsets of the Euclidean unit sphere.\n  As an application, we obtain new reconstruction results in memoryless one-bit\ncompressed sensing with non-Gaussian measurement matrices. We show that by\nquantizing at uniformly distributed thresholds, it is possible to accurately\nreconstruct low-complexity signals from a small number of one-bit quantized\nmeasurements, even if the measurement vectors are drawn from a heavy-tailed\ndistribution. Our reconstruction results are uniform in nature and robust in\nthe presence of pre-quantization noise on the analog measurements as well as\nadversarial bit corruptions in the quantization process. Moreover we show that\nif the measurement matrix is subgaussian then accurate recovery can be achieved\nvia a convex program. \n\n"}
{"id": "1805.10663", "contents": "Title: High fidelity GHZ generation within nearby nodes Abstract: Generating entanglement in a distributed scenario is a fundamental task for\nimplementing the quantum network of the future. We here report a protocol that\nuses only linear optics for generating GHZ states with high fidelities in a\nnearby node configuration. Moreover, we analytically show that the scheme\nprovides the highest success probability, and, then, the highest generation\nrate for sequential protocols. We furthermore show how to retrieve the same\nresults using a numerical approach. Both the analytical proof and the numerical\noptimization represent a novelty in the field of entanglement generation in\nquantum networks and are tools for further investigation. Finally, we give some\nestimates for the generation rate in a real scenario. \n\n"}
{"id": "1805.10926", "contents": "Title: Two types of permutation polynomials with special forms Abstract: Let $q$ be a power of a prime and $\\mathbb{F}_q$ be a finite field with $q$\nelements. In this paper, we propose four families of infinite classes of\npermutation trinomials having the form $cx-x^s + x^{qs}$ over\n$\\mathbb{F}_{q^2}$, and investigate the relationship between this type of\npermutation polynomials with that of the form $(x^q-x+\\delta)^s+cx$. Based on\nthis relation, many classes of permutation trinomials having the form\n$(x^q-x+\\delta)^s+cx$ without restriction on $\\delta$ over $\\mathbb{F}_{q^2}$\nare derived from known permutation trinomials having the form $cx-x^s +\nx^{qs}$. \n\n"}
{"id": "1806.00661", "contents": "Title: Capacity of Single-Server Single-Message Private Information Retrieval\n  with Coded Side Information Abstract: This paper considers the problem of single-server single-message private\ninformation retrieval with coded side information (PIR-CSI). In this problem,\nthere is a server storing a database, and a user which knows a linear\ncombination of a subset of messages in the database as a side information. The\nnumber of messages contributing to the side information is known to the server,\nbut the indices and the coefficients of these messages are unknown to the\nserver. The user wishes to download a message from the server privately, i.e.,\nwithout revealing which message it is requesting, while minimizing the download\ncost. In this work, we consider two different settings for the PIR-CSI problem\ndepending on the demanded message being or not being one of the messages\ncontributing to the side information. For each setting, we prove an upper bound\non the maximum download rate as a function of the size of the database and the\nsize of the side information, and propose a protocol that achieves the rate\nupper-bound. \n\n"}
{"id": "1806.03343", "contents": "Title: Resource Allocation for Low-Latency Vehicular Communications with Packet\n  Retransmission Abstract: Vehicular communications have stringent latency requirements on\nsafety-critical information transmission. However, lack of instantaneous\nchannel state information due to high mobility poses a great challenge to meet\nthese requirements and the situation gets more complicated when packet\nretransmission is considered. Based on only the obtainable large-scale fading\nchannel information, this paper performs spectrum and power allocation to\nmaximize the ergodic capacity of vehicular-to-infrastructure (V2I) links while\nguaranteeing the latency requirements of vehicular-to-vehicular (V2V) links.\nFirst, for each possible spectrum reusing pair of a V2I link and a V2V link, we\nobtain the closed-form expression of the packets' average sojourn time (the\nqueueing time plus the service time) for the V2V link. Then, an optimal power\nallocation is derived for each possible spectrum reusing pair. Afterwards, we\noptimize the spectrum reusing pattern by addressing a polynomial time solvable\nbipartite matching problem. Numerical results show that the proposed queueing\nanalysis is accurate in terms of the average packet sojourn time. Moreover, the\ndeveloped resource allocation always guarantees the V2V links' requirements on\nlatency. \n\n"}
{"id": "1806.04474", "contents": "Title: Erasure Codes for Distributed Storage: Tight Bounds and Matching\n  Constructions Abstract: This thesis makes several significant contributions to the theory of both\nRegenerating (RG) and Locally Recoverable (LR) codes. The two principal\ncontributions are characterizing the optimal rate of an LR code designed to\nrecover from $t$ erased symbols sequentially, for any $t$ and the development\nof a tight bound on the sub-packetization level (length of a vector code\nsymbol) of a sub-class of RG codes called optimal-access RG codes. There are\nhowever, several other notable contributions as well such as deriving the\ntightest-known bounds on the performance metrics such as minimum distance and\nrate of a sub-class of LR codes known as availability codes. The thesis also\npresents some low field size constructions of Maximal Recoverable codes. \n\n"}
{"id": "1806.05533", "contents": "Title: Distributed Hypothesis Testing based on Unequal-Error Protection Codes Abstract: Coding and testing schemes for binary hypothesis testing over noisy networks\nare proposed and their corresponding type-II error exponents are derived. When\ncommunication is over a discrete memoryless channel (DMC), our scheme combines\nShimokawa-Han-Amari's hypothesis testing scheme with Borade's unequal error\nprotection (UEP) for channel coding. A separate source channel coding\narchitecture is employed. The resulting exponent is optimal for the newly\nintroduced class of \\emph{generalized testing against conditional\nindependence}. When communication is over a MAC or a BC, our scheme combines\nhybrid coding with UEP. The resulting error exponent over the MAC is optimal in\nthe case of generalized testing against conditional independence with\nindependent observations at the two sensors, when the MAC decomposes into two\nindividual DMCs. In this case, separate source-channel coding is sufficient;\nthis same conclusion holds also under arbitrarily correlated sensor\nobservations when testing is against independence. For the BC, the error\nexponents region of hybrid coding with UEP exhibits a tradeoff between the\nexponents attained at the two decision centers. When both receivers aim at\nmaximizing the error exponents under different hypotheses and the marginal\ndistributions of the sensors' observations are different under these\nhypotheses, then this tradeoff can be mitigated with the following strategy.\nThe sensor makes a tentative guess on the hypothesis, submits this guess, and\napplies our coding and testing scheme for the DMC only for the decision center\nthat is not interested in maximizing the exponent under the guessed hypothesis. \n\n"}
{"id": "1806.07565", "contents": "Title: Storage, Computation, and Communication: A Fundamental Tradeoff in\n  Distributed Computing Abstract: We consider a MapReduce-like distributed computing system. We derive a lower\nbound on the communication cost for any given storage and computation costs.\nThis lower bound matches the achievable bound we proposed recently. As a\nresult, we completely characterize the optimal tradeoff between the storage,\nthe computation, and the communication. Our result generalizes the previous one\nby Li et al. to also account for the number of computed intermediate values. \n\n"}
{"id": "1806.07800", "contents": "Title: Full Coded Caching Gains for Cache-less Users Abstract: Within the context of coded caching, the work reveals the interesting\nconnection between having multiple transmitters and having heterogeneity in the\ncache sizes of the receivers. Our work effectively shows that having multiple\ntransmit antennas -- while providing full multiplexing gains -- can also\nsimultaneously completely remove the performance penalties that are typically\nassociated to cache-size unevenness. Focusing on the multiple-input\nsingle-output Broadcast Channel, the work first identifies the performance\nlimits of the extreme case where cache-aided users coincide with users that do\nnot have caches, and then expands the analysis to the case where both user\ngroups are cache-aided but with heterogeneous cache-sizes. In the first case,\nthe main contribution is a new algorithm that employs perfect matchings on a\nbipartite graph to offer full multiplexing as well as full coded-caching gains\nto both cache-aided as well as cache-less users. An interesting conclusion is\nthat, starting from a single-stream centralized coded caching setting with\nnormalized cache size $\\gamma$, then adding $L$ antennas allows for the\naddition of {up to} approximately $L/\\gamma$ extra cache-less users, at no\nadded delay costs. Similarly surprising is the finding that, {beginning} with a\nsingle-antenna hybrid system (with both cache-less and cache-aided users), then\nadding {$L-1$} antennas to the transmitter, as well as endowing the cache-less\nusers with a cumulative normalized cache size $\\Gamma_2$, increases the Degrees\nof Freedom by a \\emph{multiplicative} factor of up to $\\Gamma_{2}+L$. \n\n"}
{"id": "1806.08968", "contents": "Title: A Modulo-Based Architecture for Analog-to-Digital Conversion Abstract: Systems that capture and process analog signals must first acquire them\nthrough an analog-to-digital converter. While subsequent digital processing can\nremove statistical correlations present in the acquired data, the dynamic range\nof the converter is typically scaled to match that of the input analog signal.\nThe present paper develops an approach for analog-to-digital conversion that\naims at minimizing the number of bits per sample at the output of the\nconverter. This is attained by reducing the dynamic range of the analog signal\nby performing a modulo operation on its amplitude, and then quantizing the\nresult. While the converter itself is universal and agnostic of the statistics\nof the signal, the decoder operation on the output of the quantizer can exploit\nthe statistical structure in order to unwrap the modulo folding. The\nperformance of this method is shown to approach information theoretical limits,\nas captured by the rate-distortion function, in various settings. An\narchitecture for modulo analog-to-digital conversion via ring oscillators is\nsuggested, and its merits are numerically demonstrated. \n\n"}
{"id": "1806.10903", "contents": "Title: On Low-Complexity Decoding of Product Codes for High-Throughput\n  Fiber-Optic Systems Abstract: We study low-complexity iterative decoding algorithms for product codes. We\nrevisit two algorithms recently proposed by the authors based on bounded\ndistance decoding (BDD) of the component codes that improve the performance of\nconventional iterative BDD (iBDD). We then propose a novel decoding algorithm\nthat is based on generalized minimum distance decoding of the component codes.\nThe proposed algorithm closes over 50% of the performance gap between iBDD and\nturbo product decoding (TPD) based on the Chase-Pyndiah algorithm. Moreover,\nthe algorithm only leads to a limited increase in complexity with respect to\niBDD and has significantly lower complexity than TPD. The studied algorithms\nare particularly interesting for high-throughput fiber-optic communications. \n\n"}
{"id": "1806.11195", "contents": "Title: On the Decoding of Polar Codes on Permuted Factor Graphs Abstract: Polar codes are a channel coding scheme for the next generation of wireless\ncommunications standard (5G). The belief propagation (BP) decoder allows for\nparallel decoding of polar codes, making it suitable for high throughput\napplications. However, the error-correction performance of polar codes under BP\ndecoding is far from the requirements of 5G. It has been shown that the\nerror-correction performance of BP can be improved if the decoding is performed\non multiple permuted factor graphs of polar codes. However, a different BP\ndecoding scheduling is required for each factor graph permutation which results\nin the design of a different decoder for each permutation. Moreover, the\nselection of the different factor graph permutations is at random, which\nprevents the decoder to achieve a desirable error-correction performance with a\nsmall number of permutations. In this paper, we first show that the\npermutations on the factor graph can be mapped into suitable permutations on\nthe codeword positions. As a result, we can make use of a single decoder for\nall the permutations. In addition, we introduce a method to construct a set of\npredetermined permutations which can provide the correct codeword if the\ndecoding fails on the original permutation. We show that for the 5G polar code\nof length $1024$, the error-correction performance of the proposed decoder is\nmore than $0.25$ dB better than that of the BP decoder with the same number of\nrandom permutations at the frame error rate of $10^{-4}$. \n\n"}
{"id": "1807.00682", "contents": "Title: Dynamic Power Allocation and User Scheduling for Power-Efficient and\n  Low-Latency Communications Abstract: In this paper, we propose a joint dynamic power control and user pairing\nalgorithm for power-efficient and low-latency hybrid multiple access systems.\nIn a hybrid multiple access system, user pairing determines whether the\ntransmitter should serve a certain user by orthogonal multiple access (OMA) or\nnon-orthogonal multiple access (NOMA). The proposed optimization framework\nminimizes the long-term time-average transmit power expenditure while reducing\nthe queueing delay and satisfying time-average data rate requirements. The\nproposed technique observes channel and queue state information and adjusts\nqueue backlogs to avoid an excessive queueing delay by appropriate user pairing\nand power allocation. Further, user scheduling for determining the activation\nof a given user link as well as flexible use of resources are captured in the\nproposed algorithm. Data-intensive simulation results show that the proposed\nscheme guarantees an end-to-end delay smaller than 1 ms with high\npower-efficiency and high reliability, based on the short frame structure\ndesigned for ultra-reliable low-latency communications (URLLC). \n\n"}
{"id": "1807.00738", "contents": "Title: Treating Interference as Noise in Cellular Networks: A Stochastic\n  Geometry Approach Abstract: The interference management technique that treats interference as noise (TIN)\nis optimal when the interference is sufficiently low. Scheduling algorithms\nbased on the TIN optimality condition have recently been proposed, e.g., for\napplication to device-to-device communications. TIN, however, has never been\napplied to cellular networks. In this work, we propose a scheduling algorithm\nfor application to cellular networks that is based on the TIN optimality\ncondition. In the proposed scheduling algorithm, each base station (BS) first\nrandomly selects a user equipment (UE) in its coverage region, and then checks\nthe TIN optimality conditions. If the latter conditions are not fulfilled, the\nBS is turned off. In order to assess the performance of TIN applied to cellular\nnetworks, we introduce an analytical framework with the aid of stochastic\ngeometry theory. We develop, in particular, tractable expressions of the\nsignal-to-interference-and-noise ratio (SINR) coverage probability and average\nrate of cellular networks. In addition, we carry out asymptotic analysis to\nfind the optimal system parameters that maximize the SINR coverage probability.\nBy using the optimized system parameters, it is shown that TIN applied to\ncellular networks yields significant gains in terms of SINR coverage\nprobability and average rate. Specifically, the numerical results show that\naverage rate gains of the order of $21\\%$ over conventional scheduling\nalgorithms are obtained. \n\n"}
{"id": "1807.01166", "contents": "Title: $\\epsilon$-MSR Codes: Contacting Fewer Code Blocks for Exact Repair Abstract: $\\epsilon$-Minimum Storage Regenerating ($\\epsilon$-MSR) codes form a special\nclass of Maximum Distance Separable (MDS) codes, providing mechanisms for exact\nregeneration of a single code block in their codewords by downloading slighly\nsub-optimal amount of information from the remaining code blocks. The key\nadvantage of these codes is a significantly lower sub-packetization that grows\nonly logarithmically with the length of the code, while providing optimality in\nstorage and error-correcting capacity. However, from an implementation point of\nview, these codes require each remaining code block to be available for the\nrepair of any single code block. In this paper, we address this issue by\nconstructing $\\epsilon$-MSR codes that can repair a failed code block by\ncontacting a fewer number of available code blocks. When a code block fails,\nour repair procedure needs to contact a few compulsory code blocks and is free\nto choose any subset of available code blocks for the remaining choices.\nFurther, our construction requiresa field size linear in code length and\nensures load balancing among the contacted code blocks in terms of information\ndownloaded from them for a single repair. \n\n"}
{"id": "1807.01170", "contents": "Title: Private Coded Computation for Machine Learning Abstract: In a distributed computing system for the master-worker framework, an erasure\ncode can mitigate the effects of slow workers, also called stragglers. The\ndistributed computing system combined with coding is referred to as coded\ncomputation. We introduce a variation of coded computation that protects the\nmaster's privacy from the workers, which is referred to as private coded\ncomputation. In private coded computation, the master needs to compute a\nfunction of its own dataset and one of the datasets in a library exclusively\nshared by the external workers. After the master recovers the result of the\ndesired function through coded computation, the workers should not know which\ndataset in the library was desired by the master, which implies that the\nmaster's privacy is protected. We propose a private coded computation scheme\nfor matrix multiplication, namely private polynomial codes, based on polynomial\ncodes for conventional coded computation. As special cases of private\npolynomial codes, we propose private one-shot polynomial codes and private\nasynchronous polynomial codes. Whereas the private one-shot polynomial code\nachieves a lower communication load from the master to each worker, the private\nasynchronous polynomial code achieves faster computation than private one-shot\npolynomial codes. In terms of computation time and communication load, we\ncompare private one-shot polynomial codes and private asynchronous polynomial\ncodes with a conventional robust private information retrieval scheme which can\nbe directly applied to coded computation. \n\n"}
{"id": "1807.01251", "contents": "Title: Training behavior of deep neural network in frequency domain Abstract: Why deep neural networks (DNNs) capable of overfitting often generalize well\nin practice is a mystery [#zhang2016understanding]. To find a potential\nmechanism, we focus on the study of implicit biases underlying the training\nprocess of DNNs. In this work, for both real and synthetic datasets, we\nempirically find that a DNN with common settings first quickly captures the\ndominant low-frequency components, and then relatively slowly captures the\nhigh-frequency ones. We call this phenomenon Frequency Principle (F-Principle).\nThe F-Principle can be observed over DNNs of various structures, activation\nfunctions, and training algorithms in our experiments. We also illustrate how\nthe F-Principle help understand the effect of early-stopping as well as the\ngeneralization of DNNs. This F-Principle potentially provides insights into a\ngeneral principle underlying DNN optimization and generalization. \n\n"}
{"id": "1807.02494", "contents": "Title: Joint Channel-Estimation/Decoding with Frequency-Selective Channels and\n  Few-Bit ADCs Abstract: We propose a fast and near-optimal approach to joint channel-estimation,\nequalization, and decoding of coded single-carrier (SC) transmissions over\nfrequency-selective channels with few-bit analog-to-digital converters (ADCs).\nOur approach leverages parametric bilinear generalized approximate message\npassing (PBiGAMP) to reduce the implementation complexity of joint channel\nestimation and (soft) symbol decoding to that of a few fast Fourier transforms\n(FFTs). Furthermore, it learns and exploits sparsity in the channel impulse\nresponse. Our work is motivated by millimeter-wave systems with bandwidths on\nthe order of Gsamples/sec, where few-bit ADCs, SC transmissions, and fast\nprocessing all lead to significant reductions in power consumption and\nimplementation cost. We numerically demonstrate our approach using signals and\nchannels generated according to the IEEE 802.11ad wireless local area network\n(LAN) standard, in the case that the receiver uses analog beamforming and a\nsingle ADC. \n\n"}
{"id": "1807.03109", "contents": "Title: Sparse tensor recovery via N-mode FISTA with support augmentation Abstract: A common approach for performing sparse tensor recovery is to use an N-mode\nFISTA method. However, this approach may fail in some cases by missing some\nvalues in the true support of the tensor and compensating by erroneously\nassigning nearby values to the support. This work proposes a four-stage method\nfor performing sparse tensor reconstruction that addresses a case where N-mode\nFISTA may fail by augmenting the support set. Moreover, the proposed method\npreserves a Tucker-like structure throughout computations for computational\nefficiency. Numerical results on synthetic data demonstrate that the proposed\nmethod produces results with similar or higher accuracy than N-mode FISTA, and\nis often faster. \n\n"}
{"id": "1807.05630", "contents": "Title: Partially smoothed information measures Abstract: Smooth entropies are a tool for quantifying resource trade-offs in (quantum)\ninformation theory and cryptography. In typical bi- and multi-partite problems,\nhowever, some of the sub-systems are often left unchanged and this is not\nreflected by the standard smoothing of information measures over a ball of\nclose states. We propose to smooth instead only over a ball of close states\nwhich also have some of the reduced states on the relevant sub-systems fixed.\nThis partial smoothing of information measures naturally allows to give more\nrefined characterizations of various information-theoretic problems in the\none-shot setting. In particular, we immediately get asymptotic second-order\ncharacterizations for tasks such as privacy amplification against classical\nside information or classical state splitting. For quantum problems like state\nmerging the general resource trade-off is tightly characterized by partially\nsmoothed information measures as well. \n\n"}
{"id": "1807.06143", "contents": "Title: Quickest Detection of Dynamic Events in Networks Abstract: The problem of quickest detection of dynamic events in networks is studied.\nAt some unknown time, an event occurs, and a number of nodes in the network are\naffected by the event, in that they undergo a change in the statistics of their\nobservations. It is assumed that the event is dynamic, in that it can propagate\nalong the edges in the network, and affect more and more nodes with time. The\nevent propagation dynamics is assumed to be unknown. The goal is to design a\nsequential algorithm that can detect a \"significant\" event, i.e., when the\nevent has affected no fewer than $\\eta$ nodes, as quickly as possible, while\ncontrolling the false alarm rate. Fully connected networks are studied first,\nand the results are then extended to arbitrarily connected networks. The\ndesigned algorithms are shown to be adaptive to the unknown propagation\ndynamics, and their first-order asymptotic optimality is demonstrated as the\nfalse alarm rate goes to zero. The algorithms can be implemented with linear\ncomputational complexity in the network size at each time step, which is\ncritical for online implementation. Numerical simulations are provided to\nvalidate the theoretical results. \n\n"}
{"id": "1807.11250", "contents": "Title: Fast Analog Transmission for High-Mobility Wireless Data Acquisition in\n  Edge Learning Abstract: By implementing machine learning at the network edge, edge learning trains\nmodels by leveraging rich data distributed at edge devices (e.g., smartphones\nand sensors) and in return endow on them capabilities of seeing, listening, and\nreasoning. In edge learning, the need of high-mobility wireless data\nacquisition arises in scenarios where edge devices (or even servers) are\nmounted on the ground or aerial vehicles. In this paper, we present a novel\nsolution, called fast analog transmission (FAT), for high- mobility data\nacquisition in edge-learning systems, which has several key features. First,\nFAT incurs low-latency. Specifically, FAT requires no source-and-channel coding\nand no channel training via the proposed technique of Grassmann analog encoding\n(GAE) that encodes data samples into subspace matrices. Second, FAT supports\nspatial multiplexing by directly transmitting analog vector data over an\nantenna array. Third, FAT can be seamlessly integrated with edge learning\n(i.e., training of a classifier model in this work). In particular, by applying\na Grassmannian-classification algorithm from computer vision, the received GAE\nencoded data can be directly applied to training the model without decoding and\nconversion. This design is found by simulation to outperform conventional\nschemes in learning accuracy due to its robustness against data distortion\ninduced by fast fading. \n\n"}
{"id": "1808.00519", "contents": "Title: Orthogonal Time Frequency Space Modulation Abstract: This paper introduces a new two-dimensional modulation technique called\nOrthogonal Time Frequency Space (OTFS) modulation. OTFS has the novel and\nimportant feature of being designed in the delay-Doppler domain. When coupled\nwith a suitable equalizer, OTFS modulation is able to exploit the full channel\ndiversity over both time and frequency. Moreover, it converts the fading,\ntime-varying wireless channel experienced by modulated signals such as OFDM\ninto a time-independent channel with a complex channel gain that is essentially\nconstant for all symbols.\n  This design obviates the need for transmitter adaptation, and greatly\nsimplifies system operation. The paper describes the basic operating principles\nof OTFS as well as a possible implementation as an overlay to current or\nanticipated standardized systems. OTFS is shown to provide significant\nperformance improvement in systems with high Doppler, short packets, and/or\nlarge antenna array. In particular, simulation results indicate at least\nseveral dB of block error rate performance improvement for OTFS over OFDM in\nall of these settings. \n\n"}
{"id": "1808.01498", "contents": "Title: Amortized Channel Divergence for Asymptotic Quantum Channel\n  Discrimination Abstract: It is well known that for the discrimination of classical and quantum\nchannels in the finite, non-asymptotic regime, adaptive strategies can give an\nadvantage over non-adaptive strategies. However, Hayashi [IEEE Trans. Inf.\nTheory 55(8), 3807 (2009)] showed that in the asymptotic regime, the\nexponential error rate for the discrimination of classical channels is not\nimproved in the adaptive setting. We extend this result in several ways. First,\nwe establish the strong Stein's lemma for classical-quantum channels by showing\nthat asymptotically the exponential error rate for classical-quantum channel\ndiscrimination is not improved by adaptive strategies. Second, we recover many\nother classes of channels for which adaptive strategies do not lead to an\nasymptotic advantage. Third, we give various converse bounds on the power of\nadaptive protocols for general asymptotic quantum channel discrimination.\nIntriguingly, it remains open whether adaptive protocols can improve the\nexponential error rate for quantum channel discrimination in the asymmetric\nStein setting. Our proofs are based on the concept of amortized\ndistinguishability of quantum channels, which we analyse using data-processing\ninequalities. \n\n"}
{"id": "1808.01720", "contents": "Title: Energy-Age Tradeoff in Status Update Communication Systems with\n  Retransmission Abstract: Age-of-information is a novel performance metric in communication systems to\nindicate the freshness of the latest received data, which has wide applications\nin monitoring and control scenarios. Another important performance metric in\nthese applications is energy consumption, since monitors or sensors are usually\nenergy constrained. In this paper, we study the energy-age tradeoff in a status\nupdate system where data transmission from a source to a receiver may encounter\nfailure due to channel error. As the status sensing process consumes energy,\nwhen a transmission failure happens, the source may either retransmit the\nexisting data to save energy for sensing, or sense and transmit a new update to\nminimize age-of-information. A threshold-based retransmission policy is\nconsidered where each update is allowed to be transmitted no more than M times.\nClosed-form average age-of-information and energy consumption is derived and\nexpressed as a function of channel failure probability and maximum number of\nretransmissions M. Numerical simulations validate our analytical results, and\nillustrate the tradeoff between average age-of-information and energy\nconsumption. \n\n"}
{"id": "1808.01810", "contents": "Title: On Linearly Precoded Rate Splitting for Gaussian MIMO Broadcast Channels Abstract: In this paper, we consider a general K-user Gaussian multiple-input\nmultiple-output (MIMO) broadcast channel (BC). We assume that the channel state\nis deterministic and known to all the nodes. While the private-message capacity\nregion is well known to be achievable with dirty paper coding (DPC), we are\ninterested in the simpler linearly precoded transmission schemes. In\nparticular, we focus on linear precoding schemes combined with rate-splitting\n(RS). First, we derive an achievable rate region with minimum mean square error\n(MMSE) precoding at the transmitter and joint decoding of the sub-messages at\nthe receivers. Then, we study the achievable sum rate of this scheme and obtain\ntwo findings: 1) an analytically tractable upper bound on the sum rate that is\nshown numerically to be a close approximation, and 2) how to reduce the number\nof active streams -- crucial to the overall complexity -- while preserving the\nsum rate to within a constant loss. The latter results in two practical\nalgorithms: a stream elimination algorithm and a stream ordering algorithm.\nFinally, we investigate the constant-gap optimality of linearly precoded RS\nwith respect to the capacity. Our result reveals that, while the achievable\nrate of linear precoding alone can be arbitrarily far from the capacity, the\nintroduction of RS can help achieve the capacity region to within a constant\ngap in the two-user case. Nevertheless, we prove that the RS scheme's\nconstant-gap optimality does not extend to the three-user case. Specifically,\nwe show, through a pathological example, that the gap between the sum rate and\nthe sum capacity can be unbounded. \n\n"}
{"id": "1808.01961", "contents": "Title: Super Resolution Phase Retrieval for Sparse Signals Abstract: In a variety of fields, in particular those involving imaging and optics, we\noften measure signals whose phase is missing or has been irremediably\ndistorted. Phase retrieval attempts to recover the phase information of a\nsignal from the magnitude of its Fourier transform to enable the reconstruction\nof the original signal. Solving the phase retrieval problem is equivalent to\nrecovering a signal from its auto-correlation function. In this paper, we\nassume the original signal to be sparse; this is a natural assumption in many\napplications, such as X-ray crystallography, speckle imaging and blind channel\nestimation. We propose an algorithm that resolves the phase retrieval problem\nin three stages: i) we leverage the finite rate of innovation sampling theory\nto super-resolve the auto-correlation function from a limited number of\nsamples, ii) we design a greedy algorithm that identifies the locations of a\nsparse solution given the super-resolved auto-correlation function, iii) we\nrecover the amplitudes of the atoms given their locations and the measured\nauto-correlation function. Unlike traditional approaches that recover a\ndiscrete approximation of the underlying signal, our algorithm estimates the\nsignal on a continuous domain, which makes it the first of its kind.\n  Along with the algorithm, we derive its performance bound with a theoretical\nanalysis and propose a set of enhancements to improve its computational\ncomplexity and noise resilience. Finally, we demonstrate the benefits of the\nproposed method via a comparison against Charge Flipping, a notable algorithm\nin crystallography. \n\n"}
{"id": "1808.02023", "contents": "Title: Multi-Message Private Information Retrieval using Product-Matrix MSR and\n  MBR Codes Abstract: Multi-message private information retrieval (MPIR) is an interesting\nvariation of PIR which allows a user to download multiple messages from the\ndatabase without revealing the identity of the desired messages. Obviously, the\nuser can repeatly use a single-message PIR scheme, but we wish for a more\nefficient way to reduce the download cost. In [1], Banawan and Ukulus\ninvestigate the multi-message PIR problem with replicated database. In this\npaper, we consider multi-message PIR schemes where the database is stored using\nminimum storage regenerating (MSR) or minimum bandwidth regenerating (MBR)\ncodes which are classes of optimal regenerating codes providing efficient\nrepair when a node in the system fails. The relationships between the costs of\nstorage, retrieval and repair are analysed, and explicit schemes using the MSR\nand MBR codes from [2], which both achieve the optimal curve of the trade-off,\nare given. To the best of our knowledge, our work is the first to explore the\nmulti-message PIR with coded database. \n\n"}
{"id": "1808.02336", "contents": "Title: Lower bounds for trace reconstruction Abstract: In the trace reconstruction problem, an unknown bit string ${\\bf x}\\in\\{0,1\n\\}^n$ is sent through a deletion channel where each bit is deleted\nindependently with some probability $q\\in(0,1)$, yielding a contracted string\n$\\widetilde{\\bf x}$. How many i.i.d.\\ samples of $\\widetilde{\\bf x}$ are needed\nto reconstruct $\\bf x$ with high probability? We prove that there exist ${\\bf\nx},{\\bf y} \\in\\{0,1 \\}^n$ such that at least $c\\, n^{5/4}/\\sqrt{\\log n}$ traces\nare required to distinguish between ${\\bf x}$ and ${\\bf y}$ for some absolute\nconstant $c$, improving the previous lower bound of $c\\,n$. Furthermore, our\nresult improves the previously known lower bound for reconstruction of random\nstrings from $c \\log^2 n$ to $c \\log^{9/4}n/\\sqrt{\\log \\log n} $. \n\n"}
{"id": "1808.03880", "contents": "Title: Parallelization does not Accelerate Convex Optimization: Adaptivity\n  Lower Bounds for Non-smooth Convex Minimization Abstract: In this paper we study the limitations of parallelization in convex\noptimization. A convenient approach to study parallelization is through the\nprism of \\emph{adaptivity} which is an information theoretic measure of the\nparallel runtime of an algorithm [BS18]. Informally, adaptivity is the number\nof sequential rounds an algorithm needs to make when it can execute\npolynomially-many queries in parallel at every round. For combinatorial\noptimization with black-box oracle access, the study of adaptivity has recently\nled to exponential accelerations in parallel runtime and the natural question\nis whether dramatic accelerations are achievable for convex optimization.\n  For the problem of minimizing a non-smooth convex function $f:[0,1]^n\\to\n\\mathbb{R}$ over the unit Euclidean ball, we give a tight lower bound that\nshows that even when $\\texttt{poly}(n)$ queries can be executed in parallel,\nthere is no randomized algorithm with $\\tilde{o}(n^{1/3})$ rounds of adaptivity\nthat has convergence rate that is better than those achievable with a\none-query-per-round algorithm. A similar lower bound was obtained by Nemirovski\n[Nem94], however that result holds for the $\\ell_{\\infty}$-setting instead of\n$\\ell_2$. In addition, we also show a tight lower bound that holds for\nLipschitz and strongly convex functions.\n  At the time of writing this manuscript we were not aware of Nemirovski's\nresult. The construction we use is similar to the one in [Nem94], though our\nanalysis is different. Due to the close relationship between this work and\n[Nem94], we view the research contribution of this manuscript limited and it\nshould serve as an instructful approach to understanding lower bounds for\nparallel optimization. \n\n"}
{"id": "1808.05157", "contents": "Title: Asymptotic majorization of finite probability distributions Abstract: This paper studies majorization of high tensor powers of finitely supported\nprobability distributions. Viewing probability distributions as a resource with\nmajorization as a means of transformation corresponds to the resource theory of\npure bipartite quantum states under LOCC transformations vis-\\`a-vis Nielsen's\nTheorem. In [T. Fritz (2017)] a formula for the asymptotic exchange rate\nbetween any two finitely supported probability distributions was conjectured.\nThe main result of the present paper is Theorem 3.11, which resolves this\nconjecture. \n\n"}
{"id": "1808.05678", "contents": "Title: Optimization of MIMO Device-to-Device Networks via Matrix Fractional\n  Programming: A Minorization-Maximization Approach Abstract: Interference management is a fundamental issue in device-to-device (D2D)\ncommunications whenever the transmitter-and-receiver pairs are located in close\nproximity and frequencies are fully reused, so active links may severely\ninterfere with each other. This paper devises an optimization strategy named\nFPLinQ to coordinate the link scheduling decisions among the interfering links,\nalong with power control and beamforming. The key enabler is a novel\noptimization method called matrix fractional programming (FP) that generalizes\nprevious scalar and vector forms of FP in allowing multiple data streams per\nlink. From a theoretical perspective, this paper provides a deeper\nunderstanding of FP by showing a connection to the minorization-maximization\n(MM) algorithm. From an application perspective, this paper shows that as\ncompared to the existing methods for coordinating scheduling in the D2D\nnetwork, such as FlashLinQ, ITLinQ, and ITLinQ+, the proposed FPLinQ approach\nis more general in allowing multiple antennas at both the transmitters and the\nreceivers, and further in allowing arbitrary and multiple possible associations\nbetween the devices via matching. Numerical results show that FPLinQ\nsignificantly outperforms the previous state-of-the-art in a typical D2D\ncommunication environment. \n\n"}
{"id": "1808.06449", "contents": "Title: On the compression of messages in the multi-party setting Abstract: We consider the following communication task in the multi-party setting,\nwhich involves a joint random variable $XYZMN$ with the property that $M$ is\nindependent of $YZN$ conditioned on $X$ and $N$ is independent of $XZM$\nconditioned on $Y$. Three parties Alice, Bob and Charlie, respectively, observe\nsamples $x,y$ and $z$ from $XYZ$. Alice and Bob communicate messages to Charlie\nwith the goal that Charlie can output a sample from $MN$ having correct\ncorrelation with $XYZ$. This task reflects the simultaneous message passing\nmodel of communication complexity. Furthermore, it is a generalization of some\nwell studied problems in information theory, such as distributed source coding,\nsource coding with a helper and one sender and one receiver message\ncompression. It is also closely related to the lossy distributed source coding\ntask.\n  Our main result is an achievable communication region for this task in the\none-shot setting, through which we obtain a near optimal characterization using\nauxiliary random variables of bounded size. We employ our achievability result\nto provide a near-optimal one-shot communication region for the task of lossy\ndistributed source coding, in terms of auxiliary random variables of bounded\nsize. Finally, we show that interaction is necessary to achieve the optimal\nexpected communication cost for our main task. \n\n"}
{"id": "1808.08926", "contents": "Title: Opportunistic Treating Interference as Noise Abstract: We consider a $K$-user interference network with $M$ states, where each\ntransmitter has $M$ messages and over State $m$, Receiver $k$ wishes to decode\nthe first $\\pi_k(m) \\in \\{1,2,\\cdots,M\\}$ messages from its desired\ntransmitter. This problem of channel with states models opportunistic\ncommunications, where more messages are sent for better channel states. The\nfirst message from each transmitter has the highest priority as it is required\nto be decoded regardless of the state of the receiver; the second message is\nopportunistically decoded if the state allows a receiver to decode 2 messages;\nand the $M$-th message has the lowest priority as it is decoded if and only if\nthe receiver wishes to decode all $M$ messages. For this interference network\nwith states, we show that if any possible combination of the channel states\nsatisfies a condition under which power control and treating interference as\nnoise (TIN) are sufficient to achieve the entire generalized degrees of freedom\n(GDoF) region of this channel state by itself, then a simple layered\nsuperposition encoding scheme with power control and a successive decoding\nscheme with TIN achieves the entire GDoF region of the network with $M$ states\nfor all $KM$ messages. \n\n"}
{"id": "1808.09053", "contents": "Title: Hybrid Processing Design for Multipair Massive MIMO Relaying with\n  Channel Spatial Correlation Abstract: Massive multiple-input multiple-output (MIMO) avails of simple transceiver\ndesign which can tackle many drawbacks of relay systems in terms of complicated\nsignal processing, latency, and noise amplification. However, the cost and\ncircuit complexity of having one radio frequency (RF) chain dedicated to each\nantenna element are prohibitive in practice. In this paper, we address this\ncritical issue in amplify-and-forward (AF) relay systems using a hybrid analog\nand digital (A/D) transceiver structure. More specifically, leveraging the\nchannel long-term properties, we design the analog beamformer which aims to\nminimize the channel estimation error and remain invariant over a long\ntimescale. Then, the beamforming is completed by simple digital signal\nprocessing, i.e., maximum ratio combining/maximum ratio transmission (MRC/MRT)\nor zero-forcing (ZF) in the baseband domain. We present analytical bounds on\nthe achievable spectral efficiency taking into account the spatial correlation\nand imperfect channel state information at the relay station. Our analytical\nresults reveal that the hybrid A/D structure with ZF digital processor exploits\nspatial correlation and offers a higher spectral efficiency compared to the\nhybrid A/D structure with MRC/MRT scheme. Our numerical results showcase that\nthe hybrid A/D beamforming design captures nearly 95% of the spectral\nefficiency of a fully digital AF relaying topology even by removing half of the\nRF chains. It is also shown that the hybrid A/D structure is robust to coarse\nquantization, and even with 2-bit resolution, the system can achieve more than\n93% of the spectral efficiency offered by the same hybrid A/D topology with\ninfinite resolution phase shifters. \n\n"}
{"id": "1809.02274", "contents": "Title: Optimal Relaying Beamforming in Multiple Access Broadcast Channel (MABC)\n  Bidirectional Cognitive Radio Networks in Presence of Interferers Abstract: In this paper, a general cognitive radio system consisting of a set of users\nwith different level of spectrum access including two primary transceivers and\nseveral types of secondary users is considered. It is assumed that two\nsecondary users operate based on an underlay model at the same frequency\nbandwidth and at the same time as the primary users based on a multiple access\nbroadcast channel (MABC) bidirectional beamforming scheme. Other secondary\nusers provide a relaying service to the primary users in exchange for the\nopportunity to send their messages towards their own destinations for a fixed\nportion of the communication cycle. In addition, it is assumed that some\ninterferers are active during the communication cycle and cause interference\nfor the network. Furthermore, it is assumed that only partial channel state\ninformation (CSI) between interferers and other nodes in the network is\navailable.\n  We provide a robust optimization method against imperfection on the\ninterferers' CSI to maximize the joint primary and secondary\n{signal-to-interference-plus-noise-ratio (SINR)} with the assumption of limited\navailable power at the secondary relays. An amplify-and-forward (AF) relaying\nscheme is deployed at the secondary relays and the optimal beamforming is\nobtained using second order convex programming (SOCP) method. The simulation\nresults show the performance of the proposed beamforming method against the\nexistence of interferers, and demonstrate the effectiveness of our robust\nmethod against uncertainty in knowledge of interferers' CSIs. \n\n"}
{"id": "1809.04957", "contents": "Title: Linear Complexity of Geometric Sequences Defined by Cyclotomic Classes\n  and Balanced Binary Sequences Constructed by the Geometric Sequences Abstract: Pseudorandom number generators are required to generate pseudorandom numbers\nwhich have good statistical properties as well as unpredictability in\ncryptography. An m-sequence is a linear feedback shift register sequence with\nmaximal period over a finite field. M-sequences have good statistical\nproperties, however we must nonlinearize m-sequences for cryptographic\npurposes. A geometric sequence is a sequence given by applying a nonlinear\nfeedforward function to an m-sequence. Nogami, Tada and Uehara proposed a\ngeometric sequence whose nonlinear feedforward function is given by the\nLegendre symbol, and showed the period, periodic autocorrelation and linear\ncomplexity of the sequence. Furthermore, Nogami et al. proposed a\ngeneralization of the sequence, and showed the period and periodic\nautocorrelation. In this paper, we first investigate linear complexity of the\ngeometric sequences. In the case that the Chan--Games formula which describes\nlinear complexity of geometric sequences does not hold, we show the new formula\nby considering the sequence of complement numbers, Hasse derivative and\ncyclotomic classes. Under some conditions, we can ensure that the geometric\nsequences have a large linear complexity from the results on linear complexity\nof Sidel'nikov sequences. The geometric sequences have a long period and large\nlinear complexity under some conditions, however they do not have the balance\nproperty. In order to construct sequences that have the balance property, we\npropose interleaved sequences of the geometric sequence and its complement.\nFurthermore, we show the periodic autocorrelation and linear complexity of the\nproposed sequences. The proposed sequences have the balance property, and have\na large linear complexity if the geometric sequences have a large one. \n\n"}
{"id": "1809.06500", "contents": "Title: Range entropy: A bridge between signal complexity and self-similarity Abstract: Approximate entropy (ApEn) and sample entropy (SampEn) are widely used for\ntemporal complexity analysis of real-world phenomena. However, their\nrelationship with the Hurst exponent as a measure of self-similarity is not\nwidely studied. Additionally, ApEn and SampEn are susceptible to signal\namplitude changes. A common practice for addressing this issue is to correct\ntheir input signal amplitude by its standard deviation. In this study, we first\nshow, using simulations, that ApEn and SampEn are related to the Hurst exponent\nin their tolerance r and embedding dimension m parameters. We then propose a\nmodification to ApEn and SampEn called range entropy or RangeEn. We show that\nRangeEn is more robust to nonstationary signal changes, and it has a more\nlinear relationship with the Hurst exponent, compared to ApEn and SampEn.\nRangeEn is bounded in the tolerance r-plane between 0 (maximum entropy) and 1\n(minimum entropy) and it has no need for signal amplitude correction. Finally,\nwe demonstrate the clinical usefulness of signal entropy measures for\ncharacterisation of epileptic EEG data as a real-world example. \n\n"}
{"id": "1809.06648", "contents": "Title: Local Reconstruction Codes: A Class of MDS-PIR Capacity-Achieving Codes Abstract: We prove that a class of distance-optimal local reconstruction codes (LRCs),\nan important family of repair-efficient codes for distributed storage systems,\nachieve the maximum distance separable private information retrieval capacity\nfor the case of noncolluding nodes. This particular class of codes includes\nPyramid codes and other LRCs proposed in the literature. \n\n"}
{"id": "1809.08365", "contents": "Title: A Unified Framework for the Tractable Analysis of Multi-Antenna Wireless\n  Networks Abstract: Densifying networks and deploying more antennas at each access point are two\nprincipal ways to boost the capacity of wireless networks. However, the\ncomplicated distributions of the signal power and the accumulated interference\npower, largely induced by various space-time processing techniques, make it\nhighly challenging to quantitatively characterize the performance of\nmulti-antenna networks. In this paper, using tools from stochastic geometry, a\nunified framework is developed for the analysis of such networks. The major\nresults are two innovative representations of the coverage probability, which\nmake the analysis of multi-antenna networks almost as tractable as the\nsingle-antenna case. One is expressed as an $\\ell_1$-induced norm of a Toeplitz\nmatrix, and the other is given in a finite sum form. With a compact\nrepresentation, the former incorporates many existing analytical results on\nsingle- and multi-antenna networks as special cases, and leads to tractable\nexpressions for evaluating the coverage probability in both ad hoc and cellular\nnetworks. While the latter is more complicated for numerical evaluation, it\nhelps analytically gain key design insights. In particular, it helps prove that\nthe coverage probability of ad hoc networks is a monotonically decreasing\nconvex function of the transmitter density and that there exists a peak value\nof the coverage improvement when increasing the number of transmit antennas. On\nthe other hand, in multi-antenna cellular networks, it is shown that the\ncoverage probability is independent of the transmitter density and that the\noutage probability decreases exponentially as the number of transmit antennas\nincreases. \n\n"}
{"id": "1809.08767", "contents": "Title: Optimal Multicast of Tiled 360 VR Video Abstract: In this letter, we study optimal multicast of tiled 360 virtual reality (VR)\nvideo from one server (base station or access point) to multiple users. We\nconsider random viewing directions and random channel conditions, and adopt\ntime division multiple access (TDMA). For given video quality, we optimize the\ntransmission time and power allocation to minimize the average transmission\nenergy. For given transmission energy budget, we optimize the transmission time\nand power allocation as well as the encoding rate of each tile to maximize the\nreceived video quality. These two optimization problems are challenging\nnon-convex problems. We obtain globally optimal closed-form solutions of the\ntwo non-convex problems, which reveal important design insights for multicast\nof tiled 360 VR video. Finally, numerical results demonstrate the advantage of\nthe proposed solutions. \n\n"}
{"id": "1809.09231", "contents": "Title: Tunable Measures for Information Leakage and Applications to\n  Privacy-Utility Tradeoffs Abstract: We introduce a tunable measure for information leakage called maximal\nalpha-leakage. This measure quantifies the maximal gain of an adversary in\ninferring any (potentially random) function of a dataset from a release of the\ndata. The inferential capability of the adversary is, in turn, quantified by a\nclass of adversarial loss functions that we introduce as $\\alpha$-loss,\n$\\alpha\\in[1,\\infty]$. The choice of $\\alpha$ determines the specific\nadversarial action and ranges from refining a belief (about any function of the\ndata) for $\\alpha=1$ to guessing the most likely value for $\\alpha=\\infty$\nwhile refining the $\\alpha^{th}$ moment of the belief for $\\alpha$ in between.\nMaximal alpha-leakage then quantifies the adversarial gain under $\\alpha$-loss\nover all possible functions of the data. In particular, for the extremal values\nof $\\alpha=1$ and $\\alpha=\\infty$, maximal alpha-leakage simplifies to mutual\ninformation and maximal leakage, respectively. For $\\alpha\\in(1,\\infty)$ this\nmeasure is shown to be the Arimoto channel capacity of order $\\alpha$. We show\nthat maximal alpha-leakage satisfies data processing inequalities and a\nsub-additivity property thereby allowing for a weak composition result.\nBuilding upon these properties, we use maximal alpha-leakage as the privacy\nmeasure and study the problem of data publishing with privacy guarantees,\nwherein the utility of the released data is ensured via a hard distortion\nconstraint. Unlike average distortion, hard distortion provides a deterministic\nguarantee of fidelity. We show that under a hard distortion constraint, for\n$\\alpha>1$ the optimal mechanism is independent of $\\alpha$, and therefore, the\nresulting optimal tradeoff is the same for all values of $\\alpha>1$. Finally,\nthe tunability of maximal alpha-leakage as a privacy measure is also\nillustrated for binary data with average Hamming distortion as the utility\nmeasure. \n\n"}
{"id": "1809.09237", "contents": "Title: Nonconvex Robust Low-rank Matrix Recovery Abstract: In this paper we study the problem of recovering a low-rank matrix from a\nnumber of random linear measurements that are corrupted by outliers taking\narbitrary values. We consider a nonsmooth nonconvex formulation of the problem,\nin which we explicitly enforce the low-rank property of the solution by using a\nfactored representation of the matrix variable and employ an $\\ell_1$-loss\nfunction to robustify the solution against outliers. We show that even when a\nconstant fraction (which can be up to almost half) of the measurements are\narbitrarily corrupted, as long as certain measurement operators arising from\nthe measurement model satisfy the so-called $\\ell_1/\\ell_2$-restricted isometry\nproperty, the ground-truth matrix can be exactly recovered from any global\nminimum of the resulting optimization problem. Furthermore, we show that the\nobjective function of the optimization problem is sharp and weakly convex.\nConsequently, a subgradient Method (SubGM) with geometrically diminishing step\nsizes will converge linearly to the ground-truth matrix when suitably\ninitialized. We demonstrate the efficacy of the SubGM for the nonconvex robust\nlow-rank matrix recovery problem with various numerical experiments. \n\n"}
{"id": "1809.09281", "contents": "Title: Knowledge-Aided Normalized Iterative Hard Thresholding Algorithms and\n  Applications to Sparse Reconstruction Abstract: This paper deals with the problem of sparse recovery often found in\ncompressive sensing applications exploiting a priori knowledge. In particular,\nwe present a knowledge-aided normalized iterative hard thresholding (KA-NIHT)\nalgorithm that exploits information about the probabilities of nonzero entries.\nWe also develop a strategy to update the probabilities using a recursive\nKA-NIHT (RKA-NIHT) algorithm, which results in improved recovery. Simulation\nresults illustrate and compare the performance of the proposed and existing\nalgorithms. \n\n"}
{"id": "1810.01086", "contents": "Title: A framework for generalized group testing with inhibitors and its\n  potential application in neuroscience Abstract: The main goal of group testing with inhibitors (GTI) is to efficiently\nidentify a small number of defective items and inhibitor items in a large set\nof items. A test on a subset of items is positive if the subset satisfies some\nspecific properties. Inhibitor items cancel the effects of defective items,\nwhich often make the outcome of a test containing defective items negative.\nDifferent GTI models can be formulated by considering how specific properties\nhave different cancellation effects. This work introduces generalized GTI\n(GGTI) in which a new type of items is added, i.e., hybrid items. A hybrid item\nplays the roles of both defectives items and inhibitor items. Since the number\nof instances of GGTI is large (more than 7 million), we introduce a framework\nfor classifying all types of items non-adaptively, i.e., all tests are designed\nin advance. We then explain how GGTI can be used to classify neurons in\nneuroscience. Finally, we show how to realize our proposed scheme in practice. \n\n"}
{"id": "1810.07014", "contents": "Title: Bregman Divergence Bounds and Universality Properties of the Logarithmic\n  Loss Abstract: A loss function measures the discrepancy between the true values and their\nestimated fits, for a given instance of data. In classification problems, a\nloss function is said to be proper if a minimizer of the expected loss is the\ntrue underlying probability. We show that for binary classification, the\ndivergence associated with smooth, proper, and convex loss functions is upper\nbounded by the Kullback-Leibler (KL) divergence, to within a normalization\nconstant. This implies that by minimizing the logarithmic loss associated with\nthe KL divergence, we minimize an upper bound to any choice of loss from this\nset. As such the logarithmic loss is universal in the sense of providing\nperformance guarantees with respect to a broad class of accuracy measures.\nImportantly, this notion of universality is not problem-specific, enabling its\nuse in diverse applications, including predictive modeling, data clustering and\nsample complexity analysis. Generalizations to arbitrary finite alphabets are\nalso developed. The derived inequalities extend several well-known\n$f$-divergence results. \n\n"}
{"id": "1810.11629", "contents": "Title: Performance of Energy-Buffer Aided Incremental Relaying in Cooperative\n  Networks Abstract: In this paper, we consider a two-hop cooperative network with a direct link\nbased on an energy harvesting (EH) decode-and-forward relay. The energy-buffer\nequipped relay harvests energy from the ambience, and uses the\nharvest-store-use (HSU) architecture. Since it is known that using a\ndiscrete-state Markov chain to model the energy buffer is inaccurate even for\nmoderate number of states, we use a discrete-time continuous-state space Markov\nchain instead. We derive the limiting distribution of energy for both\nincremental on-off policy (IOFP) and the incremental best-effort policy (IBEF),\nand use them to obtain expressions for outage probability and throughput. The\ncorresponding expressions for non-incremental signalling follow as a special\ncase. We show that stable buffers using IBEP harness a diversity of two as\ncompared to those using IOFP, which attain a diversity of one. However, while\nbuffers using IBEF are consequently more reliable than those with IOFP, their\nthroughput performance is only marginally superior. Simulation results are\npresented to validate the derived analytical expressions. \n\n"}
{"id": "1810.11725", "contents": "Title: Total Power Minimization: Joint Antenna Selection and Beamforming Design Abstract: In this paper, we consider the total power minimization problem when we have\nsignal-to-interference-plus-noise ratio (SINR) constraints. The consumed power\nin the circuits depends on the number of active antennas, which can be modeled\nusing zero-norm. Due to the difficulty of dealing with the non-convex\nzero-norm, we used the standard alternate weighted one-norm approach. We\naddressed the total power minimization for a narrowband system with and without\nper-antenna power constraints (PAPCs). We derived iterative closed-form\nexpressions in both cases. Then we analysed the case when we have multiple\nbands operating at the same time. Analogous closed-form expressions are\nprovided. Our simulation results show that significant gains can be obtained in\nterms of the total power required compared to standard methods that do not take\ninto account the circuit power. \n\n"}
{"id": "1810.12655", "contents": "Title: Deep Learning for the Gaussian Wiretap Channel Abstract: End-to-end learning of communication systems with neural networks and\nparticularly autoencoders is an emerging research direction which gained\npopularity in the last year. In this approach, neural networks learn to\nsimultaneously optimize encoding and decoding functions to establish reliable\nmessage transmission. In this paper, this line of thinking is extended to\ncommunication scenarios in which an eavesdropper must further be kept ignorant\nabout the communication. The secrecy of the transmission is achieved by\nutilizing a modified secure loss function based on cross-entropy which can be\nimplemented with state-of-the-art machine-learning libraries. This secure loss\nfunction approach is applied in a Gaussian wiretap channel setup, for which it\nis shown that the neural network learns a trade-off between reliable\ncommunication and information secrecy by clustering learned constellations. As\na result, an eavesdropper with higher noise cannot distinguish between the\nsymbols anymore. \n\n"}
{"id": "1810.12983", "contents": "Title: Sleeping Multi-Armed Bandit Learning for Fast Uplink Grant Allocation in\n  Machine Type Communications Abstract: Scheduling fast uplink grant transmissions for machine type communications\n(MTCs) is one of the main challenges of future wireless systems. In this paper,\na novel fast uplink grant scheduling method based on the theory of multi-armed\nbandits (MABs) is proposed. First, a single quality-of-service metric is\ndefined as a combination of the value of data packets, maximum tolerable access\ndelay, and data rate. Since full knowledge of these metrics for all machine\ntype devices (MTDs) cannot be known in advance at the base station (BS) and the\nset of active MTDs changes over time, the problem is modeled as a sleeping MAB\nwith stochastic availability and a stochastic reward function. In particular,\ngiven that, at each time step, the knowledge on the set of active MTDs is\nprobabilistic, a novel probabilistic sleeping MAB algorithm is proposed to\nmaximize the defined metric. Analysis of the regret is presented and the effect\nof the prediction error of the source traffic prediction algorithm on the\nperformance of the proposed sleeping MAB algorithm is investigated. Moreover,\nto enable fast uplink allocation for multiple MTDs at each time, a novel method\nis proposed based on the concept of best arms ordering in the MAB setting.\nSimulation results show that the proposed framework yields a three-fold\nreduction in latency compared to a random scheduling policy since it\nprioritises the scheduling of MTDs that have stricter latency requirements.\nMoreover, by properly balancing the exploration versus exploitation tradeoff,\nthe proposed algorithm can provide system fairness by allowing the most\nimportant MTDs to be scheduled more often while also allowing the less\nimportant MTDs to be selected enough times to ensure the accuracy of estimation\nof their importance. \n\n"}
{"id": "1810.13006", "contents": "Title: Rate-Efficiency and Straggler-Robustness through Partition in\n  Distributed Two-Sided Secure Matrix Computation Abstract: Computationally efficient matrix multiplication is a fundamental requirement\nin various fields, including and particularly in data analytics. To do so, the\ncomputation task of a large-scale matrix multiplication is typically outsourced\nto multiple servers. However, due to data misusage at the servers, security is\ntypically of concern. In this paper, we study the two-sided secure matrix\nmultiplication problem, where a user is interested in the matrix product\n$\\boldsymbol{AB}$ of two finite field private matrices $\\boldsymbol{A}$ and\n$\\boldsymbol{B}$ from an information-theoretic perspective. In this problem,\nthe user exploits the computational resources of $N$ servers to compute the\nmatrix product, but simultaneously tries to conceal the private matrices from\nthe servers. Our goal is twofold: (i) to maximize the communication rate, and,\n(ii) to minimize the effective number of server observations needed to\ndetermine $\\boldsymbol{AB}$, while preserving security, where we allow for up\nto $\\ell\\leq N$ servers to collude. To this end, we propose a general aligned\nsecret sharing scheme for which we optimize the matrix partition of matrices\n$\\boldsymbol{A}$ and $\\boldsymbol{B}$ in order to either optimize objective (i)\nor (ii) as a function of the system parameters (e.g., $N$ and $\\ell$). A\nproposed inductive approach gives us analytical, close-to-optimal solutions for\nboth (i) and (ii). With respect to (i), our scheme significantly outperforms\nthe existing scheme of Chang and Tandon in terms of (a) communication rate, (b)\nmaximum tolerable number of colluding servers and (c) computational complexity. \n\n"}
{"id": "1810.13068", "contents": "Title: Symbiotic Radio: A New Communication Paradigm for Passive\n  Internet-of-Things Abstract: In this paper, a novel technique, called symbiotic radio (SR), is proposed\nfor passive Internet-of-Things (IoT), in which a backscatter device (BD) is\nintegrated with a primary transmission. The primary transmitter is designed to\nassist the primary and BD transmissions, and the primary receiver decodes the\ninformation from the primary transmitter as well as the BD. We consider a\nmultiple-input single-output (MISO) SR and the symbol period for BD\ntransmission is designed to be either the same as or much longer than that of\nthe primary system, resulting in parasitic or commensal relationship between\nthe primary and BD transmissions. We first derive the achievable rates for the\nprimary system and the BD transmission. Then, we formulate two transmit\nbeamforming optimization problems, i.e., the weighted sum-rate maximization\nproblem and the transmit power minimization problem, and solve these non-convex\nproblems by applying semi-definite relaxation technique. In addition, a novel\ntransmit beamforming structure is proposed to reduce the computational\ncomplexity of the solutions. Simulation results show that when the BD\ntransmission rate is properly designed, the proposed SR not only enables the\nopportunistic transmission for the BD via energy-efficient passive\nbackscattering, but also enhances the achievable rate of the primary system by\nproperly exploiting the additional signal path from the BD. \n\n"}
{"id": "1811.00471", "contents": "Title: Optimal 1D Trajectory Design for UAV-Enabled Multiuser Wireless Power\n  Transfer Abstract: In this paper, we study an unmanned aerial vehicle (UAV)-enabled wireless\npower transfer (WPT) network, where a UAV flies at a constant altitude in the\nsky to provide wireless energy supply for a set of ground nodes with a linear\ntopology. Our objective is to maximize the minimum received energy among all\nground nodes by optimizing the UAV's one-dimensional (1D) trajectory, subject\nto the maximum UAV flying speed constraint. Different from previous works that\nonly provided heuristic and locally optimal solutions, this paper is the first\nwork to present the globally optimal 1D UAV trajectory solution to the\nconsidered min-energy maximization problem. Towards this end, we first show\nthat for any given speed-constrained UAV trajectory, we can always construct a\nmaximum-speed trajectory and a speed-free trajectory, such that their\ncombination can achieve the same received energy at all these ground nodes.\nNext, we transform the original UAV-speed-constrained trajectory optimization\nproblem into an equivalent UAV-speed-free problem, which is then optimally\nsolved via the Lagrange dual method. The obtained optimal 1D UAV trajectory\nsolution follows the so-called successive hover-and-fly (SHF) structure, i.e.,\nthe UAV successively hovers at a finite number of hovering points each for an\noptimized hovering duration, and flies among these hovering points at the\nmaximum speed. Numerical results show that our proposed optimal solution\nsignificantly outperforms the benchmark schemes in prior works under different\nscenarios. \n\n"}
{"id": "1811.04254", "contents": "Title: Monotonicity of skew information and its applications in quantum\n  resource theory Abstract: We give an alternative proof of skew information via operator algebra\napproach and show its strong monotonicity under particular quantum TPCP maps.\nWe then formulate a family of new resource measure if the resource can be\ncharacterized by a resource destroying map and the free operation should be\nalso modified. Our measure is easy-calculating and applicable to the coherence\nresource theory as well as quantum asymmetry theory. The operational\ninterpretation needs to be further investigated. \n\n"}
{"id": "1811.07535", "contents": "Title: MIMO Channel Information Feedback Using Deep Recurrent Network Abstract: In a multiple-input multiple-output (MIMO) system, the availability of\nchannel state information (CSI) at the transmitter is essential for performance\nimprovement. Recent convolutional neural network (NN) based techniques show\ncompetitive ability in realizing CSI compression and feedback. By introducing a\nnew NN architecture, we enhance the accuracy of quantized CSI feedback in MIMO\ncommunications. The proposed NN architecture invokes a module named long\nshort-term memory (LSTM) which admits the NN to benefit from exploiting\ntemporal and frequency correlations of wireless channels. Compromising\nperformance with complexity, we further modify the NN architecture with a\nsignificantly reduced number of parameters to be trained. Finally, experiments\nshow that the proposed NN architectures achieve better performance in terms of\nboth CSI compression and recovery accuracy. \n\n"}
{"id": "1811.09177", "contents": "Title: Distributed Compression of Correlated Classical-Quantum Sources or: The\n  Price of Ignorance Abstract: We resume the investigation of the problem of independent local compression\nof correlated quantum sources, the classical case of which is covered by the\ncelebrated Slepian-Wolf theorem. We focus specifically on classical-quantum\n(cq) sources, for which one edge of the rate region, corresponding to the\ncompression of the classical part, using the quantum part as side information\nat the decoder, was previously determined by Devetak and Winter [Phys. Rev. A\n68, 042301 (2003)]. Whereas the Devetak-Winter protocol attains a rate-sum\nequal to the von Neumann entropy of the joint source, here we show that the\nfull rate region is much more complex, due to the partially quantum nature of\nthe source. In particular, in the opposite case of compressing the quantum part\nof the source, using the classical part as side information at the decoder,\ntypically the rate sum is strictly larger than the von Neumann entropy of the\ntotal source.\n  We determine the full rate region in the generic case, showing that, apart\nfrom the Devetak-Winter point, all other points in the achievable region have a\nrate sum strictly larger than the joint entropy. We can interpret the\ndifference as the price paid for the quantum encoder being ignorant of the\nclassical side information. In the general case, we give an achievable rate\nregion, via protocols that are built on the decoupling principle, and the\nprinciples of quantum state merging and quantum state redistribution. Our\nachievable region is matched almost by a single-letter converse, which however\nstill involves asymptotic errors and an unbounded auxiliary system. \n\n"}
{"id": "1811.09652", "contents": "Title: Generalised Entropies and Metric-Invariant Optimal Countermeasures for\n  Information Leakage under Symmetric Constraints Abstract: We introduce a novel generalization of entropy and conditional entropy from\nwhich most definitions from the literature can be derived as particular cases.\nWithin this general framework, we investigate the problem of designing\ncountermeasures for information leakage. In particular, we seek\nmetric-invariant solutions, i.e., they are robust against the choice of entropy\nfor quantifying the leakage. The problem can be modelled as an information\nchannel from the system to an adversary, and the countermeasures can be seen as\nmodifying this channel in order to minimise the amount of information that the\noutputs reveal about the inputs. Our main result is to fully solve the problem\nunder the highly symmetrical design constraint that the number of inputs that\ncan produce the same output is capped. Our proof is constructive and the\noptimal channels and the minimum leakage are derived in closed form. \n\n"}
{"id": "1811.10315", "contents": "Title: Investigation of Nonlinear Communication Channel with Small Dispersion\n  via Stochastic Correlator Approach Abstract: We consider the optical fiber channel modelled by the nonlinear\nSchr\\\"{o}dinger equation with additive white Gaussian noise and with large\nsignal-to-noise ratio. For the small dispersion case we present the approach to\nanalyze the stochastic nonlinear Schr\\\"{o}dinger equation. Taking into account\nthe averaging procedure (frequency filtering) of the output signal detector we\nfind the first corrections in small dispersion parameter to the correlators of\nthe input signal recovered by the backward propagation. These correlators are\nthe important ingredients for the calculation of the channel capacity and the\noptimal input signal distribution. We assert that the information channel\ncharacteristics essentially depend on the procedures of the output signal\nfiltering and the recovery of the transmitted signal. \n\n"}
{"id": "1811.10839", "contents": "Title: Maximizing Multivariate Information with Error-Correcting Codes Abstract: Multivariate mutual information provides a conceptual framework for\ncharacterizing higher-order interactions in complex systems. Two well-known\nmeasures of multivariate information---total correlation and dual total\ncorrelation---admit a spectrum of measures with varying sensitivity to\nintermediate orders of dependence. Unfortunately, these intermediate measures\nhave not received much attention due to their opaque representation of\ninformation. Here we draw on results from matroid theory to show that these\nmeasures are closely related to error-correcting codes. This connection allows\nus to derive the class of global maximizers for each measure, which coincide\nwith maximum distance separable codes of order $k$. In addition to deepening\nthe understanding of these measures and multivariate information more\ngenerally, we use these results to show that previously proposed bounds on\ninformation geometric quantities are tight at the extremes. \n\n"}
{"id": "1811.11986", "contents": "Title: Joint Uplink-Downlink Cooperative Interference Management with Flexible\n  Cell Associations Abstract: We study information theoretic models of interference networks that consist\nof K Base Station (BS) - Mobile Terminal (MT) pairs. Each BS is connected to\nthe MT carrying the same index as well as L following MTs. We fix the value of\nL and study the per user Degrees of Freedom (puDoF) in large networks. We\nassume that each MT can be associated with N BSs, and these associations are\ndetermined by a cloud-based controller that has a global view of the network.\nAn MT has to be associated with a BS, for the BS to transmit its message in the\ndownlink, or have its decoded message in the uplink. We propose puDoF inner\nbounds for arbitrary values of L when only the uplink is considered, and\ncharacterize the uplink puDoF value when only zero-forcing schemes are allowed.\nWe then introduce new achievable average uplink-downlink puDoF values, and show\ntheir optimality for the range when N \\leq (L/2) and when we restrict our\nattention to zero-forcing schemes. Additionally, for the remaining range, we\ncharacterize the optimal downlink scheme when the uplink-optimal associations\nare used. Finally, we show that the proposed scheme is information\ntheoretically optimal for Wyner's linear interference network. \n\n"}
{"id": "1811.12719", "contents": "Title: Markov chain Monte Carlo Methods For Lattice Gaussian\n  Sampling:Convergence Analysis and Enhancement Abstract: Sampling from lattice Gaussian distribution has emerged as an important\nproblem in coding, decoding and cryptography. In this paper, the classic Gibbs\nalgorithm from Markov chain Monte Carlo (MCMC) methods is demonstrated to be\ngeometrically ergodic for lattice Gaussian sampling, which means the Markov\nchain arising from it converges exponentially fast to the stationary\ndistribution. Meanwhile, the exponential convergence rate of Markov chain is\nalso derived through the spectral radius of forward operator. Then, a\ncomprehensive analysis regarding to the convergence rate is carried out and two\nsampling schemes are proposed to further enhance the convergence performance.\nThe first one, referred to as Metropolis-within-Gibbs (MWG) algorithm, improves\nthe convergence by refining the state space of the univariate sampling. On the\nother hand, the blocked strategy of Gibbs algorithm, which performs the\nsampling over multivariate at each Markov move, is also shown to yield a better\nconvergence rate than the traditional univariate sampling. In order to perform\nblocked sampling efficiently, Gibbs-Klein (GK) algorithm is proposed, which\nsamples block by block using Klein's algorithm. Furthermore, the validity of GK\nalgorithm is demonstrated by showing its ergodicity. Simulation results based\non MIMO detections are presented to confirm the convergence gain brought by the\nproposed Gibbs sampling schemes. \n\n"}
{"id": "1812.00117", "contents": "Title: Secure physical layer network coding versus secure network coding Abstract: Secure network coding realizes the secrecy of the message when the message is\ntransmitted via noiseless network and a part of edges or a part of intermediate\nnodes are eavesdropped. In this framework, if the channels of the network has\nnoise, we apply the error correction to noisy channel before applying the\nsecure network coding. In contrast, secure physical layer network coding is a\nmethod to securely transmit a message by a combination of coding operation on\nnodes when the network is given as a set of noisy channels. In this paper, we\ngive several examples of network, in which, secure physical layer network\ncoding has advantage over secure network coding. \n\n"}
{"id": "1812.00819", "contents": "Title: Fast and Reliable Initial Access with Random Beamforming for mmWave\n  Networks Abstract: Millimeter-wave (mmWave) communications rely on directional transmissions to\novercome severe path loss. Nevertheless, the use of narrow beams complicates\nthe initial access procedure and increase the latency as the transmitter and\nreceiver beams should be aligned for a proper link establishment. In this\npaper, we investigate the feasibility of random beamforming for the cell-search\nphase of initial access. We develop a stochastic geometry framework to analyze\nthe performance in terms of detection failure probability and expected latency\nof initial access as well as total data transmission. Meanwhile, we compare our\nscheme with the widely used exhaustive search and iterative search schemes, in\nboth control plane and data plane. Our numerical results show that, compared to\nthe other two schemes, random beamforming can substantially reduce the latency\nof initial access with comparable failure probability in dense networks. We\nshow that the gain of the random beamforming is more prominent in light\ntraffics and low-latency services. Our work demonstrates that developing\ncomplex cell-discovery algorithms may be unnecessary in dense mmWave networks\nand thus shed new lights on mmWave network design. \n\n"}
{"id": "1812.01469", "contents": "Title: Centralized and Decentralized Cache-Aided Interference Management in\n  Heterogeneous Parallel Channels Abstract: We consider the problem of cache-aided interference management in a network\nconsisting of $K_{\\mathrm{T}}$ single-antenna transmitters and $K_{\\mathrm{R}}$\nsingle-antenna receivers, where each node is equipped with a cache memory.\nTransmitters communicate with receivers over two heterogenous parallel\nsubchannels: the P-subchannel for which transmitters have perfect instantaneous\nknowledge of the channel state, and the N-subchannel for which the transmitters\nhave no knowledge of the instantaneous channel state. Under the assumptions of\nuncoded placement and separable one-shot linear delivery over the two\nsubchannels, we characterize the optimal degrees-of-freedom (DoF) to within a\nconstant multiplicative factor of $2$. We extend the result to a decentralized\nsetting in which no coordination is required for content placement at the\nreceivers. In this case, we characterize the optimal one-shot linear DoF to\nwithin a factor of $3$. \n\n"}
{"id": "1812.02250", "contents": "Title: Evolution of $k$-mer Frequencies and Entropy in Duplication and\n  Substitution Mutation Systems Abstract: Genomic evolution can be viewed as string-editing processes driven by\nmutations. An understanding of the statistical properties resulting from these\nmutation processes is of value in a variety of tasks related to biological\nsequence data, e.g., estimation of model parameters and compression. At the\nsame time, due to the complexity of these processes, designing tractable\nstochastic models and analyzing them are challenging. In this paper, we study\ntwo kinds of systems, each representing a set of mutations. In the first\nsystem, tandem duplications and substitution mutations are allowed and in the\nother, interspersed duplications. We provide stochastic models and, via\nstochastic approximation, study the evolution of substring frequencies for\nthese two systems separately. Specifically, we show that $k$-mer frequencies\nconverge almost surely and determine the limit set. Furthermore, we present a\nmethod for finding upper bounds on entropy for such systems. \n\n"}
{"id": "1812.03031", "contents": "Title: Information-Distilling Quantizers Abstract: Let $X$ and $Y$ be dependent random variables. This paper considers the\nproblem of designing a scalar quantizer for $Y$ to maximize the mutual\ninformation between the quantizer's output and $X$, and develops fundamental\nproperties and bounds for this form of quantization, which is connected to the\nlog-loss distortion criterion. The main focus is the regime of low $I(X;Y)$,\nwhere it is shown that, if $X$ is binary, a constant fraction of the mutual\ninformation can always be preserved using $\\mathcal{O}(\\log(1/I(X;Y)))$\nquantization levels, and there exist distributions for which this many\nquantization levels are necessary. Furthermore, for larger finite alphabets $2\n< |\\mathcal{X}| < \\infty$, it is established that an $\\eta$-fraction of the\nmutual information can be preserved using roughly $(\\log(| \\mathcal{X} |\n/I(X;Y)))^{\\eta\\cdot(|\\mathcal{X}| - 1)}$ quantization levels. \n\n"}
{"id": "1812.03436", "contents": "Title: Compressive Privacy for a Linear Dynamical System Abstract: We consider a linear dynamical system in which the state vector consists of\nboth public and private states. One or more sensors make measurements of the\nstate vector and sends information to a fusion center, which performs the final\nstate estimation. To achieve an optimal tradeoff between the utility of\nestimating the public states and protection of the private states, the\nmeasurements at each time step are linearly compressed into a lower dimensional\nspace. Under the centralized setting where all measurements are collected by a\nsingle sensor, we propose an optimization problem and an algorithm to find the\nbest compression matrix. Under the decentralized setting where measurements are\nmade separately at multiple sensors, each sensor optimizes its own local\ncompression matrix. We propose methods to separate the overall optimization\nproblem into multiple sub-problems that can be solved locally at each sensor.\nWe consider the cases where there is no message exchange between the sensors;\nand where each sensor takes turns to transmit messages to the other sensors.\nSimulations and empirical experiments demonstrate the efficiency of our\nproposed approach in allowing the fusion center to estimate the public states\nwith good accuracy while preventing it from estimating the private states\naccurately. \n\n"}
{"id": "1812.04420", "contents": "Title: Blended smoothing splines on Riemannian manifolds Abstract: We present a method to compute a fitting curve B to a set of data points\nd0,...,dm lying on a manifold M. That curve is obtained by blending together\nEuclidean B\\'ezier curves obtained on different tangent spaces. The method\nguarantees several properties among which B is C1 and is the natural cubic\nsmoothing spline when M is the Euclidean space. We show examples on the sphere\nS2 as a proof of concept. \n\n"}
{"id": "1812.09147", "contents": "Title: Reed-Solomon-Gabidulin Codes Abstract: We introduce Reed-Solomon-Gabidulin codes which is, at the same time, an\nextension to Reed-Solomon codes on the one hand and Gabidulin codes on the\nother hand. We prove that our codes have good properties with respect to the\nminimal distance and design an efficient decoding algorithm. \n\n"}
{"id": "1812.09320", "contents": "Title: The Cost of Delay in Status Updates and their Value: Non-linear Ageing Abstract: We consider a status update communication system consisting of a\nsource-destination link. A stochastic process is observed at the source, where\nsamples are extracted at random time instances, and delivered to the\ndestination, thus, providing status updates for the source. In this paper, we\nexpand the concept of information ageing by introducing the cost of update\ndelay (CoUD) metric to characterize the cost of having stale information at the\ndestination. The CoUD captures the freshness of the information at the\ndestination and can be used to reflect the information structure of the source.\nMoreover, we introduce the value of information of update (VoIU) metric that\ncaptures the reduction of CoUD upon reception of an update. Using the CoUD, its\nby-product metric called peak cost of update delay (PCoUD), and the VoIU, we\nevaluate the performance of an M/M/1 system in various settings that consider\nexact expressions and bounds. Our results indicate that the performance of CoUD\ndiffers depending on the cost assigned per time unit, however the optimal\npolicy remains the same for linear ageing and varies for non-linear ageing.\nWhen it comes to the VoIU the performance difference appears only when the cost\nincreases non-linearly with time. The study illustrates the importance of the\nnewly introduced variants of age, furthermore supported in the case of VoIU by\nits tractability. \n\n"}
{"id": "1812.10862", "contents": "Title: Secure Modulo Sum via Multiple Access Channel Abstract: We discuss secure computation of modular sum when multiple access channel\nfrom distinct players $A_1, \\ldots, A_c$ to a third party (Receiver) is given.\nThen, we define the secure modulo sum capacity as the supremum of the\ntransmission rate of modulo sum without information leakage of other\ninformation. We derive its useful lower bound, which is numerically calculated\nunder a realistic model that can be realizable as a Gaussian multiple access\nchannel (MAC). \n\n"}
{"id": "1901.00798", "contents": "Title: Scalable Information-Flow Analysis of Secure Three-Party Affine\n  Computations Abstract: Elaborate protocols in Secure Multi-party Computation enable several\nparticipants to compute a public function of their own private inputs while\nensuring that no undesired information leaks about the private inputs, and\nwithout resorting to any trusted third party. However, the public output of the\ncomputation inevitably leaks some information about the private inputs. Recent\nworks have introduced a framework and proposed some techniques for quantifying\nsuch information flow. Yet, owing to their complexity, those methods do not\nscale to practical situations that may involve large input spaces. The main\ncontribution of the work reported here is to formally investigate the\ninformation flow captured by the min-entropy in the particular case of secure\nthree-party computations of affine functions in order to make its\nquantification scalable to realistic scenarios. To this end, we mathematically\nderive an explicit formula for this entropy under uniform prior beliefs about\nthe inputs. We show that this closed-form expression can be computed in time\nconstant in the inputs sizes and logarithmic in the coefficients of the affine\nfunction. Finally, we formulate some theoretical bounds for this privacy leak\nin the presence of non-uniform prior beliefs. \n\n"}
{"id": "1901.01605", "contents": "Title: Bounds on the Length of Functional PIR and Batch codes Abstract: A functional $k$-PIR code of dimension $s$ consists of $n$ servers storing\nlinear combinations of $s$ linearly independent information symbols. Any linear\ncombination of the $s$ information symbols can be recovered by $k$ disjoint\nsubsets of servers. The goal is to find the smallest number of servers for\ngiven $k$ and $s$. We provide lower bounds on the number of servers and\nconstructions which yield upper bounds on this number. For $k \\leq 4$, exact\nbounds on the number of servers are proved. Furthermore, we provide some\nasymptotic bounds. The problem coincides with the well known private\ninformation retrieval problem based on a coded database to reduce the storage\noverhead, when each linear combination contains exactly one information symbol.\n  If any multiset of size $k$ of linear combinations from the linearly\nindependent information symbols can be recovered by $k$ disjoint subset of\nservers, then the servers form a functional $k$-batch code. A~functional\n$k$-batch code is a functional $k$-PIR code, where all the $k$ linear\ncombinations in the multiset are equal. We provide some bounds on the number of\nservers for functional $k$-batch codes. In particular we present a random\nconstruction and a construction based on simplex codes, WOM codes, and RIO\ncodes. \n\n"}
{"id": "1901.01659", "contents": "Title: Dynamic Programming for Sequential Deterministic Quantization of\n  Discrete Memoryless Channels Abstract: In this paper, under a general cost function $C$, we present a dynamic\nprogramming (DP) method to obtain an optimal sequential deterministic quantizer\n(SDQ) for $q$-ary input discrete memoryless channel (DMC). The DP method has\ncomplexity $O(q (N-M)^2 M)$, where $N$ and $M$ are the alphabet sizes of the\nDMC output and quantizer output, respectively. Then, starting from the\nquadrangle inequality, two techniques are applied to reduce the DP method's\ncomplexity. One technique makes use of the Shor-Moran-Aggarwal-Wilber-Klawe\n(SMAWK) algorithm and achieves complexity $O(q (N-M) M)$. The other technique\nis much easier to be implemented and achieves complexity $O(q (N^2 - M^2))$. We\nfurther derive a sufficient condition under which the optimal SDQ is optimal\namong all quantizers and the two techniques are applicable. This generalizes\nthe results in the literature for binary-input DMC. Next, we show that the cost\nfunction of $\\alpha$-mutual information ($\\alpha$-MI)-maximizing quantizer\nbelongs to the category of $C$. We further prove that under a weaker condition\nthan the sufficient condition we derived, the aforementioned two techniques are\napplicable to the design of $\\alpha$-MI-maximizing quantizer. Finally, we\nillustrate the particular application of our design method to practical\npulse-amplitude modulation systems. \n\n"}
{"id": "1901.02203", "contents": "Title: Optimal Multi-Quality Multicast for 360 Virtual Reality Video Abstract: A 360 virtual reality (VR) video, recording a scene of interest in every\ndirection, provides VR users with immersive viewing experience. However,\ntransmission of a 360 VR video which is of a much larger size than a\ntraditional video to mobile users brings a heavy burden to a wireless network.\nIn this paper, we consider multi-quality multicast of a 360 VR video from a\nsingle server to multiple users using time division multiple access (TDMA). To\nimprove transmission efficiency, tiling is adopted, and each tile is\npre-encoded into multiple representations with different qualities. We optimize\nthe quality level selection, transmission time allocation and transmission\npower allocation to maximize the total utility of all users under the\ntransmission time and power allocation constraints as well as the quality\nsmoothness constraints for mixed-quality tiles. The problem is a challenging\nmixed discrete-continuous opti-mization problem. We propose two low-complexity\nalgorithms to obtain two suboptimal solutions, using continuous relaxation and\nDC programming, respectively. Finally, numerical results demonstrate the\nadvantage of the proposed solutions. \n\n"}
{"id": "1901.03940", "contents": "Title: A Generalization of Wirtinger Flow for Exact Interferometric Inversion Abstract: Interferometric inversion involves recovery of a signal from\ncross-correlations of its linear transformations. A close relative of\ninterferometric inversion is the generalized phase retrieval problem, which\nconsists of recovering a signal from the auto-correlations of its linear\ntransformations. Recently, significant advancements have been made in phase\nretrieval methods despite the ill-posed, and non-convex nature of the problem.\nOne such method is Wirtinger Flow (WF), a non-convex optimization framework\nthat provides high probability guarantees of exact recovery under certain\nmeasurement models, such as coded diffraction patterns, and Gaussian sampling\nvectors. In this paper, we develop a generalization of WF for interferometric\ninversion, which we refer to as Generalized Wirtinger Flow (GWF). GWF theory\nextends the probabilistic exact recovery results of WF to arbitrary measurement\nmodels characterized in the equivalent lifted problem, hence covers a larger\nclass of measurement models. Our framework unifies the theory of low rank\nmatrix recovery (LRMR) and the non-convex optimization approach of WF, thereby\nestablishes theoretical advantages of the non-convex approach over LRMR. We\nidentify a new sufficient condition on the lifted forward model that directly\nimplies exact recovery conditions of standard WF. This condition is less\nstringent than those of LRMR, which is the state of the art approach for exact\ninterferometric inversion. We establish our sufficient condition for the\ncross-correlations of linear measurements collected by complex Gaussian\nsampling vectors, and show that the exact recovery conditions of standard WF\nimply our sufficient condition. As a result, the regularity condition of WF\nbecomes redundant in solving the interferometric inversion problem. Finally, we\ndemonstrate the effectiveness of GWF numerically in a deterministic\nmulti-static radar imaging scenario. \n\n"}
{"id": "1901.04654", "contents": "Title: Reducing Age-of-Information for Computation-Intensive Messages via\n  Packet Replacement Abstract: Freshness of data is an important performance metric for real-time\napplications, which can be measured by age-of-information. For\ncomputation-intensive messages, the embedded information is not available until\nbeing computed. In this paper, we study the age-of-information for\ncomputation-intensive messages, which are firstly transmitted to a mobile edge\nserver, and then processed in the edge server to extract the embedded\ninformation. The packet generation follows zero-wait policy, by which a new\npacket is generated when the last one is just delivered to the edge server. The\nqueue in front of the edge server adopts one-packet-buffer replacement policy,\nmeaning that only the latest received packet is preserved. We derive the\nexpression of average age-of-information for exponentially distributed\ntransmission time and computing time. With packet replacement, the average age\nis reduced compared with the case without packet replacement, especially when\nthe transmission rate is close to or greater than the computing rate. \n\n"}
{"id": "1901.05719", "contents": "Title: AI Coding: Learning to Construct Error Correction Codes Abstract: In this paper, we investigate an artificial-intelligence (AI) driven approach\nto design error correction codes (ECC). Classic error correction code was\ndesigned upon coding theory that typically defines code properties (e.g.,\nhamming distance, subchannel reliability, etc.) to reflect code performance.\nIts code design is to optimize code properties. However, an AI-driven approach\ndoesn't necessarily rely on coding theory any longer. Specifically, we propose\na constructor-evaluator framework, in which the code constructor is realized by\nAI algorithms and the code evaluator provides code performance metric\nmeasurements. The code constructor keeps improving the code construction to\nmaximize code performance that is evaluated by the code evaluator. As examples,\nwe construct linear block codes and polar codes with reinforcement learning\n(RL) and evolutionary algorithms. The results show that comparable code\nperformance can be achieved with respect to the existing codes. It is\nnoteworthy that our method can provide superior performances where existing\nclassic constructions fail to achieve optimum for a specific decoder (e.g.,\nlist decoding for polar codes). \n\n"}
{"id": "1901.05908", "contents": "Title: Locality in Index Coding for Large Min-Rank Abstract: An index code is said to be locally decodable if each receiver can decode its\ndemand using its side information and by querying only a subset of the\ntransmitted codeword symbols instead of observing the entire codeword. Local\ndecodability can be a beneficial feature in some communication scenarios, such\nas when the receivers can afford to listen to only a part of the transmissions\nbecause of limited availability of power. The locality of an index code is the\nratio of the maximum number of codeword symbols queried by a receiver to the\nmessage length. In this paper we analyze the optimum locality of linear codes\nfor the family of index coding problems whose min-rank is one less than the\nnumber of receivers in the network. We first derive the optimal trade-off\nbetween the index coding rate and locality with vector linear coding when the\nside information graph is a directed cycle. We then provide the optimal\ntrade-off achieved by scalar linear coding for a larger family of problems,\nviz., problems where the min-rank is only one less than the number of\nreceivers. While the arguments used for achievability are based on known coding\ntechniques, the converse arguments rely on new results on the structure of\nlocally decodable index codes. \n\n"}
{"id": "1901.06214", "contents": "Title: The Restricted Isometry Property of Block Diagonal Matrices for\n  Group-Sparse Signal Recovery Abstract: Group-sparsity is a common low-complexity signal model with widespread\napplication across various domains of science and engineering. The recovery of\nsuch signal ensembles from compressive measurements has been extensively\nstudied in the literature under the assumption that measurement operators are\nmodeled as densely populated random matrices. In this paper, we turn our\nattention to an acquisition model intended to ease the energy consumption of\nsensing devices by splitting the measurements up into distinct signal blocks.\nMore precisely, we present uniform guarantees for group-sparse signal recovery\nin the scenario where a number of sensors obtain independent partial signal\nobservations modeled by block diagonal measurement matrices. We establish a\ngroup-sparse variant of the classical restricted isometry property for block\ndiagonal sensing matrices acting on group-sparse vectors, and provide\nconditions under which subgaussian block diagonal random matrices satisfy this\ngroup-RIP with high probability. Two different scenarios are considered in\nparticular. In the first scenario, we assume that each sensor is equipped with\nan independently drawn measurement matrix. We later lift this requirement by\nconsidering measurement matrices with constant block diagonal entries. In other\nwords, every sensor is equipped with a copy of the same prototype matrix. The\nproblem of establishing the group-RIP is cast into a form in which one needs to\nestablish the concentration behavior of the suprema of chaos processes which\ninvolves estimating Talagrand's $\\gamma_2$ functional. As a side effect of the\nproof, we present an extension to Maurey's empirical method to provide new\nbounds on the covering number of sets consisting of finite convex combinations\nof possibly infinite sets. \n\n"}
{"id": "1901.06644", "contents": "Title: Modeling and Analysis of Two-Way Relay Non-Orthogonal Multiple Access\n  Systems Abstract: A two-way relay non-orthogonal multiple access (TWR-NOMA) system is\ninvestigated, where two groups of NOMA users exchange messages with the aid of\none half-duplex (HD) decode-and-forward (DF) relay. Since the\nsignal-plus-interference-to-noise ratios (SINRs) of NOMA signals mainly depend\non effective successive interference cancellation (SIC) schemes, imperfect SIC\n(ipSIC) and perfect SIC (pSIC) are taken into account. In order to characterize\nthe performance of TWR-NOMA systems, we first derive closed-form expressions\nfor both exact and asymptotic outage probabilities of NOMA users' signals with\nipSIC/pSIC. Based on the derived results, the diversity order and throughput of\nthe system are examined. Then we study the ergodic rates of users' signals by\nproviding the asymptotic analysis in high SNR regimes. Lastly, numerical\nsimulations are provided to verify the analytical results and show that: 1)\nTWR-NOMA is superior to TWR-OMA in terms of outage probability in low SNR\nregimes; 2) Due to the impact of interference signal (IS) at the relay, error\nfloors and throughput ceilings exist in outage probabilities and ergodic rates\nfor TWR-NOMA, respectively; and 3) In delay-limited transmission mode, TWR-NOMA\nwith ipSIC and pSIC have almost the same energy efficiency. However, in\ndelay-tolerant transmission mode, TWR-NOMA with pSIC is capable of achieving\nlarger energy efficiency compared to TWR-NOMA with ipSIC. \n\n"}
{"id": "1901.06738", "contents": "Title: On the Number of Bins in Equilibria for Signaling Games Abstract: We investigate the equilibrium behavior for the decentralized quadratic cheap\ntalk problem in which an encoder and a decoder, viewed as two decision makers,\nhave misaligned objective functions. In prior work, we have shown that the\nnumber of bins under any equilibrium has to be at most countable, generalizing\na classical result due to Crawford and Sobel who considered sources with\ndensity supported on $[0,1]$. In this paper, we refine this result in the\ncontext of exponential and Gaussian sources. For exponential sources, a\nrelation between the upper bound on the number of bins and the misalignment in\nthe objective functions is derived, the equilibrium costs are compared, and it\nis shown that there also exist equilibria with infinitely many bins under\ncertain parametric assumptions. For Gaussian sources, it is shown that there\nexist equilibria with infinitely many bins. \n\n"}
{"id": "1901.06742", "contents": "Title: Using Quantization to Deploy Heterogeneous Nodes in Two-Tier Wireless\n  Sensor Networks Abstract: We study a heterogeneous two-tier wireless sensor network in which N\nheterogeneous access points (APs) collect sensing data from densely distributed\nsensors and then forward the data to M heterogeneous fusion centers (FCs). This\nheterogeneous node deployment problem is modeled as a quantization problem with\ndistortion defined as the total power consumption of the network. The necessary\nconditions of the optimal AP and FC node deployment are explored in this paper.\nWe provide a variation of Voronoi Diagram as the optimal cell partition for\nthis network, and show that each AP should be placed between its connected FC\nand the geometric center of its cell partition. In addition, we propose a\nheterogeneous two-tier Lloyd algorithm to optimize the node deployment.\nSimulation results show that our proposed algorithm outperforms the existing\nclustering methods like Minimum Energy Routing, Agglomerative Clustering, and\nDivisive Clustering, on average. \n\n"}
{"id": "1901.06915", "contents": "Title: New Bounds on the Field Size for Maximally Recoverable Codes\n  Instantiating Grid-like Topologies Abstract: In recent years, the rapidly increasing amounts of data created and processed\nthrough the internet resulted in distributed storage systems employing erasure\ncoding based schemes. Aiming to balance the tradeoff between data recovery for\ncorrelated failures and efficient encoding and decoding, distributed storage\nsystems employing maximally recoverable codes came up. Unifying a number of\ntopologies considered both in theory and practice, Gopalan et al.\n\\cite{Gopalan2017} initiated the study of maximally recoverable codes for\ngrid-like topologies.\n  In this paper, we focus on the maximally recoverable codes that instantiate\ngrid-like topologies $T_{m\\times n}(1,b,0)$. To characterize the property of\ncodes for these topologies, we introduce the notion of \\emph{pseudo-parity\ncheck matrix}. Then, using the Combinatorial Nullstellensatz, we establish the\nfirst polynomial upper bound on the field size needed for achieving the maximal\nrecoverability in topologies $T_{m\\times n}(1,b,0)$. And using hypergraph\nindependent set approach, we further improve this general upper bound for\ntopologies $T_{4\\times n}(1,2,0)$ and $T_{3\\times n}(1,3,0)$. By relating the\nproblem to generalized \\emph{Sidon sets} in $\\mathbb{F}_q$, we also obtain\nnon-trivial lower bounds on the field size for maximally recoverable codes that\ninstantiate topologies $T_{4\\times n}(1,2,0)$ and $T_{3\\times n}(1,3,0)$. \n\n"}
{"id": "1901.07057", "contents": "Title: A New Design Framework on Device-to-Device Coded Caching with Optimal\n  Rate and Significantly Less Subpacketizations Abstract: In this paper, we propose a new design framework on Device-to-Device (D2D)\ncoded caching networks with optimal rate but significantly less file\nsubpacketizations compared to that of the well-known D2D coded caching scheme\nproposed by Ji, Caire and Molisch (JCM). The proposed design framework is\nreferred to as the {\\em Packet Type-based (PTB) design}, where D2D users are\nfirst partitioned into multiple groups, which leads to a so-called {\\em raw\npacket saving gain}. Then the corresponding multicasting group types and packet\ntypes are specified based on the prescribed node partition. By a careful\nselection of transmitters within each multicasting group, a so-called {\\em\nfurther splitting ratio gain} can also be achieved. By the joint effect of the\n{\\em raw packet saving gain} and the {\\em further splitting ratio gain}, an\norder-wise subpacketization reduction can be achieved compared to the JCM\nscheme while preserving the optimal rate for large system parameter regimes. In\naddition, as the first time presented in the literature according to our\nknowledge, we find that unequal subpacketizaton is a key to achieve a\nsubpacketization gain when the number of users is odd. As a by-product, instead\nof directly translating shared link caching schemes to D2D caching schemes, at\nleast for the sake of subpackeitzations, a new design framework is indeed\nneeded. \n\n"}
{"id": "1901.07635", "contents": "Title: Sparse Graph Codes for Non-adaptive Quantitative Group Testing Abstract: This paper considers the problem of Quantitative Group Testing (QGT).\nConsider a set of $N$ items among which $K$ items are defective. The QGT\nproblem is to identify (all or a sufficiently large fraction of) the defective\nitems, where the result of a test reveals the number of defective items in the\ntested group. In this work, we propose a non-adaptive QGT algorithm using\nsparse graph codes over bi-regular bipartite graphs with left-degree $\\ell$ and\nright degree $r$ and binary $t$-error-correcting BCH codes. The proposed scheme\nprovides exact recovery with probabilistic guarantee, i.e. recovers all the\ndefective items with high probability. In particular, we show that for the\nsub-linear regime where $\\frac{K}{N}$ vanishes as $K,N\\rightarrow\\infty$, the\nproposed algorithm requires at most ${m=c(t)K\\left(t\\log_2\\left(\\frac{\\ell\nN}{c(t)K}+1\\right)+1\\right)+1}$ tests to recover all the defective items with\nprobability approaching one as ${K,N\\rightarrow\\infty}$, where $c(t)$ depends\nonly on $t$. The results of our theoretical analysis reveal that the minimum\nnumber of required tests is achieved by $t=2$. The encoding and decoding of the\nproposed algorithm for any $t\\leq 4$ have the computational complexity of\n$\\mathcal{O}(K\\log^2 \\frac{N}{K})$ and $\\mathcal{O}(K\\log \\frac{N}{K})$,\nrespectively. Our simulation results also show that the proposed algorithm\nsignificantly outperforms a non-adaptive semi-quantitative group testing\nalgorithm recently proposed by Abdalla \\emph{et al.} in terms of the required\nnumber of tests for identifying all the defective items with high probability. \n\n"}
{"id": "1901.07769", "contents": "Title: Bit Flipping Moment Balancing Schemes for Insertion, Deletion and\n  Substitution Error Correction Abstract: In this paper, two moment balancing schemes, namely a variable index scheme\nand a fixed index scheme, for either single insertion/deletion error correction\nor multiple substitution error correction are introduced for coded sequences\noriginally developed for correcting substitution errors only. By judiciously\nflipping bits of the original substitution error correcting code word, the\nresulting word is able to correct either a reduced number of substitution\nerrors or a single insertion/deletion error. The number of flips introduced by\nthe two schemes can be kept small compared to the code length. It shows a\npractical value of applying the schemes to a long substitution error correcting\ncode for a severe channel where substitution errors dominate but\ninsertion/deletion errors can occur with a low probability. The new schemes can\nbe more easily implemented in an existing coding system than any previously\npublished moment balancing templates since no additional parity bits are\nrequired which also means the code rate remains same and the existing\nsubstitution error correcting decoder requires no changes. Moreover, the work\nextends the class of Levenshtein codes capable of correcting either single\nsubstitution or single insertion/deletion errors to codes capable of correcting\neither multiple substitution errors or single insertion/deletion error. \n\n"}
{"id": "1901.07823", "contents": "Title: Coded Caching via Projective Geometry: A new low subpacketization scheme Abstract: Coded Caching is a promising solution to reduce the peak traffic in broadcast\nnetworks by prefetching the popular content close to end users and using coded\ntransmissions. One of the chief issues of most coded caching schemes in\nliterature is the issue of large $\\textit{subpacketization}$, i.e., they\nrequire each file to be divided into a large number of subfiles. In this work,\nwe present a coded caching scheme using line graphs of bipartite graphs in\nconjunction with projective geometries over finite fields. The presented scheme\nachieves a rate $\\Theta(\\frac{K}{\\log_q{K}})$ ($K$ being the number of users,\n$q$ is some prime power) with $\\textit{subexponential}$ subpacketization\n$q^{O((\\log_q{K})^2)}$ when cached fraction is upper bounded by a constant\n($\\frac{M}{N}\\leq \\frac{1}{q^\\alpha}$) for some positive integer $\\alpha$).\nCompared to earlier schemes, the presented scheme has a lower subpacketization\n(albeit possessing a higher rate). We also present a new subpacketization\ndependent lower bound on the rate for caching schemes in which each subfile is\ncached in the same number of users. Compared to the previously known bounds,\nthis bound seems to perform better for a range of parameters of the caching\nsystem. \n\n"}
{"id": "1901.08570", "contents": "Title: End-to-End Optimized Transmission over Dispersive Intensity-Modulated\n  Channels Using Bidirectional Recurrent Neural Networks Abstract: We propose an autoencoding sequence-based transceiver for communication over\ndispersive channels with intensity modulation and direct detection (IM/DD),\ndesigned as a bidirectional deep recurrent neural network (BRNN). The receiver\nuses a sliding window technique to allow for efficient data stream estimation.\nWe find that this sliding window BRNN (SBRNN), based on end-to-end deep\nlearning of the communication system, achieves a significant bit-error-rate\nreduction at all examined distances in comparison to previous block-based\nautoencoders implemented as feed-forward neural networks (FFNNs), leading to an\nincrease of the transmission distance. We also compare the end-to-end SBRNN\nwith a state-of-the-art IM/DD solution based on two level pulse amplitude\nmodulation with an FFNN receiver, simultaneously processing multiple received\nsymbols and approximating nonlinear Volterra equalization. Our results show\nthat the SBRNN outperforms such systems at both 42 and 84\\,Gb/s, while training\nfewer parameters. Our novel SBRNN design aims at tailoring the end-to-end deep\nlearning-based systems for communication over nonlinear channels with memory,\nsuch as the optical IM/DD fiber channel. \n\n"}
{"id": "1901.09308", "contents": "Title: Energy-Efficient Resource Allocation for Secure UAV Communication\n  Systems Abstract: In this paper, we study the resource allocation and trajectory design for\nenergy-efficient secure unmanned aerial vehicle (UAV) communication systems\nwhere a UAV base station serves multiple legitimate ground users in the\nexistence of a potential eavesdropper. We aim to maximize the energy efficiency\nof the UAV by jointly optimizing its transmit power, user scheduling,\ntrajectory, and velocity. The design is formulated as a non-convex optimization\nproblem taking into account the maximum tolerable signal-to-noise ratio (SNR)\nleakage, the minimum data rate requirement of each user, and the location\nuncertainty of the eavesdropper. An iterative algorithm is proposed to obtain\nan efficient suboptimal solution. Simulation results demonstrate that the\nproposed algorithm can achieve a significant improvement of the system energy\nefficiency while satisfying communication security constraint, compared to some\nsimple scheme adopting straight flight trajectory with a constant speed. \n\n"}
{"id": "1901.09738", "contents": "Title: Bandwidth Gain from Mobile Edge Computing and Caching in Wireless\n  Multicast Systems Abstract: In this paper, we present a novel mobile edge computing (MEC) model where the\nMEC server has the input and output data of all computation tasks and\ncommunicates with multiple caching-and-computing-enabled mobile devices via a\nshared wireless link. Each task request can be served from local output\ncaching, local computing with input caching, local computing or MEC computing,\neach of which incurs a unique bandwidth requirement of the multicast link.\nAiming to minimize the transmission bandwidth, we design and optimize the local\ncaching and computing policy at mobile devices subject to latency, caching,\nenergy and multicast transmission constraints. The joint policy optimization\nproblem is shown to be NP-hard. When the output data size is smaller than the\ninput data size, we reformulate the problem as minimization of a monotone\nsubmodular function over matroid constraints and obtain the optimal solution\nvia a strongly polynomial algorithm of Schrijver. On the other hand, when the\noutput data size is larger than the input data size, by leveraging sample\napproximation and concave convex procedure together with the alternating\ndirection method of multipliers, we propose a low-complexity high-performance\nalgorithm and prove it converges to a stationary point. Furthermore, we\ntheoretically reveal how much bandwidth gain can be achieved from computing and\ncaching resources at mobile devices or the multicast transmission for symmetric\ncase. Our results indicate that exploiting the computing and caching resources\nat mobile devices as well as multicast transmission can provide significant\nbandwidth savings. \n\n"}
{"id": "1901.09807", "contents": "Title: Capacity-Achieving MIMO-NOMA: Iterative LMMSE Detection Abstract: This paper considers a low-complexity iterative Linear Minimum Mean Square\nError (LMMSE) multi-user detector for the Multiple-Input and Multiple-Output\nsystem with Non-Orthogonal Multiple Access (MIMO-NOMA), where multiple\nsingle-antenna users simultaneously communicate with a multiple-antenna base\nstation (BS). While LMMSE being a linear detector has a low complexity, it has\nsuboptimal performance in multi-user detection scenario due to the mismatch\nbetween LMMSE detection and multi-user decoding. Therefore, in this paper, we\nprovide the matching conditions between the detector and decoders for\nMIMO-NOMA, which are then used to derive the achievable rate of the iterative\ndetection. We prove that a matched iterative LMMSE detector can achieve (i) the\noptimal capacity of symmetric MIMO-NOMA with any number of users, (ii) the\noptimal sum capacity of asymmetric MIMO-NOMA with any number of users, (iii)\nall the maximal extreme points in the capacity region of asymmetric MIMO-NOMA\nwith any number of users, (iv) all points in the capacity region of two-user\nand three-user asymmetric MIMO-NOMA systems. In addition, a kind of practical\nlow-complexity error-correcting multiuser code, called irregular\nrepeat-accumulate code, is designed to match the LMMSE detector. Numerical\nresults shows that the bit error rate performance of the proposed iterative\nLMMSE detection outperforms the state-of-art methods and is within 0.8dB from\nthe associated capacity limit. \n\n"}
{"id": "cond-mat/0506652", "contents": "Title: The theoretical capacity of the Parity Source Coder Abstract: The Parity Source Coder is a protocol for data compression which is based on\na set of parity checks organized in a sparse random network. We consider here\nthe case of memoryless unbiased binary sources. We show that the theoretical\ncapacity saturate the Shannon limit at large K. We also find that the first\ncorrections to the leading behavior are exponentially small, so that the\nbehavior at finite K is very close to the optimal one. \n\n"}
{"id": "cond-mat/0604267", "contents": "Title: Survey propagation for the cascading Sourlas code Abstract: We investigate how insights from statistical physics, namely survey\npropagation, can improve decoding of a particular class of sparse error\ncorrecting codes. We show that a recently proposed algorithm, time averaged\nbelief propagation, is in fact intimately linked to a specific survey\npropagation for which Parisi's replica symmetry breaking parameter is set to\nzero, and that the latter is always superior to belief propagation in the high\nconnectivity limit. We briefly look at further improvements available by going\nto the second level of replica symmetry breaking. \n\n"}
{"id": "cond-mat/0608312", "contents": "Title: On Cavity Approximations for Graphical Models Abstract: We reformulate the Cavity Approximation (CA), a class of algorithms recently\nintroduced for improving the Bethe approximation estimates of marginals in\ngraphical models. In our new formulation, which allows for the treatment of\nmultivalued variables, a further generalization to factor graphs with arbitrary\norder of interaction factors is explicitly carried out, and a message passing\nalgorithm that implements the first order correction to the Bethe approximation\nis described. Furthermore we investigate an implementation of the CA for\npairwise interactions. In all cases considered we could confirm that CA[k] with\nincreasing $k$ provides a sequence of approximations of markedly increasing\nprecision. Furthermore in some cases we could also confirm the general\nexpectation that the approximation of order $k$, whose computational complexity\nis $O(N^{k+1})$ has an error that scales as $1/N^{k+1}$ with the size of the\nsystem. We discuss the relation between this approach and some recent\ndevelopments in the field. \n\n"}
{"id": "cond-mat/0701218", "contents": "Title: Generalized Statistics Framework for Rate Distortion Theory with Bregman\n  Divergences Abstract: A variational principle for the rate distortion (RD) theory with Bregman\ndivergences is formulated within the ambit of the generalized (nonextensive)\nstatistics of Tsallis. The Tsallis-Bregman RD lower bound is established.\nAlternate minimization schemes for the generalized Bregman RD (GBRD) theory are\nderived. A computational strategy to implement the GBRD model is presented. The\nefficacy of the GBRD model is exemplified with the aid of numerical\nsimulations. \n\n"}
{"id": "cs/0507041", "contents": "Title: Monotone Conditional Complexity Bounds on Future Prediction Errors Abstract: We bound the future loss when predicting any (computably) stochastic sequence\nonline. Solomonoff finitely bounded the total deviation of his universal\npredictor M from the true distribution m by the algorithmic complexity of m.\nHere we assume we are at a time t>1 and already observed x=x_1...x_t. We bound\nthe future prediction performance on x_{t+1}x_{t+2}... by a new variant of\nalgorithmic complexity of m given x, plus the complexity of the randomness\ndeficiency of x. The new complexity is monotone in its condition in the sense\nthat this complexity can only decrease if the condition is prolonged. We also\nbriefly discuss potential generalizations to Bayesian model classes and to\nclassification problems. \n\n"}
{"id": "cs/0510044", "contents": "Title: Belief Propagation Based Multi--User Detection Abstract: We apply belief propagation (BP) to multi--user detection in a spread\nspectrum system, under the assumption of Gaussian symbols. We prove that BP is\nboth convergent and allows to estimate the correct conditional expectation of\nthe input symbols. It is therefore an optimal --minimum mean square error--\ndetection algorithm. This suggests the possibility of designing BP detection\nalgorithms for more general systems. As a byproduct we rederive the Tse-Hanly\nformula for minimum mean square error without any recourse to random matrix\ntheory. \n\n"}
{"id": "cs/0511039", "contents": "Title: The Generalized Area Theorem and Some of its Consequences Abstract: There is a fundamental relationship between belief propagation and maximum a\nposteriori decoding. The case of transmission over the binary erasure channel\nwas investigated in detail in a companion paper. This paper investigates the\nextension to general memoryless channels (paying special attention to the\nbinary case). An area theorem for transmission over general memoryless channels\nis introduced and some of its many consequences are discussed. We show that\nthis area theorem gives rise to an upper-bound on the maximum a posteriori\nthreshold for sparse graph codes. In situations where this bound is tight, the\nextrinsic soft bit estimates delivered by the belief propagation decoder\ncoincide with the correct a posteriori probabilities above the maximum a\nposteriori threshold. More generally, it is conjectured that the fundamental\nrelationship between the maximum a posteriori and the belief propagation\ndecoder which was observed for transmission over the binary erasure channel\ncarries over to the general case. We finally demonstrate that in order for the\ndesign rate of an ensemble to approach the capacity under belief propagation\ndecoding the component codes have to be perfectly matched, a statement which is\nwell known for the special case of transmission over the binary erasure\nchannel. \n\n"}
{"id": "cs/0603095", "contents": "Title: A Turbo Coding System for High Speed Communications Abstract: Conventional turbo codes (CTCs) usually employ a block-oriented interleaving\nso that each block is separately encoded and decoded. As interleaving and\nde-interleaving are performed within a block, the message-passing process\nassociated with an iterative decoder is limited to proceed within the\ncorresponding range. This paper presents a new turbo coding scheme that uses a\nspecial interleaver structure and a multiple-round early termination test\ninvolving both sign check and a CRC code. The new interleaver structure is\nnaturally suited for high speed parallel processing and the resulting coding\nsystem offers new design options and tradeoffs that are not available to CTCs.\nIn particular, it becomes possible for the decoder to employ an efficient\ninter-block collaborative decoding algorithm, passing the information obtained\nfrom termination test proved blocks to other unproved blocks. It also becomes\nimportant to have a proper decoding schedule. The combined effect is improved\nperformance and reduction in the average decoding delay (whence the required\ncomputing power). A memory (storage) management mechanism is included as a\ncritical part of the decoder so as to provide additional design tradeoff\nbetween performance and memory size. It is shown that the latter has a\nmodular-like effect in that additional memory units render enhanced performance\ndue not only to less forced early terminations but to possible increases of the\ninterleaving depth. Depending on the decoding schedule, the degree of\nparallelism and other decoding resources available, the proposed scheme admits\na variety of decoder architectures that meet a large range of throughput and\nperformance demands. \n\n"}
{"id": "cs/0607024", "contents": "Title: Results on Parity-Check Matrices with Optimal Stopping and/or Dead-End\n  Set Enumerators Abstract: The performance of iterative decoding techniques for linear block codes\ncorrecting erasures depends very much on the sizes of the stopping sets\nassociated with the underlying Tanner graph, or, equivalently, the parity-check\nmatrix representing the code. In this paper, we introduce the notion of\ndead-end sets to explicitly demonstrate this dependency. The choice of the\nparity-check matrix entails a trade-off between performance and complexity. We\ngive bounds on the complexity of iterative decoders achieving optimal\nperformance in terms of the sizes of the underlying parity-check matrices.\nFurther, we fully characterize codes for which the optimal stopping set\nenumerator equals the weight enumerator. \n\n"}
{"id": "cs/0610021", "contents": "Title: On the Fading Paper Achievable Region of the Fading MIMO Broadcast\n  Channel Abstract: We consider transmission over the ergodic fading multi-antenna broadcast\n(MIMO-BC) channel with partial channel state information at the transmitter and\nfull information at the receiver. Over the equivalent {\\it non}-fading channel,\ncapacity has recently been shown to be achievable using transmission schemes\nthat were designed for the ``dirty paper'' channel. We focus on a similar\n``fading paper'' model. The evaluation of the fading paper capacity is\ndifficult to obtain. We confine ourselves to the {\\it linear-assignment}\ncapacity, which we define, and use convex analysis methods to prove that its\nmaximizing distribution is Gaussian. We compare our fading-paper transmission\nto an application of dirty paper coding that ignores the partial state\ninformation and assumes the channel is fixed at the average fade. We show that\na gain is easily achieved by appropriately exploiting the information. We also\nconsider a cooperative upper bound on the sum-rate capacity as suggested by\nSato. We present a numeric example that indicates that our scheme is capable of\nrealizing much of this upper bound. \n\n"}
{"id": "cs/0611007", "contents": "Title: MIMO Multichannel Beamforming: SER and Outage Using New Eigenvalue\n  Distributions of Complex Noncentral Wishart Matrices Abstract: This paper analyzes MIMO systems with multichannel beamforming in Ricean\nfading. Our results apply to a wide class of multichannel systems which\ntransmit on the eigenmodes of the MIMO channel. We first present new\nclosed-form expressions for the marginal ordered eigenvalue distributions of\ncomplex noncentral Wishart matrices. These are used to characterize the\nstatistics of the signal to noise ratio (SNR) on each eigenmode. Based on this,\nwe present exact symbol error rate (SER) expressions. We also derive\nclosed-form expressions for the diversity order, array gain, and outage\nprobability. We show that the global SER performance is dominated by the\nsubchannel corresponding to the minimum channel singular value. We also show\nthat, at low outage levels, the outage probability varies inversely with the\nRicean K-factor for cases where transmission is only on the most dominant\nsubchannel (i.e. a singlechannel beamforming system). Numerical results are\npresented to validate the theoretical analysis. \n\n"}
{"id": "cs/0612012", "contents": "Title: Geographic Gossip on Geometric Random Graphs via Affine Combinations Abstract: In recent times, a considerable amount of work has been devoted to the\ndevelopment and analysis of gossip algorithms in Geometric Random Graphs. In a\nrecently introduced model termed \"Geographic Gossip,\" each node is aware of its\nposition but possesses no further information. Traditionally, gossip protocols\nhave always used convex linear combinations to achieve averaging. We develop a\nnew protocol for Geographic Gossip, in which counter-intuitively, we use {\\it\nnon-convex affine combinations} as updates in addition to convex combinations\nto accelerate the averaging process. The dependence of the number of\ntransmissions used by our algorithm on the number of sensors $n$ is $n\n\\exp(O(\\log \\log n)^2) = n^{1 + o(1)}$. For the previous algorithm, this\ndependence was $\\tilde{O}(n^{1.5})$. The exponent 1+ o(1) of our algorithm is\nasymptotically optimal. Our algorithm involves a hierarchical structure of\n$\\log \\log n$ depth and is not completely decentralized. However, the extent of\ncontrol exercised by a sensor on another is restricted to switching the other\non or off. \n\n"}
{"id": "cs/0701078", "contents": "Title: Low SNR Capacity of Fading Channels -- MIMO and Delay Spread Abstract: Discrete-time Rayleigh fading multiple-input multiple-output (MIMO) channels\nare considered, with no channel state information at the transmitter and\nreceiver. The fading is assumed to be correlated in time and independent from\nantenna to antenna. Peak and average transmit power constraints are imposed,\neither on the sum over antennas, or on each individual antenna. In both cases,\nan upper bound and an asymptotic lower bound, as the signal-to-noise ratio\napproaches zero, on the channel capacity are presented. The limit of normalized\ncapacity is identified under the sum power constraints, and, for a subclass of\nchannels, for individual power constraints. These results carry over to a SISO\nchannel with delay spread (i.e. frequency selective fading). \n\n"}
{"id": "cs/0702099", "contents": "Title: Discrete Memoryless Interference and Broadcast Channels with\n  Confidential Messages: Secrecy Rate Regions Abstract: We study information-theoretic security for discrete memoryless interference\nand broadcast channels with independent confidential messages sent to two\nreceivers. Confidential messages are transmitted to their respective receivers\nwith information-theoretic secrecy. That is, each receiver is kept in total\nignorance with respect to the message intended for the other receiver. The\nsecrecy level is measured by the equivocation rate at the eavesdropping\nreceiver. In this paper, we present inner and outer bounds on secrecy capacity\nregions for these two communication systems. The derived outer bounds have an\nidentical mutual information expression that applies to both channel models.\nThe difference is in the input distributions over which the expression is\noptimized. The inner bound rate regions are achieved by random binning\ntechniques. For the broadcast channel, a double-binning coding scheme allows\nfor both joint encoding and preserving of confidentiality. Furthermore, we show\nthat, for a special case of the interference channel, referred to as the switch\nchannel, the two bound bounds meet. Finally, we describe several transmission\nschemes for Gaussian interference channels and derive their achievable rate\nregions while ensuring mutual information-theoretic secrecy. An encoding scheme\nin which transmitters dedicate some of their power to create artificial noise\nis proposed and shown to outperform both time-sharing and simple multiplexed\ntransmission of the confidential messages. \n\n"}
{"id": "cs/0703005", "contents": "Title: State Amplification Abstract: We consider the problem of transmitting data at rate R over a state dependent\nchannel p(y|x,s) with the state information available at the sender and at the\nsame time conveying the information about the channel state itself to the\nreceiver. The amount of state information that can be learned at the receiver\nis captured by the mutual information I(S^n; Y^n) between the state sequence\nS^n and the channel output Y^n. The optimal tradeoff is characterized between\nthe information transmission rate R and the state uncertainty reduction rate\n\\Delta, when the state information is either causally or noncausally available\nat the sender. This result is closely related and in a sense dual to a recent\nstudy by Merhav and Shamai, which solves the problem of masking the state\ninformation from the receiver rather than conveying it. \n\n"}
{"id": "cs/0703129", "contents": "Title: A theorem on the quantum evaluation of Weight Enumerators for a certain\n  class of Cyclic Codes with a note on Cyclotomic cosets Abstract: This note is a stripped down version of a published paper on the Potts\npartition function, where we concentrate solely on the linear coding aspect of\nour approach. It is meant as a resource for people interested in coding theory\nbut who do not know much of the mathematics involved and how quantum\ncomputation may provide a speed up in the computation of a very important\nquantity in coding theory. We provide a theorem on the quantum computation of\nthe Weight Enumerator polynomial for a restricted family of cyclic codes. The\ncomplexity of obtaining an exact evaluation is $O(k^{2s}(\\log q)^{2})$, where\n$s$ is a parameter which determines the class of cyclic codes in question, $q$\nis the characteristic of the finite field over which the code is defined, and\n$k$ is the dimension of the code. We also provide an overview of cyclotomic\ncosets and discuss applications including how they can be used to speed up the\ncomputation of the weight enumerator polynomial (which is related to the Potts\npartition function). We also give an algorithm which returns the coset leaders\nand the size of each coset from the list $\\{0,1,2,...,N-1\\}$, whose time\ncomplexity is soft-O(N). This algorithm uses standard techniques but we include\nit as a resource for students. Note that cyclotomic cosets do not improve the\nasymptotic complexity of the computation of weight enumerators. \n\n"}
{"id": "math/0302172", "contents": "Title: Results on zeta functions for codes Abstract: We give a new and short proof of the Mallows-Sloane upper bound for self-dual\ncodes. We formulate a version of Greene's theorem for normalized weight\nenumerators. We relate normalized rank-generating polynomials to two-variable\nzeta functions. And we show that a self-dual code has the Clifford property,\nbut that the same property does not hold in general for formally self-dual\ncodes. \n\n"}
{"id": "math/0401045", "contents": "Title: Unitary Space Time Constellation Analysis: An Upper Bound for the\n  Diversity Abstract: The diversity product and the diversity sum are two very important parameters\nfor a good-performing unitary space time constellation. A basic question is\nwhat the maximal diversity product (or sum) is. In this paper we are going to\nderive general upper bounds on the diversity sum and the diversity product for\nunitary constellations of any dimension $n$ and any size $m$ using packing\ntechniques on the compact Lie group U(n). \n\n"}
{"id": "math/0606734", "contents": "Title: Codes in spherical caps Abstract: We consider bounds on codes in spherical caps and related problems in\ngeometry and coding theory. An extension of the Delsarte method is presented\nthat relates upper bounds on the size of spherical codes to upper bounds on\ncodes in caps. Several new upper bounds on codes in caps are derived.\nApplications of these bounds to estimates of the kissing numbers and one-sided\nkissing numbers are considered.\n  It is proved that the maximum size of codes in spherical caps for large\ndimensions is determined by the maximum size of spherical codes, so these\nproblems are asymptotically equivalent. \n\n"}
{"id": "quant-ph/0511175", "contents": "Title: A Proof of the Security of Quantum Key Distribution Abstract: We prove the security of theoretical quantum key distribution against the\nmost general attacks which can be performed on the channel, by an eavesdropper\nwho has unlimited computation abilities, and the full power allowed by the\nrules of classical and quantum physics. A key created that way can then be used\nto transmit secure messages such that their security is also unaffected in the\nfuture. \n\n"}
{"id": "quant-ph/0602129", "contents": "Title: Non-catastrophic Encoders and Encoder Inverses for Quantum Convolutional\n  Codes Abstract: We present an algorithm to construct quantum circuits for encoding and\ninverse encoding of quantum convolutional codes. We show that any quantum\nconvolutional code contains a subcode of finite index which has a\nnon-catastrophic encoding circuit. Our work generalizes the conditions for\nnon-catastrophic encoders derived in a paper by Ollivier and Tillich\n(quant-ph/0401134) which are applicable only for a restricted class of quantum\nconvolutional codes. We also show that the encoders and their inverses\nconstructed by our method naturally can be applied online, i.e., qubits can be\nsent and received with constant delay. \n\n"}
{"id": "quant-ph/0702005", "contents": "Title: A decoupling approach to the quantum capacity Abstract: We give a short proof that the coherent information is an achievable rate for\nthe transmission of quantum information through a noisy quantum channel. Our\nmethod is to produce random codes by performing a unitarily covariant\nprojective measurement on a typical subspace of a tensor power state. We show\nthat, provided the rank of each measurement operator is sufficiently small, the\ntransmitted data will with high probability be decoupled from the channel's\nenvironment. We also show that our construction leads to random codes whose\naverage input is close to a product state and outline a modification yielding\nunitarily invariant ensembles of maximally entangled codes. \n\n"}
{"id": "quant-ph/0703113", "contents": "Title: Quantum Convolutional BCH Codes Abstract: Quantum convolutional codes can be used to protect a sequence of qubits of\narbitrary length against decoherence. We introduce two new families of quantum\nconvolutional codes. Our construction is based on an algebraic method which\nallows to construct classical convolutional codes from block codes, in\nparticular BCH codes. These codes have the property that they contain their\nEuclidean, respectively Hermitian, dual codes. Hence, they can be used to\ndefine quantum convolutional codes by the stabilizer code construction. We\ncompute BCH-like bounds on the free distances which can be controlled as in the\ncase of block codes, and establish that the codes have non-catastrophic\nencoders. \n\n"}
