{"id": "0708.4284", "contents": "Title: Optimal Per-Edge Processing Times in the Semi-Streaming Model Abstract: We present semi-streaming algorithms for basic graph problems that have\noptimal per-edge processing times and therefore surpass all previous\nsemi-streaming algorithms for these tasks. The semi-streaming model, which is\nappropriate when dealing with massive graphs, forbids random access to the\ninput and restricts the memory to O(n*polylog n) bits.\n  Particularly, the formerly best per-edge processing times for finding the\nconnected components and a bipartition are O(alpha(n)), for determining\nk-vertex and k-edge connectivity O(k^2n) and O(n*log n) respectively for any\nconstant k and for computing a minimum spanning forest O(log n). All these time\nbounds we reduce to O(1).\n  Every presented algorithm determines a solution asymptotically as fast as the\nbest corresponding algorithm up to date in the classical RAM model, which\ntherefore cannot convert the advantage of unlimited memory and random access\ninto superior computing times for these problems. \n\n"}
{"id": "0806.2274", "contents": "Title: Exposing Multi-Relational Networks to Single-Relational Network Analysis\n  Algorithms Abstract: Many, if not most network analysis algorithms have been designed specifically\nfor single-relational networks; that is, networks in which all edges are of the\nsame type. For example, edges may either represent \"friendship,\" \"kinship,\" or\n\"collaboration,\" but not all of them together. In contrast, a multi-relational\nnetwork is a network with a heterogeneous set of edge labels which can\nrepresent relationships of various types in a single data structure. While\nmulti-relational networks are more expressive in terms of the variety of\nrelationships they can capture, there is a need for a general framework for\ntransferring the many single-relational network analysis algorithms to the\nmulti-relational domain. It is not sufficient to execute a single-relational\nnetwork analysis algorithm on a multi-relational network by simply ignoring\nedge labels. This article presents an algebra for mapping multi-relational\nnetworks to single-relational networks, thereby exposing them to\nsingle-relational network analysis algorithms. \n\n"}
{"id": "0808.3881", "contents": "Title: Counting Hexagonal Patches and Independent Sets in Circle Graphs Abstract: A hexagonal patch is a plane graph in which inner faces have length 6, inner\nvertices have degree 3, and boundary vertices have degree 2 or 3. We consider\nthe following counting problem: given a sequence of twos and threes, how many\nhexagonal patches exist with this degree sequence along the outer face? This\nproblem is motivated by the study of benzenoid hydrocarbons and fullerenes in\ncomputational chemistry. We give the first polynomial time algorithm for this\nproblem. We show that it can be reduced to counting maximum independent sets in\ncircle graphs, and give a simple and fast algorithm for this problem. \n\n"}
{"id": "0809.3170", "contents": "Title: A New Framework of Multistage Hypothesis Tests Abstract: In this paper, we have established a general framework of multistage\nhypothesis tests which applies to arbitrarily many mutually exclusive and\nexhaustive composite hypotheses. Within the new framework, we have constructed\nspecific multistage tests which rigorously control the risk of committing\ndecision errors and are more efficient than previous tests in terms of average\nsample number and the number of sampling operations. Without truncation, the\nsample numbers of our testing plans are absolutely bounded. \n\n"}
{"id": "0811.3055", "contents": "Title: Exact phase transition of backtrack-free search with implications on the\n  power of greedy algorithms Abstract: Backtracking is a basic strategy to solve constraint satisfaction problems\n(CSPs). A satisfiable CSP instance is backtrack-free if a solution can be found\nwithout encountering any dead-end during a backtracking search, implying that\nthe instance is easy to solve. We prove an exact phase transition of\nbacktrack-free search in some random CSPs, namely in Model RB and in Model RD.\nThis is the first time an exact phase transition of backtrack-free search can\nbe identified on some random CSPs. Our technical results also have interesting\nimplications on the power of greedy algorithms, on the width of random\nhypergraphs and on the exact satisfiability threshold of random CSPs. \n\n"}
{"id": "0812.2137", "contents": "Title: A Factor 3/2 Approximation for Generalized Steiner Tree Problem with\n  Distances One and Two Abstract: We design a 3/2 approximation algorithm for the Generalized Steiner Tree\nproblem (GST) in metrics with distances 1 and 2. This is the first polynomial\ntime approximation algorithm for a wide class of non-geometric metric GST\ninstances with approximation factor below 2. \n\n"}
{"id": "0903.4217", "contents": "Title: Conditional Probability Tree Estimation Analysis and Algorithms Abstract: We consider the problem of estimating the conditional probability of a label\nin time $O(\\log n)$, where $n$ is the number of possible labels. We analyze a\nnatural reduction of this problem to a set of binary regression problems\norganized in a tree structure, proving a regret bound that scales with the\ndepth of the tree. Motivated by this analysis, we propose the first online\nalgorithm which provably constructs a logarithmic depth tree on the set of\nlabels to solve this problem. We test the algorithm empirically, showing that\nit works succesfully on a dataset with roughly $10^6$ labels. \n\n"}
{"id": "0904.0727", "contents": "Title: (Meta) Kernelization Abstract: In a parameterized problem, every instance I comes with a positive integer k.\nThe problem is said to admit a polynomial kernel if, in polynomial time, one\ncan reduce the size of the instance I to a polynomial in k, while preserving\nthe answer. In this work we give two meta-theorems on kernelzation. The first\ntheorem says that all problems expressible in Counting Monadic Second Order\nLogic and satisfying a coverability property admit a polynomial kernel on\ngraphs of bounded genus. Our second result is that all problems that have\nfinite integer index and satisfy a weaker coverability property admit a linear\nkernel on graphs of bounded genus. These theorems unify and extend all\npreviously known kernelization results for planar graph problems. \n\n"}
{"id": "0908.4499", "contents": "Title: Monadic second-order model-checking on decomposable matroids Abstract: A notion of branch-width, which generalizes the one known for graphs, can be\ndefined for matroids. We first give a proof of the polynomial time\nmodel-checking of monadic second-order formulas on representable matroids of\nbounded branch-width, by reduction to monadic second-order formulas on trees.\nThis proof is much simpler than the one previously known. We also provide a\nlink between our logical approach and a grammar that allows to build matroids\nof bounded branch-width. Finally, we introduce a new class of non-necessarily\nrepresentable matroids, described by a grammar and on which monadic\nsecond-order formulas can be checked in linear time. \n\n"}
{"id": "0909.1062", "contents": "Title: New Approximation Algorithms for Minimum Enclosing Convex Shapes Abstract: Given $n$ points in a $d$ dimensional Euclidean space, the Minimum Enclosing\nBall (MEB) problem is to find the ball with the smallest radius which contains\nall $n$ points. We give a $O(nd\\Qcal/\\sqrt{\\epsilon})$ approximation algorithm\nfor producing an enclosing ball whose radius is at most $\\epsilon$ away from\nthe optimum (where $\\Qcal$ is an upper bound on the norm of the points). This\nimproves existing results using \\emph{coresets}, which yield a $O(nd/\\epsilon)$\ngreedy algorithm. Finding the Minimum Enclosing Convex Polytope (MECP) is a\nrelated problem wherein a convex polytope of a fixed shape is given and the aim\nis to find the smallest magnification of the polytope which encloses the given\npoints. For this problem we present a $O(mnd\\Qcal/\\epsilon)$ approximation\nalgorithm, where $m$ is the number of faces of the polytope. Our algorithms\nborrow heavily from convex duality and recently developed techniques in\nnon-smooth optimization, and are in contrast with existing methods which rely\non geometric arguments. In particular, we specialize the excessive gap\nframework of \\citet{Nesterov05a} to obtain our results. \n\n"}
{"id": "0911.4732", "contents": "Title: A graph polynomial for independent sets of bipartite graphs Abstract: We introduce a new graph polynomial that encodes interesting properties of\ngraphs, for example, the number of matchings and the number of perfect\nmatchings. Most importantly, for bipartite graphs the polynomial encodes the\nnumber of independent sets (#BIS).\n  We analyze the complexity of exact evaluation of the polynomial at rational\npoints and show that for most points exact evaluation is #P-hard (assuming the\ngeneralized Riemann hypothesis) and for the rest of the points exact evaluation\nis trivial.\n  We conjecture that a natural Markov chain can be used to approximately\nevaluate the polynomial for a range of parameters. The conjecture, if true,\nwould imply an approximate counting algorithm for #BIS, a problem shown, by\n[Dyer et al. 2004], to be complete (with respect to, so called, AP-reductions)\nfor a rich logically defined sub-class of #P. We give a mild support for our\nconjecture by proving that the Markov chain is rapidly mixing on trees. As a\nby-product we show that the \"single bond flip\" Markov chain for the random\ncluster model is rapidly mixing on constant tree-width graphs. \n\n"}
{"id": "0912.0685", "contents": "Title: Uniform sampling of undirected and directed graphs with a fixed degree\n  sequence Abstract: Many applications in network analysis require algorithms to sample uniformly\nat random from the set of all graphs with a prescribed degree sequence. We\npresent a Markov chain based approach which converges to the uniform\ndistribution of all realizations for both the directed and undirected case. It\nremains an open challenge whether these Markov chains are rapidly mixing.\n  For the case of directed graphs, we also explain in this paper that a popular\nswitching algorithm fails in general to sample uniformly at random because the\nstate graph of the Markov chain decomposes into different isomorphic\ncomponents. We call degree sequences for which the state graph is strongly\nconnected arc swap sequences. To handle arbitrary degree sequences, we develop\ntwo different solutions. The first uses an additional operation (a\nreorientation of induced directed 3-cycles) which makes the state graph\nstrongly connected, the second selects randomly one of the isomorphic\ncomponents and samples inside it. Our main contribution is a precise\ncharacterization of arc swap sequences, leading to an efficient recognition\nalgorithm. Finally, we point out some interesting consequences for network\nanalysis. \n\n"}
{"id": "0912.3563", "contents": "Title: Belief propagation for graph partitioning Abstract: We study the belief propagation algorithm for the graph bi-partitioning\nproblem, i.e. the ground state of the ferromagnetic Ising model at a fixed\nmagnetization. Application of a message passing scheme to a model with a fixed\nglobal parameter is not banal and we show that the magnetization can in fact be\nfixed in a local way within the belief propagation equations. Our method\nprovides the full phase diagram of the bi-partitioning problem on random\ngraphs, as well as an efficient heuristic solver that we anticipate to be\nuseful in a wide range of application of the partitioning problem. \n\n"}
{"id": "1002.0286", "contents": "Title: Systems of Linear Equations over $\\mathbb{F}_2$ and Problems\n  Parameterized Above Average Abstract: In the problem Max Lin, we are given a system $Az=b$ of $m$ linear equations\nwith $n$ variables over $\\mathbb{F}_2$ in which each equation is assigned a\npositive weight and we wish to find an assignment of values to the variables\nthat maximizes the excess, which is the total weight of satisfied equations\nminus the total weight of falsified equations. Using an algebraic approach, we\nobtain a lower bound for the maximum excess.\n  Max Lin Above Average (Max Lin AA) is a parameterized version of Max Lin\nintroduced by Mahajan et al. (Proc. IWPEC'06 and J. Comput. Syst. Sci. 75,\n2009). In Max Lin AA all weights are integral and we are to decide whether the\nmaximum excess is at least $k$, where $k$ is the parameter.\n  It is not hard to see that we may assume that no two equations in $Az=b$ have\nthe same left-hand side and $n={\\rm rank A}$. Using our maximum excess results,\nwe prove that, under these assumptions, Max Lin AA is fixed-parameter tractable\nfor a wide special case: $m\\le 2^{p(n)}$ for an arbitrary fixed function\n$p(n)=o(n)$.\n  Max $r$-Lin AA is a special case of Max Lin AA, where each equation has at\nmost $r$ variables. In Max Exact $r$-SAT AA we are given a multiset of $m$\nclauses on $n$ variables such that each clause has $r$ variables and asked\nwhether there is a truth assignment to the $n$ variables that satisfies at\nleast $(1-2^{-r})m + k2^{-r}$ clauses. Using our maximum excess results, we\nprove that for each fixed $r\\ge 2$, Max $r$-Lin AA and Max Exact $r$-SAT AA can\nbe solved in time $2^{O(k \\log k)}+m^{O(1)}.$ This improves\n$2^{O(k^2)}+m^{O(1)}$-time algorithms for the two problems obtained by Gutin et\nal. (IWPEC 2009) and Alon et al. (SODA 2010), respectively. \n\n"}
{"id": "1002.4658", "contents": "Title: Principal Component Analysis with Contaminated Data: The High\n  Dimensional Case Abstract: We consider the dimensionality-reduction problem (finding a subspace\napproximation of observed data) for contaminated data in the high dimensional\nregime, where the number of observations is of the same magnitude as the number\nof variables of each observation, and the data set contains some (arbitrarily)\ncorrupted observations. We propose a High-dimensional Robust Principal\nComponent Analysis (HR-PCA) algorithm that is tractable, robust to contaminated\npoints, and easily kernelizable. The resulting subspace has a bounded deviation\nfrom the desired one, achieves maximal robustness -- a breakdown point of 50%\nwhile all existing algorithms have a breakdown point of zero, and unlike\nordinary PCA algorithms, achieves optimality in the limit case where the\nproportion of corrupted points goes to zero. \n\n"}
{"id": "1004.1485", "contents": "Title: Are there any good digraph width measures? Abstract: Several different measures for digraph width have appeared in the last few\nyears. However, none of them shares all the \"nice\" properties of treewidth:\nFirst, being \\emph{algorithmically useful} i.e. admitting polynomial-time\nalgorithms for all $\\MS1$-definable problems on digraphs of bounded width. And,\nsecond, having nice \\emph{structural properties} i.e. being monotone under\ntaking subdigraphs and some form of arc contractions. As for the former,\n(undirected) $\\MS1$ seems to be the least common denominator of all reasonably\nexpressive logical languages on digraphs that can speak about the edge/arc\nrelation on the vertex set.The latter property is a necessary condition for a\nwidth measure to be characterizable by some version of the cops-and-robber game\ncharacterizing the ordinary treewidth. Our main result is that \\emph{any\nreasonable} algorithmically useful and structurally nice digraph measure cannot\nbe substantially different from the treewidth of the underlying undirected\ngraph. Moreover, we introduce \\emph{directed topological minors} and argue that\nthey are the weakest useful notion of minors for digraphs. \n\n"}
{"id": "1004.1729", "contents": "Title: On the bias of BFS Abstract: Breadth First Search (BFS) and other graph traversal techniques are widely\nused for measuring large unknown graphs, such as online social networks. It has\nbeen empirically observed that an incomplete BFS is biased toward high degree\nnodes. In contrast to more studied sampling techniques, such as random walks,\nthe precise bias of BFS has not been characterized to date. In this paper, we\nquantify the degree bias of BFS sampling. In particular, we calculate the node\ndegree distribution expected to be observed by BFS as a function of the\nfraction of covered nodes, in a random graph $RG(p_k)$ with a given degree\ndistribution $p_k$. Furthermore, we also show that, for $RG(p_k)$, all commonly\nused graph traversal techniques (BFS, DFS, Forest Fire, and Snowball Sampling)\nlead to the same bias, and we show how to correct for this bias. To give a\nbroader perspective, we compare this class of exploration techniques to random\nwalks that are well-studied and easier to analyze. Next, we study by simulation\nthe effect of graph properties not captured directly by our model. We find that\nthe bias gets amplified in graphs with strong positive assortativity. Finally,\nwe demonstrate the above results by sampling the Facebook social network, and\nwe provide some practical guidelines for graph sampling in practice. \n\n"}
{"id": "1005.2638", "contents": "Title: Hierarchical Clustering for Finding Symmetries and Other Patterns in\n  Massive, High Dimensional Datasets Abstract: Data analysis and data mining are concerned with unsupervised pattern finding\nand structure determination in data sets. \"Structure\" can be understood as\nsymmetry and a range of symmetries are expressed by hierarchy. Such symmetries\ndirectly point to invariants, that pinpoint intrinsic properties of the data\nand of the background empirical domain of interest. We review many aspects of\nhierarchy here, including ultrametric topology, generalized ultrametric,\nlinkages with lattices and other discrete algebraic structures and with p-adic\nnumber representations. By focusing on symmetries in data we have a powerful\nmeans of structuring and analyzing massive, high dimensional data stores. We\nillustrate the powerfulness of hierarchical clustering in case studies in\nchemistry and finance, and we provide pointers to other published case studies. \n\n"}
{"id": "1005.2791", "contents": "Title: A note on concentration of submodular functions Abstract: We survey a few concentration inequalities for submodular and fractionally\nsubadditive functions of independent random variables, implied by the entropy\nmethod for self-bounding functions. The power of these concentration bounds is\nthat they are dimension-free, in particular implying standard deviation\nO(\\sqrt{\\E[f]}) rather than O(\\sqrt{n}) which can be obtained for any\n1-Lipschitz function of n variables. \n\n"}
{"id": "1007.2484", "contents": "Title: Schnyder decompositions for regular plane graphs and application to\n  drawing Abstract: Schnyder woods are decompositions of simple triangulations into three\nedge-disjoint spanning trees crossing each other in a specific way. In this\narticle, we define a generalization of Schnyder woods to $d$-angulations (plane\ngraphs with faces of degree $d$) for all $d\\geq 3$. A \\emph{Schnyder\ndecomposition} is a set of $d$ spanning forests crossing each other in a\nspecific way, and such that each internal edge is part of exactly $d-2$ of the\nspanning forests. We show that a Schnyder decomposition exists if and only if\nthe girth of the $d$-angulation is $d$. As in the case of Schnyder woods\n($d=3$), there are alternative formulations in terms of orientations\n(\"fractional\" orientations when $d\\geq 5$) and in terms of corner-labellings.\nMoreover, the set of Schnyder decompositions on a fixed $d$-angulation of girth\n$d$ is a distributive lattice. We also show that the structures dual to\nSchnyder decompositions (on $d$-regular plane graphs of mincut $d$ rooted at a\nvertex $v^*$) are decompositions into $d$ spanning trees rooted at $v^*$ such\nthat each edge not incident to $v^*$ is used in opposite directions by two\ntrees. Additionally, for even values of $d$, we show that a subclass of\nSchnyder decompositions, which are called even, enjoy additional properties\nthat yield a reduced formulation; in the case d=4, these correspond to\nwell-studied structures on simple quadrangulations (2-orientations and\npartitions into 2 spanning trees). In the case d=4, the dual of even Schnyder\ndecompositions yields (planar) orthogonal and straight-line drawing algorithms.\nFor a 4-regular plane graph $G$ of mincut 4 with $n$ vertices plus a marked\nvertex $v$, the vertices of $G\\backslash v$ are placed on a $(n-1) \\times\n(n-1)$ grid according to a permutation pattern, and in the orthogonal drawing\neach of the $2n-2$ edges of $G\\backslash v$ has exactly one bend. Embedding\nalso the marked vertex $v$ is doable at the cost of two additional rows and\ncolumns and 8 additional bends for the 4 edges incident to $v$. We propose a\nfurther compaction step for the drawing algorithm and show that the obtained\ngrid-size is strongly concentrated around $25n/32\\times 25n/32$ for a uniformly\nrandom instance with $n$ vertices. \n\n"}
{"id": "1007.3622", "contents": "Title: A generalized risk approach to path inference based on hidden Markov\n  models Abstract: Motivated by the unceasing interest in hidden Markov models (HMMs), this\npaper re-examines hidden path inference in these models, using primarily a\nrisk-based framework. While the most common maximum a posteriori (MAP), or\nViterbi, path estimator and the minimum error, or Posterior Decoder (PD), have\nlong been around, other path estimators, or decoders, have been either only\nhinted at or applied more recently and in dedicated applications generally\nunfamiliar to the statistical learning community. Over a decade ago, however, a\nfamily of algorithmically defined decoders aiming to hybridize the two standard\nones was proposed (Brushe et al., 1998). The present paper gives a careful\nanalysis of this hybridization approach, identifies several problems and issues\nwith it and other previously proposed approaches, and proposes practical\nresolutions of those. Furthermore, simple modifications of the classical\ncriteria for hidden path recognition are shown to lead to a new class of\ndecoders. Dynamic programming algorithms to compute these decoders in the usual\nforward-backward manner are presented. A particularly interesting subclass of\nsuch estimators can be also viewed as hybrids of the MAP and PD estimators.\nSimilar to previously proposed MAP-PD hybrids, the new class is parameterized\nby a small number of tunable parameters. Unlike their algorithmic predecessors,\nthe new risk-based decoders are more clearly interpretable, and, most\nimportantly, work \"out of the box\" in practice, which is demonstrated on some\nreal bioinformatics tasks and data. Some further generalizations and\napplications are discussed in conclusion. \n\n"}
{"id": "1008.2159", "contents": "Title: Submodular Functions: Learnability, Structure, and Optimization Abstract: Submodular functions are discrete functions that model laws of diminishing\nreturns and enjoy numerous algorithmic applications. They have been used in\nmany areas, including combinatorial optimization, machine learning, and\neconomics. In this work we study submodular functions from a learning theoretic\nangle. We provide algorithms for learning submodular functions, as well as\nlower bounds on their learnability. In doing so, we uncover several novel\nstructural results revealing ways in which submodular functions can be both\nsurprisingly structured and surprisingly unstructured. We provide several\nconcrete implications of our work in other domains including algorithmic game\ntheory and combinatorial optimization.\n  At a technical level, this research combines ideas from many areas, including\nlearning theory (distributional learning and PAC-style analyses), combinatorics\nand optimization (matroids and submodular functions), and pseudorandomness\n(lossless expander graphs). \n\n"}
{"id": "1008.2159", "contents": "Title: Submodular Functions: Learnability, Structure, and Optimization Abstract: Submodular functions are discrete functions that model laws of diminishing\nreturns and enjoy numerous algorithmic applications. They have been used in\nmany areas, including combinatorial optimization, machine learning, and\neconomics. In this work we study submodular functions from a learning theoretic\nangle. We provide algorithms for learning submodular functions, as well as\nlower bounds on their learnability. In doing so, we uncover several novel\nstructural results revealing ways in which submodular functions can be both\nsurprisingly structured and surprisingly unstructured. We provide several\nconcrete implications of our work in other domains including algorithmic game\ntheory and combinatorial optimization.\n  At a technical level, this research combines ideas from many areas, including\nlearning theory (distributional learning and PAC-style analyses), combinatorics\nand optimization (matroids and submodular functions), and pseudorandomness\n(lossless expander graphs). \n\n"}
{"id": "1008.5209", "contents": "Title: Network Flow Algorithms for Structured Sparsity Abstract: We consider a class of learning problems that involve a structured\nsparsity-inducing norm defined as the sum of $\\ell_\\infty$-norms over groups of\nvariables. Whereas a lot of effort has been put in developing fast optimization\nmethods when the groups are disjoint or embedded in a specific hierarchical\nstructure, we address here the case of general overlapping groups. To this end,\nwe show that the corresponding optimization problem is related to network flow\noptimization. More precisely, the proximal problem associated with the norm we\nconsider is dual to a quadratic min-cost flow problem. We propose an efficient\nprocedure which computes its solution exactly in polynomial time. Our algorithm\nscales up to millions of variables, and opens up a whole new range of\napplications for structured sparse models. We present several experiments on\nimage and video data, demonstrating the applicability and scalability of our\napproach for various problems. \n\n"}
{"id": "1009.3240", "contents": "Title: A Unified View of Regularized Dual Averaging and Mirror Descent with\n  Implicit Updates Abstract: We study three families of online convex optimization algorithms:\nfollow-the-proximally-regularized-leader (FTRL-Proximal), regularized dual\naveraging (RDA), and composite-objective mirror descent. We first prove\nequivalence theorems that show all of these algorithms are instantiations of a\ngeneral FTRL update. This provides theoretical insight on previous experimental\nobservations. In particular, even though the FOBOS composite mirror descent\nalgorithm handles L1 regularization explicitly, it has been observed that RDA\nis even more effective at producing sparsity. Our results demonstrate that\nFOBOS uses subgradient approximations to the L1 penalty from previous rounds,\nleading to less sparsity than RDA, which handles the cumulative penalty in\nclosed form. The FTRL-Proximal algorithm can be seen as a hybrid of these two,\nand outperforms both on a large, real-world dataset.\n  Our second contribution is a unified analysis which produces regret bounds\nthat match (up to logarithmic terms) or improve the best previously known\nbounds. This analysis also extends these algorithms in two important ways: we\nsupport a more general type of composite objective and we analyze implicit\nupdates, which replace the subgradient approximation of the current loss\nfunction with an exact optimization. \n\n"}
{"id": "1011.1161", "contents": "Title: Multiarmed Bandit Problems with Delayed Feedback Abstract: In this paper we initiate the study of optimization of bandit type problems\nin scenarios where the feedback of a play is not immediately known. This arises\nnaturally in allocation problems which have been studied extensively in the\nliterature, albeit in the absence of delays in the feedback. We study this\nproblem in the Bayesian setting. In presence of delays, no solution with\nprovable guarantees is known to exist with sub-exponential running time.\n  We show that bandit problems with delayed feedback that arise in allocation\nsettings can be forced to have significant structure, with a slight loss in\noptimality. This structure gives us the ability to reason about the\nrelationship of single arm policies to the entangled optimum policy, and\neventually leads to a O(1) approximation for a significantly general class of\npriors. The structural insights we develop are of key interest and carry over\nto the setting where the feedback of an action is available instantaneously,\nand we improve all previous results in this setting as well. \n\n"}
{"id": "1012.4767", "contents": "Title: Multiple-source multiple-sink maximum flow in planar graphs Abstract: In this paper we show an O(n^(3/2) log^2 n) time algorithm for finding a\nmaximum flow in a planar graph with multiple sources and multiple sinks. This\nis the fastest algorithm whose running time depends only on the number of\nvertices in the graph. For general (non-planar) graphs the multiple-source\nmultiple-sink version of the maximum flow problem is as difficult as the\nstandard single-source single-sink version. However, the standard reduction\ndoes not preserve the planarity of the graph, and it is not known how to\ngeneralize existing maximum flow algorithms for planar graphs to the\nmultiple-source multiple-sink maximum flow problem. \n\n"}
{"id": "1012.5870", "contents": "Title: Multiple-Source Multiple-Sink Maximum Flow in Directed Planar Graphs in\n  $O(n^{1.5} \\log n)$ Time Abstract: We give an $O(n^{1.5} \\log n)$ algorithm that, given a directed planar graph\nwith arc capacities, a set of source nodes and a set of sink nodes, finds a\nmaximum flow from the sources to the sinks. \n\n"}
{"id": "1101.4439", "contents": "Title: Reproducing Kernel Banach Spaces with the l1 Norm II: Error Analysis for\n  Regularized Least Square Regression Abstract: A typical approach in estimating the learning rate of a regularized learning\nscheme is to bound the approximation error by the sum of the sampling error,\nthe hypothesis error and the regularization error. Using a reproducing kernel\nspace that satisfies the linear representer theorem brings the advantage of\ndiscarding the hypothesis error from the sum automatically. Following this\ndirection, we illustrate how reproducing kernel Banach spaces with the l1 norm\ncan be applied to improve the learning rate estimate of l1-regularization in\nmachine learning. \n\n"}
{"id": "1101.4609", "contents": "Title: Tight Bounds on Information Dissemination in Sparse Mobile Networks Abstract: Motivated by the growing interest in mobile systems, we study the dynamics of\ninformation dissemination between agents moving independently on a plane.\nFormally, we consider $k$ mobile agents performing independent random walks on\nan $n$-node grid. At time $0$, each agent is located at a random node of the\ngrid and one agent has a rumor. The spread of the rumor is governed by a\ndynamic communication graph process ${G_t(r) | t \\geq 0}$, where two agents are\nconnected by an edge in $G_t(r)$ iff their distance at time $t$ is within their\ntransmission radius $r$. Modeling the physical reality that the speed of radio\ntransmission is much faster than the motion of the agents, we assume that the\nrumor can travel throughout a connected component of $G_t$ before the graph is\naltered by the motion. We study the broadcast time $T_B$ of the system, which\nis the time it takes for all agents to know the rumor. We focus on the sparse\ncase (below the percolation point $r_c \\approx \\sqrt{n/k}$) where, with high\nprobability, no connected component in $G_t$ has more than a logarithmic number\nof agents and the broadcast time is dominated by the time it takes for many\nindependent random walks to meet each other. Quite surprisingly, we show that\nfor a system below the percolation point the broadcast time does not depend on\nthe relation between the mobility speed and the transmission radius. In fact,\nwe prove that $T_B = \\tilde{O}(n / \\sqrt{k})$ for any $0 \\leq r < r_c$, even\nwhen the transmission range is significantly larger than the mobility range in\none step, giving a tight characterization up to logarithmic factors. Our result\ncomplements a recent result of Peres et al. (SODA 2011) who showed that above\nthe percolation point the broadcast time is polylogarithmic in $k$. \n\n"}
{"id": "1105.4593", "contents": "Title: Submodular Function Maximization via the Multilinear Relaxation and\n  Contention Resolution Schemes Abstract: We consider the problem of maximizing a non-negative submodular set function\n$f:2^N \\rightarrow \\mathbb{R}_+$ over a ground set $N$ subject to a variety of\npacking type constraints including (multiple) matroid constraints, knapsack\nconstraints, and their intersections. In this paper we develop a general\nframework that allows us to derive a number of new results, in particular when\n$f$ may be a non-monotone function. Our algorithms are based on (approximately)\nmaximizing the multilinear extension $F$ of $f$ over a polytope $P$ that\nrepresents the constraints, and then effectively rounding the fractional\nsolution. Although this approach has been used quite successfully, it has been\nlimited in some important ways. We overcome these limitations as follows.\n  First, we give constant factor approximation algorithms to maximize $F$ over\na down-closed polytope $P$ described by an efficient separation oracle.\nPreviously this was known only for monotone functions. For non-monotone\nfunctions, a constant factor was known only when the polytope was either the\nintersection of a fixed number of knapsack constraints or a matroid polytope.\nSecond, we show that contention resolution schemes are an effective way to\nround a fractional solution, even when $f$ is non-monotone. In particular,\ncontention resolution schemes for different polytopes can be combined to handle\nthe intersection of different constraints. Via LP duality we show that a\ncontention resolution scheme for a constraint is related to the correlation gap\nof weighted rank functions of the constraint. This leads to an optimal\ncontention resolution scheme for the matroid polytope.\n  Our results provide a broadly applicable framework for maximizing linear and\nsubmodular functions subject to independence constraints. We give several\nillustrative examples. Contention resolution schemes may find other\napplications. \n\n"}
{"id": "1107.0088", "contents": "Title: Sparse Sums of Positive Semidefinite Matrices Abstract: Recently there has been much interest in \"sparsifying\" sums of rank one\nmatrices: modifying the coefficients such that only a few are nonzero, while\napproximately preserving the matrix that results from the sum. Results of this\nsort have found applications in many different areas, including sparsifying\ngraphs. In this paper we consider the more general problem of sparsifying sums\nof positive semidefinite matrices that have arbitrary rank.\n  We give several algorithms for solving this problem. The first algorithm is\nbased on the method of Batson, Spielman and Srivastava (2009). The second\nalgorithm is based on the matrix multiplicative weights update method of Arora\nand Kale (2007). We also highlight an interesting connection between these two\nalgorithms.\n  Our algorithms have numerous applications. We show how they can be used to\nconstruct graph sparsifiers with auxiliary constraints, sparsifiers of\nhypergraphs, and sparse solutions to semidefinite programs. \n\n"}
{"id": "1109.2304", "contents": "Title: Efficient Minimization of Higher Order Submodular Functions using\n  Monotonic Boolean Functions Abstract: Submodular function minimization is a key problem in a wide variety of\napplications in machine learning, economics, game theory, computer vision, and\nmany others. The general solver has a complexity of $O(n^3 \\log^2 n . E +n^4\n{\\log}^{O(1)} n)$ where $E$ is the time required to evaluate the function and\n$n$ is the number of variables \\cite{Lee2015}. On the other hand, many computer\nvision and machine learning problems are defined over special subclasses of\nsubmodular functions that can be written as the sum of many submodular cost\nfunctions defined over cliques containing few variables. In such functions, the\npseudo-Boolean (or polynomial) representation \\cite{BorosH02} of these\nsubclasses are of degree (or order, or clique size) $k$ where $k \\ll n$. In\nthis work, we develop efficient algorithms for the minimization of this useful\nsubclass of submodular functions. To do this, we define novel mapping that\ntransform submodular functions of order $k$ into quadratic ones. The underlying\nidea is to use auxiliary variables to model the higher order terms and the\ntransformation is found using a carefully constructed linear program. In\nparticular, we model the auxiliary variables as monotonic Boolean functions,\nallowing us to obtain a compact transformation using as few auxiliary variables\nas possible. \n\n"}
{"id": "1109.3843", "contents": "Title: Fast approximation of matrix coherence and statistical leverage Abstract: The statistical leverage scores of a matrix $A$ are the squared row-norms of\nthe matrix containing its (top) left singular vectors and the coherence is the\nlargest leverage score. These quantities are of interest in recently-popular\nproblems such as matrix completion and Nystr\\\"{o}m-based low-rank matrix\napproximation as well as in large-scale statistical data analysis applications\nmore generally; moreover, they are of interest since they define the key\nstructural nonuniformity that must be dealt with in developing fast randomized\nmatrix algorithms. Our main result is a randomized algorithm that takes as\ninput an arbitrary $n \\times d$ matrix $A$, with $n \\gg d$, and that returns as\noutput relative-error approximations to all $n$ of the statistical leverage\nscores. The proposed algorithm runs (under assumptions on the precise values of\n$n$ and $d$) in $O(n d \\log n)$ time, as opposed to the $O(nd^2)$ time required\nby the na\\\"{i}ve algorithm that involves computing an orthogonal basis for the\nrange of $A$. Our analysis may be viewed in terms of computing a relative-error\napproximation to an underconstrained least-squares approximation problem, or,\nrelatedly, it may be viewed as an application of Johnson-Lindenstrauss type\nideas. Several practically-important extensions of our basic result are also\ndescribed, including the approximation of so-called cross-leverage scores, the\nextension of these ideas to matrices with $n \\approx d$, and the extension to\nstreaming environments. \n\n"}
{"id": "1109.4979", "contents": "Title: Latent Semantic Learning with Structured Sparse Representation for Human\n  Action Recognition Abstract: This paper proposes a novel latent semantic learning method for extracting\nhigh-level features (i.e. latent semantics) from a large vocabulary of abundant\nmid-level features (i.e. visual keywords) with structured sparse\nrepresentation, which can help to bridge the semantic gap in the challenging\ntask of human action recognition. To discover the manifold structure of\nmidlevel features, we develop a spectral embedding approach to latent semantic\nlearning based on L1-graph, without the need to tune any parameter for graph\nconstruction as a key step of manifold learning. More importantly, we construct\nthe L1-graph with structured sparse representation, which can be obtained by\nstructured sparse coding with its structured sparsity ensured by novel L1-norm\nhypergraph regularization over mid-level features. In the new embedding space,\nwe learn latent semantics automatically from abundant mid-level features\nthrough spectral clustering. The learnt latent semantics can be readily used\nfor human action recognition with SVM by defining a histogram intersection\nkernel. Different from the traditional latent semantic analysis based on topic\nmodels, our latent semantic learning method can explore the manifold structure\nof mid-level features in both L1-graph construction and spectral embedding,\nwhich results in compact but discriminative high-level features. The\nexperimental results on the commonly used KTH action dataset and unconstrained\nYouTube action dataset show the superior performance of our method. \n\n"}
{"id": "1110.2828", "contents": "Title: Testing perfection is hard Abstract: A graph property P is strongly testable if for every fixed \\epsilon>0 there\nis a one-sided \\epsilon-tester for P whose query complexity is bounded by a\nfunction of \\epsilon. In classifying the strongly testable graph properties,\nthe first author and Shapira showed that any hereditary graph property (such as\nP the family of perfect graphs) is strongly testable. A property is easily\ntestable if it is strongly testable with query complexity bounded by a\npolynomial function of \\epsilon^{-1}, and otherwise it is hard. One of our main\nresults shows that testing perfectness is hard. The proof shows that testing\nperfectness is at least as hard as testing triangle-freeness, which is hard. On\nthe other hand, we show that induced P_3-freeness is easily testable. This\nsettles one of the two exceptional graphs, the other being C_4 (and its\ncomplement), left open in the characterization by the first author and Shapira\nof graphs H for which induced H-freeness is easily testable. \n\n"}
{"id": "1110.2897", "contents": "Title: Randomized Dimensionality Reduction for k-means Clustering Abstract: We study the topic of dimensionality reduction for $k$-means clustering.\nDimensionality reduction encompasses the union of two approaches: \\emph{feature\nselection} and \\emph{feature extraction}. A feature selection based algorithm\nfor $k$-means clustering selects a small subset of the input features and then\napplies $k$-means clustering on the selected features. A feature extraction\nbased algorithm for $k$-means clustering constructs a small set of new\nartificial features and then applies $k$-means clustering on the constructed\nfeatures. Despite the significance of $k$-means clustering as well as the\nwealth of heuristic methods addressing it, provably accurate feature selection\nmethods for $k$-means clustering are not known. On the other hand, two provably\naccurate feature extraction methods for $k$-means clustering are known in the\nliterature; one is based on random projections and the other is based on the\nsingular value decomposition (SVD).\n  This paper makes further progress towards a better understanding of\ndimensionality reduction for $k$-means clustering. Namely, we present the first\nprovably accurate feature selection method for $k$-means clustering and, in\naddition, we present two feature extraction methods. The first feature\nextraction method is based on random projections and it improves upon the\nexisting results in terms of time complexity and number of features needed to\nbe extracted. The second feature extraction method is based on fast approximate\nSVD factorizations and it also improves upon the existing results in terms of\ntime complexity. The proposed algorithms are randomized and provide\nconstant-factor approximation guarantees with respect to the optimal $k$-means\nobjective value. \n\n"}
{"id": "1111.5357", "contents": "Title: Digraph Complexity Measures and Applications in Formal Language Theory Abstract: We investigate structural complexity measures on digraphs, in particular the\ncycle rank. This concept is intimately related to a classical topic in formal\nlanguage theory, namely the star height of regular languages. We explore this\nconnection, and obtain several new algorithmic insights regarding both cycle\nrank and star height. Among other results, we show that computing the cycle\nrank is NP-complete, even for sparse digraphs of maximum outdegree 2.\nNotwithstanding, we provide both a polynomial-time approximation algorithm and\nan exponential-time exact algorithm for this problem. The former algorithm\nyields an O((log n)^(3/2))- approximation in polynomial time, whereas the\nlatter yields the optimum solution, and runs in time and space O*(1.9129^n) on\ndigraphs of maximum outdegree at most two. Regarding the star height problem,\nwe identify a subclass of the regular languages for which we can precisely\ndetermine the computational complexity of the star height problem. Namely, the\nstar height problem for bideterministic languages is NP-complete, and this\nholds already for binary alphabets. Then we translate the algorithmic results\nconcerning cycle rank to the bideterministic star height problem, thus giving a\npolynomial-time approximation as well as a reasonably fast exact exponential\nalgorithm for bideterministic star height. \n\n"}
{"id": "1111.6990", "contents": "Title: Shortest Non-trivial Cycles in Directed and Undirected Surface Graphs Abstract: Let G be a graph embedded on a surface of genus g with b boundary cycles. We\ndescribe algorithms to compute multiple types of non-trivial cycles in G, using\ndifferent techniques depending on whether or not G is an undirected graph. If G\nis undirected, then we give an algorithm to compute a shortest non-separating\ncycle in 2^O(g) n log log n time. Similar algorithms are given to compute a\nshortest non-contractible or non-null-homologous cycle in 2^O(g+b) n log log n\ntime. Our algorithms for undirected G combine an algorithm of Kutz with known\ntechniques for efficiently enumerating homotopy classes of curves that may be\nshortest non-trivial cycles.\n  Our main technical contributions in this work arise from assuming G is a\ndirected graph with possibly asymmetric edge weights. For this case, we give an\nalgorithm to compute a shortest non-contractible cycle in G in O((g^3 + g b)n\nlog n) time. In order to achieve this time bound, we use a restriction of the\ninfinite cyclic cover that may be useful in other contexts. We also describe an\nalgorithm to compute a shortest non-null-homologous cycle in G in O((g^2 + g\nb)n log n) time, extending a known algorithm of Erickson to compute a shortest\nnon-separating cycle. In both the undirected and directed cases, our algorithms\nimprove the best time bounds known for many values of g and b. \n\n"}
{"id": "1112.1313", "contents": "Title: The Target Set Selection Problem on Cycle Permutation Graphs,\n  Generalized Petersen Graphs and Torus Cordalis Abstract: In this paper we consider a fundamental problem in the area of viral\nmarketing, called T{\\scriptsize ARGET} S{\\scriptsize ET} S{\\scriptsize\nELECTION} problem.\n  In a a viral marketing setting, social networks are modeled by graphs with\npotential customers of a new product as vertices and friend relationships as\nedges, where each vertex $v$ is assigned a threshold value $\\theta(v)$. The\nthresholds represent the different latent tendencies of customers (vertices) to\nbuy the new product when their friend (neighbors) do.\n  Consider a repetitive process on social network $(G,\\theta)$ where each\nvertex $v$ is associated with two states, active and inactive, which indicate\nwhether $v$ is persuaded into buying the new product. Suppose we are given a\ntarget set $S\\subseteq V(G)$. Initially, all vertices in $G$ are inactive. At\ntime step 0, we choose all vertices in $S$ to become active.\n  Then, at every time step $t>0$, all vertices that were active in time step\n$t-1$ remain active, and we activate any vertex $v$ if at least $\\theta(v)$ of\nits neighbors were active at time step $t-1$. The activation process terminates\nwhen no more vertices can get activated. We are interested in the following\noptimization problem, called T{\\scriptsize ARGET} S{\\scriptsize ET}\nS{\\scriptsize ELECTION}: Finding a target set $S$ of smallest possible size\nthat activates all vertices of $G$. There is an important and well-studied\nthreshold called strict majority threshold, where for every vertex $v$ in $G$\nwe have $\\theta(v)=\\lceil{(d(v) +1)/2}\\rceil$ and $d(v)$ is the degree of $v$\nin $G$. In this paper, we consider the T{\\scriptsize ARGET} S{\\scriptsize ET}\nS{\\scriptsize ELECTION} problem under strict majority thresholds and focus on\nthree popular regular network structures: cycle permutation graphs, generalized\nPetersen graphs and torus cordalis. \n\n"}
{"id": "1112.4105", "contents": "Title: epsilon-Samples of Kernels Abstract: We study the worst case error of kernel density estimates via subset\napproximation. A kernel density estimate of a distribution is the convolution\nof that distribution with a fixed kernel (e.g. Gaussian kernel). Given a subset\n(i.e. a point set) of the input distribution, we can compare the kernel density\nestimates of the input distribution with that of the subset and bound the worst\ncase error. If the maximum error is eps, then this subset can be thought of as\nan eps-sample (aka an eps-approximation) of the range space defined with the\ninput distribution as the ground set and the fixed kernel representing the\nfamily of ranges. Interestingly, in this case the ranges are not binary, but\nhave a continuous range (for simplicity we focus on kernels with range of\n[0,1]); these allow for smoother notions of range spaces.\n  It turns out, the use of this smoother family of range spaces has an added\nbenefit of greatly decreasing the size required for eps-samples. For instance,\nin the plane the size is O((1/eps^{4/3}) log^{2/3}(1/eps)) for disks (based on\nVC-dimension arguments) but is only O((1/eps) sqrt{log (1/eps)}) for Gaussian\nkernels and for kernels with bounded slope that only affect a bounded domain.\nThese bounds are accomplished by studying the discrepancy of these \"kernel\"\nrange spaces, and here the improvement in bounds are even more pronounced. In\nthe plane, we show the discrepancy is O(sqrt{log n}) for these kernels, whereas\nfor balls there is a lower bound of Omega(n^{1/4}). \n\n"}
{"id": "1201.0365", "contents": "Title: Lower bounding edit distances between permutations Abstract: A number of fields, including the study of genome rearrangements and the\ndesign of interconnection networks, deal with the connected problems of sorting\npermutations in \"as few moves as possible\", using a given set of allowed\noperations, or computing the number of moves the sorting process requires,\noften referred to as the \\emph{distance} of the permutation. These operations\noften act on just one or two segments of the permutation, e.g. by reversing one\nsegment or exchanging two segments. The \\emph{cycle graph} of the permutation\nto sort is a fundamental tool in the theory of genome rearrangements, and has\nproved useful in settling the complexity of many variants of the above\nproblems. In this paper, we present an algebraic reinterpretation of the cycle\ngraph of a permutation $\\pi$ as an even permutation $\\bar{\\pi}$, and show how\nto reformulate our sorting problems in terms of particular factorisations of\nthe latter permutation. Using our framework, we recover known results in a\nsimple and unified way, and obtain a new lower bound on the \\emph{prefix\ntransposition distance} (where a \\emph{prefix transposition} displaces the\ninitial segment of a permutation), which is shown to outperform previous\nresults. Moreover, we use our approach to improve the best known lower bound on\nthe \\emph{prefix transposition diameter} from $2n/3$ to $\\lfloor3n/4\\rfloor$,\nand investigate a few relations between some statistics on $\\pi$ and\n$\\bar{\\pi}$. \n\n"}
{"id": "1201.4603", "contents": "Title: Rainbow Connectivity of Sparse Random Graphs Abstract: An edge colored graph $G$ is rainbow edge connected if any two vertices are\nconnected by a path whose edges have distinct colors. The rainbow connectivity\nof a connected graph $G$, denoted by $rc(G)$, is the smallest number of colors\nthat are needed in order to make $G$ rainbow connected.\n  In this work we study the rainbow connectivity of binomial random graphs at\nthe connectivity threshold $p=\\frac{\\log n+\\om}{n}$ where $\\om=\\om(n)\\to\\infty$\nand ${\\om}=o(\\log{n})$ and of random $r$-regular graphs where $r \\geq 3$ is a\nfixed integer. Specifically, we prove that the rainbow connectivity $rc(G)$ of\n$G=G(n,p)$ satisfies $rc(G) \\sim \\max\\set{Z_1,diameter(G)}$ with high\nprobability (\\whp). Here $Z_1$ is the number of vertices in $G$ whose degree\nequals 1 and the diameter of $G$ is asymptotically equal to $\\diam$ \\whp.\nFinally, we prove that the rainbow connectivity $rc(G)$ of the random\n$r$-regular graph $G=G(n,r)$ satisfies $rc(G) =O(\\log^2{n})$ \\whp. \n\n"}
{"id": "1202.2624", "contents": "Title: A linear-time algorithm for finding a complete graph minor in a dense\n  graph Abstract: Let g(t) be the minimum number such that every graph G with average degree\nd(G) \\geq g(t) contains a K_{t}-minor. Such a function is known to exist, as\noriginally shown by Mader. Kostochka and Thomason independently proved that\ng(t) \\in \\Theta(t*sqrt{log t}). This article shows that for all fixed \\epsilon\n> 0 and fixed sufficiently large t \\geq t(\\epsilon), if d(G) \\geq\n(2+\\epsilon)g(t) then we can find this K_{t}-minor in linear time. This\nimproves a previous result by Reed and Wood who gave a linear-time algorithm\nwhen d(G) \\geq 2^{t-2}. \n\n"}
{"id": "1202.3505", "contents": "Title: Near-optimal Coresets For Least-Squares Regression Abstract: We study (constrained) least-squares regression as well as multiple response\nleast-squares regression and ask the question of whether a subset of the data,\na coreset, suffices to compute a good approximate solution to the regression.\nWe give deterministic, low order polynomial-time algorithms to construct such\ncoresets with approximation guarantees, together with lower bounds indicating\nthat there is not much room for improvement upon our results. \n\n"}
{"id": "1202.4419", "contents": "Title: Induced Disjoint Paths in Claw-Free Graphs Abstract: Paths P1,...,Pk in a graph G=(V,E) are said to be mutually induced if for any\n1 <= i < j <= k, Pi and Pj have neither common vertices nor adjacent vertices\n(except perhaps their end-vertices). The Induced Disjoint Paths problem is to\ntest whether a graph G with k pairs of specified vertices (si,ti) contains k\nmutually induced paths Pi such that Pi connects si and ti for i=1,...,k. We\nshow that this problem is fixed-parameter tractable for claw-free graphs when\nparameterized by k. Several related problems, such as the k-in-a-Path problem,\nare proven to be fixed-parameter tractable for claw-free graphs as well. We\nshow that an improvement of these results in certain directions is unlikely,\nfor example by noting that the Induced Disjoint Paths problem cannot have a\npolynomial kernel for line graphs (a type of claw-free graphs), unless NP\n\\subseteq coNP/poly. Moreover, the problem becomes NP-complete, even when k=2,\nfor the more general class of K_1,4-free graphs. Finally, we show that the\nn^O(k)-time algorithm of Fiala et al. for testing whether a claw-free graph\ncontains some k-vertex graph H as a topological induced minor is essentially\noptimal by proving that this problem is W[1]-hard even if G and H are line\ngraphs. \n\n"}
{"id": "1202.6033", "contents": "Title: The Power of Local Information in Social Networks Abstract: We study the power of \\textit{local information algorithms} for optimization\nproblems on social networks. We focus on sequential algorithms for which the\nnetwork topology is initially unknown and is revealed only within a local\nneighborhood of vertices that have been irrevocably added to the output set.\nThe distinguishing feature of this setting is that locality is necessitated by\nconstraints on the network information visible to the algorithm, rather than\nbeing desirable for reasons of efficiency or parallelizability. In this sense,\nchanges to the level of network visibility can have a significant impact on\nalgorithm design.\n  We study a range of problems under this model of algorithms with local\ninformation. We first consider the case in which the underlying graph is a\npreferential attachment network. We show that one can find the node of maximum\ndegree in the network in a polylogarithmic number of steps, using an\nopportunistic algorithm that repeatedly queries the visible node of maximum\ndegree. This addresses an open question of Bollob{\\'a}s and Riordan. In\ncontrast, local information algorithms require a linear number of queries to\nsolve the problem on arbitrary networks.\n  Motivated by problems faced by recruiters in online networks, we also\nconsider network coverage problems such as finding a minimum dominating set.\nFor this optimization problem we show that, if each node added to the output\nset reveals sufficient information about the set's neighborhood, then it is\npossible to design randomized algorithms for general networks that nearly match\nthe best approximations possible even with full access to the graph structure.\nWe show that this level of visibility is necessary.\n  We conclude that a network provider's decision of how much structure to make\nvisible to its users can have a significant effect on a user's ability to\ninteract strategically with the network. \n\n"}
{"id": "1203.0160", "contents": "Title: Scaling Datalog for Machine Learning on Big Data Abstract: In this paper, we present the case for a declarative foundation for\ndata-intensive machine learning systems. Instead of creating a new system for\neach specific flavor of machine learning task, or hardcoding new optimizations,\nwe argue for the use of recursive queries to program a variety of machine\nlearning systems. By taking this approach, database query optimization\ntechniques can be utilized to identify effective execution plans, and the\nresulting runtime plans can be executed on a single unified data-parallel query\nprocessing engine. As a proof of concept, we consider two programming\nmodels--Pregel and Iterative Map-Reduce-Update---from the machine learning\ndomain, and show how they can be captured in Datalog, tuned for a specific\ntask, and then compiled into an optimized physical plan. Experiments performed\non a large computing cluster with real data demonstrate that this declarative\napproach can provide very good performance while offering both increased\ngenerality and programming ease. \n\n"}
{"id": "1203.2507", "contents": "Title: Deviation optimal learning using greedy Q-aggregation Abstract: Given a finite family of functions, the goal of model selection aggregation\nis to construct a procedure that mimics the function from this family that is\nthe closest to an unknown regression function. More precisely, we consider a\ngeneral regression model with fixed design and measure the distance between\nfunctions by the mean squared error at the design points. While procedures\nbased on exponential weights are known to solve the problem of model selection\naggregation in expectation, they are, surprisingly, sub-optimal in deviation.\nWe propose a new formulation called Q-aggregation that addresses this\nlimitation; namely, its solution leads to sharp oracle inequalities that are\noptimal in a minimax sense. Moreover, based on the new formulation, we design\ngreedy Q-aggregation procedures that produce sparse aggregation models\nachieving the optimal rate. The convergence and performance of these greedy\nprocedures are illustrated and compared with other standard methods on\nsimulated examples. \n\n"}
{"id": "1203.5181", "contents": "Title: $k$-MLE: A fast algorithm for learning statistical mixture models Abstract: We describe $k$-MLE, a fast and efficient local search algorithm for learning\nfinite statistical mixtures of exponential families such as Gaussian mixture\nmodels. Mixture models are traditionally learned using the\nexpectation-maximization (EM) soft clustering technique that monotonically\nincreases the incomplete (expected complete) likelihood. Given prescribed\nmixture weights, the hard clustering $k$-MLE algorithm iteratively assigns data\nto the most likely weighted component and update the component models using\nMaximum Likelihood Estimators (MLEs). Using the duality between exponential\nfamilies and Bregman divergences, we prove that the local convergence of the\ncomplete likelihood of $k$-MLE follows directly from the convergence of a dual\nadditively weighted Bregman hard clustering. The inner loop of $k$-MLE can be\nimplemented using any $k$-means heuristic like the celebrated Lloyd's batched\nor Hartigan's greedy swap updates. We then show how to update the mixture\nweights by minimizing a cross-entropy criterion that implies to update weights\nby taking the relative proportion of cluster points, and reiterate the mixture\nparameter update and mixture weight update processes until convergence. Hard EM\nis interpreted as a special case of $k$-MLE when both the component update and\nthe weight update are performed successively in the inner loop. To initialize\n$k$-MLE, we propose $k$-MLE++, a careful initialization of $k$-MLE guaranteeing\nprobabilistically a global bound on the best possible complete likelihood. \n\n"}
{"id": "1204.5810", "contents": "Title: Geometry of Online Packing Linear Programs Abstract: We consider packing LP's with $m$ rows where all constraint coefficients are\nnormalized to be in the unit interval. The n columns arrive in random order and\nthe goal is to set the corresponding decision variables irrevocably when they\narrive so as to obtain a feasible solution maximizing the expected reward.\nPrevious (1 - \\epsilon)-competitive algorithms require the right-hand side of\nthe LP to be Omega((m/\\epsilon^2) log (n/\\epsilon)), a bound that worsens with\nthe number of columns and rows. However, the dependence on the number of\ncolumns is not required in the single-row case and known lower bounds for the\ngeneral case are also independent of n.\n  Our goal is to understand whether the dependence on n is required in the\nmulti-row case, making it fundamentally harder than the single-row version. We\nrefute this by exhibiting an algorithm which is (1 - \\epsilon)-competitive as\nlong as the right-hand sides are Omega((m^2/\\epsilon^2) log (m/\\epsilon)). Our\ntechniques refine previous PAC-learning based approaches which interpret the\nonline decisions as linear classifications of the columns based on sampled dual\nprices. The key ingredient of our improvement comes from a non-standard\ncovering argument together with the realization that only when the columns of\nthe LP belong to few 1-d subspaces we can obtain small such covers; bounding\nthe size of the cover constructed also relies on the geometry of linear\nclassifiers. General packing LP's are handled by perturbing the input columns,\nwhich can be seen as making the learning problem more robust. \n\n"}
{"id": "1205.4471", "contents": "Title: Sparse Signal Recovery in the Presence of Intra-Vector and Inter-Vector\n  Correlation Abstract: This work discusses the problem of sparse signal recovery when there is\ncorrelation among the values of non-zero entries. We examine intra-vector\ncorrelation in the context of the block sparse model and inter-vector\ncorrelation in the context of the multiple measurement vector model, as well as\ntheir combination. Algorithms based on the sparse Bayesian learning are\npresented and the benefits of incorporating correlation at the algorithm level\nare discussed. The impact of correlation on the limits of support recovery is\nalso discussed highlighting the different impact intra-vector and inter-vector\ncorrelations have on such limits. \n\n"}
{"id": "1207.0560", "contents": "Title: Algorithms for Approximate Minimization of the Difference Between\n  Submodular Functions, with Applications Abstract: We extend the work of Narasimhan and Bilmes [30] for minimizing set functions\nrepresentable as a difference between submodular functions. Similar to [30],\nour new algorithms are guaranteed to monotonically reduce the objective\nfunction at every step. We empirically and theoretically show that the\nper-iteration cost of our algorithms is much less than [30], and our algorithms\ncan be used to efficiently minimize a difference between submodular functions\nunder various combinatorial constraints, a problem not previously addressed. We\nprovide computational bounds and a hardness result on the mul- tiplicative\ninapproximability of minimizing the difference between submodular functions. We\nshow, however, that it is possible to give worst-case additive bounds by\nproviding a polynomial time computable lower-bound on the minima. Finally we\nshow how a number of machine learning problems can be modeled as minimizing the\ndifference between submodular functions. We experimentally show the validity of\nour algorithms by testing them on the problem of feature selection with\nsubmodular cost features. \n\n"}
{"id": "1207.1794", "contents": "Title: Design, Evaluation and Analysis of Combinatorial Optimization Heuristic\n  Algorithms Abstract: Combinatorial optimization is widely applied in a number of areas nowadays.\nUnfortunately, many combinatorial optimization problems are NP-hard which\nusually means that they are unsolvable in practice. However, it is often\nunnecessary to have an exact solution. In this case one may use heuristic\napproach to obtain a near-optimal solution in some reasonable time.\n  We focus on two combinatorial optimization problems, namely the Generalized\nTraveling Salesman Problem and the Multidimensional Assignment Problem. The\nfirst problem is an important generalization of the Traveling Salesman Problem;\nthe second one is a generalization of the Assignment Problem for an arbitrary\nnumber of dimensions. Both problems are NP-hard and have hosts of applications.\n  In this work, we discuss different aspects of heuristics design and\nevaluation. A broad spectrum of related subjects, covered in this research,\nincludes test bed generation and analysis, implementation and performance\nissues, local search neighborhoods and efficient exploration algorithms,\nmetaheuristics design and population sizing in memetic algorithm.\n  The most important results are obtained in the areas of local search and\nmemetic algorithms for the considered problems. In both cases we have\nsignificantly advanced the existing knowledge on the local search neighborhoods\nand algorithms by systematizing and improving the previous results. We have\nproposed a number of efficient heuristics which dominate the existing\nalgorithms in a wide range of time/quality requirements.\n  Several new approaches, introduced in our memetic algorithms, make them the\nstate-of-the-art metaheuristics for the corresponding problems. Population\nsizing is one of the most promising among these approaches; it is expected to\nbe applicable to virtually any memetic algorithm. \n\n"}
{"id": "1207.6549", "contents": "Title: Analysis of an exhaustive search algorithm in random graphs and the\n  n^{c\\log n} -asymptotics Abstract: We analyze the cost used by a naive exhaustive search algorithm for finding a\nmaximum independent set in random graphs under the usual G_{n,p} -model where\neach possible edge appears independently with the same probability p. The\nexpected cost turns out to be of the less common asymptotic order n^{c\\log n},\nwhich we explore from several different perspectives. Also we collect many\ninstances where such an order appears, from algorithmics to analysis, from\nprobability to algebra. The limiting distribution of the cost required by the\nalgorithm under a purely idealized random model is proved to be normal. The\napproach we develop is of some generality and is amenable for other graph\nalgorithms. \n\n"}
{"id": "1208.0378", "contents": "Title: Fast Planar Correlation Clustering for Image Segmentation Abstract: We describe a new optimization scheme for finding high-quality correlation\nclusterings in planar graphs that uses weighted perfect matching as a\nsubroutine. Our method provides lower-bounds on the energy of the optimal\ncorrelation clustering that are typically fast to compute and tight in\npractice. We demonstrate our algorithm on the problem of image segmentation\nwhere this approach outperforms existing global optimization techniques in\nminimizing the objective and is competitive with the state of the art in\nproducing high-quality segmentations. \n\n"}
{"id": "1208.0787", "contents": "Title: A Random Walk Based Model Incorporating Social Information for\n  Recommendations Abstract: Collaborative filtering (CF) is one of the most popular approaches to build a\nrecommendation system. In this paper, we propose a hybrid collaborative\nfiltering model based on a Makovian random walk to address the data sparsity\nand cold start problems in recommendation systems. More precisely, we construct\na directed graph whose nodes consist of items and users, together with item\ncontent, user profile and social network information. We incorporate user's\nratings into edge settings in the graph model. The model provides personalized\nrecommendations and predictions to individuals and groups. The proposed\nalgorithms are evaluated on MovieLens and Epinions datasets. Experimental\nresults show that the proposed methods perform well compared with other\ngraph-based methods, especially in the cold start case. \n\n"}
{"id": "1208.1544", "contents": "Title: Guess Who Rated This Movie: Identifying Users Through Subspace\n  Clustering Abstract: It is often the case that, within an online recommender system, multiple\nusers share a common account. Can such shared accounts be identified solely on\nthe basis of the user- provided ratings? Once a shared account is identified,\ncan the different users sharing it be identified as well? Whenever such user\nidentification is feasible, it opens the way to possible improvements in\npersonalized recommendations, but also raises privacy concerns. We develop a\nmodel for composite accounts based on unions of linear subspaces, and use\nsubspace clustering for carrying out the identification task. We show that a\nsignificant fraction of such accounts is identifiable in a reliable manner, and\nillustrate potential uses for personalized recommendation. \n\n"}
{"id": "1208.2294", "contents": "Title: Learning pseudo-Boolean k-DNF and Submodular Functions Abstract: We prove that any submodular function f: {0,1}^n -> {0,1,...,k} can be\nrepresented as a pseudo-Boolean 2k-DNF formula. Pseudo-Boolean DNFs are a\nnatural generalization of DNF representation for functions with integer range.\nEach term in such a formula has an associated integral constant. We show that\nan analog of Hastad's switching lemma holds for pseudo-Boolean k-DNFs if all\nconstants associated with the terms of the formula are bounded.\n  This allows us to generalize Mansour's PAC-learning algorithm for k-DNFs to\npseudo-Boolean k-DNFs, and hence gives a PAC-learning algorithm with membership\nqueries under the uniform distribution for submodular functions of the form\nf:{0,1}^n -> {0,1,...,k}. Our algorithm runs in time polynomial in n, k^{O(k\n\\log k / \\epsilon)}, 1/\\epsilon and log(1/\\delta) and works even in the\nagnostic setting. The line of previous work on learning submodular functions\n[Balcan, Harvey (STOC '11), Gupta, Hardt, Roth, Ullman (STOC '11), Cheraghchi,\nKlivans, Kothari, Lee (SODA '12)] implies only n^{O(k)} query complexity for\nlearning submodular functions in this setting, for fixed epsilon and delta.\n  Our learning algorithm implies a property tester for submodularity of\nfunctions f:{0,1}^n -> {0, ..., k} with query complexity polynomial in n for\nk=O((\\log n/ \\loglog n)^{1/2}) and constant proximity parameter \\epsilon. \n\n"}
{"id": "1209.1873", "contents": "Title: Stochastic Dual Coordinate Ascent Methods for Regularized Loss\n  Minimization Abstract: Stochastic Gradient Descent (SGD) has become popular for solving large scale\nsupervised machine learning optimization problems such as SVM, due to their\nstrong theoretical guarantees. While the closely related Dual Coordinate Ascent\n(DCA) method has been implemented in various software packages, it has so far\nlacked good convergence analysis. This paper presents a new analysis of\nStochastic Dual Coordinate Ascent (SDCA) showing that this class of methods\nenjoy strong theoretical guarantees that are comparable or better than SGD.\nThis analysis justifies the effectiveness of SDCA for practical applications. \n\n"}
{"id": "1209.3523", "contents": "Title: Eight-Fifth Approximation for TSP Paths Abstract: We prove the approximation ratio 8/5 for the metric $\\{s,t\\}$-path-TSP\nproblem, and more generally for shortest connected $T$-joins.\n  The algorithm that achieves this ratio is the simple \"Best of Many\" version\nof Christofides' algorithm (1976), suggested by An, Kleinberg and Shmoys\n(2012), which consists in determining the best Christofides $\\{s,t\\}$-tour out\nof those constructed from a family $\\Fscr_{>0}$ of trees having a convex\ncombination dominated by an optimal solution $x^*$ of the fractional\nrelaxation. They give the approximation guarantee $\\frac{\\sqrt{5}+1}{2}$ for\nsuch an $\\{s,t\\}$-tour, which is the first improvement after the 5/3 guarantee\nof Hoogeveen's Christofides type algorithm (1991). Cheriyan, Friggstad and Gao\n(2012) extended this result to a 13/8-approximation of shortest connected\n$T$-joins, for $|T|\\ge 4$.\n  The ratio 8/5 is proved by simplifying and improving the approach of An,\nKleinberg and Shmoys that consists in completing $x^*/2$ in order to dominate\nthe cost of \"parity correction\" for spanning trees. We partition the edge-set\nof each spanning tree in $\\Fscr_{>0}$ into an $\\{s,t\\}$-path (or more\ngenerally, into a $T$-join) and its complement, which induces a decomposition\nof $x^*$. This decomposition can be refined and then efficiently used to\ncomplete $x^*/2$ without using linear programming or particular properties of\n$T$, but by adding to each cut deficient for $x^*/2$ an individually tailored\nexplicitly given vector, inherent in $x^*$.\n  A simple example shows that the Best of Many Christofides algorithm may not\nfind a shorter $\\{s,t\\}$-tour than 3/2 times the incidentally common optima of\nthe problem and of its fractional relaxation. \n\n"}
{"id": "1210.2698", "contents": "Title: Improved Approximation Lower Bounds for Vertex Cover on Power Law Graphs\n  and Some Generalizations Abstract: We prove new explicit inapproximability results for the Vertex Cover Problem\non the Power Law Graphs and some functional generalizations of that class of\ngraphs. Our results depend on special bounded degree amplifier constructions\nfor those classes of graphs and could be also of independent interest. \n\n"}
{"id": "1210.4081", "contents": "Title: Getting Feasible Variable Estimates From Infeasible Ones: MRF Local\n  Polytope Study Abstract: This paper proposes a method for construction of approximate feasible primal\nsolutions from dual ones for large-scale optimization problems possessing\ncertain separability properties. Whereas infeasible primal estimates can\ntypically be produced from (sub-)gradients of the dual function, it is often\nnot easy to project them to the primal feasible set, since the projection\nitself has a complexity comparable to the complexity of the initial problem. We\npropose an alternative efficient method to obtain feasibility and show that its\nproperties influencing the convergence to the optimum are similar to the\nproperties of the Euclidean projection. We apply our method to the local\npolytope relaxation of inference problems for Markov Random Fields and\ndemonstrate its superiority over existing methods. \n\n"}
{"id": "1210.6917", "contents": "Title: Sampling-based proofs of almost-periodicity results and algorithmic\n  applications Abstract: We give new combinatorial proofs of known almost-periodicity results for\nsumsets of sets with small doubling in the spirit of Croot and Sisask, whose\nalmost-periodicity lemma has had far-reaching implications in additive\ncombinatorics. We provide an alternative (and L^p-norm free) point of view,\nwhich allows for proofs to easily be converted to probabilistic algorithms that\ndecide membership in almost-periodic sumsets of dense subsets of F_2^n.\n  As an application, we give a new algorithmic version of the quasipolynomial\nBogolyubov-Ruzsa lemma recently proved by Sanders. Together with the results by\nthe last two authors, this implies an algorithmic version of the quadratic\nGoldreich-Levin theorem in which the number of terms in the quadratic Fourier\ndecomposition of a given function is quasipolynomial in the error parameter,\ncompared with an exponential dependence previously proved by the authors. It\nalso improves the running time of the algorithm to have quasipolynomial\ndependence instead of an exponential one.\n  We also give an application to the problem of finding large subspaces in\nsumsets of dense sets. Green showed that the sumset of a dense subset of F_2^n\ncontains a large subspace. Using Fourier analytic methods, Sanders proved that\nsuch a subspace must have dimension bounded below by a constant times the\ndensity times n. We provide an alternative (and L^p norm-free) proof of a\ncomparable bound, which is analogous to a recent result of Croot, Laba and\nSisask in the integers. \n\n"}
{"id": "1211.2717", "contents": "Title: Proximal Stochastic Dual Coordinate Ascent Abstract: We introduce a proximal version of dual coordinate ascent method. We\ndemonstrate how the derived algorithmic framework can be used for numerous\nregularized loss minimization problems, including $\\ell_1$ regularization and\nstructured output SVM. The convergence rates we obtain match, and sometimes\nimprove, state-of-the-art results. \n\n"}
{"id": "1211.5414", "contents": "Title: Analysis of a randomized approximation scheme for matrix multiplication Abstract: This note gives a simple analysis of a randomized approximation scheme for\nmatrix multiplication proposed by Sarlos (2006) based on a random rotation\nfollowed by uniform column sampling. The result follows from a matrix version\nof Bernstein's inequality and a tail inequality for quadratic forms in\nsubgaussian random vectors. \n\n"}
{"id": "1211.7110", "contents": "Title: Algorithms for discovering and proving theorems about permutation\n  patterns Abstract: We present an algorithm, called BiSC, that describes the patterns avoided by\na given set of permutations. It automatically conjectures the statements of\nknown theorems such as the descriptions of stack-sortable (Knuth 1975) and\nWest-2-stack-sortable permutations (West 1990), smooth (Lakshmibai and Sandhya\n1990) and forest-like permutations (Bousquet-Melou and Butler 2007), and simsun\npermutations (Branden and Claesson 2011). The algorithm has also been used to\ndiscover new theorems and conjectures related to Young tableaux,\nWilf-equivalences and sorting devices. We further give algorithms to prove a\ncomplete description of preimages of pattern classes under certain sorting\ndevices. These generalize an algorithm of Claesson and Ulfarsson (2012) and\nallow us to prove a linear time algorithm for finding occurrences of the\npattern 4312. \n\n"}
{"id": "1301.0114", "contents": "Title: Tree-based Arithmetic and Compressed Representations of Giant Numbers Abstract: Can we do arithmetic in a completely different way, with a radically\ndifferent data structure? Could this approach provide practical benefits, like\noperations on giant numbers while having an average performance similar to\ntraditional bitstring representations?\n  While answering these questions positively, our tree based representation\ndescribed in this paper comes with a few extra benefits: it compresses giant\nnumbers such that, for instance, the largest known prime number as well as its\nrelated perfect number are represented as trees of small sizes. The same also\napplies to Fermat numbers and important computations like exponentiation of two\nbecome constant time operations.\n  At the same time, succinct representations of sparse sets, multisets and\nsequences become possible through bijections to our tree-represented natural\nnumbers. \n\n"}
{"id": "1301.1299", "contents": "Title: Automated Variational Inference in Probabilistic Programming Abstract: We present a new algorithm for approximate inference in probabilistic\nprograms, based on a stochastic gradient for variational programs. This method\nis efficient without restrictions on the probabilistic program; it is\nparticularly practical for distributions which are not analytically tractable,\nincluding highly structured distributions that arise in probabilistic programs.\nWe show how to automatically derive mean-field probabilistic programs and\noptimize them, and demonstrate that our perspective improves inference\nefficiency over other algorithms. \n\n"}
{"id": "1301.3780", "contents": "Title: Bounds on the Size of Sound Monotone Switching Networks Accepting\n  Permutation Sets of Directed Trees Abstract: In this paper, we prove almost tight bounds on the size of sound monotone\nswitching networks accepting permutations sets of directed trees. This roughly\ncorresponds to proving almost tight bounds bounds on the monotone memory\nefficiency of the directed ST-connectivity problem for the special case in\nwhich the input graph is guaranteed to have no path from s to t or be\nisomorphic to a specific directed tree. \n\n"}
{"id": "1301.5220", "contents": "Title: Properties of the Least Squares Temporal Difference learning algorithm Abstract: This paper presents four different ways of looking at the well-known Least\nSquares Temporal Differences (LSTD) algorithm for computing the value function\nof a Markov Reward Process, each of them leading to different insights: the\noperator-theory approach via the Galerkin method, the statistical approach via\ninstrumental variables, the linear dynamical system view as well as the limit\nof the TD iteration. We also give a geometric view of the algorithm as an\noblique projection. Furthermore, there is an extensive comparison of the\noptimization problem solved by LSTD as compared to Bellman Residual\nMinimization (BRM). We then review several schemes for the regularization of\nthe LSTD solution. We then proceed to treat the modification of LSTD for the\ncase of episodic Markov Reward Processes. \n\n"}
{"id": "1302.2576", "contents": "Title: The trace norm constrained matrix-variate Gaussian process for multitask\n  bipartite ranking Abstract: We propose a novel hierarchical model for multitask bipartite ranking. The\nproposed approach combines a matrix-variate Gaussian process with a generative\nmodel for task-wise bipartite ranking. In addition, we employ a novel trace\nconstrained variational inference approach to impose low rank structure on the\nposterior matrix-variate Gaussian process. The resulting posterior covariance\nfunction is derived in closed form, and the posterior mean function is the\nsolution to a matrix-variate regression with a novel spectral elastic net\nregularizer. Further, we show that variational inference for the trace\nconstrained matrix-variate Gaussian process combined with maximum likelihood\nparameter estimation for the bipartite ranking model is jointly convex. Our\nmotivating application is the prioritization of candidate disease genes. The\ngoal of this task is to aid the identification of unobserved associations\nbetween human genes and diseases using a small set of observed associations as\nwell as kernels induced by gene-gene interaction networks and disease\nontologies. Our experimental results illustrate the performance of the proposed\nmodel on real world datasets. Moreover, we find that the resulting low rank\nsolution improves the computational scalability of training and testing as\ncompared to baseline models. \n\n"}
{"id": "1302.4389", "contents": "Title: Maxout Networks Abstract: We consider the problem of designing models to leverage a recently introduced\napproximate model averaging technique called dropout. We define a simple new\nmodel called maxout (so named because its output is the max of a set of inputs,\nand because it is a natural companion to dropout) designed to both facilitate\noptimization by dropout and improve the accuracy of dropout's fast approximate\nmodel averaging technique. We empirically verify that the model successfully\naccomplishes both of these tasks. We use maxout and dropout to demonstrate\nstate of the art classification performance on four benchmark datasets: MNIST,\nCIFAR-10, CIFAR-100, and SVHN. \n\n"}
{"id": "1303.4207", "contents": "Title: Improving CUR Matrix Decomposition and the Nystr\\\"{o}m Approximation via\n  Adaptive Sampling Abstract: The CUR matrix decomposition and the Nystr\\\"{o}m approximation are two\nimportant low-rank matrix approximation techniques. The Nystr\\\"{o}m method\napproximates a symmetric positive semidefinite matrix in terms of a small\nnumber of its columns, while CUR approximates an arbitrary data matrix by a\nsmall number of its columns and rows. Thus, CUR decomposition can be regarded\nas an extension of the Nystr\\\"{o}m approximation.\n  In this paper we establish a more general error bound for the adaptive\ncolumn/row sampling algorithm, based on which we propose more accurate CUR and\nNystr\\\"{o}m algorithms with expected relative-error bounds. The proposed CUR\nand Nystr\\\"{o}m algorithms also have low time complexity and can avoid\nmaintaining the whole data matrix in RAM. In addition, we give theoretical\nanalysis for the lower error bounds of the standard Nystr\\\"{o}m method and the\nensemble Nystr\\\"{o}m method. The main theoretical results established in this\npaper are novel, and our analysis makes no special assumption on the data\nmatrices. \n\n"}
{"id": "1303.6370", "contents": "Title: Convex Tensor Decomposition via Structured Schatten Norm Regularization Abstract: We discuss structured Schatten norms for tensor decomposition that includes\ntwo recently proposed norms (\"overlapped\" and \"latent\") for\nconvex-optimization-based tensor decomposition, and connect tensor\ndecomposition with wider literature on structured sparsity. Based on the\nproperties of the structured Schatten norms, we mathematically analyze the\nperformance of \"latent\" approach for tensor decomposition, which was\nempirically found to perform better than the \"overlapped\" approach in some\nsettings. We show theoretically that this is indeed the case. In particular,\nwhen the unknown true tensor is low-rank in a specific mode, this approach\nperforms as good as knowing the mode with the smallest rank. Along the way, we\nshow a novel duality result for structures Schatten norms, establish the\nconsistency, and discuss the identifiability of this approach. We confirm\nthrough numerical simulations that our theoretical prediction can precisely\npredict the scaling behavior of the mean squared error. \n\n"}
{"id": "1303.6437", "contents": "Title: New Inapproximability Bounds for TSP Abstract: In this paper, we study the approximability of the metric Traveling Salesman\nProblem (TSP) and prove new explicit inapproximability bounds for that problem.\nThe best up to now known hardness of approximation bounds were 185/184 for the\nsymmetric case (due to Lampis) and 117/116 for the asymmetric case (due to\nPapadimitriou and Vempala). We construct here two new bounded occurrence CSP\nreductions which improve these bounds to 123/122 and 75/74, respectively. The\nlatter bound is the first improvement in more than a decade for the case of the\nasymmetric TSP. One of our main tools, which may be of independent interest, is\na new construction of a bounded degree wheel amplifier used in the proof of our\nresults. \n\n"}
{"id": "1304.6800", "contents": "Title: Approximation Hardness of Graphic TSP on Cubic Graphs Abstract: We prove explicit approximation hardness results for the Graphic TSP on cubic\nand subcubic graphs as well as the new inapproximability bounds for the\ncorresponding instances of the (1,2)-TSP. The proof technique uses new modular\nconstructions of simulating gadgets for the restricted cubic and subcubic\ninstances. The modular constructions used in the paper could be also of\nindependent interest. \n\n"}
{"id": "1304.8087", "contents": "Title: Uniqueness of Tensor Decompositions with Applications to Polynomial\n  Identifiability Abstract: We give a robust version of the celebrated result of Kruskal on the\nuniqueness of tensor decompositions: we prove that given a tensor whose\ndecomposition satisfies a robust form of Kruskal's rank condition, it is\npossible to approximately recover the decomposition if the tensor is known up\nto a sufficiently small (inverse polynomial) error.\n  Kruskal's theorem has found many applications in proving the identifiability\nof parameters for various latent variable models and mixture models such as\nHidden Markov models, topic models etc. Our robust version immediately implies\nidentifiability using only polynomially many samples in many of these settings.\nThis polynomial identifiability is an essential first step towards efficient\nlearning algorithms for these models.\n  Recently, algorithms based on tensor decompositions have been used to\nestimate the parameters of various hidden variable models efficiently in\nspecial cases as long as they satisfy certain \"non-degeneracy\" properties. Our\nmethods give a way to go beyond this non-degeneracy barrier, and establish\npolynomial identifiability of the parameters under much milder conditions.\nGiven the importance of Kruskal's theorem in the tensor literature, we expect\nthat this robust version will have several applications beyond the settings we\nexplore in this work. \n\n"}
{"id": "1305.1535", "contents": "Title: Probabilistic Constructions of Computable Objects and a Computable\n  Version of Lov\\'asz Local Lemma Abstract: A nonconstructive proof can be used to prove the existence of an object with\nsome properties without providing an explicit example of such an object. A\nspecial case is a probabilistic proof where we show that an object with\nrequired properties appears with some positive probability in some random\nprocess. Can we use such arguments to prove the existence of a computable\ninfinite object? Sometimes yes: following [8], we show how the notion of a\nlayerwise computable mapping can be used to prove a computable version of\nLov\\'asz local lemma. (A survey of Moser-Tardos proof is included to make the\npaper self-contained.) \n\n"}
{"id": "1305.2545", "contents": "Title: Bandits with Knapsacks Abstract: Multi-armed bandit problems are the predominant theoretical model of\nexploration-exploitation tradeoffs in learning, and they have countless\napplications ranging from medical trials, to communication networks, to Web\nsearch and advertising. In many of these application domains the learner may be\nconstrained by one or more supply (or budget) limits, in addition to the\ncustomary limitation on the time horizon. The literature lacks a general model\nencompassing these sorts of problems. We introduce such a model, called\n\"bandits with knapsacks\", that combines aspects of stochastic integer\nprogramming with online learning. A distinctive feature of our problem, in\ncomparison to the existing regret-minimization literature, is that the optimal\npolicy for a given latent distribution may significantly outperform the policy\nthat plays the optimal fixed arm. Consequently, achieving sublinear regret in\nthe bandits-with-knapsacks problem is significantly more challenging than in\nconventional bandit problems.\n  We present two algorithms whose reward is close to the information-theoretic\noptimum: one is based on a novel \"balanced exploration\" paradigm, while the\nother is a primal-dual algorithm that uses multiplicative updates. Further, we\nprove that the regret achieved by both algorithms is optimal up to\npolylogarithmic factors. We illustrate the generality of the problem by\npresenting applications in a number of different domains including electronic\ncommerce, routing, and scheduling. As one example of a concrete application, we\nconsider the problem of dynamic posted pricing with limited supply and obtain\nthe first algorithm whose regret, with respect to the optimal dynamic policy,\nis sublinear in the supply. \n\n"}
{"id": "1306.1716", "contents": "Title: Fast greedy algorithm for subspace clustering from corrupted and\n  incomplete data Abstract: We describe the Fast Greedy Sparse Subspace Clustering (FGSSC) algorithm\nproviding an efficient method for clustering data belonging to a few\nlow-dimensional linear or affine subspaces. The main difference of our\nalgorithm from predecessors is its ability to work with noisy data having a\nhigh rate of erasures (missed entries with the known coordinates) and errors\n(corrupted entries with unknown coordinates). We discuss here how to implement\nthe fast version of the greedy algorithm with the maximum efficiency whose\ngreedy strategy is incorporated into iterations of the basic algorithm.\n  We provide numerical evidences that, in the subspace clustering capability,\nthe fast greedy algorithm outperforms not only the existing state-of-the art\nSSC algorithm taken by the authors as a basic algorithm but also the recent\nGSSC algorithm. At the same time, its computational cost is only slightly\nhigher than the cost of SSC.\n  The numerical evidence of the algorithm significant advantage is presented\nfor a few synthetic models as well as for the Extended Yale B dataset of facial\nimages. In particular, the face recognition misclassification rate turned out\nto be 6-20 times lower than for the SSC algorithm. We provide also the\nnumerical evidence that the FGSSC algorithm is able to perform clustering of\ncorrupted data efficiently even when the sum of subspace dimensions\nsignificantly exceeds the dimension of the ambient space. \n\n"}
{"id": "1306.2978", "contents": "Title: Graphs with Plane Outside-Obstacle Representations Abstract: An \\emph{obstacle representation} of a graph consists of a set of polygonal\nobstacles and a distinct point for each vertex such that two points see each\nother if and only if the corresponding vertices are adjacent. Obstacle\nrepresentations are a recent generalization of classical polygon--vertex\nvisibility graphs, for which the characterization and recognition problems are\nlong-standing open questions.\n  In this paper, we study \\emph{plane outside-obstacle representations}, where\nall obstacles lie in the unbounded face of the representation and no two\nvisibility segments cross. We give a combinatorial characterization of the\nbiconnected graphs that admit such a representation. Based on this\ncharacterization, we present a simple linear-time recognition algorithm for\nthese graphs. As a side result, we show that the plane vertex--polygon\nvisibility graphs are exactly the maximal outerplanar graphs and that every\nchordal outerplanar graph has an outside-obstacle representation. \n\n"}
{"id": "1306.3525", "contents": "Title: Approximation Algorithms for Bayesian Multi-Armed Bandit Problems Abstract: In this paper, we consider several finite-horizon Bayesian multi-armed bandit\nproblems with side constraints which are computationally intractable (NP-Hard)\nand for which no optimal (or near optimal) algorithms are known to exist with\nsub-exponential running time. All of these problems violate the standard\nexchange property, which assumes that the reward from the play of an arm is not\ncontingent upon when the arm is played. Not only are index policies suboptimal\nin these contexts, there has been little analysis of such policies in these\nproblem settings. We show that if we consider near-optimal policies, in the\nsense of approximation algorithms, then there exists (near) index policies.\nConceptually, if we can find policies that satisfy an approximate version of\nthe exchange property, namely, that the reward from the play of an arm depends\non when the arm is played to within a constant factor, then we have an avenue\ntowards solving these problems. However such an approximate version of the\nidling bandit property does not hold on a per-play basis and are shown to hold\nin a global sense. Clearly, such a property is not necessarily true of\narbitrary single arm policies and finding such single arm policies is\nnontrivial. We show that by restricting the state spaces of arms we can find\nsingle arm policies and that these single arm policies can be combined into\nglobal (near) index policies where the approximate version of the exchange\nproperty is true in expectation. The number of different bandit problems that\ncan be addressed by this technique already demonstrate its wide applicability. \n\n"}
{"id": "1306.5918", "contents": "Title: A Randomized Nonmonotone Block Proximal Gradient Method for a Class of\n  Structured Nonlinear Programming Abstract: We propose a randomized nonmonotone block proximal gradient (RNBPG) method\nfor minimizing the sum of a smooth (possibly nonconvex) function and a\nblock-separable (possibly nonconvex nonsmooth) function. At each iteration,\nthis method randomly picks a block according to any prescribed probability\ndistribution and solves typically several associated proximal subproblems that\nusually have a closed-form solution, until a certain progress on objective\nvalue is achieved. In contrast to the usual randomized block coordinate descent\nmethod [23,20], our method has a nonmonotone flavor and uses variable stepsizes\nthat can partially utilize the local curvature information of the smooth\ncomponent of objective function. We show that any accumulation point of the\nsolution sequence of the method is a stationary point of the problem {\\it\nalmost surely} and the method is capable of finding an approximate stationary\npoint with high probability. We also establish a sublinear rate of convergence\nfor the method in terms of the minimal expected squared norm of certain\nproximal gradients over the iterations. When the problem under consideration is\nconvex, we show that the expected objective values generated by RNBPG converge\nto the optimal value of the problem. Under some assumptions, we further\nestablish a sublinear and linear rate of convergence on the expected objective\nvalues generated by a monotone version of RNBPG. Finally, we conduct some\npreliminary experiments to test the performance of RNBPG on the\n$\\ell_1$-regularized least-squares problem and a dual SVM problem in machine\nlearning. The computational results demonstrate that our method substantially\noutperforms the randomized block coordinate {\\it descent} method with fixed or\nvariable stepsizes. \n\n"}
{"id": "1307.3301", "contents": "Title: Optimal Bounds on Approximation of Submodular and XOS Functions by\n  Juntas Abstract: We investigate the approximability of several classes of real-valued\nfunctions by functions of a small number of variables ({\\em juntas}). Our main\nresults are tight bounds on the number of variables required to approximate a\nfunction $f:\\{0,1\\}^n \\rightarrow [0,1]$ within $\\ell_2$-error $\\epsilon$ over\nthe uniform distribution: 1. If $f$ is submodular, then it is $\\epsilon$-close\nto a function of $O(\\frac{1}{\\epsilon^2} \\log \\frac{1}{\\epsilon})$ variables.\nThis is an exponential improvement over previously known results. We note that\n$\\Omega(\\frac{1}{\\epsilon^2})$ variables are necessary even for linear\nfunctions. 2. If $f$ is fractionally subadditive (XOS) it is $\\epsilon$-close\nto a function of $2^{O(1/\\epsilon^2)}$ variables. This result holds for all\nfunctions with low total $\\ell_1$-influence and is a real-valued analogue of\nFriedgut's theorem for boolean functions. We show that $2^{\\Omega(1/\\epsilon)}$\nvariables are necessary even for XOS functions.\n  As applications of these results, we provide learning algorithms over the\nuniform distribution. For XOS functions, we give a PAC learning algorithm that\nruns in time $2^{poly(1/\\epsilon)} poly(n)$. For submodular functions we give\nan algorithm in the more demanding PMAC learning model (Balcan and Harvey,\n2011) which requires a multiplicative $1+\\gamma$ factor approximation with\nprobability at least $1-\\epsilon$ over the target distribution. Our uniform\ndistribution algorithm runs in time $2^{poly(1/(\\gamma\\epsilon))} poly(n)$.\nThis is the first algorithm in the PMAC model that over the uniform\ndistribution can achieve a constant approximation factor arbitrarily close to 1\nfor all submodular functions. As follows from the lower bounds in (Feldman et\nal., 2013) both of these algorithms are close to optimal. We also give\napplications for proper learning, testing and agnostic learning with value\nqueries of these classes. \n\n"}
{"id": "1308.1006", "contents": "Title: Fast Semidifferential-based Submodular Function Optimization Abstract: We present a practical and powerful new framework for both unconstrained and\nconstrained submodular function optimization based on discrete\nsemidifferentials (sub- and super-differentials). The resulting algorithms,\nwhich repeatedly compute and then efficiently optimize submodular\nsemigradients, offer new and generalize many old methods for submodular\noptimization. Our approach, moreover, takes steps towards providing a unifying\nparadigm applicable to both submodular min- imization and maximization,\nproblems that historically have been treated quite distinctly. The practicality\nof our algorithms is important since interest in submodularity, owing to its\nnatural and wide applicability, has recently been in ascendance within machine\nlearning. We analyze theoretical properties of our algorithms for minimization\nand maximization, and show that many state-of-the-art maximization algorithms\nare special cases. Lastly, we complement our theoretical analyses with\nsupporting empirical experiments. \n\n"}
{"id": "1308.1762", "contents": "Title: Spatial mixing and approximation algorithms for graphs with bounded\n  connective constant Abstract: The hard core model in statistical physics is a probability distribution on\nindependent sets in a graph in which the weight of any independent set I is\nproportional to lambda^(|I|), where lambda > 0 is the vertex activity. We show\nthat there is an intimate connection between the connective constant of a graph\nand the phenomenon of strong spatial mixing (decay of correlations) for the\nhard core model; specifically, we prove that the hard core model with vertex\nactivity lambda < lambda_c(Delta + 1) exhibits strong spatial mixing on any\ngraph of connective constant Delta, irrespective of its maximum degree, and\nhence derive an FPTAS for the partition function of the hard core model on such\ngraphs. Here lambda_c(d) := d^d/(d-1)^(d+1) is the critical activity for the\nuniqueness of the Gibbs measure of the hard core model on the infinite d-ary\ntree. As an application, we show that the partition function can be efficiently\napproximated with high probability on graphs drawn from the random graph model\nG(n,d/n) for all lambda < e/d, even though the maximum degree of such graphs is\nunbounded with high probability.\n  We also improve upon Weitz's bounds for strong spatial mixing on bounded\ndegree graphs (Weitz, 2006) by providing a computationally simple method which\nuses known estimates of the connective constant of a lattice to obtain bounds\non the vertex activities lambda for which the hard core model on the lattice\nexhibits strong spatial mixing. Using this framework, we improve upon these\nbounds for several lattices including the Cartesian lattice in dimensions 3 and\nhigher.\n  Our techniques also allow us to relate the threshold for the uniqueness of\nthe Gibbs measure on a general tree to its branching factor (Lyons, 1989). \n\n"}
{"id": "1308.3665", "contents": "Title: On Sparsification for Computing Treewidth Abstract: We investigate whether an n-vertex instance (G,k) of Treewidth, asking\nwhether the graph G has treewidth at most k, can efficiently be made sparse\nwithout changing its answer. By giving a special form of OR-cross-composition,\nwe prove that this is unlikely: if there is an e > 0 and a polynomial-time\nalgorithm that reduces n-vertex Treewidth instances to equivalent instances, of\nan arbitrary problem, with O(n^{2-e}) bits, then NP is in coNP/poly and the\npolynomial hierarchy collapses to its third level.\n  Our sparsification lower bound has implications for structural\nparameterizations of Treewidth: parameterizations by measures that do not\nexceed the vertex count, cannot have kernels with O(k^{2-e}) bits for any e >\n0, unless NP is in coNP/poly. Motivated by the question of determining the\noptimal kernel size for Treewidth parameterized by vertex cover, we improve the\nO(k^3)-vertex kernel from Bodlaender et al. (STACS 2011) to a kernel with\nO(k^2) vertices. Our improved kernel is based on a novel form of\ntreewidth-invariant set. We use the q-expansion lemma of Fomin et al. (STACS\n2011) to find such sets efficiently in graphs whose vertex count is\nsuperquadratic in their vertex cover number. \n\n"}
{"id": "1308.5546", "contents": "Title: Sparse and Non-Negative BSS for Noisy Data Abstract: Non-negative blind source separation (BSS) has raised interest in various\nfields of research, as testified by the wide literature on the topic of\nnon-negative matrix factorization (NMF). In this context, it is fundamental\nthat the sources to be estimated present some diversity in order to be\nefficiently retrieved. Sparsity is known to enhance such contrast between the\nsources while producing very robust approaches, especially to noise. In this\npaper we introduce a new algorithm in order to tackle the blind separation of\nnon-negative sparse sources from noisy measurements. We first show that\nsparsity and non-negativity constraints have to be carefully applied on the\nsought-after solution. In fact, improperly constrained solutions are unlikely\nto be stable and are therefore sub-optimal. The proposed algorithm, named nGMCA\n(non-negative Generalized Morphological Component Analysis), makes use of\nproximal calculus techniques to provide properly constrained solutions. The\nperformance of nGMCA compared to other state-of-the-art algorithms is\ndemonstrated by numerical experiments encompassing a wide variety of settings,\nwith negligible parameter tuning. In particular, nGMCA is shown to provide\nrobustness to noise and performs well on synthetic mixtures of real NMR\nspectra. \n\n"}
{"id": "1308.6273", "contents": "Title: New Algorithms for Learning Incoherent and Overcomplete Dictionaries Abstract: In sparse recovery we are given a matrix $A$ (the dictionary) and a vector of\nthe form $A X$ where $X$ is sparse, and the goal is to recover $X$. This is a\ncentral notion in signal processing, statistics and machine learning. But in\napplications such as sparse coding, edge detection, compression and super\nresolution, the dictionary $A$ is unknown and has to be learned from random\nexamples of the form $Y = AX$ where $X$ is drawn from an appropriate\ndistribution --- this is the dictionary learning problem. In most settings, $A$\nis overcomplete: it has more columns than rows. This paper presents a\npolynomial-time algorithm for learning overcomplete dictionaries; the only\npreviously known algorithm with provable guarantees is the recent work of\nSpielman, Wang and Wright who gave an algorithm for the full-rank case, which\nis rarely the case in applications. Our algorithm applies to incoherent\ndictionaries which have been a central object of study since they were\nintroduced in seminal work of Donoho and Huo. In particular, a dictionary is\n$\\mu$-incoherent if each pair of columns has inner product at most $\\mu /\n\\sqrt{n}$.\n  The algorithm makes natural stochastic assumptions about the unknown sparse\nvector $X$, which can contain $k \\leq c \\min(\\sqrt{n}/\\mu \\log n, m^{1/2\n-\\eta})$ non-zero entries (for any $\\eta > 0$). This is close to the best $k$\nallowable by the best sparse recovery algorithms even if one knows the\ndictionary $A$ exactly. Moreover, both the running time and sample complexity\ndepend on $\\log 1/\\epsilon$, where $\\epsilon$ is the target accuracy, and so\nour algorithms converge very quickly to the true dictionary. Our algorithm can\nalso tolerate substantial amounts of noise provided it is incoherent with\nrespect to the dictionary (e.g., Gaussian). In the noisy setting, our running\ntime and sample complexity depend polynomially on $1/\\epsilon$, and this is\nnecessary. \n\n"}
{"id": "1308.6384", "contents": "Title: Collecting Coupons with Random Initial Stake Abstract: Motivated by a problem in the theory of randomized search heuristics, we give\na very precise analysis for the coupon collector problem where the collector\nstarts with a random set of coupons (chosen uniformly from all sets).\n  We show that the expected number of rounds until we have a coupon of each\ntype is $nH_{n/2} - 1/2 \\pm o(1)$, where $H_{n/2}$ denotes the $(n/2)$th\nharmonic number when $n$ is even, and $H_{n/2}:= (1/2) H_{\\lfloor n/2 \\rfloor}\n+ (1/2) H_{\\lceil n/2 \\rceil}$ when $n$ is odd. Consequently, the coupon\ncollector with random initial stake is by half a round faster than the one\nstarting with exactly $n/2$ coupons (apart from additive $o(1)$ terms).\n  This result implies that classic simple heuristic called \\emph{randomized\nlocal search} needs an expected number of $nH_{n/2} - 1/2 \\pm o(1)$ iterations\nto find the optimum of any monotonic function defined on bit-strings of length\n$n$. \n\n"}
{"id": "1309.2350", "contents": "Title: Exponentially Fast Parameter Estimation in Networks Using Distributed\n  Dual Averaging Abstract: In this paper we present an optimization-based view of distributed parameter\nestimation and observational social learning in networks. Agents receive a\nsequence of random, independent and identically distributed (i.i.d.) signals,\neach of which individually may not be informative about the underlying true\nstate, but the signals together are globally informative enough to make the\ntrue state identifiable. Using an optimization-based characterization of\nBayesian learning as proximal stochastic gradient descent (with\nKullback-Leibler divergence from a prior as a proximal function), we show how\nto efficiently use a distributed, online variant of Nesterov's dual averaging\nmethod to solve the estimation with purely local information. When the true\nstate is globally identifiable, and the network is connected, we prove that\nagents eventually learn the true parameter using a randomized gossip scheme. We\ndemonstrate that with high probability the convergence is exponentially fast\nwith a rate dependent on the KL divergence of observations under the true state\nfrom observations under the second likeliest state. Furthermore, our work also\nhighlights the possibility of learning under continuous adaptation of network\nwhich is a consequence of employing constant, unit stepsize for the algorithm. \n\n"}
{"id": "1309.4714", "contents": "Title: Temporal-Difference Learning to Assist Human Decision Making during the\n  Control of an Artificial Limb Abstract: In this work we explore the use of reinforcement learning (RL) to help with\nhuman decision making, combining state-of-the-art RL algorithms with an\napplication to prosthetics. Managing human-machine interaction is a problem of\nconsiderable scope, and the simplification of human-robot interfaces is\nespecially important in the domains of biomedical technology and rehabilitation\nmedicine. For example, amputees who control artificial limbs are often required\nto quickly switch between a number of control actions or modes of operation in\norder to operate their devices. We suggest that by learning to anticipate\n(predict) a user's behaviour, artificial limbs could take on an active role in\na human's control decisions so as to reduce the burden on their users.\nRecently, we showed that RL in the form of general value functions (GVFs) could\nbe used to accurately detect a user's control intent prior to their explicit\ncontrol choices. In the present work, we explore the use of temporal-difference\nlearning and GVFs to predict when users will switch their control influence\nbetween the different motor functions of a robot arm. Experiments were\nperformed using a multi-function robot arm that was controlled by muscle\nsignals from a user's body (similar to conventional artificial limb control).\nOur approach was able to acquire and maintain forecasts about a user's\nswitching decisions in real time. It also provides an intuitive and reward-free\nway for users to correct or reinforce the decisions made by the machine\nlearning system. We expect that when a system is certain enough about its\npredictions, it can begin to take over switching decisions from the user to\nstreamline control and potentially decrease the time and effort needed to\ncomplete tasks. This preliminary study therefore suggests a way to naturally\nintegrate human- and machine-based decision making systems. \n\n"}
{"id": "1309.5469", "contents": "Title: Towards Minimizing k-Submodular Functions Abstract: In this paper we investigate k-submodular functions. This natural family of\ndiscrete functions includes submodular and bisubmodular functions as the\nspecial cases k = 1 and k = 2 respectively.\n  In particular we generalize the known Min-Max-Theorem for submodular and\nbisubmodular functions. This theorem asserts that the minimum of the\n(bi)submodular function can be found by solving a maximization problem over a\n(bi)submodular polyhedron. We define and investigate a k-submodular polyhedron\nand prove a Min-Max-Theorem for k-submodular functions. \n\n"}
{"id": "1311.2110", "contents": "Title: Curvature and Optimal Algorithms for Learning and Minimizing Submodular\n  Functions Abstract: We investigate three related and important problems connected to machine\nlearning: approximating a submodular function everywhere, learning a submodular\nfunction (in a PAC-like setting [53]), and constrained minimization of\nsubmodular functions. We show that the complexity of all three problems depends\non the 'curvature' of the submodular function, and provide lower and upper\nbounds that refine and improve previous results [3, 16, 18, 52]. Our proof\ntechniques are fairly generic. We either use a black-box transformation of the\nfunction (for approximation and learning), or a transformation of algorithms to\nuse an appropriate surrogate function (for minimization). Curiously, curvature\nhas been known to influence approximations for submodular maximization [7, 55],\nbut its effect on minimization, approximation and learning has hitherto been\nopen. We complete this picture, and also support our theoretical claims by\nempirical results. \n\n"}
{"id": "1311.3001", "contents": "Title: Informed Source Separation: A Bayesian Tutorial Abstract: Source separation problems are ubiquitous in the physical sciences; any\nsituation where signals are superimposed calls for source separation to\nestimate the original signals. In this tutorial I will discuss the Bayesian\napproach to the source separation problem. This approach has a specific\nadvantage in that it requires the designer to explicitly describe the signal\nmodel in addition to any other information or assumptions that go into the\nproblem description. This leads naturally to the idea of informed source\nseparation, where the algorithm design incorporates relevant information about\nthe specific problem. This approach promises to enable researchers to design\ntheir own high-quality algorithms that are specifically tailored to the problem\nat hand. \n\n"}
{"id": "1312.2132", "contents": "Title: Robust Subspace System Identification via Weighted Nuclear Norm\n  Optimization Abstract: Subspace identification is a classical and very well studied problem in\nsystem identification. The problem was recently posed as a convex optimization\nproblem via the nuclear norm relaxation. Inspired by robust PCA, we extend this\nframework to handle outliers. The proposed framework takes the form of a convex\noptimization problem with an objective that trades off fit, rank and sparsity.\nAs in robust PCA, it can be problematic to find a suitable regularization\nparameter. We show how the space in which a suitable parameter should be sought\ncan be limited to a bounded open set of the two dimensional parameter space. In\npractice, this is very useful since it restricts the parameter space that is\nneeded to be surveyed. \n\n"}
{"id": "1312.2177", "contents": "Title: Machine Learning Techniques for Intrusion Detection Abstract: An Intrusion Detection System (IDS) is a software that monitors a single or a\nnetwork of computers for malicious activities (attacks) that are aimed at\nstealing or censoring information or corrupting network protocols. Most\ntechniques used in today's IDS are not able to deal with the dynamic and\ncomplex nature of cyber attacks on computer networks. Hence, efficient adaptive\nmethods like various techniques of machine learning can result in higher\ndetection rates, lower false alarm rates and reasonable computation and\ncommunication costs. In this paper, we study several such schemes and compare\ntheir performance. We divide the schemes into methods based on classical\nartificial intelligence (AI) and methods based on computational intelligence\n(CI). We explain how various characteristics of CI techniques can be used to\nbuild efficient IDS. \n\n"}
{"id": "1312.5192", "contents": "Title: Nonlinear Eigenproblems in Data Analysis - Balanced Graph Cuts and the\n  RatioDCA-Prox Abstract: It has been recently shown that a large class of balanced graph cuts allows\nfor an exact relaxation into a nonlinear eigenproblem. We review briefly some\nof these results and propose a family of algorithms to compute nonlinear\neigenvectors which encompasses previous work as special cases. We provide a\ndetailed analysis of the properties and the convergence behavior of these\nalgorithms and then discuss their application in the area of balanced graph\ncuts. \n\n"}
{"id": "1312.5457", "contents": "Title: Codebook based Audio Feature Representation for Music Information\n  Retrieval Abstract: Digital music has become prolific in the web in recent decades. Automated\nrecommendation systems are essential for users to discover music they love and\nfor artists to reach appropriate audience. When manual annotations and user\npreference data is lacking (e.g. for new artists) these systems must rely on\n\\emph{content based} methods. Besides powerful machine learning tools for\nclassification and retrieval, a key component for successful recommendation is\nthe \\emph{audio content representation}.\n  Good representations should capture informative musical patterns in the audio\nsignal of songs. These representations should be concise, to enable efficient\n(low storage, easy indexing, fast search) management of huge music\nrepositories, and should also be easy and fast to compute, to enable real-time\ninteraction with a user supplying new songs to the system.\n  Before designing new audio features, we explore the usage of traditional\nlocal features, while adding a stage of encoding with a pre-computed\n\\emph{codebook} and a stage of pooling to get compact vectorial\nrepresentations. We experiment with different encoding methods, namely\n\\emph{the LASSO}, \\emph{vector quantization (VQ)} and \\emph{cosine similarity\n(CS)}. We evaluate the representations' quality in two music information\nretrieval applications: query-by-tag and query-by-example. Our results show\nthat concise representations can be used for successful performance in both\napplications. We recommend using top-$\\tau$ VQ encoding, which consistently\nperforms well in both applications, and requires much less computation time\nthan the LASSO. \n\n"}
{"id": "1312.6114", "contents": "Title: Auto-Encoding Variational Bayes Abstract: How can we perform efficient inference and learning in directed probabilistic\nmodels, in the presence of continuous latent variables with intractable\nposterior distributions, and large datasets? We introduce a stochastic\nvariational inference and learning algorithm that scales to large datasets and,\nunder some mild differentiability conditions, even works in the intractable\ncase. Our contributions are two-fold. First, we show that a reparameterization\nof the variational lower bound yields a lower bound estimator that can be\nstraightforwardly optimized using standard stochastic gradient methods. Second,\nwe show that for i.i.d. datasets with continuous latent variables per\ndatapoint, posterior inference can be made especially efficient by fitting an\napproximate inference model (also called a recognition model) to the\nintractable posterior using the proposed lower bound estimator. Theoretical\nadvantages are reflected in experimental results. \n\n"}
{"id": "1312.6157", "contents": "Title: Distinction between features extracted using deep belief networks Abstract: Data representation is an important pre-processing step in many machine\nlearning algorithms. There are a number of methods used for this task such as\nDeep Belief Networks (DBNs) and Discrete Fourier Transforms (DFTs). Since some\nof the features extracted using automated feature extraction methods may not\nalways be related to a specific machine learning task, in this paper we propose\ntwo methods in order to make a distinction between extracted features based on\ntheir relevancy to the task. We applied these two methods to a Deep Belief\nNetwork trained for a face recognition task. \n\n"}
{"id": "1312.6447", "contents": "Title: Incremental Network Design with Maximum Flows Abstract: We study an incremental network design problem, where in each time period of\nthe planning horizon an arc can be added to the network and a maximum flow\nproblem is solved, and where the objective is to maximize the cumulative flow\nover the entire planning horizon. After presenting two mixed integer\nprogramming (MIP) formulations for this NP-complete problem, we describe\nseveral heuristics and prove performance bounds for some special cases. In a\nseries of computational experiments, we compare the performance of the MIP\nformulations as well as the heuristics. \n\n"}
{"id": "1312.6724", "contents": "Title: Local algorithms for interactive clustering Abstract: We study the design of interactive clustering algorithms for data sets\nsatisfying natural stability assumptions. Our algorithms start with any initial\nclustering and only make local changes in each step; both are desirable\nfeatures in many applications. We show that in this constrained setting one can\nstill design provably efficient algorithms that produce accurate clusterings.\nWe also show that our algorithms perform well on real-world data. \n\n"}
{"id": "1312.6838", "contents": "Title: Greedy Column Subset Selection for Large-scale Data Sets Abstract: In today's information systems, the availability of massive amounts of data\nnecessitates the development of fast and accurate algorithms to summarize these\ndata and represent them in a succinct format. One crucial problem in big data\nanalytics is the selection of representative instances from large and\nmassively-distributed data, which is formally known as the Column Subset\nSelection (CSS) problem. The solution to this problem enables data analysts to\nunderstand the insights of the data and explore its hidden structure. The\nselected instances can also be used for data preprocessing tasks such as\nlearning a low-dimensional embedding of the data points or computing a low-rank\napproximation of the corresponding matrix. This paper presents a fast and\naccurate greedy algorithm for large-scale column subset selection. The\nalgorithm minimizes an objective function which measures the reconstruction\nerror of the data matrix based on the subset of selected columns. The paper\nfirst presents a centralized greedy algorithm for column subset selection which\ndepends on a novel recursive formula for calculating the reconstruction error\nof the data matrix. The paper then presents a MapReduce algorithm which selects\na few representative columns from a matrix whose columns are massively\ndistributed across several commodity machines. The algorithm first learns a\nconcise representation of all columns using random projection, and it then\nsolves a generalized column subset selection problem at each machine in which a\nsubset of columns are selected from the sub-matrix on that machine such that\nthe reconstruction error of the concise representation is minimized. The paper\ndemonstrates the effectiveness and efficiency of the proposed algorithm through\nan empirical evaluation on benchmark data sets. \n\n"}
{"id": "1401.0579", "contents": "Title: More Algorithms for Provable Dictionary Learning Abstract: In dictionary learning, also known as sparse coding, the algorithm is given\nsamples of the form $y = Ax$ where $x\\in \\mathbb{R}^m$ is an unknown random\nsparse vector and $A$ is an unknown dictionary matrix in $\\mathbb{R}^{n\\times\nm}$ (usually $m > n$, which is the overcomplete case). The goal is to learn $A$\nand $x$. This problem has been studied in neuroscience, machine learning,\nvisions, and image processing. In practice it is solved by heuristic algorithms\nand provable algorithms seemed hard to find. Recently, provable algorithms were\nfound that work if the unknown feature vector $x$ is $\\sqrt{n}$-sparse or even\nsparser. Spielman et al. \\cite{DBLP:journals/jmlr/SpielmanWW12} did this for\ndictionaries where $m=n$; Arora et al. \\cite{AGM} gave an algorithm for\novercomplete ($m >n$) and incoherent matrices $A$; and Agarwal et al.\n\\cite{DBLP:journals/corr/AgarwalAN13} handled a similar case but with weaker\nguarantees.\n  This raised the problem of designing provable algorithms that allow sparsity\n$\\gg \\sqrt{n}$ in the hidden vector $x$. The current paper designs algorithms\nthat allow sparsity up to $n/poly(\\log n)$. It works for a class of matrices\nwhere features are individually recoverable, a new notion identified in this\npaper that may motivate further work.\n  The algorithm runs in quasipolynomial time because they use limited\nenumeration. \n\n"}
{"id": "1401.2662", "contents": "Title: Directed Width Parameters and Circumference of Digraphs Abstract: We prove that the directed treewidth, DAG-width and Kelly-width of a digraph\nare bounded above by its circumference plus one. \n\n"}
{"id": "1401.5899", "contents": "Title: Kernel Least Mean Square with Adaptive Kernel Size Abstract: Kernel adaptive filters (KAF) are a class of powerful nonlinear filters\ndeveloped in Reproducing Kernel Hilbert Space (RKHS). The Gaussian kernel is\nusually the default kernel in KAF algorithms, but selecting the proper kernel\nsize (bandwidth) is still an open important issue especially for learning with\nsmall sample sizes. In previous research, the kernel size was set manually or\nestimated in advance by Silvermans rule based on the sample distribution. This\nstudy aims to develop an online technique for optimizing the kernel size of the\nkernel least mean square (KLMS) algorithm. A sequential optimization strategy\nis proposed, and a new algorithm is developed, in which the filter weights and\nthe kernel size are both sequentially updated by stochastic gradient algorithms\nthat minimize the mean square error (MSE). Theoretical results on convergence\nare also presented. The excellent performance of the new algorithm is confirmed\nby simulations on static function estimation and short term chaotic time series\nprediction. \n\n"}
{"id": "1401.6963", "contents": "Title: Optimal Spread in Network Consensus Models Abstract: In a model of network communication based on a random walk in an undirected\ngraph, what subset of nodes (subject to constraints on the set size), enable\nthe fastest spread of information? The dynamics of spread is described by a\nprocess dual to the movement from informed to uninformed nodes. In this\nsetting, an optimal set $A$ minimizes the sum of the expected first hitting\ntimes $F(A)$, of random walks that start at nodes outside the set.\n  In this paper,the problem is reformulated so that the search for solutions is\nrestricted to a class of optimal and \"near\" optimal subsets of the graph. We\nintroduce a submodular, non-decreasing rank function $\\rho$, that permits some\ncomparison between the solution obtained by the classical greedy algorithm and\none obtained by our methods. The supermodularity and non-increasing properties\nof $F$ are used to show that the rank of our solution is at least\n$(1-\\frac{1}{e})$ times the rank of the optimal set. When the solution has a\nhigher rank than the greedy solution this constant can be improved to\n$(1-\\frac{1}{e})(1+\\chi)$ where $\\chi >0$ is determined a posteriori. The\nmethod requires the evaluation of $F$ for sets of some fixed cardinality $m$,\nwhere $m$ is much smaller than the cardinality of the optimal set. When $F$ has\nforward elemental curvature $\\kappa$, we can provide a rough description of the\ntrade-off between solution quality and computational effort $m$ in terms of\n$\\kappa$. \n\n"}
{"id": "1402.0119", "contents": "Title: Randomized Nonlinear Component Analysis Abstract: Classical methods such as Principal Component Analysis (PCA) and Canonical\nCorrelation Analysis (CCA) are ubiquitous in statistics. However, these\ntechniques are only able to reveal linear relationships in data. Although\nnonlinear variants of PCA and CCA have been proposed, these are computationally\nprohibitive in the large scale.\n  In a separate strand of recent research, randomized methods have been\nproposed to construct features that help reveal nonlinear patterns in data. For\nbasic tasks such as regression or classification, random features exhibit\nlittle or no loss in performance, while achieving drastic savings in\ncomputational requirements.\n  In this paper we leverage randomness to design scalable new variants of\nnonlinear PCA and CCA; our ideas extend to key multivariate analysis tools such\nas spectral clustering or LDA. We demonstrate our algorithms through\nexperiments on real-world data, on which we compare against the\nstate-of-the-art. A simple R implementation of the presented algorithms is\nprovided. \n\n"}
{"id": "1402.2333", "contents": "Title: Modeling sequential data using higher-order relational features and\n  predictive training Abstract: Bi-linear feature learning models, like the gated autoencoder, were proposed\nas a way to model relationships between frames in a video. By minimizing\nreconstruction error of one frame, given the previous frame, these models learn\n\"mapping units\" that encode the transformations inherent in a sequence, and\nthereby learn to encode motion. In this work we extend bi-linear models by\nintroducing \"higher-order mapping units\" that allow us to encode\ntransformations between frames and transformations between transformations.\n  We show that this makes it possible to encode temporal structure that is more\ncomplex and longer-range than the structure captured within standard bi-linear\nmodels. We also show that a natural way to train the model is by replacing the\ncommonly used reconstruction objective with a prediction objective which forces\nthe model to correctly predict the evolution of the input multiple steps into\nthe future. Learning can be achieved by back-propagating the multi-step\nprediction through time. We test the model on various temporal prediction\ntasks, and show that higher-order mappings and predictive training both yield a\nsignificant improvement over bi-linear models in terms of prediction accuracy. \n\n"}
{"id": "1402.2589", "contents": "Title: Partitioning Perfect Graphs into Stars Abstract: The partition of graphs into \"nice\" subgraphs is a central algorithmic\nproblem with strong ties to matching theory. We study the partitioning of\nundirected graphs into same-size stars, a problem known to be NP-complete even\nfor the case of stars on three vertices. We perform a thorough computational\ncomplexity study of the problem on subclasses of perfect graphs and identify\nseveral polynomial-time solvable cases, for example, on interval graphs and\nbipartite permutation graphs, and also NP-complete cases, for example, on grid\ngraphs and chordal graphs. \n\n"}
{"id": "1402.3849", "contents": "Title: Scalable Kernel Clustering: Approximate Kernel k-means Abstract: Kernel-based clustering algorithms have the ability to capture the non-linear\nstructure in real world data. Among various kernel-based clustering algorithms,\nkernel k-means has gained popularity due to its simple iterative nature and\nease of implementation. However, its run-time complexity and memory footprint\nincrease quadratically in terms of the size of the data set, and hence, large\ndata sets cannot be clustered efficiently. In this paper, we propose an\napproximation scheme based on randomization, called the Approximate Kernel\nk-means. We approximate the cluster centers using the kernel similarity between\na few sampled points and all the points in the data set. We show that the\nproposed method achieves better clustering performance than the traditional low\nrank kernel approximation based clustering schemes. We also demonstrate that\nits running time and memory requirements are significantly lower than those of\nkernel k-means, with only a small reduction in the clustering quality on\nseveral public domain large data sets. We then employ ensemble clustering\ntechniques to further enhance the performance of our algorithm. \n\n"}
{"id": "1402.4322", "contents": "Title: On the properties of $\\alpha$-unchaining single linkage hierarchical\n  clustering Abstract: In the election of a hierarchical clustering method, theoretic properties may\ngive some insight to determine which method is the most suitable to treat a\nclustering problem. Herein, we study some basic properties of two hierarchical\nclustering methods: $\\alpha$-unchaining single linkage or $SL(\\alpha)$ and a\nmodified version of this one, $SL^*(\\alpha)$. We compare the results with the\nproperties satisfied by the classical linkage-based hierarchical clustering\nmethods. \n\n"}
{"id": "1402.6310", "contents": "Title: Approximating the Cubicity of Trees Abstract: Cubicity of a graph $G$ is the smallest dimension $d$, for which $G$ is a\nunit disc graph in ${\\mathbb{R}}^d$, under the $l^\\infty$ metric, i.e. $G$ can\nbe represented as an intersection graph of $d$-dimensional (axis-parallel) unit\nhypercubes. We call such an intersection representation a $d$-dimensional cube\nrepresentation of $G$. Computing cubicity is known to be inapproximable in\npolynomial time, within an $O(n^{1-\\epsilon})$ factor for any $\\epsilon >0$,\nunless NP=ZPP.\n  In this paper, we present a randomized algorithm that runs in polynomial time\nand computes cube representations of trees, of dimension within a constant\nfactor of the optimum. It is also shown that the cubicity of trees can be\napproximated within a constant factor in deterministic polynomial time, if the\ncube representation is not required to be computed. As far as we know, this is\nthe first constant factor approximation algorithm for computing the cubicity of\ntrees. It is not yet clear whether computing the cubicity of trees is NP-hard\nor not. \n\n"}
{"id": "1402.7224", "contents": "Title: On low treewidth graphs and supertrees Abstract: Compatibility of unrooted phylogenetic trees is a well studied problem in\nphylogenetics. It asks to determine whether for a set of k input trees there\nexists a larger tree (called a supertree) that contains the topologies of all k\ninput trees. When any such supertree exists we call the instance compatible and\notherwise incompatible. It is known that the problem is NP-hard and FPT,\nalthough a constructive FPT algorithm is not known. It has been shown that\nwhenever the treewidth of an auxiliary structure known as the display graph is\nstrictly larger than the number of input trees, the instance is incompatible.\nHere we show that whenever the treewidth of the display graph is at most 2, the\ninstance is compatible. Furthermore, we give a polynomial-time algorithm to\nconstruct a supertree in this case. Finally, we demonstrate both compatible and\nincompatible instances that have display graphs with treewidth 3, highlighting\nthat the treewidth of the display graph is (on its own) not sufficient to\ndetermine compatibility. \n\n"}
{"id": "1403.0156", "contents": "Title: Sleep Analytics and Online Selective Anomaly Detection Abstract: We introduce a new problem, the Online Selective Anomaly Detection (OSAD), to\nmodel a specific scenario emerging from research in sleep science. Scientists\nhave segmented sleep into several stages and stage two is characterized by two\npatterns (or anomalies) in the EEG time series recorded on sleep subjects.\nThese two patterns are sleep spindle (SS) and K-complex. The OSAD problem was\nintroduced to design a residual system, where all anomalies (known and unknown)\nare detected but the system only triggers an alarm when non-SS anomalies\nappear. The solution of the OSAD problem required us to combine techniques from\nboth machine learning and control theory. Experiments on data from real\nsubjects attest to the effectiveness of our approach. \n\n"}
{"id": "1403.0628", "contents": "Title: Unconstrained Online Linear Learning in Hilbert Spaces: Minimax\n  Algorithms and Normal Approximations Abstract: We study algorithms for online linear optimization in Hilbert spaces,\nfocusing on the case where the player is unconstrained. We develop a novel\ncharacterization of a large class of minimax algorithms, recovering, and even\nimproving, several previous results as immediate corollaries. Moreover, using\nour tools, we develop an algorithm that provides a regret bound of\n$\\mathcal{O}\\Big(U \\sqrt{T \\log(U \\sqrt{T} \\log^2 T +1)}\\Big)$, where $U$ is\nthe $L_2$ norm of an arbitrary comparator and both $T$ and $U$ are unknown to\nthe player. This bound is optimal up to $\\sqrt{\\log \\log T}$ terms. When $T$ is\nknown, we derive an algorithm with an optimal regret bound (up to constant\nfactors). For both the known and unknown $T$ case, a Normal approximation to\nthe conditional value of the game proves to be the key analysis tool. \n\n"}
{"id": "1403.1515", "contents": "Title: Linear Recognition of Almost Interval Graphs Abstract: Let $\\mbox{interval} + k v$, $\\mbox{interval} + k e$, and $\\mbox{interval} -\nk e$ denote the classes of graphs that can be obtained from some interval graph\nby adding $k$ vertices, adding $k$ edges, and deleting $k$ edges, respectively.\nWhen $k$ is small, these graph classes are called almost interval graphs. They\nare well motivated from computational biology, where the data ought to be\nrepresented by an interval graph while we can only expect an almost interval\ngraph for the best. For any fixed $k$, we give linear-time algorithms for\nrecognizing all these classes, and in the case of membership, our algorithms\nprovide also a specific interval graph as evidence. When $k$ is part of the\ninput, these problems are also known as graph modification problems, all\nNP-complete. Our results imply that they are fixed-parameter tractable\nparameterized by $k$, thereby resolving the long-standing open problem on the\nparameterized complexity of recognizing $\\mbox{interval}+ k e$, first asked by\nBodlaender et al. [Bioinformatics, 11:49--57, 1995]. Moreover, our algorithms\nfor recognizing $\\mbox{interval}+ k v$ and $\\mbox{interval}- k e$ run in times\n$O(6^k \\cdot (n + m))$ and $O(8^k \\cdot (n + m))$, (where $n$ and $m$ stand for\nthe numbers of vertices and edges respectively in the input graph,)\nsignificantly improving the $O(k^{2k}\\cdot n^3m)$-time algorithm of Heggernes\net al. [STOC 2007] and the $O(10^k \\cdot n^9)$-time algorithm of Cao and Marx\n[SODA 2014] respectively. \n\n"}
{"id": "1403.5607", "contents": "Title: Bayesian Optimization with Unknown Constraints Abstract: Recent work on Bayesian optimization has shown its effectiveness in global\noptimization of difficult black-box objective functions. Many real-world\noptimization problems of interest also have constraints which are unknown a\npriori. In this paper, we study Bayesian optimization for constrained problems\nin the general case that noise may be present in the constraint functions, and\nthe objective and constraints may be evaluated independently. We provide\nmotivating practical examples, and present a general framework to solve such\nproblems. We demonstrate the effectiveness of our approach on optimizing the\nperformance of online latent Dirichlet allocation subject to topic sparsity\nconstraints, tuning a neural network given test-time memory constraints, and\noptimizing Hamiltonian Monte Carlo to achieve maximal effectiveness in a fixed\ntime, subject to passing standard convergence diagnostics. \n\n"}
{"id": "1404.0736", "contents": "Title: Exploiting Linear Structure Within Convolutional Networks for Efficient\n  Evaluation Abstract: We present techniques for speeding up the test-time evaluation of large\nconvolutional networks, designed for object recognition tasks. These models\ndeliver impressive accuracy but each image evaluation requires millions of\nfloating point operations, making their deployment on smartphones and\nInternet-scale clusters problematic. The computation is dominated by the\nconvolution operations in the lower layers of the model. We exploit the linear\nstructure present within the convolutional filters to derive approximations\nthat significantly reduce the required computation. Using large\nstate-of-the-art models, we demonstrate we demonstrate speedups of\nconvolutional layers on both CPU and GPU by a factor of 2x, while keeping the\naccuracy within 1% of the original model. \n\n"}
{"id": "1404.2824", "contents": "Title: Normal, Abby Normal, Prefix Normal Abstract: A prefix normal word is a binary word with the property that no substring has\nmore 1s than the prefix of the same length. This class of words is important in\nthe context of binary jumbled pattern matching. In this paper we present\nresults about the number $pnw(n)$ of prefix normal words of length $n$, showing\nthat $pnw(n) =\\Omega\\left(2^{n - c\\sqrt{n\\ln n}}\\right)$ for some $c$ and\n$pnw(n) = O \\left(\\frac{2^n (\\ln n)^2}{n}\\right)$. We introduce efficient\nalgorithms for testing the prefix normal property and a \"mechanical algorithm\"\nfor computing prefix normal forms. We also include games which can be played\nwith prefix normal words. In these games Alice wishes to stay normal but Bob\nwants to drive her \"abnormal\" -- we discuss which parameter settings allow\nAlice to succeed. \n\n"}
{"id": "1405.0329", "contents": "Title: Forbidden Induced Subgraphs of Normal Helly Circular-Arc Graphs:\n  Characterization and Detection Abstract: A normal Helly circular-arc graph is the intersection graph of arcs on a\ncircle of which no three or less arcs cover the whole circle. Lin, Soulignac,\nand Szwarcfiter [Discrete Appl. Math. 2013] characterized circular-arc graphs\nthat are not normal Helly circular-arc graphs, and used it to develop the first\nrecognition algorithm for this graph class. As open problems, they ask for the\nforbidden induced subgraph characterization and a direct recognition algorithm\nfor normal Helly circular-arc graphs, both of which are resolved by the current\npaper. Moreover, when the input is not a normal Helly circular-arc graph, our\nrecognition algorithm finds in linear time a minimal forbidden induced subgraph\nas certificate. \n\n"}
{"id": "1405.2798", "contents": "Title: Two-Stage Metric Learning Abstract: In this paper, we present a novel two-stage metric learning algorithm. We\nfirst map each learning instance to a probability distribution by computing its\nsimilarities to a set of fixed anchor points. Then, we define the distance in\nthe input data space as the Fisher information distance on the associated\nstatistical manifold. This induces in the input data space a new family of\ndistance metric with unique properties. Unlike kernelized metric learning, we\ndo not require the similarity measure to be positive semi-definite. Moreover,\nit can also be interpreted as a local metric learning algorithm with well\ndefined distance approximation. We evaluate its performance on a number of\ndatasets. It outperforms significantly other metric learning methods and SVM. \n\n"}
{"id": "1405.7910", "contents": "Title: Optimal CUR Matrix Decompositions Abstract: The CUR decomposition of an $m \\times n$ matrix $A$ finds an $m \\times c$\nmatrix $C$ with a subset of $c < n$ columns of $A,$ together with an $r \\times\nn$ matrix $R$ with a subset of $r < m$ rows of $A,$ as well as a $c \\times r$\nlow-rank matrix $U$ such that the matrix $C U R$ approximates the matrix $A,$\nthat is, $ || A - CUR ||_F^2 \\le (1+\\epsilon) || A - A_k||_F^2$, where\n$||.||_F$ denotes the Frobenius norm and $A_k$ is the best $m \\times n$ matrix\nof rank $k$ constructed via the SVD. We present input-sparsity-time and\ndeterministic algorithms for constructing such a CUR decomposition where\n$c=O(k/\\epsilon)$ and $r=O(k/\\epsilon)$ and rank$(U) = k$. Up to constant\nfactors, our algorithms are simultaneously optimal in $c, r,$ and rank$(U)$. \n\n"}
{"id": "1406.2587", "contents": "Title: Structural Sparsity of Complex Networks: Bounded Expansion in Random\n  Models and Real-World Graphs Abstract: This research establishes that many real-world networks exhibit bounded\nexpansion, a strong notion of structural sparsity, and demonstrates that it can\nbe leveraged to design efficient algorithms for network analysis. We analyze\nseveral common network models regarding their structural sparsity. We show\nthat, with high probability, (1) graphs sampled with a prescribed s parse\ndegree sequence; (2) perturbed bounded-degree graphs; (3) stochastic block\nmodels with small probabilities; result in graphs of bounded expansion.\n  In contrast, we show that the Kleinberg and the Barabasi-Albert model have\nunbounded expansion. We support our findings with empirical measurements on a\ncorpus of real-world networks. \n\n"}
{"id": "1406.3816", "contents": "Title: Simultaneous Model Selection and Optimization through Parameter-free\n  Stochastic Learning Abstract: Stochastic gradient descent algorithms for training linear and kernel\npredictors are gaining more and more importance, thanks to their scalability.\nWhile various methods have been proposed to speed up their convergence, the\nmodel selection phase is often ignored. In fact, in theoretical works most of\nthe time assumptions are made, for example, on the prior knowledge of the norm\nof the optimal solution, while in the practical world validation methods remain\nthe only viable approach. In this paper, we propose a new kernel-based\nstochastic gradient descent algorithm that performs model selection while\ntraining, with no parameters to tune, nor any form of cross-validation. The\nalgorithm builds on recent advancement in online learning theory for\nunconstrained settings, to estimate over time the right regularization in a\ndata-dependent way. Optimal rates of convergence are proved under standard\nsmoothness assumptions on the target function, using the range space of the\nfractional integral operator associated with the kernel. \n\n"}
{"id": "1406.5665", "contents": "Title: Constant Factor Approximation for Balanced Cut in the PIE model Abstract: We propose and study a new semi-random semi-adversarial model for Balanced\nCut, a planted model with permutation-invariant random edges (PIE). Our model\nis much more general than planted models considered previously. Consider a set\nof vertices V partitioned into two clusters $L$ and $R$ of equal size. Let $G$\nbe an arbitrary graph on $V$ with no edges between $L$ and $R$. Let\n$E_{random}$ be a set of edges sampled from an arbitrary permutation-invariant\ndistribution (a distribution that is invariant under permutation of vertices in\n$L$ and in $R$). Then we say that $G + E_{random}$ is a graph with\npermutation-invariant random edges.\n  We present an approximation algorithm for the Balanced Cut problem that finds\na balanced cut of cost $O(|E_{random}|) + n \\text{polylog}(n)$ in this model.\nIn the regime when $|E_{random}| = \\Omega(n \\text{polylog}(n))$, this is a\nconstant factor approximation with respect to the cost of the planted cut. \n\n"}
{"id": "1407.0202", "contents": "Title: SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly\n  Convex Composite Objectives Abstract: In this work we introduce a new optimisation method called SAGA in the spirit\nof SAG, SDCA, MISO and SVRG, a set of recently proposed incremental gradient\nalgorithms with fast linear convergence rates. SAGA improves on the theory\nbehind SAG and SVRG, with better theoretical convergence rates, and has support\nfor composite objectives where a proximal operator is used on the regulariser.\nUnlike SDCA, SAGA supports non-strongly convex problems directly, and is\nadaptive to any inherent strong convexity of the problem. We give experimental\nresults showing the effectiveness of our method. \n\n"}
{"id": "1407.1543", "contents": "Title: Dictionary Learning and Tensor Decomposition via the Sum-of-Squares\n  Method Abstract: We give a new approach to the dictionary learning (also known as \"sparse\ncoding\") problem of recovering an unknown $n\\times m$ matrix $A$ (for $m \\geq\nn$) from examples of the form \\[ y = Ax + e, \\] where $x$ is a random vector in\n$\\mathbb R^m$ with at most $\\tau m$ nonzero coordinates, and $e$ is a random\nnoise vector in $\\mathbb R^n$ with bounded magnitude. For the case $m=O(n)$,\nour algorithm recovers every column of $A$ within arbitrarily good constant\naccuracy in time $m^{O(\\log m/\\log(\\tau^{-1}))}$, in particular achieving\npolynomial time if $\\tau = m^{-\\delta}$ for any $\\delta>0$, and time $m^{O(\\log\nm)}$ if $\\tau$ is (a sufficiently small) constant. Prior algorithms with\ncomparable assumptions on the distribution required the vector $x$ to be much\nsparser---at most $\\sqrt{n}$ nonzero coordinates---and there were intrinsic\nbarriers preventing these algorithms from applying for denser $x$.\n  We achieve this by designing an algorithm for noisy tensor decomposition that\ncan recover, under quite general conditions, an approximate rank-one\ndecomposition of a tensor $T$, given access to a tensor $T'$ that is\n$\\tau$-close to $T$ in the spectral norm (when considered as a matrix). To our\nknowledge, this is the first algorithm for tensor decomposition that works in\nthe constant spectral-norm noise regime, where there is no guarantee that the\nlocal optima of $T$ and $T'$ have similar structures.\n  Our algorithm is based on a novel approach to using and analyzing the Sum of\nSquares semidefinite programming hierarchy (Parrilo 2000, Lasserre 2001), and\nit can be viewed as an indication of the utility of this very general and\npowerful tool for unsupervised learning problems. \n\n"}
{"id": "1407.2433", "contents": "Title: Identifying Cover Songs Using Information-Theoretic Measures of\n  Similarity Abstract: This paper investigates methods for quantifying similarity between audio\nsignals, specifically for the task of of cover song detection. We consider an\ninformation-theoretic approach, where we compute pairwise measures of\npredictability between time series. We compare discrete-valued approaches\noperating on quantised audio features, to continuous-valued approaches. In the\ndiscrete case, we propose a method for computing the normalised compression\ndistance, where we account for correlation between time series. In the\ncontinuous case, we propose to compute information-based measures of similarity\nas statistics of the prediction error between time series. We evaluate our\nmethods on two cover song identification tasks using a data set comprised of\n300 Jazz standards and using the Million Song Dataset. For both datasets, we\nobserve that continuous-valued approaches outperform discrete-valued\napproaches. We consider approaches to estimating the normalised compression\ndistance (NCD) based on string compression and prediction, where we observe\nthat our proposed normalised compression distance with alignment (NCDA)\nimproves average performance over NCD, for sequential compression algorithms.\nFinally, we demonstrate that continuous-valued distances may be combined to\nimprove performance with respect to baseline approaches. Using a large-scale\nfilter-and-refine approach, we demonstrate state-of-the-art performance for\ncover song identification using the Million Song Dataset. \n\n"}
{"id": "1407.3200", "contents": "Title: Lock-in Problem for Parallel Rotor-router Walks Abstract: The rotor-router model, also called the Propp machine, was introduced as a\ndeterministic alternative to the random walk. In this model, a group of\nidentical tokens are initially placed at nodes of the graph. Each node\nmaintains a cyclic ordering of the outgoing arcs, and during consecutive turns\nthe tokens are propagated along arcs chosen according to this ordering in\nround-robin fashion. The behavior of the model is fully deterministic. Yanovski\net al.(2003) proved that a single rotor-router walk on any graph with m edges\nand diameter $D$ stabilizes to a traversal of an Eulerian circuit on the set of\nall 2m directed arcs on the edge set of the graph, and that such periodic\nbehaviour of the system is achieved after an initial transient phase of at most\n2mD steps. The case of multiple parallel rotor-routers was studied\nexperimentally, leading Yanovski et al. to the conjecture that a system of $k\n\\textgreater{} 1$ parallel walks also stabilizes with a period of length at\nmost $2m$ steps. In this work we disprove this conjecture, showing that the\nperiod of parallel rotor-router walks can in fact, be superpolynomial in the\nsize of graph. On the positive side, we provide a characterization of the\nperiodic behavior of parallel router walks, in terms of a structural property\nof stable states called a subcycle decomposition. This property provides us the\ntools to efficiently detect whether a given system configuration corresponds to\nthe transient or to the limit behavior of the system. Moreover, we provide\npolynomial upper bounds of $O(m^4 D^2 + mD \\log k)$ and $O(m^5 k^2)$ on the\nnumber of steps it takes for the system to stabilize. Thus, we are able to\npredict any future behavior of the system using an algorithm that takes\npolynomial time and space. In addition, we show that there exists a separation\nbetween the stabilization time of the single-walk and multiple-walk\nrotor-router systems, and that for some graphs the latter can be asymptotically\nlarger even for the case of $k = 2$ walks. \n\n"}
{"id": "1407.5158", "contents": "Title: Tight convex relaxations for sparse matrix factorization Abstract: Based on a new atomic norm, we propose a new convex formulation for sparse\nmatrix factorization problems in which the number of nonzero elements of the\nfactors is assumed fixed and known. The formulation counts sparse PCA with\nmultiple factors, subspace clustering and low-rank sparse bilinear regression\nas potential applications. We compute slow rates and an upper bound on the\nstatistical dimension of the suggested norm for rank 1 matrices, showing that\nits statistical dimension is an order of magnitude smaller than the usual\n$\\ell\\_1$-norm, trace norm and their combinations. Even though our convex\nformulation is in theory hard and does not lead to provably polynomial time\nalgorithmic schemes, we propose an active set algorithm leveraging the\nstructure of the convex problem to solve it and show promising numerical\nresults. \n\n"}
{"id": "1407.5374", "contents": "Title: Acyclic Edge Coloring through the Lov\\'asz Local Lemma Abstract: We give a probabilistic analysis of a Moser-type algorithm for the Lov\\'{a}sz\nLocal Lemma (LLL), adjusted to search for acyclic edge colorings of a graph. We\nthus improve the best known upper bound to acyclic chromatic index, also\nobtained by analyzing a similar algorithm, but through the entropic method\n(basically counting argument). Specifically we show that a graph with maximum\ndegree $\\Delta$ has an acyclic proper edge coloring with at most $\\lceil\n3.74(\\Delta-1)\\rceil+1 $ colors, whereas, previously, the best bound was\n$4(\\Delta-1)$. The main contribution of this work is that it comprises a\nprobabilistic analysis of a Moser-type algorithm applied to events pertaining\nto dependent variables. \n\n"}
{"id": "1407.7644", "contents": "Title: Estimating the Accuracies of Multiple Classifiers Without Labeled Data Abstract: In various situations one is given only the predictions of multiple\nclassifiers over a large unlabeled test data. This scenario raises the\nfollowing questions: Without any labeled data and without any a-priori\nknowledge about the reliability of these different classifiers, is it possible\nto consistently and computationally efficiently estimate their accuracies?\nFurthermore, also in a completely unsupervised manner, can one construct a more\naccurate unsupervised ensemble classifier? In this paper, focusing on the\nbinary case, we present simple, computationally efficient algorithms to solve\nthese questions. Furthermore, under standard classifier independence\nassumptions, we prove our methods are consistent and study their asymptotic\nerror. Our approach is spectral, based on the fact that the off-diagonal\nentries of the classifiers' covariance matrix and 3-d tensor are rank-one. We\nillustrate the competitive performance of our algorithms via extensive\nexperiments on both artificial and real datasets. \n\n"}
{"id": "1408.4045", "contents": "Title: Relax, no need to round: integrality of clustering formulations Abstract: We study exact recovery conditions for convex relaxations of point cloud\nclustering problems, focusing on two of the most common optimization problems\nfor unsupervised clustering: $k$-means and $k$-median clustering. Motivations\nfor focusing on convex relaxations are: (a) they come with a certificate of\noptimality, and (b) they are generic tools which are relatively parameter-free,\nnot tailored to specific assumptions over the input. More precisely, we\nconsider the distributional setting where there are $k$ clusters in\n$\\mathbb{R}^m$ and data from each cluster consists of $n$ points sampled from a\nsymmetric distribution within a ball of unit radius. We ask: what is the\nminimal separation distance between cluster centers needed for convex\nrelaxations to exactly recover these $k$ clusters as the optimal integral\nsolution? For the $k$-median linear programming relaxation we show a tight\nbound: exact recovery is obtained given arbitrarily small pairwise separation\n$\\epsilon > 0$ between the balls. In other words, the pairwise center\nseparation is $\\Delta > 2+\\epsilon$. Under the same distributional model, the\n$k$-means LP relaxation fails to recover such clusters at separation as large\nas $\\Delta = 4$. Yet, if we enforce PSD constraints on the $k$-means LP, we get\nexact cluster recovery at center separation $\\Delta > 2\\sqrt2(1+\\sqrt{1/m})$.\nIn contrast, common heuristics such as Lloyd's algorithm (a.k.a. the $k$-means\nalgorithm) can fail to recover clusters in this setting; even with arbitrarily\nlarge cluster separation, k-means++ with overseeding by any constant factor\nfails with high probability at exact cluster recovery. To complement the\ntheoretical analysis, we provide an experimental study of the recovery\nguarantees for these various methods, and discuss several open problems which\nthese experiments suggest. \n\n"}
{"id": "1409.5834", "contents": "Title: Tight Error Bounds for Structured Prediction Abstract: Structured prediction tasks in machine learning involve the simultaneous\nprediction of multiple labels. This is typically done by maximizing a score\nfunction on the space of labels, which decomposes as a sum of pairwise\nelements, each depending on two specific labels. Intuitively, the more pairwise\nterms are used, the better the expected accuracy. However, there is currently\nno theoretical account of this intuition. This paper takes a significant step\nin this direction.\n  We formulate the problem as classifying the vertices of a known graph\n$G=(V,E)$, where the vertices and edges of the graph are labelled and correlate\nsemi-randomly with the ground truth. We show that the prospects for achieving\nlow expected Hamming error depend on the structure of the graph $G$ in\ninteresting ways. For example, if $G$ is a very poor expander, like a path,\nthen large expected Hamming error is inevitable. Our main positive result shows\nthat, for a wide class of graphs including 2D grid graphs common in machine\nvision applications, there is a polynomial-time algorithm with small and\ninformation-theoretically near-optimal expected error. Our results provide a\nfirst step toward a theoretical justification for the empirical success of the\nefficient approximate inference algorithms that are used for structured\nprediction in models where exact inference is intractable. \n\n"}
{"id": "1410.0440", "contents": "Title: Scalable Nonlinear Learning with Adaptive Polynomial Expansions Abstract: Can we effectively learn a nonlinear representation in time comparable to\nlinear learning? We describe a new algorithm that explicitly and adaptively\nexpands higher-order interaction features over base linear representations. The\nalgorithm is designed for extreme computational efficiency, and an extensive\nexperimental study shows that its computation/prediction tradeoff ability\ncompares very favorably against strong baselines. \n\n"}
{"id": "1410.1228", "contents": "Title: Interactive Fingerprinting Codes and the Hardness of Preventing False\n  Discovery Abstract: We show an essentially tight bound on the number of adaptively chosen\nstatistical queries that a computationally efficient algorithm can answer\naccurately given $n$ samples from an unknown distribution. A statistical query\nasks for the expectation of a predicate over the underlying distribution, and\nan answer to a statistical query is accurate if it is \"close\" to the correct\nexpectation over the distribution. This question was recently studied by Dwork\net al., who showed how to answer $\\tilde{\\Omega}(n^2)$ queries efficiently, and\nalso by Hardt and Ullman, who showed that answering $\\tilde{O}(n^3)$ queries is\nhard. We close the gap between the two bounds and show that, under a standard\nhardness assumption, there is no computationally efficient algorithm that,\ngiven $n$ samples from an unknown distribution, can give valid answers to\n$O(n^2)$ adaptively chosen statistical queries. An implication of our results\nis that computationally efficient algorithms for answering arbitrary,\nadaptively chosen statistical queries may as well be differentially private.\n  We obtain our results using a new connection between the problem of answering\nadaptively chosen statistical queries and a combinatorial object called an\ninteractive fingerprinting code. In order to optimize our hardness result, we\ngive a new Fourier-analytic approach to analyzing fingerprinting codes that is\nsimpler, more flexible, and yields better parameters than previous\nconstructions. \n\n"}
{"id": "1410.3886", "contents": "Title: Tighter Low-rank Approximation via Sampling the Leveraged Element Abstract: In this work, we propose a new randomized algorithm for computing a low-rank\napproximation to a given matrix. Taking an approach different from existing\nliterature, our method first involves a specific biased sampling, with an\nelement being chosen based on the leverage scores of its row and column, and\nthen involves weighted alternating minimization over the factored form of the\nintended low-rank matrix, to minimize error only on these samples. Our method\ncan leverage input sparsity, yet produce approximations in {\\em spectral} (as\nopposed to the weaker Frobenius) norm; this combines the best aspects of\notherwise disparate current results, but with a dependence on the condition\nnumber $\\kappa = \\sigma_1/\\sigma_r$. In particular we require $O(nnz(M) +\n\\frac{n\\kappa^2 r^5}{\\epsilon^2})$ computations to generate a rank-$r$\napproximation to $M$ in spectral norm. In contrast, the best existing method\nrequires $O(nnz(M)+ \\frac{nr^2}{\\epsilon^4})$ time to compute an approximation\nin Frobenius norm. Besides the tightness in spectral norm, we have a better\ndependence on the error $\\epsilon$. Our method is naturally and highly\nparallelizable.\n  Our new approach enables two extensions that are interesting on their own.\nThe first is a new method to directly compute a low-rank approximation (in\nefficient factored form) to the product of two given matrices; it computes a\nsmall random set of entries of the product, and then executes weighted\nalternating minimization (as before) on these. The sampling strategy is\ndifferent because now we cannot access leverage scores of the product matrix\n(but instead have to work with input matrices). The second extension is an\nimproved algorithm with smaller communication complexity for the distributed\nPCA setting (where each server has small set of rows of the matrix, and want to\ncompute low rank approximation with small amount of communication with other\nservers). \n\n"}
{"id": "1410.5392", "contents": "Title: Scalable Parallel Factorizations of SDD Matrices and Efficient Sampling\n  for Gaussian Graphical Models Abstract: Motivated by a sampling problem basic to computational statistical inference,\nwe develop a nearly optimal algorithm for a fundamental problem in spectral\ngraph theory and numerical analysis. Given an $n\\times n$ SDDM matrix ${\\bf\n\\mathbf{M}}$, and a constant $-1 \\leq p \\leq 1$, our algorithm gives efficient\naccess to a sparse $n\\times n$ linear operator $\\tilde{\\mathbf{C}}$ such that\n$${\\mathbf{M}}^{p} \\approx \\tilde{\\mathbf{C}} \\tilde{\\mathbf{C}}^\\top.$$ The\nsolution is based on factoring ${\\bf \\mathbf{M}}$ into a product of simple and\nsparse matrices using squaring and spectral sparsification. For ${\\mathbf{M}}$\nwith $m$ non-zero entries, our algorithm takes work nearly-linear in $m$, and\npolylogarithmic depth on a parallel machine with $m$ processors. This gives the\nfirst sampling algorithm that only requires nearly linear work and $n$ i.i.d.\nrandom univariate Gaussian samples to generate i.i.d. random samples for\n$n$-dimensional Gaussian random fields with SDDM precision matrices. For\nsampling this natural subclass of Gaussian random fields, it is optimal in the\nrandomness and nearly optimal in the work and parallel complexity. In addition,\nour sampling algorithm can be directly extended to Gaussian random fields with\nSDD precision matrices. \n\n"}
{"id": "1410.6801", "contents": "Title: Dimensionality Reduction for k-Means Clustering and Low Rank\n  Approximation Abstract: We show how to approximate a data matrix $\\mathbf{A}$ with a much smaller\nsketch $\\mathbf{\\tilde A}$ that can be used to solve a general class of\nconstrained k-rank approximation problems to within $(1+\\epsilon)$ error.\nImportantly, this class of problems includes $k$-means clustering and\nunconstrained low rank approximation (i.e. principal component analysis). By\nreducing data points to just $O(k)$ dimensions, our methods generically\naccelerate any exact, approximate, or heuristic algorithm for these ubiquitous\nproblems.\n  For $k$-means dimensionality reduction, we provide $(1+\\epsilon)$ relative\nerror results for many common sketching techniques, including random row\nprojection, column selection, and approximate SVD. For approximate principal\ncomponent analysis, we give a simple alternative to known algorithms that has\napplications in the streaming setting. Additionally, we extend recent work on\ncolumn-based matrix reconstruction, giving column subsets that not only `cover'\na good subspace for $\\bv{A}$, but can be used directly to compute this\nsubspace.\n  Finally, for $k$-means clustering, we show how to achieve a $(9+\\epsilon)$\napproximation by Johnson-Lindenstrauss projecting data points to just $O(\\log\nk/\\epsilon^2)$ dimensions. This gives the first result that leverages the\nspecific structure of $k$-means to achieve dimension independent of input size\nand sublinear in $k$. \n\n"}
{"id": "1410.7171", "contents": "Title: Exponentiated Subgradient Algorithm for Online Optimization under the\n  Random Permutation Model Abstract: Online optimization problems arise in many resource allocation tasks, where\nthe future demands for each resource and the associated utility functions\nchange over time and are not known apriori, yet resources need to be allocated\nat every point in time despite the future uncertainty. In this paper, we\nconsider online optimization problems with general concave utilities. We modify\nand extend an online optimization algorithm proposed by Devanur et al. for\nlinear programming to this general setting. The model we use for the arrival of\nthe utilities and demands is known as the random permutation model, where a\nfixed collection of utilities and demands are presented to the algorithm in\nrandom order. We prove that under this model the algorithm achieves a\ncompetitive ratio of $1-O(\\epsilon)$ under a near-optimal assumption that the\nbid to budget ratio is $O (\\frac{\\epsilon^2}{\\log({m}/{\\epsilon})})$, where $m$\nis the number of resources, while enjoying a significantly lower computational\ncost than the optimal algorithm proposed by Kesselheim et al. We draw a\nconnection between the proposed algorithm and subgradient methods used in\nconvex optimization. In addition, we present numerical experiments that\ndemonstrate the performance and speed of this algorithm in comparison to\nexisting algorithms. \n\n"}
{"id": "1410.7455", "contents": "Title: Parallel training of DNNs with Natural Gradient and Parameter Averaging Abstract: We describe the neural-network training framework used in the Kaldi speech\nrecognition toolkit, which is geared towards training DNNs with large amounts\nof training data using multiple GPU-equipped or multi-core machines. In order\nto be as hardware-agnostic as possible, we needed a way to use multiple\nmachines without generating excessive network traffic. Our method is to average\nthe neural network parameters periodically (typically every minute or two), and\nredistribute the averaged parameters to the machines for further training. Each\nmachine sees different data. By itself, this method does not work very well.\nHowever, we have another method, an approximate and efficient implementation of\nNatural Gradient for Stochastic Gradient Descent (NG-SGD), which seems to allow\nour periodic-averaging method to work well, as well as substantially improving\nthe convergence of SGD on a single machine. \n\n"}
{"id": "1410.8864", "contents": "Title: Greedy Subspace Clustering Abstract: We consider the problem of subspace clustering: given points that lie on or\nnear the union of many low-dimensional linear subspaces, recover the subspaces.\nTo this end, one first identifies sets of points close to the same subspace and\nuses the sets to estimate the subspaces. As the geometric structure of the\nclusters (linear subspaces) forbids proper performance of general distance\nbased approaches such as K-means, many model-specific methods have been\nproposed. In this paper, we provide new simple and efficient algorithms for\nthis problem. Our statistical analysis shows that the algorithms are guaranteed\nexact (perfect) clustering performance under certain conditions on the number\nof points and the affinity between subspaces. These conditions are weaker than\nthose considered in the standard statistical literature. Experimental results\non synthetic data generated from the standard unions of subspaces model\ndemonstrate our theory. We also show that our algorithm performs competitively\nagainst state-of-the-art algorithms on real-world applications such as motion\nsegmentation and face clustering, with much simpler implementation and lower\ncomputational cost. \n\n"}
{"id": "1411.2021", "contents": "Title: Partitioning Well-Clustered Graphs: Spectral Clustering Works! Abstract: In this paper we study variants of the widely used spectral clustering that\npartitions a graph into k clusters by (1) embedding the vertices of a graph\ninto a low-dimensional space using the bottom eigenvectors of the Laplacian\nmatrix, and (2) grouping the embedded points into k clusters via k-means\nalgorithms. We show that, for a wide class of graphs, spectral clustering gives\na good approximation of the optimal clustering. While this approach was\nproposed in the early 1990s and has comprehensive applications, prior to our\nwork similar results were known only for graphs generated from stochastic\nmodels.\n  We also give a nearly-linear time algorithm for partitioning well-clustered\ngraphs based on computing a matrix exponential and approximate nearest neighbor\ndata structures. \n\n"}
{"id": "1411.2374", "contents": "Title: Similarity Learning for High-Dimensional Sparse Data Abstract: A good measure of similarity between data points is crucial to many tasks in\nmachine learning. Similarity and metric learning methods learn such measures\nautomatically from data, but they do not scale well respect to the\ndimensionality of the data. In this paper, we propose a method that can learn\nefficiently similarity measure from high-dimensional sparse data. The core idea\nis to parameterize the similarity measure as a convex combination of rank-one\nmatrices with specific sparsity structures. The parameters are then optimized\nwith an approximate Frank-Wolfe procedure to maximally satisfy relative\nsimilarity constraints on the training data. Our algorithm greedily\nincorporates one pair of features at a time into the similarity measure,\nproviding an efficient way to control the number of active features and thus\nreduce overfitting. It enjoys very appealing convergence guarantees and its\ntime and memory complexity depends on the sparsity of the data instead of the\ndimension of the feature space. Our experiments on real-world high-dimensional\ndatasets demonstrate its potential for classification, dimensionality reduction\nand data exploration. \n\n"}
{"id": "1411.7718", "contents": "Title: Classification with Noisy Labels by Importance Reweighting Abstract: In this paper, we study a classification problem in which sample labels are\nrandomly corrupted. In this scenario, there is an unobservable sample with\nnoise-free labels. However, before being observed, the true labels are\nindependently flipped with a probability $\\rho\\in[0,0.5)$, and the random label\nnoise can be class-conditional. Here, we address two fundamental problems\nraised by this scenario. The first is how to best use the abundant surrogate\nloss functions designed for the traditional classification problem when there\nis label noise. We prove that any surrogate loss function can be used for\nclassification with noisy labels by using importance reweighting, with\nconsistency assurance that the label noise does not ultimately hinder the\nsearch for the optimal classifier of the noise-free sample. The other is the\nopen problem of how to obtain the noise rate $\\rho$. We show that the rate is\nupper bounded by the conditional probability $P(y|x)$ of the noisy sample.\nConsequently, the rate can be estimated, because the upper bound can be easily\nreached in classification problems. Experimental results on synthetic and real\ndatasets confirm the efficiency of our methods. \n\n"}
{"id": "1412.4646", "contents": "Title: Fewer runs than word length Abstract: The work takes another look at the number of runs that a string might contain\nand provides an alternative proof for the bound. We also propose another\nstronger conjecture that states that, for a fixed order on the alphabet, within\nevery factor of a word there are at most as many occurrences of Lyndon roots\ncorresponding to runs in a word as the length of the factor (only first such\noccurrences for each run are considered). \n\n"}
{"id": "1412.6632", "contents": "Title: Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN) Abstract: In this paper, we present a multimodal Recurrent Neural Network (m-RNN) model\nfor generating novel image captions. It directly models the probability\ndistribution of generating a word given previous words and an image. Image\ncaptions are generated by sampling from this distribution. The model consists\nof two sub-networks: a deep recurrent neural network for sentences and a deep\nconvolutional network for images. These two sub-networks interact with each\nother in a multimodal layer to form the whole m-RNN model. The effectiveness of\nour model is validated on four benchmark datasets (IAPR TC-12, Flickr 8K,\nFlickr 30K and MS COCO). Our model outperforms the state-of-the-art methods. In\naddition, we apply the m-RNN model to retrieval tasks for retrieving images or\nsentences, and achieves significant performance improvement over the\nstate-of-the-art methods which directly optimize the ranking objective function\nfor retrieval. The project page of this work is:\nwww.stat.ucla.edu/~junhua.mao/m-RNN.html . \n\n"}
{"id": "1412.7753", "contents": "Title: Learning Longer Memory in Recurrent Neural Networks Abstract: Recurrent neural network is a powerful model that learns temporal patterns in\nsequential data. For a long time, it was believed that recurrent networks are\ndifficult to train using simple optimizers, such as stochastic gradient\ndescent, due to the so-called vanishing gradient problem. In this paper, we\nshow that learning longer term patterns in real data, such as in natural\nlanguage, is perfectly possible using gradient descent. This is achieved by\nusing a slight structural modification of the simple recurrent neural network\narchitecture. We encourage some of the hidden units to change their state\nslowly by making part of the recurrent weight matrix close to identity, thus\nforming kind of a longer term memory. We evaluate our model in language\nmodeling experiments, where we obtain similar performance to the much more\ncomplex Long Short Term Memory (LSTM) networks (Hochreiter & Schmidhuber,\n1997). \n\n"}
{"id": "1501.03326", "contents": "Title: Unbiased Bayes for Big Data: Paths of Partial Posteriors Abstract: A key quantity of interest in Bayesian inference are expectations of\nfunctions with respect to a posterior distribution. Markov Chain Monte Carlo is\na fundamental tool to consistently compute these expectations via averaging\nsamples drawn from an approximate posterior. However, its feasibility is being\nchallenged in the era of so called Big Data as all data needs to be processed\nin every iteration. Realising that such simulation is an unnecessarily hard\nproblem if the goal is estimation, we construct a computationally scalable\nmethodology that allows unbiased estimation of the required expectations --\nwithout explicit simulation from the full posterior. The scheme's variance is\nfinite by construction and straightforward to control, leading to algorithms\nthat are provably unbiased and naturally arrive at a desired error tolerance.\nThis is achieved at an average computational complexity that is sub-linear in\nthe size of the dataset and its free parameters are easy to tune. We\ndemonstrate the utility and generality of the methodology on a range of common\nstatistical models applied to large-scale benchmark and real-world datasets. \n\n"}
{"id": "1501.05800", "contents": "Title: A Reconfigurations Analogue of Brooks' Theorem and its Consequences Abstract: Let $G$ be a simple undirected graph on $n$ vertices with maximum\ndegree~$\\Delta$. Brooks' Theorem states that $G$ has a $\\Delta$-colouring\nunless~$G$ is a complete graph, or a cycle with an odd number of vertices. To\nrecolour $G$ is to obtain a new proper colouring by changing the colour of one\nvertex. We show an analogue of Brooks' Theorem by proving that from any\n$k$-colouring, $k>\\Delta$, a $\\Delta$-colouring of $G$ can be obtained by a\nsequence of $O(n^2)$ recolourings using only the original $k$ colours unless\n$G$ is a complete graph or a cycle with an odd number of vertices, or\n$k=\\Delta+1$, $G$ is $\\Delta$-regular and, for each vertex $v$ in $G$, no two\nneighbours of $v$ are coloured alike.\n  We use this result to study the reconfiguration graph $R_k(G)$ of the\n$k$-colourings of $G$. The vertex set of $R_k(G)$ is the set of all possible\n$k$-colourings of $G$ and two colourings are adjacent if they differ on exactly\none vertex. We prove that for $\\Delta\\geq 3$, $R_{\\Delta+1}(G)$ consists of\nisolated vertices and at most one further component which has diameter\n$O(n^2)$. This result enables us to complete both a structural classification\nand an algorithmic classification for reconfigurations of colourings of graphs\nof bounded maximum degree. \n\n"}
{"id": "1501.06195", "contents": "Title: Randomized sketches for kernels: Fast and optimal non-parametric\n  regression Abstract: Kernel ridge regression (KRR) is a standard method for performing\nnon-parametric regression over reproducing kernel Hilbert spaces. Given $n$\nsamples, the time and space complexity of computing the KRR estimate scale as\n$\\mathcal{O}(n^3)$ and $\\mathcal{O}(n^2)$ respectively, and so is prohibitive\nin many cases. We propose approximations of KRR based on $m$-dimensional\nrandomized sketches of the kernel matrix, and study how small the projection\ndimension $m$ can be chosen while still preserving minimax optimality of the\napproximate KRR estimate. For various classes of randomized sketches, including\nthose based on Gaussian and randomized Hadamard matrices, we prove that it\nsuffices to choose the sketch dimension $m$ proportional to the statistical\ndimension (modulo logarithmic factors). Thus, we obtain fast and minimax\noptimal approximations to the KRR estimate for non-parametric regression. \n\n"}
{"id": "1501.06794", "contents": "Title: Computing Functions of Random Variables via Reproducing Kernel Hilbert\n  Space Representations Abstract: We describe a method to perform functional operations on probability\ndistributions of random variables. The method uses reproducing kernel Hilbert\nspace representations of probability distributions, and it is applicable to all\noperations which can be applied to points drawn from the respective\ndistributions. We refer to our approach as {\\em kernel probabilistic\nprogramming}. We illustrate it on synthetic data, and show how it can be used\nfor nonparametric structural equation models, with an application to causal\ninference. \n\n"}
{"id": "1501.06946", "contents": "Title: New Bounds on Optimal Sorting Networks Abstract: We present new parallel sorting networks for $17$ to $20$ inputs. For $17,\n19,$ and $20$ inputs these new networks are faster (i.e., they require less\ncomputation steps) than the previously known best networks. Therefore, we\nimprove upon the known upper bounds for minimal depth sorting networks on $17,\n19,$ and $20$ channels. Furthermore, we show that our sorting network for $17$\ninputs is optimal in the sense that no sorting network using less layers\nexists. This solves the main open problem of [D. Bundala & J. Za\\'vodn\\'y.\nOptimal sorting networks, Proc. LATA 2014]. \n\n"}
{"id": "1502.00702", "contents": "Title: Hybrid Orthogonal Projection and Estimation (HOPE): A New Framework to\n  Probe and Learn Neural Networks Abstract: In this paper, we propose a novel model for high-dimensional data, called the\nHybrid Orthogonal Projection and Estimation (HOPE) model, which combines a\nlinear orthogonal projection and a finite mixture model under a unified\ngenerative modeling framework. The HOPE model itself can be learned\nunsupervised from unlabelled data based on the maximum likelihood estimation as\nwell as discriminatively from labelled data. More interestingly, we have shown\nthe proposed HOPE models are closely related to neural networks (NNs) in a\nsense that each hidden layer can be reformulated as a HOPE model. As a result,\nthe HOPE framework can be used as a novel tool to probe why and how NNs work,\nmore importantly, to learn NNs in either supervised or unsupervised ways. In\nthis work, we have investigated the HOPE framework to learn NNs for several\nstandard tasks, including image recognition on MNIST and speech recognition on\nTIMIT. Experimental results have shown that the HOPE framework yields\nsignificant performance gains over the current state-of-the-art methods in\nvarious types of NN learning problems, including unsupervised feature learning,\nsupervised or semi-supervised learning. \n\n"}
{"id": "1502.03044", "contents": "Title: Show, Attend and Tell: Neural Image Caption Generation with Visual\n  Attention Abstract: Inspired by recent work in machine translation and object detection, we\nintroduce an attention based model that automatically learns to describe the\ncontent of images. We describe how we can train this model in a deterministic\nmanner using standard backpropagation techniques and stochastically by\nmaximizing a variational lower bound. We also show through visualization how\nthe model is able to automatically learn to fix its gaze on salient objects\nwhile generating the corresponding words in the output sequence. We validate\nthe use of attention with state-of-the-art performance on three benchmark\ndatasets: Flickr8k, Flickr30k and MS COCO. \n\n"}
{"id": "1502.03167", "contents": "Title: Batch Normalization: Accelerating Deep Network Training by Reducing\n  Internal Covariate Shift Abstract: Training Deep Neural Networks is complicated by the fact that the\ndistribution of each layer's inputs changes during training, as the parameters\nof the previous layers change. This slows down the training by requiring lower\nlearning rates and careful parameter initialization, and makes it notoriously\nhard to train models with saturating nonlinearities. We refer to this\nphenomenon as internal covariate shift, and address the problem by normalizing\nlayer inputs. Our method draws its strength from making normalization a part of\nthe model architecture and performing the normalization for each training\nmini-batch. Batch Normalization allows us to use much higher learning rates and\nbe less careful about initialization. It also acts as a regularizer, in some\ncases eliminating the need for Dropout. Applied to a state-of-the-art image\nclassification model, Batch Normalization achieves the same accuracy with 14\ntimes fewer training steps, and beats the original model by a significant\nmargin. Using an ensemble of batch-normalized networks, we improve upon the\nbest published result on ImageNet classification: reaching 4.9% top-5\nvalidation error (and 4.8% test error), exceeding the accuracy of human raters. \n\n"}
{"id": "1502.03496", "contents": "Title: Spectral Sparsification of Random-Walk Matrix Polynomials Abstract: We consider a fundamental algorithmic question in spectral graph theory:\nCompute a spectral sparsifier of random-walk matrix-polynomial\n$$L_\\alpha(G)=D-\\sum_{r=1}^d\\alpha_rD(D^{-1}A)^r$$ where $A$ is the adjacency\nmatrix of a weighted, undirected graph, $D$ is the diagonal matrix of weighted\ndegrees, and $\\alpha=(\\alpha_1...\\alpha_d)$ are nonnegative coefficients with\n$\\sum_{r=1}^d\\alpha_r=1$. Recall that $D^{-1}A$ is the transition matrix of\nrandom walks on the graph. The sparsification of $L_\\alpha(G)$ appears to be\nalgorithmically challenging as the matrix power $(D^{-1}A)^r$ is defined by all\npaths of length $r$, whose precise calculation would be prohibitively\nexpensive.\n  In this paper, we develop the first nearly linear time algorithm for this\nsparsification problem: For any $G$ with $n$ vertices and $m$ edges, $d$\ncoefficients $\\alpha$, and $\\epsilon > 0$, our algorithm runs in time\n$O(d^2m\\log^2n/\\epsilon^{2})$ to construct a Laplacian matrix\n$\\tilde{L}=D-\\tilde{A}$ with $O(n\\log n/\\epsilon^{2})$ non-zeros such that\n$\\tilde{L}\\approx_{\\epsilon}L_\\alpha(G)$.\n  Matrix polynomials arise in mathematical analysis of matrix functions as well\nas numerical solutions of matrix equations. Our work is particularly motivated\nby the algorithmic problems for speeding up the classic Newton's method in\napplications such as computing the inverse square-root of the precision matrix\nof a Gaussian random field, as well as computing the $q$th-root transition (for\n$q\\geq1$) in a time-reversible Markov model. The key algorithmic step for both\napplications is the construction of a spectral sparsifier of a constant degree\nrandom-walk matrix-polynomials introduced by Newton's method. Our algorithm can\nalso be used to build efficient data structures for effective resistances for\nmulti-step time-reversible Markov models, and we anticipate that it could be\nuseful for other tasks in network analysis. \n\n"}
{"id": "1502.03508", "contents": "Title: Adding vs. Averaging in Distributed Primal-Dual Optimization Abstract: Distributed optimization methods for large-scale machine learning suffer from\na communication bottleneck. It is difficult to reduce this bottleneck while\nstill efficiently and accurately aggregating partial work from different\nmachines. In this paper, we present a novel generalization of the recent\ncommunication-efficient primal-dual framework (CoCoA) for distributed\noptimization. Our framework, CoCoA+, allows for additive combination of local\nupdates to the global parameters at each iteration, whereas previous schemes\nwith convergence guarantees only allow conservative averaging. We give stronger\n(primal-dual) convergence rate guarantees for both CoCoA as well as our new\nvariants, and generalize the theory for both methods to cover non-smooth convex\nloss functions. We provide an extensive experimental comparison that shows the\nmarkedly improved performance of CoCoA+ on several real-world distributed\ndatasets, especially when scaling up the number of machines. \n\n"}
{"id": "1502.04622", "contents": "Title: Particle Gibbs for Bayesian Additive Regression Trees Abstract: Additive regression trees are flexible non-parametric models and popular\noff-the-shelf tools for real-world non-linear regression. In application\ndomains, such as bioinformatics, where there is also demand for probabilistic\npredictions with measures of uncertainty, the Bayesian additive regression\ntrees (BART) model, introduced by Chipman et al. (2010), is increasingly\npopular. As data sets have grown in size, however, the standard\nMetropolis-Hastings algorithms used to perform inference in BART are proving\ninadequate. In particular, these Markov chains make local changes to the trees\nand suffer from slow mixing when the data are high-dimensional or the best\nfitting trees are more than a few layers deep. We present a novel sampler for\nBART based on the Particle Gibbs (PG) algorithm (Andrieu et al., 2010) and a\ntop-down particle filtering algorithm for Bayesian decision trees\n(Lakshminarayanan et al., 2013). Rather than making local changes to individual\ntrees, the PG sampler proposes a complete tree to fit the residual. Experiments\nshow that the PG sampler outperforms existing samplers in many settings. \n\n"}
{"id": "1502.05983", "contents": "Title: Sorting Networks: The Final Countdown Abstract: In this paper we extend the knowledge on the problem of empirically searching\nfor sorting networks of minimal depth. We present new search space pruning\ntechniques for the last four levels of a candidate sorting network by\nconsidering only the output set representation of a network. We present an\nalgorithm for checking whether an $n$-input sorting network of depth $d$ exists\nby considering the minimal up to permutation and reflection itemsets at each\nlevel and using the pruning at the last four levels. We experimentally\nevaluated this algorithm to find the optimal depth sorting networks for all $n\n\\leq 12$. \n\n"}
{"id": "1503.00164", "contents": "Title: Analysis of Crowdsourced Sampling Strategies for HodgeRank with Sparse\n  Random Graphs Abstract: Crowdsourcing platforms are now extensively used for conducting subjective\npairwise comparison studies. In this setting, a pairwise comparison dataset is\ntypically gathered via random sampling, either \\emph{with} or \\emph{without}\nreplacement. In this paper, we use tools from random graph theory to analyze\nthese two random sampling methods for the HodgeRank estimator. Using the\nFiedler value of the graph as a measurement for estimator stability\n(informativeness), we provide a new estimate of the Fiedler value for these two\nrandom graph models. In the asymptotic limit as the number of vertices tends to\ninfinity, we prove the validity of the estimate. Based on our findings, for a\nsmall number of items to be compared, we recommend a two-stage sampling\nstrategy where a greedy sampling method is used initially and random sampling\n\\emph{without} replacement is used in the second stage. When a large number of\nitems is to be compared, we recommend random sampling with replacement as this\nis computationally inexpensive and trivially parallelizable. Experiments on\nsynthetic and real-world datasets support our analysis. \n\n"}
{"id": "1503.00323", "contents": "Title: Sparse Approximation of a Kernel Mean Abstract: Kernel means are frequently used to represent probability distributions in\nmachine learning problems. In particular, the well known kernel density\nestimator and the kernel mean embedding both have the form of a kernel mean.\nUnfortunately, kernel means are faced with scalability issues. A single point\nevaluation of the kernel density estimator, for example, requires a computation\ntime linear in the training sample size. To address this challenge, we present\na method to efficiently construct a sparse approximation of a kernel mean. We\ndo so by first establishing an incoherence-based bound on the approximation\nerror, and then noticing that, for the case of radial kernels, the bound can be\nminimized by solving the $k$-center problem. The outcome is a linear time\nconstruction of a sparse kernel mean, which also lends itself naturally to an\nautomatic sparsity selection scheme. We show the computational gains of our\nmethod by looking at three problems involving kernel means: Euclidean embedding\nof distributions, class proportion estimation, and clustering using the\nmean-shift algorithm. \n\n"}
{"id": "1503.01212", "contents": "Title: Hierarchies of Relaxations for Online Prediction Problems with Evolving\n  Constraints Abstract: We study online prediction where regret of the algorithm is measured against\na benchmark defined via evolving constraints. This framework captures online\nprediction on graphs, as well as other prediction problems with combinatorial\nstructure. A key aspect here is that finding the optimal benchmark predictor\n(even in hindsight, given all the data) might be computationally hard due to\nthe combinatorial nature of the constraints. Despite this, we provide\npolynomial-time \\emph{prediction} algorithms that achieve low regret against\ncombinatorial benchmark sets. We do so by building improper learning algorithms\nbased on two ideas that work together. The first is to alleviate part of the\ncomputational burden through random playout, and the second is to employ\nLasserre semidefinite hierarchies to approximate the resulting integer program.\nInterestingly, for our prediction algorithms, we only need to compute the\nvalues of the semidefinite programs and not the rounded solutions. However, the\nintegrality gap for Lasserre hierarchy \\emph{does} enter the generic regret\nbound in terms of Rademacher complexity of the benchmark set. This establishes\na trade-off between the computation time and the regret bound of the algorithm. \n\n"}
{"id": "1503.02746", "contents": "Title: Asymptotic Delsarte cliques in distance-regular graphs Abstract: We give a new bound on the parameter $\\lambda$ (number of common neighbors of\na pair of adjacent vertices) in a distance-regular graph $G$, improving and\ngeneralizing bounds for strongly regular graphs by Spielman (1996) and Pyber\n(2014). The new bound is one of the ingredients of recent progress on the\ncomplexity of testing isomorphism of strongly regular graphs (Babai, Chen, Sun,\nTeng, Wilmes 2013). The proof is based on a clique geometry found by Metsch\n(1991) under certain constraints on the parameters. We also give a simplified\nproof of the following asymptotic consequence of Metsch's result: if $k\\mu =\no(\\lambda^2)$ then each edge of $G$ belongs to a unique maximal clique of size\nasymptotically equal to $\\lambda$, and all other cliques have size\n$o(\\lambda)$. Here $k$ denotes the degree and $\\mu$ the number of common\nneighbors of a pair of vertices at distance 2. We point out that Metsch's\ncliques are \"asymptotically Delsarte\" when $k\\mu = o(\\lambda^2)$, so families\nof distance-regular graphs with parameters satisfying $k\\mu = o(\\lambda^2)$ are\n\"asymptotically Delsarte-geometric.\" \n\n"}
{"id": "1503.03167", "contents": "Title: Deep Convolutional Inverse Graphics Network Abstract: This paper presents the Deep Convolution Inverse Graphics Network (DC-IGN), a\nmodel that learns an interpretable representation of images. This\nrepresentation is disentangled with respect to transformations such as\nout-of-plane rotations and lighting variations. The DC-IGN model is composed of\nmultiple layers of convolution and de-convolution operators and is trained\nusing the Stochastic Gradient Variational Bayes (SGVB) algorithm. We propose a\ntraining procedure to encourage neurons in the graphics code layer to represent\na specific transformation (e.g. pose or light). Given a single input image, our\nmodel can generate new images of the same object with variations in pose and\nlighting. We present qualitative and quantitative results of the model's\nefficacy at learning a 3D rendering engine. \n\n"}
{"id": "1503.05479", "contents": "Title: Interpolating Convex and Non-Convex Tensor Decompositions via the\n  Subspace Norm Abstract: We consider the problem of recovering a low-rank tensor from its noisy\nobservation. Previous work has shown a recovery guarantee with signal to noise\nratio $O(n^{\\lceil K/2 \\rceil /2})$ for recovering a $K$th order rank one\ntensor of size $n\\times \\cdots \\times n$ by recursive unfolding. In this paper,\nwe first improve this bound to $O(n^{K/4})$ by a much simpler approach, but\nwith a more careful analysis. Then we propose a new norm called the subspace\nnorm, which is based on the Kronecker products of factors obtained by the\nproposed simple estimator. The imposed Kronecker structure allows us to show a\nnearly ideal $O(\\sqrt{n}+\\sqrt{H^{K-1}})$ bound, in which the parameter $H$\ncontrols the blend from the non-convex estimator to mode-wise nuclear norm\nminimization. Furthermore, we empirically demonstrate that the subspace norm\nachieves the nearly ideal denoising performance even with $H=O(1)$. \n\n"}
{"id": "1503.06394", "contents": "Title: Large-scale Log-determinant Computation through Stochastic Chebyshev\n  Expansions Abstract: Logarithms of determinants of large positive definite matrices appear\nubiquitously in machine learning applications including Gaussian graphical and\nGaussian process models, partition functions of discrete graphical models,\nminimum-volume ellipsoids, metric learning and kernel learning. Log-determinant\ncomputation involves the Cholesky decomposition at the cost cubic in the number\nof variables, i.e., the matrix dimension, which makes it prohibitive for\nlarge-scale applications. We propose a linear-time randomized algorithm to\napproximate log-determinants for very large-scale positive definite and general\nnon-singular matrices using a stochastic trace approximation, called the\nHutchinson method, coupled with Chebyshev polynomial expansions that both rely\non efficient matrix-vector multiplications. We establish rigorous additive and\nmultiplicative approximation error bounds depending on the condition number of\nthe input matrix. In our experiments, the proposed algorithm can provide very\nhigh accuracy solutions at orders of magnitude faster time than the Cholesky\ndecomposition and Schur completion, and enables us to compute log-determinants\nof matrices involving tens of millions of variables. \n\n"}
{"id": "1504.05287", "contents": "Title: Decomposing Overcomplete 3rd Order Tensors using Sum-of-Squares\n  Algorithms Abstract: Tensor rank and low-rank tensor decompositions have many applications in\nlearning and complexity theory. Most known algorithms use unfoldings of tensors\nand can only handle rank up to $n^{\\lfloor p/2 \\rfloor}$ for a $p$-th order\ntensor in $\\mathbb{R}^{n^p}$. Previously no efficient algorithm can decompose\n3rd order tensors when the rank is super-linear in the dimension. Using ideas\nfrom sum-of-squares hierarchy, we give the first quasi-polynomial time\nalgorithm that can decompose a random 3rd order tensor decomposition when the\nrank is as large as $n^{3/2}/\\textrm{polylog} n$.\n  We also give a polynomial time algorithm for certifying the injective norm of\nrandom low rank tensors. Our tensor decomposition algorithm exploits the\nrelationship between injective norm and the tensor components. The proof relies\non interesting tools for decoupling random variables to prove better matrix\nconcentration bounds, which can be useful in other settings. \n\n"}
{"id": "1504.05477", "contents": "Title: Randomized Block Krylov Methods for Stronger and Faster Approximate\n  Singular Value Decomposition Abstract: Since being analyzed by Rokhlin, Szlam, and Tygert and popularized by Halko,\nMartinsson, and Tropp, randomized Simultaneous Power Iteration has become the\nmethod of choice for approximate singular value decomposition. It is more\naccurate than simpler sketching algorithms, yet still converges quickly for any\nmatrix, independently of singular value gaps. After $\\tilde{O}(1/\\epsilon)$\niterations, it gives a low-rank approximation within $(1+\\epsilon)$ of optimal\nfor spectral norm error.\n  We give the first provable runtime improvement on Simultaneous Iteration: a\nsimple randomized block Krylov method, closely related to the classic Block\nLanczos algorithm, gives the same guarantees in just\n$\\tilde{O}(1/\\sqrt{\\epsilon})$ iterations and performs substantially better\nexperimentally. Despite their long history, our analysis is the first of a\nKrylov subspace method that does not depend on singular value gaps, which are\nunreliable in practice.\n  Furthermore, while it is a simple accuracy benchmark, even $(1+\\epsilon)$\nerror for spectral norm low-rank approximation does not imply that an algorithm\nreturns high quality principal components, a major issue for data applications.\nWe address this problem for the first time by showing that both Block Krylov\nIteration and a minor modification of Simultaneous Iteration give nearly\noptimal PCA for any matrix. This result further justifies their strength over\nnon-iterative sketching methods.\n  Finally, we give insight beyond the worst case, justifying why both\nalgorithms can run much faster in practice than predicted. We clarify how\nsimple techniques can take advantage of common matrix properties to\nsignificantly improve runtime. \n\n"}
{"id": "1504.05487", "contents": "Title: Deep Convolutional Neural Networks Based on Semi-Discrete Frames Abstract: Deep convolutional neural networks have led to breakthrough results in\npractical feature extraction applications. The mathematical analysis of these\nnetworks was pioneered by Mallat, 2012. Specifically, Mallat considered\nso-called scattering networks based on identical semi-discrete wavelet frames\nin each network layer, and proved translation-invariance as well as deformation\nstability of the resulting feature extractor. The purpose of this paper is to\ndevelop Mallat's theory further by allowing for different and, most\nimportantly, general semi-discrete frames (such as, e.g., Gabor frames,\nwavelets, curvelets, shearlets, ridgelets) in distinct network layers. This\nallows to extract wider classes of features than point singularities resolved\nby the wavelet transform. Our generalized feature extractor is proven to be\ntranslation-invariant, and we develop deformation stability results for a\nlarger class of deformations than those considered by Mallat. For Mallat's\nwavelet-based feature extractor, we get rid of a number of technical\nconditions. The mathematical engine behind our results is continuous frame\ntheory, which allows us to completely detach the invariance and deformation\nstability proofs from the particular algebraic structure of the underlying\nframes. \n\n"}
{"id": "1504.06544", "contents": "Title: Sampling Correctors Abstract: In many situations, sample data is obtained from a noisy or imperfect source.\nIn order to address such corruptions, this paper introduces the concept of a\nsampling corrector. Such algorithms use structure that the distribution is\npurported to have, in order to allow one to make \"on-the-fly\" corrections to\nsamples drawn from probability distributions. These algorithms then act as\nfilters between the noisy data and the end user.\n  We show connections between sampling correctors, distribution learning\nalgorithms, and distribution property testing algorithms. We show that these\nconnections can be utilized to expand the applicability of known distribution\nlearning and property testing algorithms as well as to achieve improved\nalgorithms for those tasks.\n  As a first step, we show how to design sampling correctors using proper\nlearning algorithms. We then focus on the question of whether algorithms for\nsampling correctors can be more efficient in terms of sample complexity than\nlearning algorithms for the analogous families of distributions. When\ncorrecting monotonicity, we show that this is indeed the case when also granted\nquery access to the cumulative distribution function. We also obtain sampling\ncorrectors for monotonicity without this stronger type of access, provided that\nthe distribution be originally very close to monotone (namely, at a distance\n$O(1/\\log^2 n)$). In addition to that, we consider a restricted error model\nthat aims at capturing \"missing data\" corruptions. In this model, we show that\ndistributions that are close to monotone have sampling correctors that are\nsignificantly more efficient than achievable by the learning approach.\n  We also consider the question of whether an additional source of independent\nrandom bits is required by sampling correctors to implement the correction\nprocess. \n\n"}
{"id": "1504.06692", "contents": "Title: Learning like a Child: Fast Novel Visual Concept Learning from Sentence\n  Descriptions of Images Abstract: In this paper, we address the task of learning novel visual concepts, and\ntheir interactions with other concepts, from a few images with sentence\ndescriptions. Using linguistic context and visual features, our method is able\nto efficiently hypothesize the semantic meaning of new words and add them to\nits word dictionary so that they can be used to describe images which contain\nthese novel concepts. Our method has an image captioning module based on m-RNN\nwith several improvements. In particular, we propose a transposed weight\nsharing scheme, which not only improves performance on image captioning, but\nalso makes the model more suitable for the novel concept learning task. We\npropose methods to prevent overfitting the new concepts. In addition, three\nnovel concept datasets are constructed for this new task. In the experiments,\nwe show that our method effectively learns novel visual concepts from a few\nexamples without disturbing the previously learned concepts. The project page\nis http://www.stat.ucla.edu/~junhua.mao/projects/child_learning.html \n\n"}
{"id": "1504.07676", "contents": "Title: Explaining the Success of AdaBoost and Random Forests as Interpolating\n  Classifiers Abstract: There is a large literature explaining why AdaBoost is a successful\nclassifier. The literature on AdaBoost focuses on classifier margins and\nboosting's interpretation as the optimization of an exponential likelihood\nfunction. These existing explanations, however, have been pointed out to be\nincomplete. A random forest is another popular ensemble method for which there\nis substantially less explanation in the literature. We introduce a novel\nperspective on AdaBoost and random forests that proposes that the two\nalgorithms work for similar reasons. While both classifiers achieve similar\npredictive accuracy, random forests cannot be conceived as a direct\noptimization procedure. Rather, random forests is a self-averaging,\ninterpolating algorithm which creates what we denote as a \"spikey-smooth\"\nclassifier, and we view AdaBoost in the same light. We conjecture that both\nAdaBoost and random forests succeed because of this mechanism. We provide a\nnumber of examples and some theoretical justification to support this\nexplanation. In the process, we question the conventional wisdom that suggests\nthat boosting algorithms for classification require regularization or early\nstopping and should be limited to low complexity classes of learners, such as\ndecision stumps. We conclude that boosting should be used like random forests:\nwith large decision trees and without direct regularization or early stopping. \n\n"}
{"id": "1504.07697", "contents": "Title: Polynomial Factorization over Finite Fields By Computing Euler-Poincare\n  Characteristics of Drinfeld Modules Abstract: We propose and rigorously analyze two randomized algorithms to factor\nunivariate polynomials over finite fields using rank $2$ Drinfeld modules. The\nfirst algorithm estimates the degree of an irreducible factor of a polynomial\nfrom Euler-Poincare characteristics of random Drinfeld modules. Knowledge of a\nfactor degree allows one to rapidly extract all factors of that degree. As a\nconsequence, the problem of factoring polynomials over finite fields in time\nnearly linear in the degree is reduced to finding Euler-Poincare\ncharacteristics of random Drinfeld modules with high probability. Notably, the\nworst case complexity of polynomial factorization over finite fields is reduced\nto the average case complexity of a problem concerning Drinfeld modules. The\nsecond algorithm is a random Drinfeld module analogue of Berlekamp's algorithm.\nDuring the course of its analysis, we prove a new bound on degree distributions\nin factorization patterns of polynomials over finite fields in certain short\nintervals. \n\n"}
{"id": "1505.00146", "contents": "Title: Thompson Sampling for Budgeted Multi-armed Bandits Abstract: Thompson sampling is one of the earliest randomized algorithms for\nmulti-armed bandits (MAB). In this paper, we extend the Thompson sampling to\nBudgeted MAB, where there is random cost for pulling an arm and the total cost\nis constrained by a budget. We start with the case of Bernoulli bandits, in\nwhich the random rewards (costs) of an arm are independently sampled from a\nBernoulli distribution. To implement the Thompson sampling algorithm in this\ncase, at each round, we sample two numbers from the posterior distributions of\nthe reward and cost for each arm, obtain their ratio, select the arm with the\nmaximum ratio, and then update the posterior distributions. We prove that the\ndistribution-dependent regret bound of this algorithm is $O(\\ln B)$, where $B$\ndenotes the budget. By introducing a Bernoulli trial, we further extend this\nalgorithm to the setting that the rewards (costs) are drawn from general\ndistributions, and prove that its regret bound remains almost the same. Our\nsimulation results demonstrate the effectiveness of the proposed algorithm. \n\n"}
{"id": "1505.00449", "contents": "Title: Algorithms for the minimum sum coloring problem: a review Abstract: The Minimum Sum Coloring Problem (MSCP) is a variant of the well-known vertex\ncoloring problem which has a number of AI related applications. Due to its\ntheoretical and practical relevance, MSCP attracts increasing attention. The\nonly existing review on the problem dates back to 2004 and mainly covers the\nhistory of MSCP and theoretical developments on specific graphs. In recent\nyears, the field has witnessed significant progresses on approximation\nalgorithms and practical solution algorithms. The purpose of this review is to\nprovide a comprehensive inspection of the most recent and representative MSCP\nalgorithms. To be informative, we identify the general framework followed by\npractical solution algorithms and the key ingredients that make them\nsuccessful. By classifying the main search strategies and putting forward the\ncritical elements of the reviewed methods, we wish to encourage future\ndevelopment of more powerful methods and motivate new applications. \n\n"}
{"id": "1505.01419", "contents": "Title: Fast Differentially Private Matrix Factorization Abstract: Differentially private collaborative filtering is a challenging task, both in\nterms of accuracy and speed. We present a simple algorithm that is provably\ndifferentially private, while offering good performance, using a novel\nconnection of differential privacy to Bayesian posterior sampling via\nStochastic Gradient Langevin Dynamics. Due to its simplicity the algorithm\nlends itself to efficient implementation. By careful systems design and by\nexploiting the power law behavior of the data to maximize CPU cache bandwidth\nwe are able to generate 1024 dimensional models at a rate of 8.5 million\nrecommendations per second on a single PC. \n\n"}
{"id": "1505.01918", "contents": "Title: An Asymptotically Optimal Policy for Uniform Bandits of Unknown Support Abstract: Consider the problem of a controller sampling sequentially from a finite\nnumber of $N \\geq 2$ populations, specified by random variables $X^i_k$, $ i =\n1,\\ldots , N,$ and $k = 1, 2, \\ldots$; where $X^i_k$ denotes the outcome from\npopulation $i$ the $k^{th}$ time it is sampled. It is assumed that for each\nfixed $i$, $\\{ X^i_k \\}_{k \\geq 1}$ is a sequence of i.i.d. uniform random\nvariables over some interval $[a_i, b_i]$, with the support (i.e., $a_i, b_i$)\nunknown to the controller. The objective is to have a policy $\\pi$ for\ndeciding, based on available data, from which of the $N$ populations to sample\nfrom at any time $n=1,2,\\ldots$ so as to maximize the expected sum of outcomes\nof $n$ samples or equivalently to minimize the regret due to lack on\ninformation of the parameters $\\{ a_i \\}$ and $\\{ b_i \\}$. In this paper, we\npresent a simple inflated sample mean (ISM) type policy that is asymptotically\noptimal in the sense of its regret achieving the asymptotic lower bound of\nBurnetas and Katehakis (1996). Additionally, finite horizon regret bounds are\ngiven. \n\n"}
{"id": "1505.02000", "contents": "Title: Deep Learning for Medical Image Segmentation Abstract: This report provides an overview of the current state of the art deep\nlearning architectures and optimisation techniques, and uses the ADNI\nhippocampus MRI dataset as an example to compare the effectiveness and\nefficiency of different convolutional architectures on the task of patch-based\n3-dimensional hippocampal segmentation, which is important in the diagnosis of\nAlzheimer's Disease. We found that a slightly unconventional \"stacked 2D\"\napproach provides much better classification performance than simple 2D patches\nwithout requiring significantly more computational power. We also examined the\npopular \"tri-planar\" approach used in some recently published studies, and\nfound that it provides much better results than the 2D approaches, but also\nwith a moderate increase in computational power requirement. Finally, we\nevaluated a full 3D convolutional architecture, and found that it provides\nmarginally better results than the tri-planar approach, but at the cost of a\nvery significant increase in computational power requirement. \n\n"}
{"id": "1505.02213", "contents": "Title: Measuring dependence powerfully and equitably Abstract: Given a high-dimensional data set we often wish to find the strongest\nrelationships within it. A common strategy is to evaluate a measure of\ndependence on every variable pair and retain the highest-scoring pairs for\nfollow-up. This strategy works well if the statistic used is equitable [Reshef\net al. 2015a], i.e., if, for some measure of noise, it assigns similar scores\nto equally noisy relationships regardless of relationship type (e.g., linear,\nexponential, periodic).\n  In this paper, we introduce and characterize a population measure of\ndependence called MIC*. We show three ways that MIC* can be viewed: as the\npopulation value of MIC, a highly equitable statistic from [Reshef et al.\n2011], as a canonical \"smoothing\" of mutual information, and as the supremum of\nan infinite sequence defined in terms of optimal one-dimensional partitions of\nthe marginals of the joint distribution. Based on this theory, we introduce an\nefficient approach for computing MIC* from the density of a pair of random\nvariables, and we define a new consistent estimator MICe for MIC* that is\nefficiently computable. In contrast, there is no known polynomial-time\nalgorithm for computing the original equitable statistic MIC. We show through\nsimulations that MICe has better bias-variance properties than MIC. We then\nintroduce and prove the consistency of a second statistic, TICe, that is a\ntrivial side-product of the computation of MICe and whose goal is powerful\nindependence testing rather than equitability.\n  We show in simulations that MICe and TICe have good equitability and power\nagainst independence respectively. The analyses here complement a more in-depth\nempirical evaluation of several leading measures of dependence [Reshef et al.\n2015b] that shows state-of-the-art performance for MICe and TICe. \n\n"}
{"id": "1505.02250", "contents": "Title: Newton Sketch: A Linear-time Optimization Algorithm with\n  Linear-Quadratic Convergence Abstract: We propose a randomized second-order method for optimization known as the\nNewton Sketch: it is based on performing an approximate Newton step using a\nrandomly projected or sub-sampled Hessian. For self-concordant functions, we\nprove that the algorithm has super-linear convergence with exponentially high\nprobability, with convergence and complexity guarantees that are independent of\ncondition numbers and related problem-dependent quantities. Given a suitable\ninitialization, similar guarantees also hold for strongly convex and smooth\nobjectives without self-concordance. When implemented using randomized\nprojections based on a sub-sampled Hadamard basis, the algorithm typically has\nsubstantially lower complexity than Newton's method. We also describe\nextensions of our methods to programs involving convex constraints that are\nequipped with self-concordant barriers. We discuss and illustrate applications\nto linear programs, quadratic programs with convex constraints, logistic\nregression and other generalized linear models, as well as semidefinite\nprograms. \n\n"}
{"id": "1505.02371", "contents": "Title: Computing maximal autarkies with few and simple oracle queries Abstract: We consider the algorithmic task of computing a maximal autarky for a\nclause-set F, i.e., a partial assignment which satisfies every clause of F it\ntouches, and where this property is destroyed by adding any non-empty set of\nfurther assignments. We employ SAT solvers as oracles, using various\ncapabilities. Using the standard SAT oracle, log_2(n(F)) oracle calls suffice,\nwhere n(F) is the number of variables, but the drawback is that (translated)\ncardinality constraints are employed, which makes this approach less efficient\nin practice. Using an extended SAT oracle, motivated by the capabilities of\nmodern SAT solvers, we show how to compute maximal autarkies with 2 n(F)^{1/2}\nsimpler oracle calls. This novel algorithm combines the previous two main\napproaches, based on the autarky-resolution duality and on SAT translations. \n\n"}
{"id": "1505.03036", "contents": "Title: Removing systematic errors for exoplanet search via latent causes Abstract: We describe a method for removing the effect of confounders in order to\nreconstruct a latent quantity of interest. The method, referred to as\nhalf-sibling regression, is inspired by recent work in causal inference using\nadditive noise models. We provide a theoretical justification and illustrate\nthe potential of the method in a challenging astronomy application. \n\n"}
{"id": "1505.04636", "contents": "Title: Graph Partitioning via Parallel Submodular Approximation to Accelerate\n  Distributed Machine Learning Abstract: Distributed computing excels at processing large scale data, but the\ncommunication cost for synchronizing the shared parameters may slow down the\noverall performance. Fortunately, the interactions between parameter and data\nin many problems are sparse, which admits efficient partition in order to\nreduce the communication overhead.\n  In this paper, we formulate data placement as a graph partitioning problem.\nWe propose a distributed partitioning algorithm. We give both theoretical\nguarantees and a highly efficient implementation. We also provide a highly\nefficient implementation of the algorithm and demonstrate its promising results\non both text datasets and social networks. We show that the proposed algorithm\nleads to 1.6x speedup of a state-of-the-start distributed machine learning\nsystem by eliminating 90\\% of the network communication. \n\n"}
{"id": "1505.04636", "contents": "Title: Graph Partitioning via Parallel Submodular Approximation to Accelerate\n  Distributed Machine Learning Abstract: Distributed computing excels at processing large scale data, but the\ncommunication cost for synchronizing the shared parameters may slow down the\noverall performance. Fortunately, the interactions between parameter and data\nin many problems are sparse, which admits efficient partition in order to\nreduce the communication overhead.\n  In this paper, we formulate data placement as a graph partitioning problem.\nWe propose a distributed partitioning algorithm. We give both theoretical\nguarantees and a highly efficient implementation. We also provide a highly\nefficient implementation of the algorithm and demonstrate its promising results\non both text datasets and social networks. We show that the proposed algorithm\nleads to 1.6x speedup of a state-of-the-start distributed machine learning\nsystem by eliminating 90\\% of the network communication. \n\n"}
{"id": "1505.05114", "contents": "Title: Solving Random Quadratic Systems of Equations Is Nearly as Easy as\n  Solving Linear Systems Abstract: We consider the fundamental problem of solving quadratic systems of equations\nin $n$ variables, where $y_i = |\\langle \\boldsymbol{a}_i, \\boldsymbol{x}\n\\rangle|^2$, $i = 1, \\ldots, m$ and $\\boldsymbol{x} \\in \\mathbb{R}^n$ is\nunknown. We propose a novel method, which starting with an initial guess\ncomputed by means of a spectral method, proceeds by minimizing a nonconvex\nfunctional as in the Wirtinger flow approach. There are several key\ndistinguishing features, most notably, a distinct objective functional and\nnovel update rules, which operate in an adaptive fashion and drop terms bearing\ntoo much influence on the search direction. These careful selection rules\nprovide a tighter initial guess, better descent directions, and thus enhanced\npractical performance. On the theoretical side, we prove that for certain\nunstructured models of quadratic systems, our algorithms return the correct\nsolution in linear time, i.e. in time proportional to reading the data\n$\\{\\boldsymbol{a}_i\\}$ and $\\{y_i\\}$ as soon as the ratio $m/n$ between the\nnumber of equations and unknowns exceeds a fixed numerical constant. We extend\nthe theory to deal with noisy systems in which we only have $y_i \\approx\n|\\langle \\boldsymbol{a}_i, \\boldsymbol{x} \\rangle|^2$ and prove that our\nalgorithms achieve a statistical accuracy, which is nearly un-improvable. We\ncomplement our theoretical study with numerical examples showing that solving\nrandom quadratic systems is both computationally and statistically not much\nharder than solving linear systems of the same size---hence the title of this\npaper. For instance, we demonstrate empirically that the computational cost of\nour algorithm is about four times that of solving a least-squares problem of\nthe same size. \n\n"}
{"id": "1505.06915", "contents": "Title: Large-scale Machine Learning for Metagenomics Sequence Classification Abstract: Metagenomics characterizes the taxonomic diversity of microbial communities\nby sequencing DNA directly from an environmental sample. One of the main\nchallenges in metagenomics data analysis is the binning step, where each\nsequenced read is assigned to a taxonomic clade. Due to the large volume of\nmetagenomics datasets, binning methods need fast and accurate algorithms that\ncan operate with reasonable computing requirements. While standard\nalignment-based methods provide state-of-the-art performance, compositional\napproaches that assign a taxonomic class to a DNA read based on the k-mers it\ncontains have the potential to provide faster solutions. In this work, we\ninvestigate the potential of modern, large-scale machine learning\nimplementations for taxonomic affectation of next-generation sequencing reads\nbased on their k-mers profile. We show that machine learning-based\ncompositional approaches benefit from increasing the number of fragments\nsampled from reference genome to tune their parameters, up to a coverage of\nabout 10, and from increasing the k-mer size to about 12. Tuning these models\ninvolves training a machine learning model on about 10 8 samples in 10 7\ndimensions, which is out of reach of standard soft-wares but can be done\nefficiently with modern implementations for large-scale machine learning. The\nresulting models are competitive in terms of accuracy with well-established\nalignment tools for problems involving a small to moderate number of candidate\nspecies, and for reasonable amounts of sequencing errors. We show, however,\nthat compositional approaches are still limited in their ability to deal with\nproblems involving a greater number of species, and more sensitive to\nsequencing errors. We finally confirm that compositional approach achieve\nfaster prediction times, with a gain of 3 to 15 times with respect to the\nBWA-MEM short read mapper, depending on the number of candidate species and the\nlevel of sequencing noise. \n\n"}
{"id": "1506.00671", "contents": "Title: Sample-Optimal Density Estimation in Nearly-Linear Time Abstract: We design a new, fast algorithm for agnostically learning univariate\nprobability distributions whose densities are well approximated by piecewise\npolynomial functions. Let $f$ be the density function of an arbitrary\nunivariate distribution, and suppose that $f$ is $\\mathrm{OPT}$-close in\n$L_1$-distance to an unknown piecewise polynomial function with $t$ interval\npieces and degree $d$. Our algorithm draws $n = O(t(d+1)/\\epsilon^2)$ samples\nfrom $f$, runs in time $\\tilde{O}(n \\cdot \\mathrm{poly}(d))$, and with\nprobability at least $9/10$ outputs an $O(t)$-piecewise degree-$d$ hypothesis\n$h$ that is $4 \\cdot \\mathrm{OPT} +\\epsilon$ close to $f$.\n  Our general algorithm yields (nearly) sample-optimal and nearly-linear time\nestimators for a wide range of structured distribution families over both\ncontinuous and discrete domains in a unified way. For most of our applications,\nthese are the first sample-optimal and nearly-linear time estimators in the\nliterature. As a consequence, our work resolves the sample and computational\ncomplexities of a broad class of inference tasks via a single \"meta-algorithm\".\nMoreover, we experimentally demonstrate that our algorithm performs very well\nin practice.\n  Our algorithm consists of three \"levels\": (i) At the top level, we employ an\niterative greedy algorithm for finding a good partition of the real line into\nthe pieces of a piecewise polynomial. (ii) For each piece, we show that the\nsub-problem of finding a good polynomial fit on the current interval can be\nsolved efficiently with a separation oracle method. (iii) We reduce the task of\nfinding a separating hyperplane to a combinatorial problem and give an\nefficient algorithm for this problem. Combining these three procedures gives a\ndensity estimation algorithm with the claimed guarantees. \n\n"}
{"id": "1506.02227", "contents": "Title: Primal Method for ERM with Flexible Mini-batching Schemes and Non-convex\n  Losses Abstract: In this work we develop a new algorithm for regularized empirical risk\nminimization. Our method extends recent techniques of Shalev-Shwartz [02/2015],\nwhich enable a dual-free analysis of SDCA, to arbitrary mini-batching schemes.\nMoreover, our method is able to better utilize the information in the data\ndefining the ERM problem. For convex loss functions, our complexity results\nmatch those of QUARTZ, which is a primal-dual method also allowing for\narbitrary mini-batching schemes. The advantage of a dual-free analysis comes\nfrom the fact that it guarantees convergence even for non-convex loss\nfunctions, as long as the average loss is convex. We illustrate through\nexperiments the utility of being able to design arbitrary mini-batching\nschemes. \n\n"}
{"id": "1506.02717", "contents": "Title: An Improved BKW Algorithm for LWE with Applications to Cryptography and\n  Lattices Abstract: In this paper, we study the Learning With Errors problem and its binary\nvariant, where secrets and errors are binary or taken in a small interval. We\nintroduce a new variant of the Blum, Kalai and Wasserman algorithm, relying on\na quantization step that generalizes and fine-tunes modulus switching. In\ngeneral this new technique yields a significant gain in the constant in front\nof the exponent in the overall complexity. We illustrate this by solving p\nwithin half a day a LWE instance with dimension n = 128, modulus $q = n^2$,\nGaussian noise $\\alpha = 1/(\\sqrt{n/\\pi} \\log^2 n)$ and binary secret, using\n$2^{28}$ samples, while the previous best result based on BKW claims a time\ncomplexity of $2^{74}$ with $2^{60}$ samples for the same parameters. We then\nintroduce variants of BDD, GapSVP and UniqueSVP, where the target point is\nrequired to lie in the fundamental parallelepiped, and show how the previous\nalgorithm is able to solve these variants in subexponential time. Moreover, we\nalso show how the previous algorithm can be used to solve the BinaryLWE problem\nwith n samples in subexponential time $2^{(\\ln 2/2+o(1))n/\\log \\log n}$. This\nanalysis does not require any heuristic assumption, contrary to other algebraic\napproaches; instead, it uses a variant of an idea by Lyubashevsky to generate\nmany samples from a small number of samples. This makes it possible to\nasymptotically and heuristically break the NTRU cryptosystem in subexponential\ntime (without contradicting its security assumption). We are also able to solve\nsubset sum problems in subexponential time for density $o(1)$, which is of\nindependent interest: for such density, the previous best algorithm requires\nexponential time. As a direct application, we can solve in subexponential time\nthe parameters of a cryptosystem based on this problem proposed at TCC 2010. \n\n"}
{"id": "1506.05011", "contents": "Title: Bayesian representation learning with oracle constraints Abstract: Representation learning systems typically rely on massive amounts of labeled\ndata in order to be trained to high accuracy. Recently, high-dimensional\nparametric models like neural networks have succeeded in building rich\nrepresentations using either compressive, reconstructive or supervised\ncriteria. However, the semantic structure inherent in observations is\noftentimes lost in the process. Human perception excels at understanding\nsemantics but cannot always be expressed in terms of labels. Thus,\n\\emph{oracles} or \\emph{human-in-the-loop systems}, for example crowdsourcing,\nare often employed to generate similarity constraints using an implicit\nsimilarity function encoded in human perception. In this work we propose to\ncombine \\emph{generative unsupervised feature learning} with a\n\\emph{probabilistic treatment of oracle information like triplets} in order to\ntransfer implicit privileged oracle knowledge into explicit nonlinear Bayesian\nlatent factor models of the observations. We use a fast variational algorithm\nto learn the joint model and demonstrate applicability to a well-known image\ndataset. We show how implicit triplet information can provide rich information\nto learn representations that outperform previous metric learning approaches as\nwell as generative models without this side-information in a variety of\npredictive tasks. In addition, we illustrate that the proposed approach\ncompartmentalizes the latent spaces semantically which allows interpretation of\nthe latent variables. \n\n"}
{"id": "1506.06438", "contents": "Title: Taming the Wild: A Unified Analysis of Hogwild!-Style Algorithms Abstract: Stochastic gradient descent (SGD) is a ubiquitous algorithm for a variety of\nmachine learning problems. Researchers and industry have developed several\ntechniques to optimize SGD's runtime performance, including asynchronous\nexecution and reduced precision. Our main result is a martingale-based analysis\nthat enables us to capture the rich noise models that may arise from such\ntechniques. Specifically, we use our new analysis in three ways: (1) we derive\nconvergence rates for the convex case (Hogwild!) with relaxed assumptions on\nthe sparsity of the problem; (2) we analyze asynchronous SGD algorithms for\nnon-convex matrix problems including matrix completion; and (3) we design and\nanalyze an asynchronous SGD algorithm, called Buckwild!, that uses\nlower-precision arithmetic. We show experimentally that our algorithms run\nefficiently for a variety of problems on modern hardware. \n\n"}
{"id": "1506.07615", "contents": "Title: Completing Low-Rank Matrices with Corrupted Samples from Few\n  Coefficients in General Basis Abstract: Subspace recovery from corrupted and missing data is crucial for various\napplications in signal processing and information theory. To complete missing\nvalues and detect column corruptions, existing robust Matrix Completion (MC)\nmethods mostly concentrate on recovering a low-rank matrix from few corrupted\ncoefficients w.r.t. standard basis, which, however, does not apply to more\ngeneral basis, e.g., Fourier basis. In this paper, we prove that the range\nspace of an $m\\times n$ matrix with rank $r$ can be exactly recovered from few\ncoefficients w.r.t. general basis, though $r$ and the number of corrupted\nsamples are both as high as $O(\\min\\{m,n\\}/\\log^3 (m+n))$. Our model covers\nprevious ones as special cases, and robust MC can recover the intrinsic matrix\nwith a higher rank. Moreover, we suggest a universal choice of the\nregularization parameter, which is $\\lambda=1/\\sqrt{\\log n}$. By our\n$\\ell_{2,1}$ filtering algorithm, which has theoretical guarantees, we can\nfurther reduce the computational cost of our model. As an application, we also\nfind that the solutions to extended robust Low-Rank Representation and to our\nextended robust MC are mutually expressible, so both our theory and algorithm\ncan be applied to the subspace clustering problem with missing values under\ncertain conditions. Experiments verify our theories. \n\n"}
{"id": "1506.08187", "contents": "Title: A geometric alternative to Nesterov's accelerated gradient descent Abstract: We propose a new method for unconstrained optimization of a smooth and\nstrongly convex function, which attains the optimal rate of convergence of\nNesterov's accelerated gradient descent. The new algorithm has a simple\ngeometric interpretation, loosely inspired by the ellipsoid method. We provide\nsome numerical evidence that the new method can be superior to Nesterov's\naccelerated gradient descent. \n\n"}
{"id": "1506.08189", "contents": "Title: Correlation Clustering and Biclustering with Locally Bounded Errors Abstract: We consider a generalized version of the correlation clustering problem,\ndefined as follows. Given a complete graph $G$ whose edges are labeled with $+$\nor $-$, we wish to partition the graph into clusters while trying to avoid\nerrors: $+$ edges between clusters or $-$ edges within clusters. Classically,\none seeks to minimize the total number of such errors. We introduce a new\nframework that allows the objective to be a more general function of the number\nof errors at each vertex (for example, we may wish to minimize the number of\nerrors at the worst vertex) and provide a rounding algorithm which converts\n\"fractional clusterings\" into discrete clusterings while causing only a\nconstant-factor blowup in the number of errors at each vertex. This rounding\nalgorithm yields constant-factor approximation algorithms for the discrete\nproblem under a wide variety of objective functions. \n\n"}
{"id": "1506.09039", "contents": "Title: Scalable Discrete Sampling as a Multi-Armed Bandit Problem Abstract: Drawing a sample from a discrete distribution is one of the building\ncomponents for Monte Carlo methods. Like other sampling algorithms, discrete\nsampling suffers from the high computational burden in large-scale inference\nproblems. We study the problem of sampling a discrete random variable with a\nhigh degree of dependency that is typical in large-scale Bayesian inference and\ngraphical models, and propose an efficient approximate solution with a\nsubsampling approach. We make a novel connection between the discrete sampling\nand Multi-Armed Bandits problems with a finite reward population and provide\nthree algorithms with theoretical guarantees. Empirical evaluations show the\nrobustness and efficiency of the approximate algorithms in both synthetic and\nreal-world large-scale problems. \n\n"}
{"id": "1507.01569", "contents": "Title: Emphatic Temporal-Difference Learning Abstract: Emphatic algorithms are temporal-difference learning algorithms that change\ntheir effective state distribution by selectively emphasizing and\nde-emphasizing their updates on different time steps. Recent works by Sutton,\nMahmood and White (2015), and Yu (2015) show that by varying the emphasis in a\nparticular way, these algorithms become stable and convergent under off-policy\ntraining with linear function approximation. This paper serves as a unified\nsummary of the available results from both works. In addition, we demonstrate\nthe empirical benefits from the flexibility of emphatic algorithms, including\nstate-dependent discounting, state-dependent bootstrapping, and the\nuser-specified allocation of function approximation resources. \n\n"}
{"id": "1507.02564", "contents": "Title: Sampling from a log-concave distribution with Projected Langevin Monte\n  Carlo Abstract: We extend the Langevin Monte Carlo (LMC) algorithm to compactly supported\nmeasures via a projection step, akin to projected Stochastic Gradient Descent\n(SGD). We show that (projected) LMC allows to sample in polynomial time from a\nlog-concave distribution with smooth potential. This gives a new Markov chain\nto sample from a log-concave distribution. Our main result shows in particular\nthat when the target distribution is uniform, LMC mixes in $\\tilde{O}(n^7)$\nsteps (where $n$ is the dimension). We also provide preliminary experimental\nevidence that LMC performs at least as well as hit-and-run, for which a better\nmixing time of $\\tilde{O}(n^4)$ was proved by Lov{\\'a}sz and Vempala. \n\n"}
{"id": "1507.02805", "contents": "Title: On the Connectedness of Clash-free Timetables Abstract: We investigate the connectedness of clash-free timetables with respect to the\nKempe-exchange operation. This investigation is related to the connectedness of\nthe search space of timetabling problem instances, which is a desirable\nproperty, for example for two-step algorithms using the Kempe-exchange during\nthe optimization step. The theoretical framework for our investigations is\nbased on the study of reconfiguration graphs, which model the search space of\ntimetabling problems. We contribute to this framework by including timeslot\navailability requirements in the analysis and we derive improved conditions for\nthe connectedness of clash-free timetables in this setting. We apply the\ntheoretical insights to establish the connectedness of clash-free timetables\nfor a number of benchmark instances. \n\n"}
{"id": "1507.03028", "contents": "Title: Endomorphisms, train track maps, and fully irreducible monodromies Abstract: Any endomorphism of a finitely generated free group naturally descends to an\ninjective endomorphism of its stable quotient. In this paper, we prove a\ngeometric incarnation of this phenomenon: namely, that every expanding\nirreducible train track map inducing an endomorphism of the fundamental group\ngives rise to an expanding irreducible train track representative of the\ninjective endomorphism of the stable quotient. As an application, we prove that\nthe property of having fully irreducible monodromy for a splitting of a\nhyperbolic free-by-cyclic group depends only on the component of the\nBNS-invariant containing the associated homomorphism to the integers. \n\n"}
{"id": "1507.03292", "contents": "Title: Cluster-Aided Mobility Predictions Abstract: Predicting the future location of users in wireless net- works has numerous\napplications, and can help service providers to improve the quality of service\nperceived by their clients. The location predictors proposed so far estimate\nthe next location of a specific user by inspecting the past individual\ntrajectories of this user. As a consequence, when the training data collected\nfor a given user is limited, the resulting prediction is inaccurate. In this\npaper, we develop cluster-aided predictors that exploit past trajectories\ncollected from all users to predict the next location of a given user. These\npredictors rely on clustering techniques and extract from the training data\nsimilarities among the mobility patterns of the various users to improve the\nprediction accuracy. Specifically, we present CAMP (Cluster-Aided Mobility\nPredictor), a cluster-aided predictor whose design is based on recent\nnon-parametric bayesian statistical tools. CAMP is robust and adaptive in the\nsense that it exploits similarities in users' mobility only if such\nsimilarities are really present in the training data. We analytically prove the\nconsistency of the predictions provided by CAMP, and investigate its\nperformance using two large-scale datasets. CAMP significantly outperforms\nexisting predictors, and in particular those that only exploit individual past\ntrajectories. \n\n"}
{"id": "1507.04888", "contents": "Title: Maximum Entropy Deep Inverse Reinforcement Learning Abstract: This paper presents a general framework for exploiting the representational\ncapacity of neural networks to approximate complex, nonlinear reward functions\nin the context of solving the inverse reinforcement learning (IRL) problem. We\nshow in this context that the Maximum Entropy paradigm for IRL lends itself\nnaturally to the efficient training of deep architectures. At test time, the\napproach leads to a computational complexity independent of the number of\ndemonstrations, which makes it especially well-suited for applications in\nlife-long learning scenarios. Our approach achieves performance commensurate to\nthe state-of-the-art on existing benchmarks while exceeding on an alternative\nbenchmark based on highly varying reward structures. Finally, we extend the\nbasic architecture - which is equivalent to a simplified subclass of Fully\nConvolutional Neural Networks (FCNNs) with width one - to include larger\nconvolutions in order to eliminate dependency on precomputed spatial features\nand work on raw input representations. \n\n"}
{"id": "1507.05950", "contents": "Title: On the Worst-Case Approximability of Sparse PCA Abstract: It is well known that Sparse PCA (Sparse Principal Component Analysis) is\nNP-hard to solve exactly on worst-case instances. What is the complexity of\nsolving Sparse PCA approximately? Our contributions include: 1) a simple and\nefficient algorithm that achieves an $n^{-1/3}$-approximation; 2) NP-hardness\nof approximation to within $(1-\\varepsilon)$, for some small constant\n$\\varepsilon > 0$; 3) SSE-hardness of approximation to within any constant\nfactor; and 4) an $\\exp\\exp\\left(\\Omega\\left(\\sqrt{\\log \\log n}\\right)\\right)$\n(\"quasi-quasi-polynomial\") gap for the standard semidefinite program. \n\n"}
{"id": "1507.06175", "contents": "Title: Efficient Low-Redundancy Codes for Correcting Multiple Deletions Abstract: We consider the problem of constructing binary codes to recover from $k$-bit\ndeletions with efficient encoding/decoding, for a fixed $k$. The single\ndeletion case is well understood, with the Varshamov-Tenengolts-Levenshtein\ncode from 1965 giving an asymptotically optimal construction with $\\approx\n2^n/n$ codewords of length $n$, i.e., at most $\\log n$ bits of redundancy.\nHowever, even for the case of two deletions, there was no known explicit\nconstruction with redundancy less than $n^{\\Omega(1)}$.\n  For any fixed $k$, we construct a binary code with $c_k \\log n$ redundancy\nthat can be decoded from $k$ deletions in $O_k(n \\log^4 n)$ time. The\ncoefficient $c_k$ can be taken to be $O(k^2 \\log k)$, which is only\nquadratically worse than the optimal, non-constructive bound of $O(k)$. We also\nindicate how to modify this code to allow for a combination of up to $k$\ninsertions and deletions. \n\n"}
{"id": "1507.06970", "contents": "Title: Perturbed Iterate Analysis for Asynchronous Stochastic Optimization Abstract: We introduce and analyze stochastic optimization methods where the input to\neach gradient update is perturbed by bounded noise. We show that this framework\nforms the basis of a unified approach to analyze asynchronous implementations\nof stochastic optimization algorithms.In this framework, asynchronous\nstochastic optimization algorithms can be thought of as serial methods\noperating on noisy inputs. Using our perturbed iterate framework, we provide\nnew analyses of the Hogwild! algorithm and asynchronous stochastic coordinate\ndescent, that are simpler than earlier analyses, remove many assumptions of\nprevious models, and in some cases yield improved upper bounds on the\nconvergence rates. We proceed to apply our framework to develop and analyze\nKroMagnon: a novel, parallel, sparse stochastic variance-reduced gradient\n(SVRG) algorithm. We demonstrate experimentally on a 16-core machine that the\nsparse and parallel version of SVRG is in some cases more than four orders of\nmagnitude faster than the standard SVRG algorithm. \n\n"}
{"id": "1507.07237", "contents": "Title: A Deterministic Algorithm for Maximizing Submodular Functions Abstract: The problem of maximizing a non-negative submodular function was introduced\nby Feige, Mirrokni, and Vondrak [FOCS'07] who provided a deterministic\nlocal-search based algorithm that guarantees an approximation ratio of $\\frac 1\n3$, as well as a randomized $\\frac 2 5$-approximation algorithm. An extensive\nline of research followed and various algorithms with improving approximation\nratios were developed, all of them are randomized. Finally, Buchbinder et al.\n[FOCS'12] presented a randomized $\\frac 1 2$-approximation algorithm, which is\nthe best possible.\n  This paper gives the first deterministic algorithm for maximizing a\nnon-negative submodular function that achieves an approximation ratio better\nthan $\\frac 1 3$. The approximation ratio of our algorithm is $\\frac 2 5$. Our\nalgorithm is based on recursive composition of solutions obtained by the local\nsearch algorithm of Feige et al. We show that the $\\frac 2 5$ approximation\nratio can be guaranteed when the recursion depth is $2$, and leave open the\nquestion of whether the approximation ratio improves as the recursion depth\nincreases. \n\n"}
{"id": "1507.07368", "contents": "Title: Almost Optimal Cover-Free Families Abstract: Roughly speaking, an $(n,(r,s))$-Cover Free Family (CFF) is a small set of\n$n$-bit strings such that: \"in any $d:=r+s$ indices we see all patterns of\nweight $r$\". CFFs have been of interest for a long time both in discrete\nmathematics as part of block design theory, and in theoretical computer science\nwhere they have found a variety of applications, for example, in parametrized\nalgorithms where they were introduced in the recent breakthrough work of Fomin,\nLokshtanov and Saurabh under the name `lopsided universal sets'.\n  In this paper we give the first explicit construction of cover-free families\nof optimal size up to lower order multiplicative terms, {for any $r$ and $s$}.\nIn fact, our construction time is almost linear in the size of the family.\nBefore our work, such a result existed only for $r=d^{o(1)}$. and $r=\n\\omega(d/(\\log\\log d\\log\\log\\log d))$. As a sample application, we improve the\nrunning times of parameterized algorithms from the recent work of Gabizon,\nLokshtanov and Pilipczuk. \n\n"}
{"id": "1507.07495", "contents": "Title: Estimating an Activity Driven Hidden Markov Model Abstract: We define a Hidden Markov Model (HMM) in which each hidden state has\ntime-dependent $\\textit{activity levels}$ that drive transitions and emissions,\nand show how to estimate its parameters. Our construction is motivated by the\nproblem of inferring human mobility on sub-daily time scales from, for example,\nmobile phone records. \n\n"}
{"id": "1507.07497", "contents": "Title: An Efficient Parallel Algorithm for Spectral Sparsification of Laplacian\n  and SDDM Matrix Polynomials Abstract: For \"large\" class $\\mathcal{C}$ of continuous probability density functions\n(p.d.f.), we demonstrate that for every $w\\in\\mathcal{C}$ there is mixture of\ndiscrete Binomial distributions (MDBD) with $T\\geq N\\sqrt{\\phi_{w}/\\delta}$\ndistinct Binomial distributions $B(\\cdot,N)$ that $\\delta$-approximates a\ndiscretized p.d.f. $\\widehat{w}(i/N)\\triangleq\nw(i/N)/[\\sum_{\\ell=0}^{N}w(\\ell/N)]$ for all $i\\in[3:N-3]$, where\n$\\phi_{w}\\geq\\max_{x\\in[0,1]}|w(x)|$. Also, we give two efficient parallel\nalgorithms to find such MDBD.\n  Moreover, we propose a sequential algorithm that on input MDBD with $N=2^k$\nfor $k\\in\\mathbb{N}_{+}$ that induces a discretized p.d.f. $\\beta$, $B=D-M$\nthat is either Laplacian or SDDM matrix and parameter $\\epsilon\\in(0,1)$,\noutputs in $\\widehat{O}(\\epsilon^{-2}m + \\epsilon^{-4}nT)$ time a spectral\nsparsifier $D-\\widehat{M}_{N} \\approx_{\\epsilon}\nD-D\\sum_{i=0}^{N}\\beta_{i}(D^{-1} M)^i$ of a matrix-polynomial, where\n$\\widehat{O}(\\cdot)$ notation hides $\\mathrm{poly}(\\log n,\\log N)$ factors.\nThis improves the Cheng et al.'s [CCLPT15] algorithm whose run time is\n$\\widehat{O}(\\epsilon^{-2} m N^2 + NT)$.\n  Furthermore, our algorithm is parallelizable and runs in work\n$\\widehat{O}(\\epsilon^{-2}m + \\epsilon^{-4}nT)$ and depth $O(\\log\nN\\cdot\\mathrm{poly}(\\log n)+\\log T)$. Our main algorithmic contribution is to\npropose the first efficient parallel algorithm that on input continuous p.d.f.\n$w\\in\\mathcal{C}$, matrix $B=D-M$ as above, outputs a spectral sparsifier of\nmatrix-polynomial whose coefficients approximate component-wise the discretized\np.d.f. $\\widehat{w}$.\n  Our results yield the first efficient and parallel algorithm that runs in\nnearly linear work and poly-logarithmic depth and analyzes the long term\nbehaviour of Markov chains in non-trivial settings. In addition, we strengthen\nthe Spielman and Peng's [PS14] parallel SDD solver. \n\n"}
{"id": "1507.08286", "contents": "Title: Deep Learning for Single-View Instance Recognition Abstract: Deep learning methods have typically been trained on large datasets in which\nmany training examples are available. However, many real-world product datasets\nhave only a small number of images available for each product. We explore the\nuse of deep learning methods for recognizing object instances when we have only\na single training example per class. We show that feedforward neural networks\noutperform state-of-the-art methods for recognizing objects from novel\nviewpoints even when trained from just a single image per object. To further\nimprove our performance on this task, we propose to take advantage of a\nsupplementary dataset in which we observe a separate set of objects from\nmultiple viewpoints. We introduce a new approach for training deep learning\nmethods for instance recognition with limited training data, in which we use an\nauxiliary multi-view dataset to train our network to be robust to viewpoint\nchanges. We find that this approach leads to a more robust classifier for\nrecognizing objects from novel viewpoints, outperforming previous\nstate-of-the-art approaches including keypoint-matching, template-based\ntechniques, and sparse coding. \n\n"}
{"id": "1508.00625", "contents": "Title: Sparse PCA via Bipartite Matchings Abstract: We consider the following multi-component sparse PCA problem: given a set of\ndata points, we seek to extract a small number of sparse components with\ndisjoint supports that jointly capture the maximum possible variance. These\ncomponents can be computed one by one, repeatedly solving the single-component\nproblem and deflating the input data matrix, but as we show this greedy\nprocedure is suboptimal. We present a novel algorithm for sparse PCA that\njointly optimizes multiple disjoint components. The extracted features capture\nvariance that lies within a multiplicative factor arbitrarily close to 1 from\nthe optimal. Our algorithm is combinatorial and computes the desired components\nby solving multiple instances of the bipartite maximum weight matching problem.\nIts complexity grows as a low order polynomial in the ambient dimension of the\ninput data matrix, but exponentially in its rank. However, it can be\neffectively applied on a low-dimensional sketch of the data; this allows us to\nobtain polynomial-time approximation guarantees via spectral bounds. We\nevaluate our algorithm on real data-sets and empirically demonstrate that in\nmany cases it outperforms existing, deflation-based approaches. \n\n"}
{"id": "1508.03337", "contents": "Title: A Randomized Rounding Algorithm for Sparse PCA Abstract: We present and analyze a simple, two-step algorithm to approximate the\noptimal solution of the sparse PCA problem. Our approach first solves a L1\npenalized version of the NP-hard sparse PCA optimization problem and then uses\na randomized rounding strategy to sparsify the resulting dense solution. Our\nmain theoretical result guarantees an additive error approximation and provides\na tradeoff between sparsity and accuracy. Our experimental evaluation indicates\nthat our approach is competitive in practice, even compared to state-of-the-art\ntoolboxes such as Spasm. \n\n"}
{"id": "1508.03712", "contents": "Title: Towards an Axiomatic Approach to Hierarchical Clustering of Measures Abstract: We propose some axioms for hierarchical clustering of probability measures\nand investigate their ramifications. The basic idea is to let the user\nstipulate the clusters for some elementary measures. This is done without the\nneed of any notion of metric, similarity or dissimilarity. Our main results\nthen show that for each suitable choice of user-defined clustering on\nelementary measures we obtain a unique notion of clustering on a large set of\ndistributions satisfying a set of additivity and continuity axioms. We\nillustrate the developed theory by numerous examples including some with and\nsome without a density. \n\n"}
{"id": "1508.04211", "contents": "Title: Scalable Bayesian Non-Negative Tensor Factorization for Massive Count\n  Data Abstract: We present a Bayesian non-negative tensor factorization model for\ncount-valued tensor data, and develop scalable inference algorithms (both batch\nand online) for dealing with massive tensors. Our generative model can handle\noverdispersed counts as well as infer the rank of the decomposition. Moreover,\nleveraging a reparameterization of the Poisson distribution as a multinomial\nfacilitates conjugacy in the model and enables simple and efficient Gibbs\nsampling and variational Bayes (VB) inference updates, with a computational\ncost that only depends on the number of nonzeros in the tensor. The model also\nprovides a nice interpretability for the factors; in our model, each factor\ncorresponds to a \"topic\". We develop a set of online inference algorithms that\nallow further scaling up the model to massive tensors, for which batch\ninference methods may be infeasible. We apply our framework on diverse\nreal-world applications, such as \\emph{multiway} topic modeling on a scientific\npublications database, analyzing a political science data set, and analyzing a\nmassive household transactions data set. \n\n"}
{"id": "1508.04816", "contents": "Title: Reducing multi-qubit interactions in adiabatic quantum computation\n  without adding auxiliary qubits. Part 1: The \"deduc-reduc\" method and its\n  application to quantum factorization of numbers Abstract: Adiabatic quantum computing has recently been used to factor 56153 [Dattani &\nBryans, arXiv:1411.6758] at room temperature, which is orders of magnitude\nlarger than any number attempted yet using Shor's algorithm (circuit-based\nquantum computation). However, this number is still vastly smaller than RSA-768\nwhich is the largest number factored thus far on a classical computer. We\naddress a major issue arising in the scaling of adiabatic quantum factorization\nto much larger numbers. Namely, the existence of many 4-qubit, 3-qubit and\n2-qubit interactions in the Hamiltonians. We showcase our method on various\nexamples, one of which shows that we can remove 94% of the 4-qubit interactions\nand 83% of the 3-qubit interactions in the factorization of a 25-digit number\nwith almost no effort, without adding any auxiliary qubits. Our method is not\nlimited to quantum factoring. Its importance extends to the wider field of\ndiscrete optimization. Any CSP (constraint-satisfiability problem),\npsuedo-boolean optimization problem, or QUBO (quadratic unconstrained Boolean\noptimization) problem can in principle benefit from the \"deduction-reduction\"\nmethod which we introduce in this paper. We provide an open source code which\ntakes in a Hamiltonian (or a discrete discrete function which needs to be\noptimized), and returns a Hamiltonian that has the same unique ground state(s),\nno new auxiliary variables, and as few multi-qubit (multi-variable) terms as\npossible with deduc-reduc. \n\n"}
{"id": "1508.06901", "contents": "Title: Compressive Sensing via Low-Rank Gaussian Mixture Models Abstract: We develop a new compressive sensing (CS) inversion algorithm by utilizing\nthe Gaussian mixture model (GMM). While the compressive sensing is performed\nglobally on the entire image as implemented in our lensless camera, a low-rank\nGMM is imposed on the local image patches. This low-rank GMM is derived via\neigenvalue thresholding of the GMM trained on the projection of the measurement\ndata, thus learned {\\em in situ}. The GMM and the projection of the measurement\ndata are updated iteratively during the reconstruction. Our GMM algorithm\ndegrades to the piecewise linear estimator (PLE) if each patch is represented\nby a single Gaussian model. Inspired by this, a low-rank PLE algorithm is also\ndeveloped for CS inversion, constituting an additional contribution of this\npaper. Extensive results on both simulation data and real data captured by the\nlensless camera demonstrate the efficacy of the proposed algorithm.\nFurthermore, we compare the CS reconstruction results using our algorithm with\nthe JPEG compression. Simulation results demonstrate that when limited\nbandwidth is available (a small number of measurements), our algorithm can\nachieve comparable results as JPEG. \n\n"}
{"id": "1508.07096", "contents": "Title: Partitioning Large Scale Deep Belief Networks Using Dropout Abstract: Deep learning methods have shown great promise in many practical\napplications, ranging from speech recognition, visual object recognition, to\ntext processing. However, most of the current deep learning methods suffer from\nscalability problems for large-scale applications, forcing researchers or users\nto focus on small-scale problems with fewer parameters.\n  In this paper, we consider a well-known machine learning model, deep belief\nnetworks (DBNs) that have yielded impressive classification performance on a\nlarge number of benchmark machine learning tasks. To scale up DBN, we propose\nan approach that can use the computing clusters in a distributed environment to\ntrain large models, while the dense matrix computations within a single machine\nare sped up using graphics processors (GPU). When training a DBN, each machine\nrandomly drops out a portion of neurons in each hidden layer, for each training\ncase, making the remaining neurons only learn to detect features that are\ngenerally helpful for producing the correct answer. Within our approach, we\nhave developed four methods to combine outcomes from each machine to form a\nunified model. Our preliminary experiment on the mnst handwritten digit\ndatabase demonstrates that our approach outperforms the state of the art test\nerror rate. \n\n"}
{"id": "1509.01698", "contents": "Title: HAMSI: A Parallel Incremental Optimization Algorithm Using Quadratic\n  Approximations for Solving Partially Separable Problems Abstract: We propose HAMSI (Hessian Approximated Multiple Subsets Iteration), which is\na provably convergent, second order incremental algorithm for solving\nlarge-scale partially separable optimization problems. The algorithm is based\non a local quadratic approximation, and hence, allows incorporating curvature\ninformation to speed-up the convergence. HAMSI is inherently parallel and it\nscales nicely with the number of processors. Combined with techniques for\neffectively utilizing modern parallel computer architectures, we illustrate\nthat the proposed method converges more rapidly than a parallel stochastic\ngradient descent when both methods are used to solve large-scale matrix\nfactorization problems. This performance gain comes only at the expense of\nusing memory that scales linearly with the total size of the optimization\nvariables. We conclude that HAMSI may be considered as a viable alternative in\nmany large scale problems, where first order methods based on variants of\nstochastic gradient descent are applicable. \n\n"}
{"id": "1509.05473", "contents": "Title: Algorithmic statistics, prediction and machine learning Abstract: Algorithmic statistics considers the following problem: given a binary string\n$x$ (e.g., some experimental data), find a \"good\" explanation of this data. It\nuses algorithmic information theory to define formally what is a good\nexplanation. In this paper we extend this framework in two directions.\n  First, the explanations are not only interesting in themselves but also used\nfor prediction: we want to know what kind of data we may reasonably expect in\nsimilar situations (repeating the same experiment). We show that some kind of\nhierarchy can be constructed both in terms of algorithmic statistics and using\nthe notion of a priori probability, and these two approaches turn out to be\nequivalent.\n  Second, a more realistic approach that goes back to machine learning theory,\nassumes that we have not a single data string $x$ but some set of \"positive\nexamples\" $x_1,\\ldots,x_l$ that all belong to some unknown set $A$, a property\nthat we want to learn. We want this set $A$ to contain all positive examples\nand to be as small and simple as possible. We show how algorithmic statistic\ncan be extended to cover this situation. \n\n"}
{"id": "1509.06664", "contents": "Title: Reasoning about Entailment with Neural Attention Abstract: While most approaches to automatically recognizing entailment relations have\nused classifiers employing hand engineered features derived from complex\nnatural language processing pipelines, in practice their performance has been\nonly slightly better than bag-of-word pair classifiers using only lexical\nsimilarity. The only attempt so far to build an end-to-end differentiable\nneural network for entailment failed to outperform such a simple similarity\nclassifier. In this paper, we propose a neural model that reads two sentences\nto determine entailment using long short-term memory units. We extend this\nmodel with a word-by-word neural attention mechanism that encourages reasoning\nover entailments of pairs of words and phrases. Furthermore, we present a\nqualitative analysis of attention weights produced by this model, demonstrating\nsuch reasoning capabilities. On a large entailment dataset this model\noutperforms the previous best neural model and a classifier with engineered\nfeatures by a substantial margin. It is the first generic end-to-end\ndifferentiable system that achieves state-of-the-art accuracy on a textual\nentailment dataset. \n\n"}
{"id": "1509.07823", "contents": "Title: Computational Intelligence Challenges and Applications on Large-Scale\n  Astronomical Time Series Databases Abstract: Time-domain astronomy (TDA) is facing a paradigm shift caused by the\nexponential growth of the sample size, data complexity and data generation\nrates of new astronomical sky surveys. For example, the Large Synoptic Survey\nTelescope (LSST), which will begin operations in northern Chile in 2022, will\ngenerate a nearly 150 Petabyte imaging dataset of the southern hemisphere sky.\nThe LSST will stream data at rates of 2 Terabytes per hour, effectively\ncapturing an unprecedented movie of the sky. The LSST is expected not only to\nimprove our understanding of time-varying astrophysical objects, but also to\nreveal a plethora of yet unknown faint and fast-varying phenomena. To cope with\na change of paradigm to data-driven astronomy, the fields of astroinformatics\nand astrostatistics have been created recently. The new data-oriented paradigms\nfor astronomy combine statistics, data mining, knowledge discovery, machine\nlearning and computational intelligence, in order to provide the automated and\nrobust methods needed for the rapid detection and classification of known\nastrophysical objects as well as the unsupervised characterization of novel\nphenomena. In this article we present an overview of machine learning and\ncomputational intelligence applications to TDA. Future big data challenges and\nnew lines of research in TDA, focusing on the LSST, are identified and\ndiscussed from the viewpoint of computational intelligence/machine learning.\nInterdisciplinary collaboration will be required to cope with the challenges\nposed by the deluge of astronomical data coming from the LSST. \n\n"}
{"id": "1509.08216", "contents": "Title: Fast Algorithms for Finding Pattern Avoiders and Counting Pattern\n  Occurrences in Permutations Abstract: Given a set $\\Pi$ of permutation patterns of length at most $k$, we present\nan algorithm for building $S_{\\le n}(\\Pi)$, the set of permutations of length\nat most $n$ avoiding the patterns in $\\Pi$, in time $O(|S_{\\le n - 1}(\\Pi)|\n\\cdot k + |S_{n}(\\Pi)|)$. Additionally, we present an $O(n!k)$-time algorithm\nfor counting the number of copies of patterns from $\\Pi$ in each permutation in\n$S_n$. Surprisingly, when $|\\Pi| = 1$, this runtime can be improved to $O(n!)$,\nspending only constant time per permutation. Whereas the previous best\nalgorithms, based on generate-and-check, take exponential time per permutation\nanalyzed, all of our algorithms take time at most polynomial per outputted\npermutation.\n  If we want to solve only the enumerative variant of each problem, computing\n$|S_{\\le n}(\\Pi)|$ or tallying permutations according to $\\Pi$-patterns, rather\nthan to store information about every permutation, then all of our algorithms\ncan be implemented in $O(n^{k+1}k)$ space.\n  Using our algorithms, we generated $|S_5(\\Pi)|, \\ldots, |S_{16}(\\Pi)|$ for\neach $\\Pi \\subseteq S_4$ with $|\\Pi| > 4$, and analyzed OEIS matches. We\nobtained a number of potentially novel pattern-avoidance conjectures.\n  Our algorithms extend to considering permutations in any set closed under\nstandardization of subsequences. Our algorithms also partially adapt to\nconsidering vincular patterns. \n\n"}
{"id": "1509.09308", "contents": "Title: Fast Algorithms for Convolutional Neural Networks Abstract: Deep convolutional neural networks take GPU days of compute time to train on\nlarge data sets. Pedestrian detection for self driving cars requires very low\nlatency. Image recognition for mobile phones is constrained by limited\nprocessing resources. The success of convolutional neural networks in these\nsituations is limited by how fast we can compute them. Conventional FFT based\nconvolution is fast for large filters, but state of the art convolutional\nneural networks use small, 3x3 filters. We introduce a new class of fast\nalgorithms for convolutional neural networks using Winograd's minimal filtering\nalgorithms. The algorithms compute minimal complexity convolution over small\ntiles, which makes them fast with small filters and small batch sizes. We\nbenchmark a GPU implementation of our algorithm with the VGG network and show\nstate of the art throughput at batch sizes from 1 to 64. \n\n"}
{"id": "1510.01722", "contents": "Title: Structured Transforms for Small-Footprint Deep Learning Abstract: We consider the task of building compact deep learning pipelines suitable for\ndeployment on storage and power constrained mobile devices. We propose a\nunified framework to learn a broad family of structured parameter matrices that\nare characterized by the notion of low displacement rank. Our structured\ntransforms admit fast function and gradient evaluation, and span a rich range\nof parameter sharing configurations whose statistical modeling capacity can be\nexplicitly tuned along a continuum from structured to unstructured.\nExperimental results show that these transforms can significantly accelerate\ninference and forward/backward passes during training, and offer superior\naccuracy-compactness-speed tradeoffs in comparison to a number of existing\ntechniques. In keyword spotting applications in mobile speech recognition, our\nmethods are much more effective than standard linear low-rank bottleneck layers\nand nearly retain the performance of state of the art models, while providing\nmore than 3.5-fold compression. \n\n"}
{"id": "1510.03349", "contents": "Title: Toward a Better Understanding of Leaderboard Abstract: The leaderboard in machine learning competitions is a tool to show the\nperformance of various participants and to compare them. However, the\nleaderboard quickly becomes no longer accurate, due to hack or overfitting.\nThis article gives two pieces of advice to prevent easy hack or overfitting. By\nfollowing these advice, we reach the conclusion that something like the Ladder\nleaderboard introduced in [blum2015ladder] is inevitable. With this\nunderstanding, we naturally simplify Ladder by eliminating its redundant\ncomputation and explain how to choose the parameter and interpret it. We also\nprove that the sample complexity is cubic to the desired precision of the\nleaderboard. \n\n"}
{"id": "1510.05058", "contents": "Title: A Distance Measure for the Analysis of Polar Opinion Dynamics in Social\n  Networks Abstract: Analysis of opinion dynamics in social networks plays an important role in\ntoday's life. For applications such as predicting users' political preference,\nit is particularly important to be able to analyze the dynamics of competing\nopinions. While observing the evolution of polar opinions of a social network's\nusers over time, can we tell when the network \"behaved\" abnormally?\nFurthermore, can we predict how the opinions of the users will change in the\nfuture? Do opinions evolve according to existing network opinion dynamics\nmodels? To answer such questions, it is not sufficient to study individual user\nbehavior, since opinions can spread far beyond users' egonets. We need a method\nto analyze opinion dynamics of all network users simultaneously and capture the\neffect of individuals' behavior on the global evolution pattern of the social\nnetwork.\n  In this work, we introduce Social Network Distance (SND) - a distance measure\nthat quantifies the \"cost\" of evolution of one snapshot of a social network\ninto another snapshot under various models of polar opinion propagation. SND\nhas a rich semantics of a transportation problem, yet, is computable in time\nlinear in the number of users, which makes SND applicable to the analysis of\nlarge-scale online social networks. In our experiments with synthetic and\nreal-world Twitter data, we demonstrate the utility of our distance measure for\nanomalous event detection. It achieves a true positive rate of 0.83, twice as\nhigh as that of alternatives. When employed for opinion prediction in Twitter,\nour method's accuracy is 75.63%, which is 7.5% higher than that of the next\nbest method.\n  Source Code: https://cs.ucsb.edu/~victor/pub/ucsb/dbl/snd/ \n\n"}
{"id": "1510.05137", "contents": "Title: Integrality Gaps and Approximation Algorithms for Dispersers and\n  Bipartite Expanders Abstract: We study the problem of approximating the quality of a disperser. A bipartite\ngraph $G$ on $([N],[M])$ is a $(\\rho N,(1-\\delta)M)$-disperser if for any\nsubset $S\\subseteq [N]$ of size $\\rho N$, the neighbor set $\\Gamma(S)$ contains\nat least $(1-\\delta)M$ distinct vertices. Our main results are strong\nintegrality gaps in the Lasserre hierarchy and an approximation algorithm for\ndispersers.\n  \\begin{enumerate}\n  \\item For any $\\alpha>0$, $\\delta>0$, and a random bipartite graph $G$ with\nleft degree $D=O(\\log N)$, we prove that the Lasserre hierarchy cannot\ndistinguish whether $G$ is an $(N^{\\alpha},(1-\\delta)M)$-disperser or not an\n$(N^{1-\\alpha},\\delta M)$-disperser.\n  \\item For any $\\rho>0$, we prove that there exist infinitely many constants\n$d$ such that the Lasserre hierarchy cannot distinguish whether a random\nbipartite graph $G$ with right degree $d$ is a $(\\rho N,\n(1-(1-\\rho)^d)M)$-disperser or not a $(\\rho N, (1-\\Omega(\\frac{1-\\rho}{\\rho d +\n1-\\rho}))M)$-disperser. We also provide an efficient algorithm to find a subset\nof size exact $\\rho N$ that has an approximation ratio matching the integrality\ngap within an extra loss of\n$\\frac{\\min\\{\\frac{\\rho}{1-\\rho},\\frac{1-\\rho}{\\rho}\\}}{\\log d}$.\n\\end{enumerate}\n  Our method gives an integrality gap in the Lasserre hierarchy for bipartite\nexpanders with left degree~$D$. $G$ on $([N],[M])$ is a $(\\rho N,a)$-expander\nif for any subset $S\\subseteq [N]$ of size $\\rho N$, the neighbor set\n$\\Gamma(S)$ contains at least $a \\cdot \\rho N$ distinct vertices. We prove that\nfor any constant $\\epsilon>0$, there exist constants $\\epsilon'<\\epsilon,\\rho,$\nand $D$ such that the Lasserre hierarchy cannot distinguish whether a bipartite\ngraph on $([N],[M])$ with left degree $D$ is a $(\\rho N,\n(1-\\epsilon')D)$-expander or not a $(\\rho N, (1-\\epsilon)D)$-expander. \n\n"}
{"id": "1510.07420", "contents": "Title: Crushing runtimes in adiabatic quantum computation with Energy Landscape\n  Manipulation (ELM): Application to Quantum Factoring Abstract: We introduce two methods for speeding up adiabatic quantum computations by\nincreasing the energy between the ground and first excited states. Our methods\nare even more general. They can be used to shift a Hamiltonian's density of\nstates away from the ground state, so that fewer states occupy the low-lying\nenergies near the minimum, hence allowing for faster adiabatic passages to find\nthe ground state with less risk of getting caught in an undesired low-lying\nexcited state during the passage. Even more generally, our methods can be used\nto transform a discrete optimization problem into a new one whose unique\nminimum still encodes the desired answer, but with the objective function's\nvalues forming a different landscape. Aspects of the landscape such as the\nobjective function's range, or the values of certain coefficients, or how many\ndifferent inputs lead to a given output value, can be decreased *or* increased.\nOne of the many examples for which these methods are useful is in finding the\nground state of a Hamiltonian using NMR: If it is difficult to find a molecule\nsuch that the distances between the spins match the interactions in the\nHamiltonian, the interactions in the Hamiltonian can be changed without at all\nchanging the ground state. We apply our methods to an AQC algorithm for integer\nfactorization, and the first method reduces the maximum runtime in our example\nby up to 754%, and the second method reduces the maximum runtime of another\nexample by up to 250%. These two methods may also be combined. \n\n"}
{"id": "1510.08865", "contents": "Title: Mixed Robust/Average Submodular Partitioning: Fast Algorithms,\n  Guarantees, and Applications to Parallel Machine Learning and Multi-Label\n  Image Segmentation Abstract: We study two mixed robust/average-case submodular partitioning problems that\nwe collectively call Submodular Partitioning. These problems generalize both\npurely robust instances of the problem (namely max-min submodular fair\nallocation (SFA) and min-max submodular load balancing (SLB) and also\ngeneralize average-case instances (that is the submodular welfare problem (SWP)\nand submodular multiway partition (SMP). While the robust versions have been\nstudied in the theory community, existing work has focused on tight\napproximation guarantees, and the resultant algorithms are not, in general,\nscalable to very large real-world applications. This is in contrast to the\naverage case, where most of the algorithms are scalable. In the present paper,\nwe bridge this gap, by proposing several new algorithms (including those based\non greedy, majorization-minimization, minorization-maximization, and relaxation\nalgorithms) that not only scale to large sizes but that also achieve\ntheoretical approximation guarantees close to the state-of-the-art, and in some\ncases achieve new tight bounds. We also provide new scalable algorithms that\napply to additive combinations of the robust and average-case extreme\nobjectives. We show that these problems have many applications in machine\nlearning (ML). This includes: 1) data partitioning and load balancing for\ndistributed machine algorithms on parallel machines; 2) data clustering; and 3)\nmulti-label image segmentation with (only) Boolean submodular functions via\npixel partitioning. We empirically demonstrate the efficacy of our algorithms\non real-world problems involving data partitioning for distributed optimization\nof standard machine learning objectives (including both convex and deep neural\nnetwork objectives), and also on purely unsupervised (i.e., no supervised or\nsemi-supervised learning, and no interactive segmentation) image segmentation. \n\n"}
{"id": "1510.08983", "contents": "Title: Highway Long Short-Term Memory RNNs for Distant Speech Recognition Abstract: In this paper, we extend the deep long short-term memory (DLSTM) recurrent\nneural networks by introducing gated direct connections between memory cells in\nadjacent layers. These direct links, called highway connections, enable\nunimpeded information flow across different layers and thus alleviate the\ngradient vanishing problem when building deeper LSTMs. We further introduce the\nlatency-controlled bidirectional LSTMs (BLSTMs) which can exploit the whole\nhistory while keeping the latency under control. Efficient algorithms are\nproposed to train these novel networks using both frame and sequence\ndiscriminative criteria. Experiments on the AMI distant speech recognition\n(DSR) task indicate that we can train deeper LSTMs and achieve better\nimprovement from sequence training with highway LSTMs (HLSTMs). Our novel model\nobtains $43.9/47.7\\%$ WER on AMI (SDM) dev and eval sets, outperforming all\nprevious works. It beats the strong DNN and DLSTM baselines with $15.7\\%$ and\n$5.3\\%$ relative improvement respectively. \n\n"}
{"id": "1511.02124", "contents": "Title: Barrier Frank-Wolfe for Marginal Inference Abstract: We introduce a globally-convergent algorithm for optimizing the\ntree-reweighted (TRW) variational objective over the marginal polytope. The\nalgorithm is based on the conditional gradient method (Frank-Wolfe) and moves\npseudomarginals within the marginal polytope through repeated maximum a\nposteriori (MAP) calls. This modular structure enables us to leverage black-box\nMAP solvers (both exact and approximate) for variational inference, and obtains\nmore accurate results than tree-reweighted algorithms that optimize over the\nlocal consistency relaxation. Theoretically, we bound the sub-optimality for\nthe proposed algorithm despite the TRW objective having unbounded gradients at\nthe boundary of the marginal polytope. Empirically, we demonstrate the\nincreased quality of results found by tightening the relaxation over the\nmarginal polytope as well as the spanning tree polytope on synthetic and\nreal-world instances. \n\n"}
{"id": "1511.02163", "contents": "Title: Submodular Hamming Metrics Abstract: We show that there is a largely unexplored class of functions (positive\npolymatroids) that can define proper discrete metrics over pairs of binary\nvectors and that are fairly tractable to optimize over. By exploiting\nsubmodularity, we are able to give hardness results and approximation\nalgorithms for optimizing over such metrics. Additionally, we demonstrate\nempirically the effectiveness of these metrics and associated algorithms on\nboth a metric minimization task (a form of clustering) and also a metric\nmaximization task (generating diverse k-best lists). \n\n"}
{"id": "1511.04707", "contents": "Title: Deep Linear Discriminant Analysis Abstract: We introduce Deep Linear Discriminant Analysis (DeepLDA) which learns\nlinearly separable latent representations in an end-to-end fashion. Classic LDA\nextracts features which preserve class separability and is used for\ndimensionality reduction for many classification problems. The central idea of\nthis paper is to put LDA on top of a deep neural network. This can be seen as a\nnon-linear extension of classic LDA. Instead of maximizing the likelihood of\ntarget labels for individual samples, we propose an objective function that\npushes the network to produce feature distributions which: (a) have low\nvariance within the same class and (b) high variance between different classes.\nOur objective is derived from the general LDA eigenvalue problem and still\nallows to train with stochastic gradient descent and back-propagation. For\nevaluation we test our approach on three different benchmark datasets (MNIST,\nCIFAR-10 and STL-10). DeepLDA produces competitive results on MNIST and\nCIFAR-10 and outperforms a network trained with categorical cross entropy (same\narchitecture) on a supervised setting of STL-10. \n\n"}
{"id": "1511.05053", "contents": "Title: A Polynomial Lower Bound for Testing Monotonicity Abstract: We show that every algorithm for testing $n$-variate Boolean functions for\nmonotonicity must have query complexity $\\tilde{\\Omega}(n^{1/4})$. All previous\nlower bounds for this problem were designed for non-adaptive algorithms and, as\na result, the best previous lower bound for general (possibly adaptive)\nmonotonicity testers was only $\\Omega(\\log n)$. Combined with the query\ncomplexity of the non-adaptive monotonicity tester of Khot, Minzer, and Safra\n(FOCS 2015), our lower bound shows that adaptivity can result in at most a\nquadratic reduction in the query complexity for testing monotonicity.\n  By contrast, we show that there is an exponential gap between the query\ncomplexity of adaptive and non-adaptive algorithms for testing regular linear\nthreshold functions (LTFs) for monotonicity. Chen, De, Servedio, and Tan (STOC\n2015) recently showed that non-adaptive algorithms require almost\n$\\Omega(n^{1/2})$ queries for this task. We introduce a new adaptive\nmonotonicity testing algorithm which has query complexity $O(\\log n)$ when the\ninput is a regular LTF. \n\n"}
{"id": "1511.06037", "contents": "Title: Enumeration and Random Generation of Unlabeled Classes of Graphs: A\n  Practical Study of Cycle Pointing and the Dissymmetry Theorem Abstract: Our work studies the enumeration and random generation of unlabeled\ncombinatorial classes of unrooted graphs. While the technique of vertex\npointing provides a straightforward procedure for analyzing a labeled class of\nunrooted graphs by first studying its rooted counterpart, the existence of\nnontrivial symmetries in the unlabeled case causes this technique to break\ndown. Instead, techniques such as the dissymmetry theorem (of Otter) and cycle\npointing (of Bodirsky et al.) have emerged in the unlabeled case, with the\nformer providing an enumeration of the class and the latter providing both an\nenumeration and an unbiased sampler. In this work, we extend the power of the\ndissymmetry theorem by showing that it in fact provides a Boltzmann sampler for\nthe class in question. We then present an exposition of the cycle pointing\ntechnique, with a focus on the enumeration and random generation of the\nunderlying unpointed class. Finally, we apply cycle pointing to enumerate and\nimplement samplers for the classes of distance-hereditary graphs and three-leaf\npower graphs. \n\n"}
{"id": "1511.06233", "contents": "Title: Towards Open Set Deep Networks Abstract: Deep networks have produced significant gains for various visual recognition\nproblems, leading to high impact academic and commercial applications. Recent\nwork in deep networks highlighted that it is easy to generate images that\nhumans would never classify as a particular object class, yet networks classify\nsuch images high confidence as that given class - deep network are easily\nfooled with images humans do not consider meaningful. The closed set nature of\ndeep networks forces them to choose from one of the known classes leading to\nsuch artifacts. Recognition in the real world is open set, i.e. the recognition\nsystem should reject unknown/unseen classes at test time. We present a\nmethodology to adapt deep networks for open set recognition, by introducing a\nnew model layer, OpenMax, which estimates the probability of an input being\nfrom an unknown class. A key element of estimating the unknown probability is\nadapting Meta-Recognition concepts to the activation patterns in the\npenultimate layer of the network. OpenMax allows rejection of \"fooling\" and\nunrelated open set images presented to the system; OpenMax greatly reduces the\nnumber of obvious errors made by a deep network. We prove that the OpenMax\nconcept provides bounded open space risk, thereby formally providing an open\nset recognition solution. We evaluate the resulting open set deep networks\nusing pre-trained networks from the Caffe Model-zoo on ImageNet 2012 validation\ndata, and thousands of fooling and open set images. The proposed OpenMax model\nsignificantly outperforms open set recognition accuracy of basic deep networks\nas well as deep networks with thresholding of SoftMax probabilities. \n\n"}
{"id": "1511.06251", "contents": "Title: Stochastic modified equations and adaptive stochastic gradient\n  algorithms Abstract: We develop the method of stochastic modified equations (SME), in which\nstochastic gradient algorithms are approximated in the weak sense by\ncontinuous-time stochastic differential equations. We exploit the continuous\nformulation together with optimal control theory to derive novel adaptive\nhyper-parameter adjustment policies. Our algorithms have competitive\nperformance with the added benefit of being robust to varying models and\ndatasets. This provides a general methodology for the analysis and design of\nstochastic gradient algorithms. \n\n"}
{"id": "1511.06306", "contents": "Title: Robust Convolutional Neural Networks under Adversarial Noise Abstract: Recent studies have shown that Convolutional Neural Networks (CNNs) are\nvulnerable to a small perturbation of input called \"adversarial examples\". In\nthis work, we propose a new feedforward CNN that improves robustness in the\npresence of adversarial noise. Our model uses stochastic additive noise added\nto the input image and to the CNN models. The proposed model operates in\nconjunction with a CNN trained with either standard or adversarial objective\nfunction. In particular, convolution, max-pooling, and ReLU layers are modified\nto benefit from the noise model. Our feedforward model is parameterized by only\na mean and variance per pixel which simplifies computations and makes our\nmethod scalable to a deep architecture. From CIFAR-10 and ImageNet test, the\nproposed model outperforms other methods and the improvement is more evident\nfor difficult classification tasks or stronger adversarial noise. \n\n"}
{"id": "1511.06728", "contents": "Title: Hand Pose Estimation through Semi-Supervised and Weakly-Supervised\n  Learning Abstract: We propose a method for hand pose estimation based on a deep regressor\ntrained on two different kinds of input. Raw depth data is fused with an\nintermediate representation in the form of a segmentation of the hand into\nparts. This intermediate representation contains important topological\ninformation and provides useful cues for reasoning about joint locations. The\nmapping from raw depth to segmentation maps is learned in a\nsemi/weakly-supervised way from two different datasets: (i) a synthetic dataset\ncreated through a rendering pipeline including densely labeled ground truth\n(pixelwise segmentations); and (ii) a dataset with real images for which ground\ntruth joint positions are available, but not dense segmentations. Loss for\ntraining on real images is generated from a patch-wise restoration process,\nwhich aligns tentative segmentation maps with a large dictionary of synthetic\nposes. The underlying premise is that the domain shift between synthetic and\nreal data is smaller in the intermediate representation, where labels carry\ngeometric and topological meaning, than in the raw input domain. Experiments on\nthe NYU dataset show that the proposed training method decreases error on\njoints over direct regression of joints from depth data by 15.7%. \n\n"}
{"id": "1511.07263", "contents": "Title: Input Sparsity Time Low-Rank Approximation via Ridge Leverage Score\n  Sampling Abstract: We present a new algorithm for finding a near optimal low-rank approximation\nof a matrix $A$ in $O(nnz(A))$ time. Our method is based on a recursive\nsampling scheme for computing a representative subset of $A$'s columns, which\nis then used to find a low-rank approximation.\n  This approach differs substantially from prior $O(nnz(A))$ time algorithms,\nwhich are all based on fast Johnson-Lindenstrauss random projections. It\nmatches the guarantees of these methods while offering a number of advantages.\n  Not only are sampling algorithms faster for sparse and structured data, but\nthey can also be applied in settings where random projections cannot. For\nexample, we give new single-pass streaming algorithms for the column subset\nselection and projection-cost preserving sample problems. Our method has also\nbeen used to give the fastest algorithms for provably approximating kernel\nmatrices [MM16]. \n\n"}
{"id": "1512.01274", "contents": "Title: MXNet: A Flexible and Efficient Machine Learning Library for\n  Heterogeneous Distributed Systems Abstract: MXNet is a multi-language machine learning (ML) library to ease the\ndevelopment of ML algorithms, especially for deep neural networks. Embedded in\nthe host language, it blends declarative symbolic expression with imperative\ntensor computation. It offers auto differentiation to derive gradients. MXNet\nis computation and memory efficient and runs on various heterogeneous systems,\nranging from mobile devices to distributed GPU clusters.\n  This paper describes both the API design and the system implementation of\nMXNet, and explains how embedding of both symbolic expression and tensor\noperation is handled in a unified fashion. Our preliminary experiments reveal\npromising results on large scale deep neural network applications using\nmultiple GPU machines. \n\n"}
{"id": "1512.01926", "contents": "Title: Thinking Required Abstract: There exists a theory of a single general-purpose learning algorithm which\ncould explain the principles its operation. It assumes the initial rough\narchitecture, a small library of simple innate circuits which are prewired at\nbirth. and proposes that all significant mental algorithms are learned. Given\ncurrent understanding and observations, this paper reviews and lists the\ningredients of such an algorithm from architectural and functional\nperspectives. \n\n"}
{"id": "1512.03549", "contents": "Title: Words are not Equal: Graded Weighting Model for building Composite\n  Document Vectors Abstract: Despite the success of distributional semantics, composing phrases from word\nvectors remains an important challenge. Several methods have been tried for\nbenchmark tasks such as sentiment classification, including word vector\naveraging, matrix-vector approaches based on parsing, and on-the-fly learning\nof paragraph vectors. Most models usually omit stop words from the composition.\nInstead of such an yes-no decision, we consider several graded schemes where\nwords are weighted according to their discriminatory relevance with respect to\nits use in the document (e.g., idf). Some of these methods (particularly\ntf-idf) are seen to result in a significant improvement in performance over\nprior state of the art. Further, combining such approaches into an ensemble\nbased on alternate classifiers such as the RNN model, results in an 1.6%\nperformance improvement on the standard IMDB movie review dataset, and a 7.01%\nimprovement on Amazon product reviews. Since these are language free models and\ncan be obtained in an unsupervised manner, they are of interest also for\nunder-resourced languages such as Hindi as well and many more languages. We\ndemonstrate the language free aspects by showing a gain of 12% for two review\ndatasets over earlier results, and also release a new larger dataset for future\ntesting (Singh,2015). \n\n"}
{"id": "1512.03965", "contents": "Title: The Power of Depth for Feedforward Neural Networks Abstract: We show that there is a simple (approximately radial) function on $\\reals^d$,\nexpressible by a small 3-layer feedforward neural networks, which cannot be\napproximated by any 2-layer network, to more than a certain constant accuracy,\nunless its width is exponential in the dimension. The result holds for\nvirtually all known activation functions, including rectified linear units,\nsigmoids and thresholds, and formally demonstrates that depth -- even if\nincreased by 1 -- can be exponentially more valuable than width for standard\nfeedforward neural networks. Moreover, compared to related results in the\ncontext of Boolean functions, our result requires fewer assumptions, and the\nproof techniques and construction are very different. \n\n"}
{"id": "1512.04047", "contents": "Title: Parameterizing edge modification problems above lower bounds Abstract: We study the parameterized complexity of a variant of the $F$-free Editing\nproblem: Given a graph $G$ and a natural number $k$, is it possible to modify\nat most $k$ edges in $G$ so that the resulting graph contains no induced\nsubgraph isomorphic to $F$? In our variant, the input additionally contains a\nvertex-disjoint packing $\\mathcal{H}$ of induced subgraphs of $G$, which\nprovides a lower bound $h(\\mathcal{H})$ on the number of edge modifications\nrequired to transform $G$ into an $F$-free graph. While earlier works used the\nnumber $k$ as parameter or structural parameters of the input graph $G$, we\nconsider instead the parameter $\\ell:=k-h(\\mathcal{H})$, that is, the number of\nedge modifications above the lower bound $h(\\mathcal{H})$. We develop a\nframework of generic data reduction rules to show fixed-parameter tractability\nwith respect to $\\ell$ for $K_3$-Free Editing, Feedback Arc Set in Tournaments,\nand Cluster Editing when the packing $\\mathcal{H}$ contains subgraphs with\nbounded solution size. For $K_3$-Free Editing, we also prove NP-hardness in\ncase of edge-disjoint packings of $K_3$s and $\\ell=0$, while for $K_q$-Free\nEditing and $q\\ge 6$, NP-hardness for $\\ell=0$ even holds for vertex-disjoint\npackings of $K_q$s. In addition, we provide NP-hardness results for $F$-free\nVertex Deletion, were the aim is to delete a minimum number of vertices to make\nthe input graph $F$-free. \n\n"}
{"id": "1512.05059", "contents": "Title: Streaming Kernel Principal Component Analysis Abstract: Kernel principal component analysis (KPCA) provides a concise set of basis\nvectors which capture non-linear structures within large data sets, and is a\ncentral tool in data analysis and learning. To allow for non-linear relations,\ntypically a full $n \\times n$ kernel matrix is constructed over $n$ data\npoints, but this requires too much space and time for large values of $n$.\nTechniques such as the Nystr\\\"om method and random feature maps can help\ntowards this goal, but they do not explicitly maintain the basis vectors in a\nstream and take more space than desired. We propose a new approach for\nstreaming KPCA which maintains a small set of basis elements in a stream,\nrequiring space only logarithmic in $n$, and also improves the dependence on\nthe error parameter. Our technique combines together random feature maps with\nrecent advances in matrix sketching, it has guaranteed spectral norm error\nbounds with respect to the original kernel matrix, and it compares favorably in\npractice to state-of-the-art approaches. \n\n"}
{"id": "1512.06658", "contents": "Title: Deep Learning for Surface Material Classification Using Haptic And\n  Visual Information Abstract: When a user scratches a hand-held rigid tool across an object surface, an\nacceleration signal can be captured, which carries relevant information about\nthe surface. More importantly, such a haptic signal is complementary to the\nvisual appearance of the surface, which suggests the combination of both\nmodalities for the recognition of the surface material. In this paper, we\npresent a novel deep learning method dealing with the surface material\nclassification problem based on a Fully Convolutional Network (FCN), which\ntakes as input the aforementioned acceleration signal and a corresponding image\nof the surface texture. Compared to previous surface material classification\nsolutions, which rely on a careful design of hand-crafted domain-specific\nfeatures, our method automatically extracts discriminative features utilizing\nthe advanced deep learning methodologies. Experiments performed on the TUM\nsurface material database demonstrate that our method achieves state-of-the-art\nclassification accuracy robustly and efficiently. \n\n"}
{"id": "1512.07422", "contents": "Title: Adaptive Algorithms for Online Convex Optimization with Long-term\n  Constraints Abstract: We present an adaptive online gradient descent algorithm to solve online\nconvex optimization problems with long-term constraints , which are constraints\nthat need to be satisfied when accumulated over a finite number of rounds T ,\nbut can be violated in intermediate rounds. For some user-defined trade-off\nparameter $\\beta$ $\\in$ (0, 1), the proposed algorithm achieves cumulative\nregret bounds of O(T^max{$\\beta$,1--$\\beta$}) and O(T^(1--$\\beta$/2)) for the\nloss and the constraint violations respectively. Our results hold for convex\nlosses and can handle arbitrary convex constraints without requiring knowledge\nof the number of rounds in advance. Our contributions improve over the best\nknown cumulative regret bounds by Mahdavi, et al. (2012) that are respectively\nO(T^1/2) and O(T^3/4) for general convex domains, and respectively O(T^2/3) and\nO(T^2/3) when further restricting to polyhedral domains. We supplement the\nanalysis with experiments validating the performance of our algorithm in\npractice. \n\n"}
{"id": "1601.00062", "contents": "Title: Practical Algorithms for Learning Near-Isometric Linear Embeddings Abstract: We propose two practical non-convex approaches for learning near-isometric,\nlinear embeddings of finite sets of data points. Given a set of training points\n$\\mathcal{X}$, we consider the secant set $S(\\mathcal{X})$ that consists of all\npairwise difference vectors of $\\mathcal{X}$, normalized to lie on the unit\nsphere. The problem can be formulated as finding a symmetric and positive\nsemi-definite matrix $\\boldsymbol{\\Psi}$ that preserves the norms of all the\nvectors in $S(\\mathcal{X})$ up to a distortion parameter $\\delta$. Motivated by\nnon-negative matrix factorization, we reformulate our problem into a Frobenius\nnorm minimization problem, which is solved by the Alternating Direction Method\nof Multipliers (ADMM) and develop an algorithm, FroMax. Another method solves\nfor a projection matrix $\\boldsymbol{\\Psi}$ by minimizing the restricted\nisometry property (RIP) directly over the set of symmetric, postive\nsemi-definite matrices. Applying ADMM and a Moreau decomposition on a proximal\nmapping, we develop another algorithm, NILE-Pro, for dimensionality reduction.\nFroMax is shown to converge faster for smaller $\\delta$ while NILE-Pro\nconverges faster for larger $\\delta$. Both non-convex approaches are then\nempirically demonstrated to be more computationally efficient than prior convex\napproaches for a number of applications in machine learning and signal\nprocessing. \n\n"}
{"id": "1601.02377", "contents": "Title: Implicit Look-alike Modelling in Display Ads: Transfer Collaborative\n  Filtering to CTR Estimation Abstract: User behaviour targeting is essential in online advertising. Compared with\nsponsored search keyword targeting and contextual advertising page content\ntargeting, user behaviour targeting builds users' interest profiles via\ntracking their online behaviour and then delivers the relevant ads according to\neach user's interest, which leads to higher targeting accuracy and thus more\nimproved advertising performance. The current user profiling methods include\nbuilding keywords and topic tags or mapping users onto a hierarchical taxonomy.\nHowever, to our knowledge, there is no previous work that explicitly\ninvestigates the user online visits similarity and incorporates such similarity\ninto their ad response prediction. In this work, we propose a general framework\nwhich learns the user profiles based on their online browsing behaviour, and\ntransfers the learned knowledge onto prediction of their ad response.\nTechnically, we propose a transfer learning model based on the probabilistic\nlatent factor graphic models, where the users' ad response profiles are\ngenerated from their online browsing profiles. The large-scale experiments\nbased on real-world data demonstrate significant improvement of our solution\nover some strong baselines. \n\n"}
{"id": "1601.03095", "contents": "Title: Submodular Optimization under Noise Abstract: We consider the problem of maximizing a monotone submodular function under\nnoise. There has been a great deal of work on optimization of submodular\nfunctions under various constraints, resulting in algorithms that provide\ndesirable approximation guarantees. In many applications, however, we do not\nhave access to the submodular function we aim to optimize, but rather to some\nerroneous or noisy version of it. This raises the question of whether provable\nguarantees are obtainable in presence of error and noise. We provide initial\nanswers, by focusing on the question of maximizing a monotone submodular\nfunction under a cardinality constraint when given access to a noisy oracle of\nthe function. We show that:\n  - For a cardinality constraint $k \\geq 2$, there is an approximation\nalgorithm whose approximation ratio is arbitrarily close to $1-1/e$;\n  - For $k=1$ there is an algorithm whose approximation ratio is arbitrarily\nclose to $1/2$. No randomized algorithm can obtain an approximation ratio\nbetter than $1/2+o(1)$;\n  -If the noise is adversarial, no non-trivial approximation guarantee can be\nobtained. \n\n"}
{"id": "1601.03603", "contents": "Title: Protection of flows under targeted attacks Abstract: Due to the importance of robustness in many real-world optimization problems,\nthe field of robust optimization has gained a lot of attention over the past\ndecade. We concentrate on maximum flow problems and introduce a novel robust\noptimization model which, compared to known models from the literature,\nfeatures several advantageous properties: (i) We consider a general class of\npath-based flow problems which can be used to model a large variety of network\nrouting problems (and other packing problems). (ii) We aim at solutions that\nare robust against targeted attacks by a potent adversary who may attack any\nflow path of his choice on any edge of the network. (iii) In contrast to\nprevious robust maximum flow models, for which no efficient algorithms are\nknown, optimal robust flows for the most important basic variants of our model\ncan be found in polynomial time.\n  We also consider generalizations where the flow player can spend a budget to\nprotect the network against the interdictor. Here, we show that the problem can\nbe solved efficiently when the interdiction costs are determined by the flow\nplayer from scratch. However, the problem becomes hard to approximate when the\nflow player has to improve an initial protection infrastructure. \n\n"}
{"id": "1601.03754", "contents": "Title: Dual-tree $k$-means with bounded iteration runtime Abstract: k-means is a widely used clustering algorithm, but for $k$ clusters and a\ndataset size of $N$, each iteration of Lloyd's algorithm costs $O(kN)$ time.\nAlthough there are existing techniques to accelerate single Lloyd iterations,\nnone of these are tailored to the case of large $k$, which is increasingly\ncommon as dataset sizes grow. We propose a dual-tree algorithm that gives the\nexact same results as standard $k$-means; when using cover trees, we use\nadaptive analysis techniques to, under some assumptions, bound the\nsingle-iteration runtime of the algorithm as $O(N + k log k)$. To our knowledge\nthese are the first sub-$O(kN)$ bounds for exact Lloyd iterations. We then show\nthat this theoretically favorable algorithm performs competitively in practice,\nespecially for large $N$ and $k$ in low dimensions. Further, the algorithm is\ntree-independent, so any type of tree may be used. \n\n"}
{"id": "1601.06551", "contents": "Title: Robust Influence Maximization Abstract: In this paper, we address the important issue of uncertainty in the edge\ninfluence probability estimates for the well studied influence maximization\nproblem --- the task of finding $k$ seed nodes in a social network to maximize\nthe influence spread. We propose the problem of robust influence maximization,\nwhich maximizes the worst-case ratio between the influence spread of the chosen\nseed set and the optimal seed set, given the uncertainty of the parameter\ninput. We design an algorithm that solves this problem with a\nsolution-dependent bound. We further study uniform sampling and adaptive\nsampling methods to effectively reduce the uncertainty on parameters and\nimprove the robustness of the influence maximization task. Our empirical\nresults show that parameter uncertainty may greatly affect influence\nmaximization performance and prior studies that learned influence probabilities\ncould lead to poor performance in robust influence maximization due to\nrelatively large uncertainty in parameter estimates, and information cascade\nbased adaptive sampling method may be an effective way to improve the\nrobustness of influence maximization. \n\n"}
{"id": "1602.02018", "contents": "Title: Compressive Spectral Clustering Abstract: Spectral clustering has become a popular technique due to its high\nperformance in many contexts. It comprises three main steps: create a\nsimilarity graph between N objects to cluster, compute the first k eigenvectors\nof its Laplacian matrix to define a feature vector for each object, and run\nk-means on these features to separate objects into k classes. Each of these\nthree steps becomes computationally intensive for large N and/or k. We propose\nto speed up the last two steps based on recent results in the emerging field of\ngraph signal processing: graph filtering of random signals, and random sampling\nof bandlimited graph signals. We prove that our method, with a gain in\ncomputation time that can reach several orders of magnitude, is in fact an\napproximation of spectral clustering, for which we are able to control the\nerror. We test the performance of our method on artificial and real-world\nnetwork data. \n\n"}
{"id": "1602.02355", "contents": "Title: Hyperparameter optimization with approximate gradient Abstract: Most models in machine learning contain at least one hyperparameter to\ncontrol for model complexity. Choosing an appropriate set of hyperparameters is\nboth crucial in terms of model accuracy and computationally challenging. In\nthis work we propose an algorithm for the optimization of continuous\nhyperparameters using inexact gradient information. An advantage of this method\nis that hyperparameters can be updated before model parameters have fully\nconverged. We also give sufficient conditions for the global convergence of\nthis method, based on regularity conditions of the involved functions and\nsummability of errors. Finally, we validate the empirical performance of this\nmethod on the estimation of regularization constants of L2-regularized logistic\nregression and kernel Ridge regression. Empirical benchmarks indicate that our\napproach is highly competitive with respect to state of the art methods. \n\n"}
{"id": "1602.02377", "contents": "Title: Find an Optimal Path in Static System and Dynamical System within\n  Polynomial Runtime Abstract: We study an ancient problem that in a static or dynamical system, sought an\noptimal path, which the context always means within an extremal condition. In\nfact, through those discussions about this theme, we established a universal\nessential calculated model to serve for these complex systems. Meanwhile we\nutilize the sample space to character the system. These contents in this paper\nwould involve in several major areas including the geometry, probability, graph\nalgorithms and some prior approaches, which stands the ultimately subtle linear\nalgorithm to solve this class problem. Along with our progress, our discussion\nwould demonstrate more general meaning and robust character, which provides\nclear ideas or notion to support our concrete applications, who work in a more\npopular complex system. \n\n"}
{"id": "1602.02747", "contents": "Title: Independent sets and cuts in large-girth regular graphs Abstract: We present a local algorithm producing an independent set of expected size\n$0.44533n$ on large-girth 3-regular graphs and $0.40407n$ on large-girth\n4-regular graphs. We also construct a cut (or bisection or bipartite subgraph)\nwith $1.34105n$ edges on large-girth 3-regular graphs. These decrease the gaps\nbetween the best known upper and lower bounds from $0.0178$ to $0.01$, from\n$0.0242$ to $0.0123$ and from $0.0724$ to $0.0616$, respectively. We are using\nlocal algorithms, therefore, the method also provides upper bounds for the\nfractional coloring numbers of $1 / 0.44533 \\approx 2.24554$ and $1 / 0.40407\n\\approx 2.4748$ and fractional edge coloring number $1.5 / 1.34105 \\approx\n1.1185$. Our algorithms are applications of the technique introduced by Hoppen\nand Wormald. \n\n"}
{"id": "1602.03014", "contents": "Title: Herding as a Learning System with Edge-of-Chaos Dynamics Abstract: Herding defines a deterministic dynamical system at the edge of chaos. It\ngenerates a sequence of model states and parameters by alternating parameter\nperturbations with state maximizations, where the sequence of states can be\ninterpreted as \"samples\" from an associated MRF model. Herding differs from\nmaximum likelihood estimation in that the sequence of parameters does not\nconverge to a fixed point and differs from an MCMC posterior sampling approach\nin that the sequence of states is generated deterministically. Herding may be\ninterpreted as a\"perturb and map\" method where the parameter perturbations are\ngenerated using a deterministic nonlinear dynamical system rather than randomly\nfrom a Gumbel distribution. This chapter studies the distinct statistical\ncharacteristics of the herding algorithm and shows that the fast convergence\nrate of the controlled moments may be attributed to edge of chaos dynamics. The\nherding algorithm can also be generalized to models with latent variables and\nto a discriminative learning setting. The perceptron cycling theorem ensures\nthat the fast moment matching property is preserved in the more general\nframework. \n\n"}
{"id": "1602.03351", "contents": "Title: Adaptive Skills, Adaptive Partitions (ASAP) Abstract: We introduce the Adaptive Skills, Adaptive Partitions (ASAP) framework that\n(1) learns skills (i.e., temporally extended actions or options) as well as (2)\nwhere to apply them. We believe that both (1) and (2) are necessary for a truly\ngeneral skill learning framework, which is a key building block needed to scale\nup to lifelong learning agents. The ASAP framework can also solve related new\ntasks simply by adapting where it applies its existing learned skills. We prove\nthat ASAP converges to a local optimum under natural conditions. Finally, our\nexperimental results, which include a RoboCup domain, demonstrate the ability\nof ASAP to learn where to reuse skills as well as solve multiple tasks with\nconsiderably less experience than solving each task from scratch. \n\n"}
{"id": "1602.03476", "contents": "Title: Conditional Dependence via Shannon Capacity: Axioms, Estimators and\n  Applications Abstract: We conduct an axiomatic study of the problem of estimating the strength of a\nknown causal relationship between a pair of variables. We propose that an\nestimate of causal strength should be based on the conditional distribution of\nthe effect given the cause (and not on the driving distribution of the cause),\nand study dependence measures on conditional distributions. Shannon capacity,\nappropriately regularized, emerges as a natural measure under these axioms. We\nexamine the problem of calculating Shannon capacity from the observed samples\nand propose a novel fixed-$k$ nearest neighbor estimator, and demonstrate its\nconsistency. Finally, we demonstrate an application to single-cell\nflow-cytometry, where the proposed estimators significantly reduce sample\ncomplexity. \n\n"}
{"id": "1602.04133", "contents": "Title: Deep Gaussian Processes for Regression using Approximate Expectation\n  Propagation Abstract: Deep Gaussian processes (DGPs) are multi-layer hierarchical generalisations\nof Gaussian processes (GPs) and are formally equivalent to neural networks with\nmultiple, infinitely wide hidden layers. DGPs are nonparametric probabilistic\nmodels and as such are arguably more flexible, have a greater capacity to\ngeneralise, and provide better calibrated uncertainty estimates than\nalternative deep models. This paper develops a new approximate Bayesian\nlearning scheme that enables DGPs to be applied to a range of medium to large\nscale regression problems for the first time. The new method uses an\napproximate Expectation Propagation procedure and a novel and efficient\nextension of the probabilistic backpropagation algorithm for learning. We\nevaluate the new method for non-linear regression on eleven real-world\ndatasets, showing that it always outperforms GP regression and is almost always\nbetter than state-of-the-art deterministic and sampling-based approximate\ninference methods for Bayesian neural networks. As a by-product, this work\nprovides a comprehensive analysis of six approximate Bayesian methods for\ntraining neural networks. \n\n"}
{"id": "1602.04505", "contents": "Title: Quasi-4-Connected Components Abstract: We introduce a new decomposition of a graphs into quasi-4-connected\ncomponents, where we call a graph quasi-4-connected if it is 3-connected and it\nonly has separations of order 3 that remove a single vertex. Moreover, we give\na cubic time algorithm computing the decomposition of a given graph.\n  Our decomposition into quasi-4-connected components refines the well-known\ndecompositions of graphs into biconnected and triconnected components. We\nrelate our decomposition to Robertson and Seymour's theory of tangles by\nestablishing a correspondence between the quasi-4-connected components of a\ngraph and its tangles of order 4. \n\n"}
{"id": "1602.04799", "contents": "Title: Quantum Perceptron Models Abstract: We demonstrate how quantum computation can provide non-trivial improvements\nin the computational and statistical complexity of the perceptron model. We\ndevelop two quantum algorithms for perceptron learning. The first algorithm\nexploits quantum information processing to determine a separating hyperplane\nusing a number of steps sublinear in the number of data points $N$, namely\n$O(\\sqrt{N})$. The second algorithm illustrates how the classical mistake bound\nof $O(\\frac{1}{\\gamma^2})$ can be further improved to\n$O(\\frac{1}{\\sqrt{\\gamma}})$ through quantum means, where $\\gamma$ denotes the\nmargin. Such improvements are achieved through the application of quantum\namplitude amplification to the version space interpretation of the perceptron\nmodel. \n\n"}
{"id": "1602.07194", "contents": "Title: Lens depth function and k-relative neighborhood graph: versatile tools\n  for ordinal data analysis Abstract: In recent years it has become popular to study machine learning problems in a\nsetting of ordinal distance information rather than numerical distance\nmeasurements. By ordinal distance information we refer to binary answers to\ndistance comparisons such as $d(A,B)<d(C,D)$. For many problems in machine\nlearning and statistics it is unclear how to solve them in such a scenario. Up\nto now, the main approach is to explicitly construct an ordinal embedding of\nthe data points in the Euclidean space, an approach that has a number of\ndrawbacks. In this paper, we propose algorithms for the problems of medoid\nestimation, outlier identification, classification, and clustering when given\nonly ordinal data. They are based on estimating the lens depth function and the\n$k$-relative neighborhood graph on a data set. Our algorithms are simple, are\nmuch faster than an ordinal embedding approach and avoid some of its drawbacks,\nand can easily be parallelized. \n\n"}
{"id": "1602.07337", "contents": "Title: Sparse Estimation of Multivariate Poisson Log-Normal Models from Count\n  Data Abstract: Modeling data with multivariate count responses is a challenging problem due\nto the discrete nature of the responses. Existing methods for univariate count\nresponses cannot be easily extended to the multivariate case since the\ndependency among multiple responses needs to be properly accommodated. In this\npaper, we propose a multivariate Poisson log-normal regression model for\nmultivariate data with count responses. By simultaneously estimating the\nregression coefficients and inverse covariance matrix over the latent variables\nwith an efficient Monte Carlo EM algorithm, the proposed regression model takes\nadvantages of association among multiple count responses to improve the model\nprediction performance. Simulation studies and applications to real world data\nare conducted to systematically evaluate the performance of the proposed method\nin comparison with conventional methods. \n\n"}
{"id": "1602.07570", "contents": "Title: Bayesian Exploration: Incentivizing Exploration in Bayesian Games Abstract: We consider a ubiquitous scenario in the Internet economy when individual\ndecision-makers (henceforth, agents) both produce and consume information as\nthey make strategic choices in an uncertain environment. This creates a\nthree-way tradeoff between exploration (trying out insufficiently explored\nalternatives to help others in the future), exploitation (making optimal\ndecisions given the information discovered by other agents), and incentives of\nthe agents (who are myopically interested in exploitation, while preferring the\nothers to explore). We posit a principal who controls the flow of information\nfrom agents that came before, and strives to coordinate the agents towards a\nsocially optimal balance between exploration and exploitation, not using any\nmonetary transfers. The goal is to design a recommendation policy for the\nprincipal which respects agents' incentives and minimizes a suitable notion of\nregret.\n  We extend prior work in this direction to allow the agents to interact with\none another in a shared environment: at each time step, multiple agents arrive\nto play a Bayesian game, receive recommendations, choose their actions, receive\ntheir payoffs, and then leave the game forever. The agents now face two sources\nof uncertainty: the actions of the other agents and the parameters of the\nuncertain game environment.\n  Our main contribution is to show that the principal can achieve constant\nregret when the utilities are deterministic (where the constant depends on the\nprior distribution, but not on the time horizon), and logarithmic regret when\nthe utilities are stochastic. As a key technical tool, we introduce the concept\nof explorable actions, the actions which some incentive-compatible policy can\nrecommend with non-zero probability. We show how the principal can identify\n(and explore) all explorable actions, and use the revealed information to\nperform optimally. \n\n"}
{"id": "1602.07754", "contents": "Title: A Compressed Sensing Based Decomposition of Electrodermal Activity\n  Signals Abstract: The measurement and analysis of Electrodermal Activity (EDA) offers\napplications in diverse areas ranging from market research, to seizure\ndetection, to human stress analysis. Unfortunately, the analysis of EDA signals\nis made difficult by the superposition of numerous components which can obscure\nthe signal information related to a user's response to a stimulus. We show how\nsimple pre-processing followed by a novel compressed sensing based\ndecomposition can mitigate the effects of the undesired noise components and\nhelp reveal the underlying physiological signal. The proposed framework allows\nfor decomposition of EDA signals with provable bounds on the recovery of user\nresponses. We test our procedure on both synthetic and real-world EDA signals\nfrom wearable sensors and demonstrate that our approach allows for more\naccurate recovery of user responses as compared to the existing techniques. \n\n"}
{"id": "1603.01191", "contents": "Title: A fixed-parameter algorithm for a routing open shop problem: unit\n  processing times, few machines and locations Abstract: The open shop problem is to find a minimum makespan schedule to process each\njob $J_i$ on each machine $M_q$ for $p_{iq}$ time such that, at any time, each\nmachine processes at most one job and each job is processed by at most one\nmachine. We study a problem variant in which the jobs are located in the\nvertices of an edge-weighted graph. The weights determine the time needed for\nthe machines to travel between jobs in different vertices. We show that the\nproblem with $m$ machines and $n$ unit-time jobs in $g$ vertices is solvable in\n$2^{O(gm^2\\log gm)}+O(mn\\log n)$ time. \n\n"}
{"id": "1603.03827", "contents": "Title: Sequential Short-Text Classification with Recurrent and Convolutional\n  Neural Networks Abstract: Recent approaches based on artificial neural networks (ANNs) have shown\npromising results for short-text classification. However, many short texts\noccur in sequences (e.g., sentences in a document or utterances in a dialog),\nand most existing ANN-based systems do not leverage the preceding short texts\nwhen classifying a subsequent one. In this work, we present a model based on\nrecurrent neural networks and convolutional neural networks that incorporates\nthe preceding short texts. Our model achieves state-of-the-art results on three\ndifferent datasets for dialog act prediction. \n\n"}
{"id": "1603.05642", "contents": "Title: Optimal Black-Box Reductions Between Optimization Objectives Abstract: The diverse world of machine learning applications has given rise to a\nplethora of algorithms and optimization methods, finely tuned to the specific\nregression or classification task at hand. We reduce the complexity of\nalgorithm design for machine learning by reductions: we develop reductions that\ntake a method developed for one setting and apply it to the entire spectrum of\nsmoothness and strong-convexity in applications.\n  Furthermore, unlike existing results, our new reductions are OPTIMAL and more\nPRACTICAL. We show how these new reductions give rise to new and faster running\ntimes on training linear classifiers for various families of loss functions,\nand conclude with experiments showing their successes also in practice. \n\n"}
{"id": "1603.05643", "contents": "Title: Variance Reduction for Faster Non-Convex Optimization Abstract: We consider the fundamental problem in non-convex optimization of efficiently\nreaching a stationary point. In contrast to the convex case, in the long\nhistory of this basic problem, the only known theoretical results on\nfirst-order non-convex optimization remain to be full gradient descent that\nconverges in $O(1/\\varepsilon)$ iterations for smooth objectives, and\nstochastic gradient descent that converges in $O(1/\\varepsilon^2)$ iterations\nfor objectives that are sum of smooth functions.\n  We provide the first improvement in this line of research. Our result is\nbased on the variance reduction trick recently introduced to convex\noptimization, as well as a brand new analysis of variance reduction that is\nsuitable for non-convex optimization. For objectives that are sum of smooth\nfunctions, our first-order minibatch stochastic method converges with an\n$O(1/\\varepsilon)$ rate, and is faster than full gradient descent by\n$\\Omega(n^{1/3})$.\n  We demonstrate the effectiveness of our methods on empirical risk\nminimizations with non-convex loss functions and training neural nets. \n\n"}
{"id": "1603.06038", "contents": "Title: Tensor Methods and Recommender Systems Abstract: A substantial progress in development of new and efficient tensor\nfactorization techniques has led to an extensive research of their\napplicability in recommender systems field. Tensor-based recommender models\npush the boundaries of traditional collaborative filtering techniques by taking\ninto account a multifaceted nature of real environments, which allows to\nproduce more accurate, situational (e.g. context-aware, criteria-driven)\nrecommendations. Despite the promising results, tensor-based methods are poorly\ncovered in existing recommender systems surveys. This survey aims to complement\nprevious works and provide a comprehensive overview on the subject. To the best\nof our knowledge, this is the first attempt to consolidate studies from various\napplication domains in an easily readable, digestible format, which helps to\nget a notion of the current state of the field. We also provide a high level\ndiscussion of the future perspectives and directions for further improvement of\ntensor-based recommendation systems. \n\n"}
{"id": "1603.07340", "contents": "Title: Peeling and Nibbling the Cactus: Subexponential-Time Algorithms for\n  Counting Triangulations and Related Problems Abstract: Given a set of $n$ points $S$ in the plane, a triangulation $T$ of $S$ is a\nmaximal set of non-crossing segments with endpoints in $S$. We present an\nalgorithm that computes the number of triangulations on a given set of $n$\npoints in time $n^{(11+ o(1))\\sqrt{n} }$, significantly improving the previous\nbest running time of $O(2^n n^2)$ by Alvarez and Seidel [SoCG 2013]. Our main\ntool is identifying separators of size $O(\\sqrt{n})$ of a triangulation in a\ncanonical way. The definition of the separators are based on the decomposition\nof the triangulation into nested layers (\"cactus graphs\"). Based on the above\nalgorithm, we develop a simple and formal framework to count other non-crossing\nstraight-line graphs in $n^{O(\\sqrt{n})}$ time. We demonstrate the usefulness\nof the framework by applying it to counting non-crossing Hamilton cycles,\nspanning trees, perfect matchings, $3$-colorable triangulations, connected\ngraphs, cycle decompositions, quadrangulations, $3$-regular graphs, and more. \n\n"}
{"id": "1603.08318", "contents": "Title: Exclusivity Regularized Machine Abstract: It has been recognized that the diversity of base learners is of utmost\nimportance to a good ensemble. This paper defines a novel measurement of\ndiversity, termed as exclusivity. With the designed exclusivity, we further\npropose an ensemble model, namely Exclusivity Regularized Machine (ERM), to\njointly suppress the training error of ensemble and enhance the diversity\nbetween bases. Moreover, an Augmented Lagrange Multiplier based algorithm is\ncustomized to effectively and efficiently seek the optimal solution of ERM.\nTheoretical analysis on convergence and global optimality of the proposed\nalgorithm, as well as experiments are provided to reveal the efficacy of our\nmethod and show its superiority over state-of-the-art alternatives in terms of\naccuracy and efficiency. \n\n"}
{"id": "1603.09420", "contents": "Title: Minimal Gated Unit for Recurrent Neural Networks Abstract: Recently recurrent neural networks (RNN) has been very successful in handling\nsequence data. However, understanding RNN and finding the best practices for\nRNN is a difficult task, partly because there are many competing and complex\nhidden units (such as LSTM and GRU). We propose a gated unit for RNN, named as\nMinimal Gated Unit (MGU), since it only contains one gate, which is a minimal\ndesign among all gated hidden units. The design of MGU benefits from evaluation\nresults on LSTM and GRU in the literature. Experiments on various sequence data\nshow that MGU has comparable accuracy with GRU, but has a simpler structure,\nfewer parameters, and faster training. Hence, MGU is suitable in RNN's\napplications. Its simple architecture also means that it is easier to evaluate\nand tune, and in principle it is easier to study MGU's properties theoretically\nand empirically. \n\n"}
{"id": "1604.01357", "contents": "Title: Heavy hitters via cluster-preserving clustering Abstract: In turnstile $\\ell_p$ $\\varepsilon$-heavy hitters, one maintains a\nhigh-dimensional $x\\in\\mathbb{R}^n$ subject to $\\texttt{update}(i,\\Delta)$\ncausing $x_i\\leftarrow x_i + \\Delta$, where $i\\in[n]$, $\\Delta\\in\\mathbb{R}$.\nUpon receiving a query, the goal is to report a small list $L\\subset[n]$, $|L|\n= O(1/\\varepsilon^p)$, containing every \"heavy hitter\" $i\\in[n]$ with $|x_i|\n\\ge \\varepsilon \\|x_{\\overline{1/\\varepsilon^p}}\\|_p$, where $x_{\\overline{k}}$\ndenotes the vector obtained by zeroing out the largest $k$ entries of $x$ in\nmagnitude.\n  For any $p\\in(0,2]$ the CountSketch solves $\\ell_p$ heavy hitters using\n$O(\\varepsilon^{-p}\\log n)$ words of space with $O(\\log n)$ update time,\n$O(n\\log n)$ query time to output $L$, and whose output after any query is\ncorrect with high probability (whp) $1 - 1/poly(n)$. Unfortunately the query\ntime is very slow. To remedy this, the work [CM05] proposed for $p=1$ in the\nstrict turnstile model, a whp correct algorithm achieving suboptimal space\n$O(\\varepsilon^{-1}\\log^2 n)$, worse update time $O(\\log^2 n)$, but much better\nquery time $O(\\varepsilon^{-1}poly(\\log n))$.\n  We show this tradeoff between space and update time versus query time is\nunnecessary. We provide a new algorithm, ExpanderSketch, which in the most\ngeneral turnstile model achieves optimal $O(\\varepsilon^{-p}\\log n)$ space,\n$O(\\log n)$ update time, and fast $O(\\varepsilon^{-p}poly(\\log n))$ query time,\nand whp correctness. Our main innovation is an efficient reduction from the\nheavy hitters to a clustering problem in which each heavy hitter is encoded as\nsome form of noisy spectral cluster in a much bigger graph, and the goal is to\nidentify every cluster. Since every heavy hitter must be found, correctness\nrequires that every cluster be found. We then develop a \"cluster-preserving\nclustering\" algorithm, partitioning the graph into clusters without destroying\nany original cluster. \n\n"}
{"id": "1604.02486", "contents": "Title: The Salesman's Improved Paths: 3/2+1/34 Integrality Gap and\n  Approximation Ratio Abstract: We give a new, strongly polynomial-time algorithm and improved analysis for\nthe metric $s-t$ path TSP. It finds a tour of cost less than 1.53 times the\noptimum of the subtour elimination LP, while known examples show that 1.5 is a\nlower bound for the integrality gap.\n  A key new idea is the deletion of some edges of Christofides' trees, which is\nthen accompanied by novel arguments of the analysis: edge-deletion disconnects\nthe trees, which are then partly reconnected by `parity correction'. We show\nthat the arising `connectivity correction' can be achieved for a minor extra\ncost.\n  On the one hand this algorithm and analysis extend previous tools such as the\nbest-of-many Christofides algorithm. On the other hand, powerful new tools are\nsolicited, such as a flow problem for analyzing the reconnection cost, and the\nconstruction of a set of more and more restrictive spanning trees, each of\nwhich can still be found by the greedy algorithm. We show that these trees can\nreplace the convex combination of spanning trees in the best-of-may\nChristofides algorithm.\n  These new methods lead to improving the integrality ratio and approximation\nguarantee below 1.53, as it is already sketched in the preliminary shortened\nversion of this article that appeared in FOCS 2016. The algorithm and analysis\nhave been significantly simplified in the current article, and details of\nproofs and explanations have been added. \n\n"}
{"id": "1604.04618", "contents": "Title: Make Up Your Mind: The Price of Online Queries in Differential Privacy Abstract: We consider the problem of answering queries about a sensitive dataset\nsubject to differential privacy. The queries may be chosen adversarially from a\nlarger set Q of allowable queries in one of three ways, which we list in order\nfrom easiest to hardest to answer:\n  Offline: The queries are chosen all at once and the differentially private\nmechanism answers the queries in a single batch.\n  Online: The queries are chosen all at once, but the mechanism only receives\nthe queries in a streaming fashion and must answer each query before seeing the\nnext query.\n  Adaptive: The queries are chosen one at a time and the mechanism must answer\neach query before the next query is chosen. In particular, each query may\ndepend on the answers given to previous queries.\n  Many differentially private mechanisms are just as efficient in the adaptive\nmodel as they are in the offline model. Meanwhile, most lower bounds for\ndifferential privacy hold in the offline setting. This suggests that the three\nmodels may be equivalent.\n  We prove that these models are all, in fact, distinct. Specifically, we show\nthat there is a family of statistical queries such that exponentially more\nqueries from this family can be answered in the offline model than in the\nonline model. We also exhibit a family of search queries such that\nexponentially more queries from this family can be answered in the online model\nthan in the adaptive model. We also investigate whether such separations might\nhold for simple queries like threshold queries over the real line. \n\n"}
{"id": "1604.04827", "contents": "Title: h-Index Manipulation by Undoing Merges Abstract: The h-index is an important bibliographic measure used to assess the\nperformance of researchers. Dutiful researchers merge different versions of\ntheir articles in their Google Scholar profile even though this can decrease\ntheir h-index. In this article, we study the manipulation of the h-index by\nundoing such merges. In contrast to manipulation by merging articles (van\nBevern et al. [Artif. Intel. 240:19-35, 2016]) such manipulation is harder to\ndetect. We present numerous results on computational complexity (from\nlinear-time algorithms to parameterized computational hardness results) and\nempirically indicate that at least small improvements of the h-index by\nsplitting merged articles are unfortunately easily achievable. \n\n"}
{"id": "1604.06968", "contents": "Title: Agnostic Estimation of Mean and Covariance Abstract: We consider the problem of estimating the mean and covariance of a\ndistribution from iid samples in $\\mathbb{R}^n$, in the presence of an $\\eta$\nfraction of malicious noise; this is in contrast to much recent work where the\nnoise itself is assumed to be from a distribution of known type. The agnostic\nproblem includes many interesting special cases, e.g., learning the parameters\nof a single Gaussian (or finding the best-fit Gaussian) when $\\eta$ fraction of\ndata is adversarially corrupted, agnostically learning a mixture of Gaussians,\nagnostic ICA, etc. We present polynomial-time algorithms to estimate the mean\nand covariance with error guarantees in terms of information-theoretic lower\nbounds. As a corollary, we also obtain an agnostic algorithm for Singular Value\nDecomposition. \n\n"}
{"id": "1604.07128", "contents": "Title: On the Grundy number of Cameron graphs Abstract: The Grundy number of a graph is the maximal number of colors attained by a\nfirst-fit coloring of the graph. The class of Cameron graphs is the Seidel\nswitching class of cographs. In this paper we show that the Grundy number is\ncomputable in polynomial time for Cameron graphs. \n\n"}
{"id": "1604.07356", "contents": "Title: Fast nonlinear embeddings via structured matrices Abstract: We present a new paradigm for speeding up randomized computations of several\nfrequently used functions in machine learning. In particular, our paradigm can\nbe applied for improving computations of kernels based on random embeddings.\nAbove that, the presented framework covers multivariate randomized functions.\nAs a byproduct, we propose an algorithmic approach that also leads to a\nsignificant reduction of space complexity. Our method is based on careful\nrecycling of Gaussian vectors into structured matrices that share properties of\nfully random matrices. The quality of the proposed structured approach follows\nfrom combinatorial properties of the graphs encoding correlations between rows\nof these structured matrices. Our framework covers as special cases already\nknown structured approaches such as the Fast Johnson-Lindenstrauss Transform,\nbut is much more general since it can be applied also to highly nonlinear\nembeddings. We provide strong concentration results showing the quality of the\npresented paradigm. \n\n"}
{"id": "1604.07706", "contents": "Title: Distributed Clustering of Linear Bandits in Peer to Peer Networks Abstract: We provide two distributed confidence ball algorithms for solving linear\nbandit problems in peer to peer networks with limited communication\ncapabilities. For the first, we assume that all the peers are solving the same\nlinear bandit problem, and prove that our algorithm achieves the optimal\nasymptotic regret rate of any centralised algorithm that can instantly\ncommunicate information between the peers. For the second, we assume that there\nare clusters of peers solving the same bandit problem within each cluster, and\nwe prove that our algorithm discovers these clusters, while achieving the\noptimal asymptotic regret rate within each one. Through experiments on several\nreal-world datasets, we demonstrate the performance of proposed algorithms\ncompared to the state-of-the-art. \n\n"}
{"id": "1604.07724", "contents": "Title: Assessing the Computational Complexity of Multi-Layer Subgraph Detection Abstract: Multi-layer graphs consist of several graphs (layers) over the same vertex\nset. They are motivated by real-world problems where entities (vertices) are\nassociated via multiple types of relationships (edges in different layers). We\nchart the border of computational (in)tractability for the class of subgraph\ndetection problems on multi-layer graphs, including fundamental problems such\nas maximum matching, finding certain clique relaxations (motivated by community\ndetection), or path problems. Mostly encountering hardness results, sometimes\neven for two or three layers, we can also spot some islands of tractability. \n\n"}
{"id": "1605.01107", "contents": "Title: Decentralized Dynamic Discriminative Dictionary Learning Abstract: We consider discriminative dictionary learning in a distributed online\nsetting, where a network of agents aims to learn a common set of dictionary\nelements of a feature space and model parameters while sequentially receiving\nobservations. We formulate this problem as a distributed stochastic program\nwith a non-convex objective and present a block variant of the Arrow-Hurwicz\nsaddle point algorithm to solve it. Using Lagrange multipliers to penalize the\ndiscrepancy between them, only neighboring nodes exchange model information. We\nshow that decisions made with this saddle point algorithm asymptotically\nachieve a first-order stationarity condition on average. \n\n"}
{"id": "1605.03243", "contents": "Title: On \"Exponential Lower Bounds for Polytopes in Combinatorial\n  Optimization\" by Fiorini et al. (2015): A Refutation For Models With Disjoint\n  Sets of Descriptive Variables Abstract: We provide a numerical refutation of the developments of Fiorini et al.\n(2015)* for models with disjoint sets of descriptive variables. We also provide\nan insight into the meaning of the existence of a one-to-one linear map between\nsolutions of such models.\n  *: Fiorini, S., S. Massar, S. Pokutta, H.R. Tiwary, and R. de Wolf (2015).\nExponential Lower Bounds for Polytopes in Combinatorial Optimization. Journal\nof the ACM 62:2, Article No. 17. \n\n"}
{"id": "1605.03391", "contents": "Title: Unbiased split variable selection for random survival forests using\n  maximally selected rank statistics Abstract: The most popular approach for analyzing survival data is the Cox regression\nmodel. The Cox model may, however, be misspecified, and its proportionality\nassumption may not always be fulfilled. An alternative approach for survival\nprediction is random forests for survival outcomes. The standard split\ncriterion for random survival forests is the log-rank test statistics, which\nfavors splitting variables with many possible split points. Conditional\ninference forests avoid this split variable selection bias. However, linear\nrank statistics are utilized by default in conditional inference forests to\nselect the optimal splitting variable, which cannot detect non-linear effects\nin the independent variables. An alternative is to use maximally selected rank\nstatistics for the split point selection. As in conditional inference forests,\nsplitting variables are compared on the p-value scale. However, instead of the\nconditional Monte-Carlo approach used in conditional inference forests, p-value\napproximations are employed. We describe several p-value approximations and the\nimplementation of the proposed random forest approach. A simulation study\ndemonstrates that unbiased split variable selection is possible. However, there\nis a trade-off between unbiased split variable selection and runtime. In\nbenchmark studies of prediction performance on simulated and real datasets the\nnew method performs better than random survival forests if informative\ndichotomous variables are combined with uninformative variables with more\ncategories and better than conditional inference forests if non-linear\ncovariate effects are included. In a runtime comparison the method proves to be\ncomputationally faster than both alternatives, if a simple p-value\napproximation is used. \n\n"}
{"id": "1605.03843", "contents": "Title: Asymptotic sequential Rademacher complexity of a finite function class Abstract: For a finite function class we describe the large sample limit of the\nsequential Rademacher complexity in terms of the viscosity solution of a\n$G$-heat equation. In the language of Peng's sublinear expectation theory, the\nsame quantity equals to the expected value of the largest order statistics of a\nmultidimensional $G$-normal random variable. We illustrate this result by\nderiving upper and lower bounds for the asymptotic sequential Rademacher\ncomplexity. \n\n"}
{"id": "1605.06715", "contents": "Title: Factored Temporal Sigmoid Belief Networks for Sequence Learning Abstract: Deep conditional generative models are developed to simultaneously learn the\ntemporal dependencies of multiple sequences. The model is designed by\nintroducing a three-way weight tensor to capture the multiplicative\ninteractions between side information and sequences. The proposed model builds\non the Temporal Sigmoid Belief Network (TSBN), a sequential stack of Sigmoid\nBelief Networks (SBNs). The transition matrices are further factored to reduce\nthe number of parameters and improve generalization. When side information is\nnot available, a general framework for semi-supervised learning based on the\nproposed model is constituted, allowing robust sequence classification.\nExperimental results show that the proposed approach achieves state-of-the-art\npredictive and classification performance on sequential data, and has the\ncapacity to synthesize sequences, with controlled style transitioning and\nblending. \n\n"}
{"id": "1605.07133", "contents": "Title: Towards Multi-Agent Communication-Based Language Learning Abstract: We propose an interactive multimodal framework for language learning. Instead\nof being passively exposed to large amounts of natural text, our learners\n(implemented as feed-forward neural networks) engage in cooperative referential\ngames starting from a tabula rasa setup, and thus develop their own language\nfrom the need to communicate in order to succeed at the game. Preliminary\nexperiments provide promising results, but also suggest that it is important to\nensure that agents trained in this way do not develop an adhoc communication\ncode only effective for the game they are playing \n\n"}
{"id": "1605.07221", "contents": "Title: Global Optimality of Local Search for Low Rank Matrix Recovery Abstract: We show that there are no spurious local minima in the non-convex factorized\nparametrization of low-rank matrix recovery from incoherent linear\nmeasurements. With noisy measurements we show all local minima are very close\nto a global optimum. Together with a curvature bound at saddle points, this\nyields a polynomial time global convergence guarantee for stochastic gradient\ndescent {\\em from random initialization}. \n\n"}
{"id": "1605.07950", "contents": "Title: On Fast Convergence of Proximal Algorithms for SQRT-Lasso Optimization:\n  Don't Worry About Its Nonsmooth Loss Function Abstract: Many machine learning techniques sacrifice convenient computational\nstructures to gain estimation robustness and modeling flexibility. However, by\nexploring the modeling structures, we find these \"sacrifices\" do not always\nrequire more computational efforts. To shed light on such a \"free-lunch\"\nphenomenon, we study the square-root-Lasso (SQRT-Lasso) type regression\nproblem. Specifically, we show that the nonsmooth loss functions of SQRT-Lasso\ntype regression ease tuning effort and gain adaptivity to inhomogeneous noise,\nbut is not necessarily more challenging than Lasso in computation. We can\ndirectly apply proximal algorithms (e.g. proximal gradient descent, proximal\nNewton, and proximal Quasi-Newton algorithms) without worrying the\nnonsmoothness of the loss function. Theoretically, we prove that the proximal\nalgorithms combined with the pathwise optimization scheme enjoy fast\nconvergence guarantees with high probability. Numerical results are provided to\nsupport our theory. \n\n"}
{"id": "1605.08361", "contents": "Title: No bad local minima: Data independent training error guarantees for\n  multilayer neural networks Abstract: We use smoothed analysis techniques to provide guarantees on the training\nloss of Multilayer Neural Networks (MNNs) at differentiable local minima.\nSpecifically, we examine MNNs with piecewise linear activation functions,\nquadratic loss and a single output, under mild over-parametrization. We prove\nthat for a MNN with one hidden layer, the training error is zero at every\ndifferentiable local minimum, for almost every dataset and dropout-like noise\nrealization. We then extend these results to the case of more than one hidden\nlayer. Our theoretical guarantees assume essentially nothing on the training\ndata, and are verified numerically. These results suggest why the highly\nnon-convex loss of such MNNs can be easily optimized using local updates (e.g.,\nstochastic gradient descent), as observed empirically. \n\n"}
{"id": "1605.08374", "contents": "Title: Kronecker Determinantal Point Processes Abstract: Determinantal Point Processes (DPPs) are probabilistic models over all\nsubsets a ground set of $N$ items. They have recently gained prominence in\nseveral applications that rely on \"diverse\" subsets. However, their\napplicability to large problems is still limited due to the $\\mathcal O(N^3)$\ncomplexity of core tasks such as sampling and learning. We enable efficient\nsampling and learning for DPPs by introducing KronDPP, a DPP model whose kernel\nmatrix decomposes as a tensor product of multiple smaller kernel matrices. This\ndecomposition immediately enables fast exact sampling. But contrary to what one\nmay expect, leveraging the Kronecker product structure for speeding up DPP\nlearning turns out to be more difficult. We overcome this challenge, and derive\nbatch and stochastic optimization algorithms for efficiently learning the\nparameters of a KronDPP. \n\n"}
{"id": "1605.08540", "contents": "Title: Induced Minor Free Graphs: Isomorphism and Clique-width Abstract: Given two graphs $G$ and $H$, we say that $G$ contains $H$ as an induced\nminor if a graph isomorphic to $H$ can be obtained from $G$ by a sequence of\nvertex deletions and edge contractions. We study the complexity of Graph\nIsomorphism on graphs that exclude a fixed graph as an induced minor. More\nprecisely, we determine for every graph $H$ that Graph Isomorphism is\npolynomial-time solvable on $H$-induced-minor-free graphs or that it is\nGI-complete. Additionally, we classify those graphs $H$ for which\n$H$-induced-minor-free graphs have bounded clique-width. These two results\ncomplement similar dichotomies for graphs that exclude a fixed graph as an\ninduced subgraph, minor, or subgraph. \n\n"}
{"id": "1605.08754", "contents": "Title: Faster Eigenvector Computation via Shift-and-Invert Preconditioning Abstract: We give faster algorithms and improved sample complexities for estimating the\ntop eigenvector of a matrix $\\Sigma$ -- i.e. computing a unit vector $x$ such\nthat $x^T \\Sigma x \\ge (1-\\epsilon)\\lambda_1(\\Sigma)$:\n  Offline Eigenvector Estimation: Given an explicit $A \\in \\mathbb{R}^{n \\times\nd}$ with $\\Sigma = A^TA$, we show how to compute an $\\epsilon$ approximate top\neigenvector in time $\\tilde O([nnz(A) + \\frac{d*sr(A)}{gap^2} ]* \\log\n1/\\epsilon )$ and $\\tilde O([\\frac{nnz(A)^{3/4} (d*sr(A))^{1/4}}{\\sqrt{gap}} ]\n* \\log 1/\\epsilon )$. Here $nnz(A)$ is the number of nonzeros in $A$, $sr(A)$\nis the stable rank, $gap$ is the relative eigengap. By separating the $gap$\ndependence from the $nnz(A)$ term, our first runtime improves upon the\nclassical power and Lanczos methods. It also improves prior work using fast\nsubspace embeddings [AC09, CW13] and stochastic optimization [Sha15c], giving\nsignificantly better dependencies on $sr(A)$ and $\\epsilon$. Our second running\ntime improves these further when $nnz(A) \\le \\frac{d*sr(A)}{gap^2}$.\n  Online Eigenvector Estimation: Given a distribution $D$ with covariance\nmatrix $\\Sigma$ and a vector $x_0$ which is an $O(gap)$ approximate top\neigenvector for $\\Sigma$, we show how to refine to an $\\epsilon$ approximation\nusing $ O(\\frac{var(D)}{gap*\\epsilon})$ samples from $D$. Here $var(D)$ is a\nnatural notion of variance. Combining our algorithm with previous work to\ninitialize $x_0$, we obtain improved sample complexity and runtime results\nunder a variety of assumptions on $D$.\n  We achieve our results using a general framework that we believe is of\nindependent interest. We give a robust analysis of the classic method of\nshift-and-invert preconditioning to reduce eigenvector computation to\napproximately solving a sequence of linear systems. We then apply fast\nstochastic variance reduced gradient (SVRG) based system solvers to achieve our\nclaims. \n\n"}
{"id": "1605.09346", "contents": "Title: Minding the Gaps for Block Frank-Wolfe Optimization of Structured SVMs Abstract: In this paper, we propose several improvements on the block-coordinate\nFrank-Wolfe (BCFW) algorithm from Lacoste-Julien et al. (2013) recently used to\noptimize the structured support vector machine (SSVM) objective in the context\nof structured prediction, though it has wider applications. The key intuition\nbehind our improvements is that the estimates of block gaps maintained by BCFW\nreveal the block suboptimality that can be used as an adaptive criterion.\nFirst, we sample objects at each iteration of BCFW in an adaptive non-uniform\nway via gapbased sampling. Second, we incorporate pairwise and away-step\nvariants of Frank-Wolfe into the block-coordinate setting. Third, we cache\noracle calls with a cache-hit criterion based on the block gaps. Fourth, we\nprovide the first method to compute an approximate regularization path for\nSSVM. Finally, we provide an exhaustive empirical evaluation of all our methods\non four structured prediction datasets. \n\n"}
{"id": "1606.02838", "contents": "Title: Sketching for Large-Scale Learning of Mixture Models Abstract: Learning parameters from voluminous data can be prohibitive in terms of\nmemory and computational requirements. We propose a \"compressive learning\"\nframework where we estimate model parameters from a sketch of the training\ndata. This sketch is a collection of generalized moments of the underlying\nprobability distribution of the data. It can be computed in a single pass on\nthe training set, and is easily computable on streams or distributed datasets.\nThe proposed framework shares similarities with compressive sensing, which aims\nat drastically reducing the dimension of high-dimensional signals while\npreserving the ability to reconstruct them. To perform the estimation task, we\nderive an iterative algorithm analogous to sparse reconstruction algorithms in\nthe context of linear inverse problems. We exemplify our framework with the\ncompressive estimation of a Gaussian Mixture Model (GMM), providing heuristics\non the choice of the sketching procedure and theoretical guarantees of\nreconstruction. We experimentally show on synthetic data that the proposed\nalgorithm yields results comparable to the classical Expectation-Maximization\n(EM) technique while requiring significantly less memory and fewer computations\nwhen the number of database elements is large. We further demonstrate the\npotential of the approach on real large-scale data (over 10 8 training samples)\nfor the task of model-based speaker verification. Finally, we draw some\nconnections between the proposed framework and approximate Hilbert space\nembedding of probability distributions using random features. We show that the\nproposed sketching operator can be seen as an innovative method to design\ntranslation-invariant kernels adapted to the analysis of GMMs. We also use this\ntheoretical framework to derive information preservation guarantees, in the\nspirit of infinite-dimensional compressive sensing. \n\n"}
{"id": "1606.03077", "contents": "Title: Efficient Robust Proper Learning of Log-concave Distributions Abstract: We study the {\\em robust proper learning} of univariate log-concave\ndistributions (over continuous and discrete domains). Given a set of samples\ndrawn from an unknown target distribution, we want to compute a log-concave\nhypothesis distribution that is as close as possible to the target, in total\nvariation distance. In this work, we give the first computationally efficient\nalgorithm for this learning problem. Our algorithm achieves the\ninformation-theoretically optimal sample size (up to a constant factor), runs\nin polynomial time, and is robust to model misspecification with nearly-optimal\nerror guarantees.\n  Specifically, we give an algorithm that, on input $n=O(1/\\eps^{5/2})$ samples\nfrom an unknown distribution $f$, runs in time $\\widetilde{O}(n^{8/5})$, and\noutputs a log-concave hypothesis $h$ that (with high probability) satisfies\n$\\dtv(h, f) = O(\\opt)+\\eps$, where $\\opt$ is the minimum total variation\ndistance between $f$ and the class of log-concave distributions. Our approach\nto the robust proper learning problem is quite flexible and may be applicable\nto many other univariate distribution families. \n\n"}
{"id": "1606.03203", "contents": "Title: Causal Bandits: Learning Good Interventions via Causal Inference Abstract: We study the problem of using causal models to improve the rate at which good\ninterventions can be learned online in a stochastic environment. Our formalism\ncombines multi-arm bandits and causal inference to model a novel type of bandit\nfeedback that is not exploited by existing approaches. We propose a new\nalgorithm that exploits the causal feedback and prove a bound on its simple\nregret that is strictly better (in all quantities) than algorithms that do not\nuse the additional causal information. \n\n"}
{"id": "1606.04449", "contents": "Title: Recurrent neural network training with preconditioned stochastic\n  gradient descent Abstract: This paper studies the performance of a recently proposed preconditioned\nstochastic gradient descent (PSGD) algorithm on recurrent neural network (RNN)\ntraining. PSGD adaptively estimates a preconditioner to accelerate gradient\ndescent, and is designed to be simple, general and easy to use, as stochastic\ngradient descent (SGD). RNNs, especially the ones requiring extremely long term\nmemories, are difficult to train. We have tested PSGD on a set of synthetic\npathological RNN learning problems and the real world MNIST handwritten digit\nrecognition task. Experimental results suggest that PSGD is able to achieve\nhighly competitive performance without using any trick like preprocessing,\npretraining or parameter tweaking. \n\n"}
{"id": "1606.05340", "contents": "Title: Exponential expressivity in deep neural networks through transient chaos Abstract: We combine Riemannian geometry with the mean field theory of high dimensional\nchaos to study the nature of signal propagation in generic, deep neural\nnetworks with random weights. Our results reveal an order-to-chaos expressivity\nphase transition, with networks in the chaotic phase computing nonlinear\nfunctions whose global curvature grows exponentially with depth but not width.\nWe prove this generic class of deep random functions cannot be efficiently\ncomputed by any shallow network, going beyond prior work restricted to the\nanalysis of single functions. Moreover, we formalize and quantitatively\ndemonstrate the long conjectured idea that deep networks can disentangle highly\ncurved manifolds in input space into flat manifolds in hidden space. Our\ntheoretical analysis of the expressive power of deep networks broadly applies\nto arbitrary nonlinearities, and provides a quantitative underpinning for\npreviously abstract notions about the geometry of deep functions. \n\n"}
{"id": "1606.06237", "contents": "Title: Online and Differentially-Private Tensor Decomposition Abstract: In this paper, we resolve many of the key algorithmic questions regarding\nrobustness, memory efficiency, and differential privacy of tensor\ndecomposition. We propose simple variants of the tensor power method which\nenjoy these strong properties. We present the first guarantees for online\ntensor power method which has a linear memory requirement. Moreover, we present\na noise calibrated tensor power method with efficient privacy guarantees. At\nthe heart of all these guarantees lies a careful perturbation analysis derived\nin this paper which improves up on the existing results significantly. \n\n"}
{"id": "1606.06399", "contents": "Title: Uniqueness Trees: A Possible Polynomial Approach to the Graph\n  Isomorphism Problem Abstract: This paper presents the novel `uniqueness tree' algorithm, as one possible\nmethod for determining whether two finite, undirected graphs are isomorphic. We\nprove that the algorithm has polynomial time complexity in the worst case, and\nthat it will always detect the presence of an isomorphism whenever one exists.\nWe also propose that the algorithm will equivalently discern the lack of an\nisomorphism whenever one does not exist, and some initial justifications are\ngiven for this proposition, although it cannot yet be rigorously proven.\nFinally, we present experimental evidence for both the effectiveness and\nefficiency of the uniqueness tree method, using data gathered from a practical\nimplementation of the algorithm. Some consequences and directions for further\nresearch are discussed. \n\n"}
{"id": "1606.07081", "contents": "Title: Finite Sample Prediction and Recovery Bounds for Ordinal Embedding Abstract: The goal of ordinal embedding is to represent items as points in a\nlow-dimensional Euclidean space given a set of constraints in the form of\ndistance comparisons like \"item $i$ is closer to item $j$ than item $k$\".\nOrdinal constraints like this often come from human judgments. To account for\nerrors and variation in judgments, we consider the noisy situation in which the\ngiven constraints are independently corrupted by reversing the correct\nconstraint with some probability. This paper makes several new contributions to\nthis problem. First, we derive prediction error bounds for ordinal embedding\nwith noise by exploiting the fact that the rank of a distance matrix of points\nin $\\mathbb{R}^d$ is at most $d+2$. These bounds characterize how well a\nlearned embedding predicts new comparative judgments. Second, we investigate\nthe special case of a known noise model and study the Maximum Likelihood\nestimator. Third, knowledge of the noise model enables us to relate prediction\nerrors to embedding accuracy. This relationship is highly non-trivial since we\nshow that the linear map corresponding to distance comparisons is\nnon-invertible, but there exists a nonlinear map that is invertible. Fourth,\ntwo new algorithms for ordinal embedding are proposed and evaluated in\nexperiments. \n\n"}
{"id": "1606.07230", "contents": "Title: Deep Learning Markov Random Field for Semantic Segmentation Abstract: Semantic segmentation tasks can be well modeled by Markov Random Field (MRF).\nThis paper addresses semantic segmentation by incorporating high-order\nrelations and mixture of label contexts into MRF. Unlike previous works that\noptimized MRFs using iterative algorithm, we solve MRF by proposing a\nConvolutional Neural Network (CNN), namely Deep Parsing Network (DPN), which\nenables deterministic end-to-end computation in a single forward pass.\nSpecifically, DPN extends a contemporary CNN to model unary terms and\nadditional layers are devised to approximate the mean field (MF) algorithm for\npairwise terms. It has several appealing properties. First, different from the\nrecent works that required many iterations of MF during back-propagation, DPN\nis able to achieve high performance by approximating one iteration of MF.\nSecond, DPN represents various types of pairwise terms, making many existing\nmodels as its special cases. Furthermore, pairwise terms in DPN provide a\nunified framework to encode rich contextual information in high-dimensional\ndata, such as images and videos. Third, DPN makes MF easier to be parallelized\nand speeded up, thus enabling efficient inference. DPN is thoroughly evaluated\non standard semantic image/video segmentation benchmarks, where a single DPN\nmodel yields state-of-the-art segmentation accuracies on PASCAL VOC 2012,\nCityscapes dataset and CamVid dataset. \n\n"}
{"id": "1606.08061", "contents": "Title: Exact gradient updates in time independent of output size for the\n  spherical loss family Abstract: An important class of problems involves training deep neural networks with\nsparse prediction targets of very high dimension D. These occur naturally in\ne.g. neural language models or the learning of word-embeddings, often posed as\npredicting the probability of next words among a vocabulary of size D (e.g.\n200,000). Computing the equally large, but typically non-sparse D-dimensional\noutput vector from a last hidden layer of reasonable dimension d (e.g. 500)\nincurs a prohibitive O(Dd) computational cost for each example, as does\nupdating the $D \\times d$ output weight matrix and computing the gradient\nneeded for backpropagation to previous layers. While efficient handling of\nlarge sparse network inputs is trivial, the case of large sparse targets is\nnot, and has thus so far been sidestepped with approximate alternatives such as\nhierarchical softmax or sampling-based approximations during training. In this\nwork we develop an original algorithmic approach which, for a family of loss\nfunctions that includes squared error and spherical softmax, can compute the\nexact loss, gradient update for the output weights, and gradient for\nbackpropagation, all in $O(d^{2})$ per example instead of $O(Dd)$, remarkably\nwithout ever computing the D-dimensional output. The proposed algorithm yields\na speedup of up to $D/4d$ i.e. two orders of magnitude for typical sizes, for\nthat critical part of the computations that often dominates the training time\nin this kind of network architecture. \n\n"}
{"id": "1606.08117", "contents": "Title: Improved Recurrent Neural Networks for Session-based Recommendations Abstract: Recurrent neural networks (RNNs) were recently proposed for the session-based\nrecommendation task. The models showed promising improvements over traditional\nrecommendation approaches. In this work, we further study RNN-based models for\nsession-based recommendations. We propose the application of two techniques to\nimprove model performance, namely, data augmentation, and a method to account\nfor shifts in the input data distribution. We also empirically study the use of\ngeneralised distillation, and a novel alternative model that directly predicts\nitem embeddings. Experiments on the RecSys Challenge 2015 dataset demonstrate\nrelative improvements of 12.8% and 14.8% over previously reported results on\nthe Recall@20 and Mean Reciprocal Rank@20 metrics respectively. \n\n"}
{"id": "1606.08561", "contents": "Title: Estimating the class prior and posterior from noisy positives and\n  unlabeled data Abstract: We develop a classification algorithm for estimating posterior distributions\nfrom positive-unlabeled data, that is robust to noise in the positive labels\nand effective for high-dimensional data. In recent years, several algorithms\nhave been proposed to learn from positive-unlabeled data; however, many of\nthese contributions remain theoretical, performing poorly on real\nhigh-dimensional data that is typically contaminated with noise. We build on\nthis previous work to develop two practical classification algorithms that\nexplicitly model the noise in the positive labels and utilize univariate\ntransforms built on discriminative classifiers. We prove that these univariate\ntransforms preserve the class prior, enabling estimation in the univariate\nspace and avoiding kernel density estimation for high-dimensional data. The\ntheoretical development and both parametric and nonparametric algorithms\nproposed here constitutes an important step towards wide-spread use of robust\nclassification algorithms for positive-unlabeled data. \n\n"}
{"id": "1606.08571", "contents": "Title: Alternating Back-Propagation for Generator Network Abstract: This paper proposes an alternating back-propagation algorithm for learning\nthe generator network model. The model is a non-linear generalization of factor\nanalysis. In this model, the mapping from the continuous latent factors to the\nobserved signal is parametrized by a convolutional neural network. The\nalternating back-propagation algorithm iterates the following two steps: (1)\nInferential back-propagation, which infers the latent factors by Langevin\ndynamics or gradient descent. (2) Learning back-propagation, which updates the\nparameters given the inferred latent factors by gradient descent. The gradient\ncomputations in both steps are powered by back-propagation, and they share most\nof their code in common. We show that the alternating back-propagation\nalgorithm can learn realistic generator models of natural images, video\nsequences, and sounds. Moreover, it can also be used to learn from incomplete\nor indirect training data. \n\n"}
{"id": "1607.00345", "contents": "Title: Convergence Rate of Frank-Wolfe for Non-Convex Objectives Abstract: We give a simple proof that the Frank-Wolfe algorithm obtains a stationary\npoint at a rate of $O(1/\\sqrt{t})$ on non-convex objectives with a Lipschitz\ncontinuous gradient. Our analysis is affine invariant and is the first, to the\nbest of our knowledge, giving a similar rate to what was already proven for\nprojected gradient methods (though on slightly different measures of\nstationarity). \n\n"}
{"id": "1607.01167", "contents": "Title: Deterministic polynomial-time approximation algorithms for partition\n  functions and graph polynomials Abstract: In this paper we show a new way of constructing deterministic polynomial-time\napproximation algorithms for computing complex-valued evaluations of a large\nclass of graph polynomials on bounded degree graphs. In particular, our\napproach works for the Tutte polynomial and independence polynomial, as well as\npartition functions of complex-valued spin and edge-coloring models.\n  More specifically, we define a large class of graph polynomials $\\mathcal C$\nand show that if $p\\in \\cal C$ and there is a disk $D$ centered at zero in the\ncomplex plane such that $p(G)$ does not vanish on $D$ for all bounded degree\ngraphs $G$, then for each $z$ in the interior of $D$ there exists a\ndeterministic polynomial-time approximation algorithm for evaluating $p(G)$ at\n$z$. This gives an explicit connection between absence of zeros of graph\npolynomials and the existence of efficient approximation algorithms, allowing\nus to show new relationships between well-known conjectures.\n  Our work builds on a recent line of work initiated by. Barvinok, which\nprovides a new algorithmic approach besides the existing Markov chain Monte\nCarlo method and the correlation decay method for these types of problems. \n\n"}
{"id": "1607.01551", "contents": "Title: On Sampling and Greedy MAP Inference of Constrained Determinantal Point\n  Processes Abstract: Subset selection problems ask for a small, diverse yet representative subset\nof the given data. When pairwise similarities are captured by a kernel, the\ndeterminants of submatrices provide a measure of diversity or independence of\nitems within a subset. Matroid theory gives another notion of independence,\nthus giving rise to optimization and sampling questions about Determinantal\nPoint Processes (DPPs) under matroid constraints. Partition constraints, as a\nspecial case, arise naturally when incorporating additional labeling or\nclustering information, besides the kernel, in DPPs. Finding the maximum\ndeterminant submatrix under matroid constraints on its row/column indices has\nbeen previously studied. However, the corresponding question of sampling from\nDPPs under matroid constraints has been unresolved, beyond the simple\ncardinality constrained k-DPPs. We give the first polynomial time algorithm to\nsample exactly from DPPs under partition constraints, for any constant number\nof partitions. We complement this by a complexity theoretic barrier that rules\nout such a result under general matroid constraints. Our experiments indicate\nthat partition-constrained DPPs offer more flexibility and more diversity than\nk-DPPs and their naive extensions, while being reasonably efficient in running\ntime. We also show that a simple greedy initialization followed by local search\ngives improved approximation guarantees for the problem of MAP inference from\nk- DPPs on well-conditioned kernels. Our experiments show that this improvement\nis significant for larger values of k, supporting our theoretical result. \n\n"}
{"id": "1607.02922", "contents": "Title: Characterization and recognition of proper tagged probe interval graphs Abstract: Interval graphs were used in the study of genomics by the famous molecular\nbiologist Benzer. Later on probe interval graphs were introduced by Zhang as a\ngeneralization of interval graphs for the study of cosmid contig mapping of\nDNA.\n  A tagged probe interval graph (briefly, TPIG) is motivated by similar\napplications to genomics, where the set of vertices is partitioned into two\nsets, namely, probes and nonprobes and there is an interval on the real line\ncorresponding to each vertex. The graph has an edge between two probe vertices\nif their corresponding intervals intersect, has an edge between a probe vertex\nand a nonprobe vertex if the interval corresponding to a nonprobe vertex\ncontains at least one end point of the interval corresponding to a probe vertex\nand the set of non-probe vertices is an independent set. This class of graphs\nhave been defined nearly two decades ago, but till today there is no known\nrecognition algorithm for it.\n  In this paper, we consider a natural subclass of TPIG, namely, the class of\nproper tagged probe interval graphs (in short PTPIG). We present\ncharacterization and a linear time recognition algorithm for PTPIG. To obtain\nthis characterization theorem we introduce a new concept called canonical\nsequence for proper interval graphs, which, we belief, has an independent\ninterest in the study of proper interval graphs. Also to obtain the recognition\nalgorithm for PTPIG, we introduce and solve a variation of consecutive $1$'s\nproblem, namely, oriented consecutive $1$'s problem and some variations of\nPQ-tree algorithm. We also discuss the interrelations between the classes of\nPTPIG and TPIG with probe interval graphs and probe proper interval graphs. \n\n"}
{"id": "1607.02959", "contents": "Title: From Behavior to Sparse Graphical Games: Efficient Recovery of\n  Equilibria Abstract: In this paper we study the problem of exact recovery of the pure-strategy\nNash equilibria (PSNE) set of a graphical game from noisy observations of joint\nactions of the players alone. We consider sparse linear influence games --- a\nparametric class of graphical games with linear payoffs, and represented by\ndirected graphs of n nodes (players) and in-degree of at most k. We present an\n$\\ell_1$-regularized logistic regression based algorithm for recovering the\nPSNE set exactly, that is both computationally efficient --- i.e. runs in\npolynomial time --- and statistically efficient --- i.e. has logarithmic sample\ncomplexity. Specifically, we show that the sufficient number of samples\nrequired for exact PSNE recovery scales as $\\mathcal{O}(\\mathrm{poly}(k) \\log\nn)$. We also validate our theoretical results using synthetic experiments. \n\n"}
{"id": "1607.03204", "contents": "Title: Information Projection and Approximate Inference for Structured Sparse\n  Variables Abstract: Approximate inference via information projection has been recently introduced\nas a general-purpose approach for efficient probabilistic inference given\nsparse variables. This manuscript goes beyond classical sparsity by proposing\nefficient algorithms for approximate inference via information projection that\nare applicable to any structure on the set of variables that admits enumeration\nusing a \\emph{matroid}. We show that the resulting information projection can\nbe reduced to combinatorial submodular optimization subject to matroid\nconstraints. Further, leveraging recent advances in submodular optimization, we\nprovide an efficient greedy algorithm with strong optimization-theoretic\nguarantees. The class of probabilistic models that can be expressed in this way\nis quite broad and, as we show, includes group sparse regression, group sparse\nprincipal components analysis and sparse canonical correlation analysis, among\nothers. Moreover, empirical results on simulated data and high dimensional\nneuroimaging data highlight the superior performance of the information\nprojection approach as compared to established baselines for a range of\nprobabilistic models. \n\n"}
{"id": "1607.05527", "contents": "Title: An Approximation Algorithm for the Art Gallery Problem Abstract: Given a simple polygon $\\mathcal{P}$ on $n$ vertices, two points $x,y$ in\n$\\mathcal{P}$ are said to be visible to each other if the line segment between\n$x$ and $y$ is contained in $\\mathcal{P}$. The Point Guard Art Gallery problem\nasks for a minimum set $S$ such that every point in $\\mathcal{P}$ is visible\nfrom a point in $S$. The set $S$ is referred to as guards. Assuming integer\ncoordinates and a specific general position assumption, we present the first\n$O(\\log \\text{OPT})$-approximation algorithm for the point guard problem for\nsimple polygons. This algorithm combines ideas of a paper of Efrat and\nHar-Peled [Inf. Process. Lett. 2006] and Deshpande et. al. [WADS 2007]. We also\npoint out a mistake in the latter. \n\n"}
{"id": "1607.06017", "contents": "Title: Doubly Accelerated Methods for Faster CCA and Generalized\n  Eigendecomposition Abstract: We study $k$-GenEV, the problem of finding the top $k$ generalized\neigenvectors, and $k$-CCA, the problem of finding the top $k$ vectors in\ncanonical-correlation analysis. We propose algorithms $\\mathtt{LazyEV}$ and\n$\\mathtt{LazyCCA}$ to solve the two problems with running times linearly\ndependent on the input size and on $k$.\n  Furthermore, our algorithms are DOUBLY-ACCELERATED: our running times depend\nonly on the square root of the matrix condition number, and on the square root\nof the eigengap. This is the first such result for both $k$-GenEV or $k$-CCA.\nWe also provide the first gap-free results, which provide running times that\ndepend on $1/\\sqrt{\\varepsilon}$ rather than the eigengap. \n\n"}
{"id": "1607.07676", "contents": "Title: Complexity of Token Swapping and its Variants Abstract: In the Token Swapping problem we are given a graph with a token placed on\neach vertex. Each token has exactly one destination vertex, and we try to move\nall the tokens to their destinations, using the minimum number of swaps, i.e.,\noperations of exchanging the tokens on two adjacent vertices. As the main\nresult of this paper, we show that Token Swapping is $W[1]$-hard parameterized\nby the length $k$ of a shortest sequence of swaps. In fact, we prove that, for\nany computable function $f$, it cannot be solved in time $f(k)n^{o(k / \\log\nk)}$ where $n$ is the number of vertices of the input graph, unless the ETH\nfails. This lower bound almost matches the trivial $n^{O(k)}$-time algorithm.\n  We also consider two generalizations of the Token Swapping, namely Colored\nToken Swapping (where the tokens have different colors and tokens of the same\ncolor are indistinguishable), and Subset Token Swapping (where each token has a\nset of possible destinations). To complement the hardness result, we prove that\neven the most general variant, Subset Token Swapping, is FPT in nowhere-dense\ngraph classes.\n  Finally, we consider the complexities of all three problems in very\nrestricted classes of graphs: graphs of bounded treewidth and diameter, stars,\ncliques, and paths, trying to identify the borderlines between polynomial and\nNP-hard cases. \n\n"}
{"id": "1607.07837", "contents": "Title: First Efficient Convergence for Streaming k-PCA: a Global, Gap-Free, and\n  Near-Optimal Rate Abstract: We study streaming principal component analysis (PCA), that is to find, in\n$O(dk)$ space, the top $k$ eigenvectors of a $d\\times d$ hidden matrix $\\bf\n\\Sigma$ with online vectors drawn from covariance matrix $\\bf \\Sigma$.\n  We provide $\\textit{global}$ convergence for Oja's algorithm which is\npopularly used in practice but lacks theoretical understanding for $k>1$. We\nalso provide a modified variant $\\mathsf{Oja}^{++}$ that runs $\\textit{even\nfaster}$ than Oja's. Our results match the information theoretic lower bound in\nterms of dependency on error, on eigengap, on rank $k$, and on dimension $d$,\nup to poly-log factors. In addition, our convergence rate can be made gap-free,\nthat is proportional to the approximation error and independent of the\neigengap.\n  In contrast, for general rank $k$, before our work (1) it was open to design\nany algorithm with efficient global convergence rate; and (2) it was open to\ndesign any algorithm with (even local) gap-free convergence rate in $O(dk)$\nspace. \n\n"}
{"id": "1607.08456", "contents": "Title: Kernel functions based on triplet comparisons Abstract: Given only information in the form of similarity triplets \"Object A is more\nsimilar to object B than to object C\" about a data set, we propose two ways of\ndefining a kernel function on the data set. While previous approaches construct\na low-dimensional Euclidean embedding of the data set that reflects the given\nsimilarity triplets, we aim at defining kernel functions that correspond to\nhigh-dimensional embeddings. These kernel functions can subsequently be used to\napply any kernel method to the data set. \n\n"}
{"id": "1607.08863", "contents": "Title: Exponentially fast convergence to (strict) equilibrium via hedging Abstract: Motivated by applications to data networks where fast convergence is\nessential, we analyze the problem of learning in generic N-person games that\nadmit a Nash equilibrium in pure strategies. Specifically, we consider a\nscenario where players interact repeatedly and try to learn from past\nexperience by small adjustments based on local - and possibly imperfect -\npayoff information. For concreteness, we focus on the so-called \"hedge\" variant\nof the exponential weights algorithm where players select an action with\nprobability proportional to the exponential of the action's cumulative payoff\nover time. When players have perfect information on their mixed payoffs, the\nalgorithm converges locally to a strict equilibrium and the rate of convergence\nis exponentially fast - of the order of\n$\\mathcal{O}(\\exp(-a\\sum_{j=1}^{t}\\gamma_{j}))$ where $a>0$ is a constant and\n$\\gamma_{j}$ is the algorithm's step-size. In the presence of uncertainty,\nconvergence requires a more conservative step-size policy, but with high\nprobability, the algorithm remains locally convergent and achieves an\nexponential convergence rate. \n\n"}
{"id": "1608.00529", "contents": "Title: Hardness of Permutation Pattern Matching Abstract: Permutation Pattern Matching (or PPM) is a decision problem whose input is a\npair of permutations $\\pi$ and $\\tau$, represented as sequences of integers,\nand the task is to determine whether $\\tau$ contains a subsequence\norder-isomorphic to $\\pi$. Bose, Buss and Lubiw proved that PPM is NP-complete\non general inputs.\n  We show that PPM is NP-complete even when $\\pi$ has no decreasing subsequence\nof length 3 and $\\tau$ has no decreasing subsequence of length 4. This provides\nthe first known example of PPM being hard when one or both of $\\pi$ and\n$\\sigma$ are restricted to a proper hereditary class of permutations.\n  This hardness result is tight in the sense that PPM is known to be polynomial\nwhen both $\\pi$ and $\\tau$ avoid a decreasing subsequence of length 3, as well\nas when $\\pi$ avoids a decreasing subsequence of length 2. The result is also\ntight in another sense: we will show that for any hereditary proper subclass C\nof the class of permutations avoiding a decreasing sequence of length 3, there\nis a polynomial algorithm solving PPM instances where $\\pi$ is from C and\n$\\tau$ is arbitrary.\n  We also obtain analogous hardness and tractability results for the class of\nso-called skew-merged patterns.\n  From these results, we deduce a complexity dichotomy for the PPM problem\nrestricted to $\\pi$ belonging to $Av(\\rho)$, where $Av(\\rho)$ denotes the class\nof permutations avoiding a permutation $\\rho$. Specifically, we show that the\nproblem is polynomial when $\\rho$ is in the set {1, 12, 21, 132, 213, 231,\n312}, and it is NP-complete for any other $\\rho$. \n\n"}
{"id": "1608.02071", "contents": "Title: Transferring Knowledge from Text to Predict Disease Onset Abstract: In many domains such as medicine, training data is in short supply. In such\ncases, external knowledge is often helpful in building predictive models. We\npropose a novel method to incorporate publicly available domain expertise to\nbuild accurate models. Specifically, we use word2vec models trained on a\ndomain-specific corpus to estimate the relevance of each feature's text\ndescription to the prediction problem. We use these relevance estimates to\nrescale the features, causing more important features to experience weaker\nregularization.\n  We apply our method to predict the onset of five chronic diseases in the next\nfive years in two genders and two age groups. Our rescaling approach improves\nthe accuracy of the model, particularly when there are few positive examples.\nFurthermore, our method selects 60% fewer features, easing interpretation by\nphysicians. Our method is applicable to other domains where feature and outcome\ndescriptions are available. \n\n"}
{"id": "1608.02861", "contents": "Title: Classification with the pot-pot plot Abstract: We propose a procedure for supervised classification that is based on\npotential functions. The potential of a class is defined as a kernel density\nestimate multiplied by the class's prior probability. The method transforms the\ndata to a potential-potential (pot-pot) plot, where each data point is mapped\nto a vector of potentials. Separation of the classes, as well as classification\nof new data points, is performed on this plot. For this, either the\n$\\alpha$-procedure ($\\alpha$-P) or $k$-nearest neighbors ($k$-NN) are employed.\nFor data that are generated from continuous distributions, these classifiers\nprove to be strongly Bayes-consistent. The potentials depend on the kernel and\nits bandwidth used in the density estimate. We investigate several variants of\nbandwidth selection, including joint and separate pre-scaling and a bandwidth\nregression approach. The new method is applied to benchmark data from the\nliterature, including simulated data sets as well as 50 sets of real data. It\ncompares favorably to known classification methods such as LDA, QDA, max kernel\ndensity estimates, $k$-NN, and $DD$-plot classification using depth functions. \n\n"}
{"id": "1608.03585", "contents": "Title: Warm Starting Bayesian Optimization Abstract: We develop a framework for warm-starting Bayesian optimization, that reduces\nthe solution time required to solve an optimization problem that is one in a\nsequence of related problems. This is useful when optimizing the output of a\nstochastic simulator that fails to provide derivative information, for which\nBayesian optimization methods are well-suited. Solving sequences of related\noptimization problems arises when making several business decisions using one\noptimization model and input data collected over different time periods or\nmarkets. While many gradient-based methods can be warm started by initiating\noptimization at the solution to the previous problem, this warm start approach\ndoes not apply to Bayesian optimization methods, which carry a full metamodel\nof the objective function from iteration to iteration. Our approach builds a\njoint statistical model of the entire collection of related objective\nfunctions, and uses a value of information calculation to recommend points to\nevaluate. \n\n"}
{"id": "1608.05258", "contents": "Title: Parameter Learning for Log-supermodular Distributions Abstract: We consider log-supermodular models on binary variables, which are\nprobabilistic models with negative log-densities which are submodular. These\nmodels provide probabilistic interpretations of common combinatorial\noptimization tasks such as image segmentation. In this paper, we focus\nprimarily on parameter estimation in the models from known upper-bounds on the\nintractable log-partition function. We show that the bound based on separable\noptimization on the base polytope of the submodular function is always inferior\nto a bound based on \"perturb-and-MAP\" ideas. Then, to learn parameters, given\nthat our approximation of the log-partition function is an expectation (over\nour own randomization), we use a stochastic subgradient technique to maximize a\nlower-bound on the log-likelihood. This can also be extended to conditional\nmaximum likelihood. We illustrate our new results in a set of experiments in\nbinary image denoising, where we highlight the flexibility of a probabilistic\nmodel to learn with missing data. \n\n"}
{"id": "1608.05347", "contents": "Title: Probabilistic Data Analysis with Probabilistic Programming Abstract: Probabilistic techniques are central to data analysis, but different\napproaches can be difficult to apply, combine, and compare. This paper\nintroduces composable generative population models (CGPMs), a computational\nabstraction that extends directed graphical models and can be used to describe\nand compose a broad class of probabilistic data analysis techniques. Examples\ninclude hierarchical Bayesian models, multivariate kernel methods,\ndiscriminative machine learning, clustering algorithms, dimensionality\nreduction, and arbitrary probabilistic programs. We also demonstrate the\nintegration of CGPMs into BayesDB, a probabilistic programming platform that\ncan express data analysis tasks using a modeling language and a structured\nquery language. The practical value is illustrated in two ways. First, CGPMs\nare used in an analysis that identifies satellite data records which probably\nviolate Kepler's Third Law, by composing causal probabilistic programs with\nnon-parametric Bayes in under 50 lines of probabilistic code. Second, for\nseveral representative data analysis tasks, we report on lines of code and\naccuracy measurements of various CGPMs, plus comparisons with standard baseline\nsolutions from Python and MATLAB libraries. \n\n"}
{"id": "1608.05639", "contents": "Title: Operator-Valued Bochner Theorem, Fourier Feature Maps for\n  Operator-Valued Kernels, and Vector-Valued Learning Abstract: This paper presents a framework for computing random operator-valued feature\nmaps for operator-valued positive definite kernels. This is a generalization of\nthe random Fourier features for scalar-valued kernels to the operator-valued\ncase. Our general setting is that of operator-valued kernels corresponding to\nRKHS of functions with values in a Hilbert space. We show that in general, for\na given kernel, there are potentially infinitely many random feature maps,\nwhich can be bounded or unbounded. Most importantly, given a kernel, we present\na general, closed form formula for computing a corresponding probability\nmeasure, which is required for the construction of the Fourier features, and\nwhich, unlike the scalar case, is not uniquely and automatically determined by\nthe kernel. We also show that, under appropriate conditions, random bounded\nfeature maps can always be computed. Furthermore, we show the uniform\nconvergence, under the Hilbert-Schmidt norm, of the resulting approximate\nkernel to the exact kernel on any compact subset of Euclidean space. Our\nconvergence requires differentiable kernels, an improvement over the\ntwice-differentiability requirement in previous work in the scalar setting. We\nthen show how operator-valued feature maps and their approximations can be\nemployed in a general vector-valued learning framework. The mathematical\nformulation is illustrated by numerical examples on matrix-valued kernels. \n\n"}
{"id": "1608.06253", "contents": "Title: Multi-Dueling Bandits and Their Application to Online Ranker Evaluation Abstract: New ranking algorithms are continually being developed and refined,\nnecessitating the development of efficient methods for evaluating these\nrankers. Online ranker evaluation focuses on the challenge of efficiently\ndetermining, from implicit user feedback, which ranker out of a finite set of\nrankers is the best. Online ranker evaluation can be modeled by dueling ban-\ndits, a mathematical model for online learning under limited feedback from\npairwise comparisons. Comparisons of pairs of rankers is performed by\ninterleaving their result sets and examining which documents users click on.\nThe dueling bandits model addresses the key issue of which pair of rankers to\ncompare at each iteration, thereby providing a solution to the\nexploration-exploitation trade-off. Recently, methods for simultaneously\ncomparing more than two rankers have been developed. However, the question of\nwhich rankers to compare at each iteration was left open. We address this\nquestion by proposing a generalization of the dueling bandits model that uses\nsimultaneous comparisons of an unrestricted number of rankers. We evaluate our\nalgorithm on synthetic data and several standard large-scale online ranker\nevaluation datasets. Our experimental results show that the algorithm yields\norders of magnitude improvement in performance compared to stateof- the-art\ndueling bandit algorithms. \n\n"}
{"id": "1608.06984", "contents": "Title: Learning an Optimization Algorithm through Human Design Iterations Abstract: Solving optimal design problems through crowdsourcing faces a dilemma: On one\nhand, human beings have been shown to be more effective than algorithms at\nsearching for good solutions of certain real-world problems with\nhigh-dimensional or discrete solution spaces; on the other hand, the cost of\nsetting up crowdsourcing environments, the uncertainty in the crowd's\ndomain-specific competence, and the lack of commitment of the crowd, all\ncontribute to the lack of real-world application of design crowdsourcing. We\nare thus motivated to investigate a solution-searching mechanism where an\noptimization algorithm is tuned based on human demonstrations on solution\nsearching, so that the search can be continued after human participants abandon\nthe problem. To do so, we model the iterative search process as a Bayesian\nOptimization (BO) algorithm, and propose an inverse BO (IBO) algorithm to find\nthe maximum likelihood estimators of the BO parameters based on human\nsolutions. We show through a vehicle design and control problem that the search\nperformance of BO can be improved by recovering its parameters based on an\neffective human search. Thus, IBO has the potential to improve the success rate\nof design crowdsourcing activities, by requiring only good search strategies\ninstead of good solutions from the crowd. \n\n"}
{"id": "1608.07647", "contents": "Title: Elementary polytopes with high lift-and-project ranks for strong\n  positive semidefinite operators Abstract: We consider operators acting on convex subsets of the unit hypercube. These\noperators are used in constructing convex relaxations of combinatorial\noptimization problems presented as a 0,1 integer programming problem or a 0,1\npolynomial optimization problem. Our focus is mostly on operators that, when\nexpressed as a lift-and-project operator, involve the use of semidefiniteness\nconstraints in the lifted space, including operators due to Lasserre and\nvariants of the Sherali--Adams and Bienstock--Zuckerberg operators. We study\nthe performance of these semidefinite-optimization-based lift-and-project\noperators on some elementary polytopes --- hypercubes that are chipped (at\nleast one vertex of the hypercube removed by intersection with a closed\nhalfspace) or cropped (all $2^n$ vertices of the hypercube removed by\nintersection with $2^n$ closed halfspaces) to varying degrees of severity\n$\\rho$. We prove bounds on $\\rho$ where these operators would perform badly on\nthe aforementioned examples. We also show that the integrality gap of the\nchipped hypercube is invariant under the application of several\nlift-and-project operators of varying strengths. \n\n"}
{"id": "1609.00265", "contents": "Title: Testing $k$-Monotonicity Abstract: A Boolean $k$-monotone function defined over a finite poset domain ${\\cal D}$\nalternates between the values $0$ and $1$ at most $k$ times on any ascending\nchain in ${\\cal D}$. Therefore, $k$-monotone functions are natural\ngeneralizations of the classical monotone functions, which are the $1$-monotone\nfunctions. Motivated by the recent interest in $k$-monotone functions in the\ncontext of circuit complexity and learning theory, and by the central role that\nmonotonicity testing plays in the context of property testing, we initiate a\nsystematic study of $k$-monotone functions, in the property testing model. In\nthis model, the goal is to distinguish functions that are $k$-monotone (or are\nclose to being $k$-monotone) from functions that are far from being\n$k$-monotone. Our results include the following:\n  - We demonstrate a separation between testing $k$-monotonicity and testing\nmonotonicity, on the hypercube domain $\\{0,1\\}^d$, for $k\\geq 3$;\n  - We demonstrate a separation between testing and learning on $\\{0,1\\}^d$,\nfor $k=\\omega(\\log d)$: testing $k$-monotonicity can be performed with\n$2^{O(\\sqrt d \\cdot \\log d\\cdot \\log{1/\\varepsilon})}$ queries, while learning\n$k$-monotone functions requires $2^{\\Omega(k\\cdot \\sqrt\nd\\cdot{1/\\varepsilon})}$ queries (Blais et al. (RANDOM 2015)).\n  - We present a tolerant test for functions $f\\colon[n]^d\\to \\{0,1\\}$ with\ncomplexity independent of $n$, which makes progress on a problem left open by\nBerman et al. (STOC 2014).\n  Our techniques exploit the testing-by-learning paradigm, use novel\napplications of Fourier analysis on the grid $[n]^d$, and draw connections to\ndistribution testing techniques. \n\n"}
{"id": "1609.01508", "contents": "Title: Low-rank Bandits with Latent Mixtures Abstract: We study the task of maximizing rewards from recommending items (actions) to\nusers sequentially interacting with a recommender system. Users are modeled as\nlatent mixtures of C many representative user classes, where each class\nspecifies a mean reward profile across actions. Both the user features (mixture\ndistribution over classes) and the item features (mean reward vector per class)\nare unknown a priori. The user identity is the only contextual information\navailable to the learner while interacting. This induces a low-rank structure\non the matrix of expected rewards r a,b from recommending item a to user b. The\nproblem reduces to the well-known linear bandit when either user or item-side\nfeatures are perfectly known. In the setting where each user, with its\nstochastically sampled taste profile, interacts only for a small number of\nsessions, we develop a bandit algorithm for the two-sided uncertainty. It\ncombines the Robust Tensor Power Method of Anandkumar et al. (2014b) with the\nOFUL linear bandit algorithm of Abbasi-Yadkori et al. (2011). We provide the\nfirst rigorous regret analysis of this combination, showing that its regret\nafter T user interactions is $\\tilde O(C\\sqrt{BT})$, with B the number of\nusers. An ingredient towards this result is a novel robustness property of\nOFUL, of independent interest. \n\n"}
{"id": "1609.03261", "contents": "Title: Less than a Single Pass: Stochastically Controlled Stochastic Gradient\n  Method Abstract: We develop and analyze a procedure for gradient-based optimization that we\nrefer to as stochastically controlled stochastic gradient (SCSG). As a member\nof the SVRG family of algorithms, SCSG makes use of gradient estimates at two\nscales, with the number of updates at the faster scale being governed by a\ngeometric random variable. Unlike most existing algorithms in this family, both\nthe computation cost and the communication cost of SCSG do not necessarily\nscale linearly with the sample size $n$; indeed, these costs are independent of\n$n$ when the target accuracy is low. An experimental evaluation on real\ndatasets confirms the effectiveness of SCSG. \n\n"}
{"id": "1609.04167", "contents": "Title: Proceedings of the third \"international Traveling Workshop on\n  Interactions between Sparse models and Technology\" (iTWIST'16) Abstract: The third edition of the \"international - Traveling Workshop on Interactions\nbetween Sparse models and Technology\" (iTWIST) took place in Aalborg, the 4th\nlargest city in Denmark situated beautifully in the northern part of the\ncountry, from the 24th to 26th of August 2016. The workshop venue was at the\nAalborg University campus. One implicit objective of this biennial workshop is\nto foster collaboration between international scientific teams by disseminating\nideas through both specific oral/poster presentations and free discussions. For\nthis third edition, iTWIST'16 gathered about 50 international participants and\nfeatures 8 invited talks, 12 oral presentations, and 12 posters on the\nfollowing themes, all related to the theory, application and generalization of\nthe \"sparsity paradigm\": Sparsity-driven data sensing and processing (e.g.,\noptics, computer vision, genomics, biomedical, digital communication, channel\nestimation, astronomy); Application of sparse models in non-convex/non-linear\ninverse problems (e.g., phase retrieval, blind deconvolution, self\ncalibration); Approximate probabilistic inference for sparse problems; Sparse\nmachine learning and inference; \"Blind\" inverse problems and dictionary\nlearning; Optimization for sparse modelling; Information theory, geometry and\nrandomness; Sparsity? What's next? (Discrete-valued signals; Union of\nlow-dimensional spaces, Cosparsity, mixed/group norm, model-based,\nlow-complexity models, ...); Matrix/manifold sensing/processing (graph,\nlow-rank approximation, ...); Complexity/accuracy tradeoffs in numerical\nmethods/optimization; Electronic/optical compressive sensors (hardware). \n\n"}
{"id": "1609.06831", "contents": "Title: Hawkes Processes with Stochastic Excitations Abstract: We propose an extension to Hawkes processes by treating the levels of\nself-excitation as a stochastic differential equation. Our new point process\nallows better approximation in application domains where events and intensities\naccelerate each other with correlated levels of contagion. We generalize a\nrecent algorithm for simulating draws from Hawkes processes whose levels of\nexcitation are stochastic processes, and propose a hybrid Markov chain Monte\nCarlo approach for model fitting. Our sampling procedure scales linearly with\nthe number of required events and does not require stationarity of the point\nprocess. A modular inference procedure consisting of a combination between\nGibbs and Metropolis Hastings steps is put forward. We recover expectation\nmaximization as a special case. Our general approach is illustrated for\ncontagion following geometric Brownian motion and exponential Langevin\ndynamics. \n\n"}
{"id": "1609.06942", "contents": "Title: Randomized Independent Component Analysis Abstract: Independent component analysis (ICA) is a method for recovering statistically\nindependent signals from observations of unknown linear combinations of the\nsources. Some of the most accurate ICA decomposition methods require searching\nfor the inverse transformation which minimizes different approximations of the\nMutual Information, a measure of statistical independence of random vectors.\nTwo such approximations are the Kernel Generalized Variance or the Kernel\nCanonical Correlation which has been shown to reach the highest performance of\nICA methods. However, the computational effort necessary just for computing\nthese measures is cubic in the sample size. Hence, optimizing them becomes even\nmore computationally demanding, in terms of both space and time. Here, we\npropose a couple of alternative novel measures based on randomized features of\nthe samples - the Randomized Generalized Variance and the Randomized Canonical\nCorrelation. The computational complexity of calculating the proposed\nalternatives is linear in the sample size and provide a controllable\napproximation of their Kernel-based non-random versions. We also show that\noptimization of the proposed statistical properties yields a comparable\nseparation error at an order of magnitude faster compared to Kernel-based\nmeasures. \n\n"}
{"id": "1609.07088", "contents": "Title: Learning Modular Neural Network Policies for Multi-Task and Multi-Robot\n  Transfer Abstract: Reinforcement learning (RL) can automate a wide variety of robotic skills,\nbut learning each new skill requires considerable real-world data collection\nand manual representation engineering to design policy classes or features.\nUsing deep reinforcement learning to train general purpose neural network\npolicies alleviates some of the burden of manual representation engineering by\nusing expressive policy classes, but exacerbates the challenge of data\ncollection, since such methods tend to be less efficient than RL with\nlow-dimensional, hand-designed representations. Transfer learning can mitigate\nthis problem by enabling us to transfer information from one skill to another\nand even from one robot to another. We show that neural network policies can be\ndecomposed into \"task-specific\" and \"robot-specific\" modules, where the\ntask-specific modules are shared across robots, and the robot-specific modules\nare shared across all tasks on that robot. This allows for sharing task\ninformation, such as perception, between robots and sharing robot information,\nsuch as dynamics and kinematics, between tasks. We exploit this decomposition\nto train mix-and-match modules that can solve new robot-task combinations that\nwere not seen during training. Using a novel neural network architecture, we\ndemonstrate the effectiveness of our transfer method for enabling zero-shot\ngeneralization with a variety of robots and tasks in simulation for both visual\nand non-visual tasks. \n\n"}
{"id": "1609.07574", "contents": "Title: Dynamic Pricing in High-dimensions Abstract: We study the pricing problem faced by a firm that sells a large number of\nproducts, described via a wide range of features, to customers that arrive over\ntime. Customers independently make purchasing decisions according to a general\nchoice model that includes products features and customers' characteristics,\nencoded as $d$-dimensional numerical vectors, as well as the price offered. The\nparameters of the choice model are a priori unknown to the firm, but can be\nlearned as the (binary-valued) sales data accrues over time. The firm's\nobjective is to minimize the regret, i.e., the expected revenue loss against a\nclairvoyant policy that knows the parameters of the choice model in advance,\nand always offers the revenue-maximizing price. This setting is motivated in\npart by the prevalence of online marketplaces that allow for real-time pricing.\nWe assume a structured choice model, parameters of which depend on $s_0$ out of\nthe $d$ product features. We propose a dynamic policy, called Regularized\nMaximum Likelihood Pricing (RMLP) that leverages the (sparsity) structure of\nthe high-dimensional model and obtains a logarithmic regret in $T$. More\nspecifically, the regret of our algorithm is of $O(s_0 \\log d \\cdot \\log T)$.\nFurthermore, we show that no policy can obtain regret better than $O(s_0 (\\log\nd + \\log T))$. \n\n"}
{"id": "1610.00732", "contents": "Title: Sequential Low-Rank Change Detection Abstract: Detecting emergence of a low-rank signal from high-dimensional data is an\nimportant problem arising from many applications such as camera surveillance\nand swarm monitoring using sensors. We consider a procedure based on the\nlargest eigenvalue of the sample covariance matrix over a sliding window to\ndetect the change. To achieve dimensionality reduction, we present a\nsketching-based approach for rank change detection using the low-dimensional\nlinear sketches of the original high-dimensional observations. The premise is\nthat when the sketching matrix is a random Gaussian matrix, and the dimension\nof the sketching vector is sufficiently large, the rank of sample covariance\nmatrix for these sketches equals the rank of the original sample covariance\nmatrix with high probability. Hence, we may be able to detect the low-rank\nchange using sample covariance matrices of the sketches without having to\nrecover the original covariance matrix. We character the performance of the\nlargest eigenvalue statistic in terms of the false-alarm-rate and the expected\ndetection delay, and present an efficient online implementation via subspace\ntracking. \n\n"}
{"id": "1610.01238", "contents": "Title: Find Your Own Way: Weakly-Supervised Segmentation of Path Proposals for\n  Urban Autonomy Abstract: We present a weakly-supervised approach to segmenting proposed drivable paths\nin images with the goal of autonomous driving in complex urban environments.\nUsing recorded routes from a data collection vehicle, our proposed method\ngenerates vast quantities of labelled images containing proposed paths and\nobstacles without requiring manual annotation, which we then use to train a\ndeep semantic segmentation network. With the trained network we can segment\nproposed paths and obstacles at run-time using a vehicle equipped with only a\nmonocular camera without relying on explicit modelling of road or lane\nmarkings. We evaluate our method on the large-scale KITTI and Oxford RobotCar\ndatasets and demonstrate reliable path proposal and obstacle segmentation in a\nwide variety of environments under a range of lighting, weather and traffic\nconditions. We illustrate how the method can generalise to multiple path\nproposals at intersections and outline plans to incorporate the system into a\nframework for autonomous urban driving. \n\n"}
{"id": "1610.01980", "contents": "Title: Polynomial-time Tensor Decompositions with Sum-of-Squares Abstract: We give new algorithms based on the sum-of-squares method for tensor\ndecomposition. Our results improve the best known running times from\nquasi-polynomial to polynomial for several problems, including decomposing\nrandom overcomplete 3-tensors and learning overcomplete dictionaries with\nconstant relative sparsity. We also give the first robust analysis for\ndecomposing overcomplete 4-tensors in the smoothed analysis model. A key\ningredient of our analysis is to establish small spectral gaps in moment\nmatrices derived from solutions to sum-of-squares relaxations. To enable this\nanalysis we augment sum-of-squares relaxations with spectral analogs of maximum\nentropy constraints. \n\n"}
{"id": "1610.02164", "contents": "Title: Deep Reinforcement Learning From Raw Pixels in Doom Abstract: Using current reinforcement learning methods, it has recently become possible\nto learn to play unknown 3D games from raw pixels. In this work, we study the\nchallenges that arise in such complex environments, and summarize current\nmethods to approach these. We choose a task within the Doom game, that has not\nbeen approached yet. The goal for the agent is to fight enemies in a 3D world\nconsisting of five rooms. We train the DQN and LSTM-A3C algorithms on this\ntask. Results show that both algorithms learn sensible policies, but fail to\nachieve high scores given the amount of training. We provide insights into the\nlearned behavior, which can serve as a valuable starting point for further\nresearch in the Doom domain. \n\n"}
{"id": "1610.02828", "contents": "Title: Ranking academic institutions on potential paper acceptance in upcoming\n  conferences Abstract: The crux of the problem in KDD Cup 2016 involves developing data mining\ntechniques to rank research institutions based on publications. Rank importance\nof research institutions are derived from predictions on the number of full\nresearch papers that would potentially get accepted in upcoming top-tier\nconferences, utilizing public information on the web. This paper describes our\nsolution to KDD Cup 2016. We used a two step approach in which we first\nidentify full research papers corresponding to each conference of interest and\nthen train two variants of exponential smoothing models to make predictions.\nOur solution achieves an overall score of 0.7508, while the winning submission\nscored 0.7656 in the overall results. \n\n"}
{"id": "1610.02906", "contents": "Title: A General Framework for Content-enhanced Network Representation Learning Abstract: This paper investigates the problem of network embedding, which aims at\nlearning low-dimensional vector representation of nodes in networks. Most\nexisting network embedding methods rely solely on the network structure, i.e.,\nthe linkage relationships between nodes, but ignore the rich content\ninformation associated with it, which is common in real world networks and\nbeneficial to describing the characteristics of a node. In this paper, we\npropose content-enhanced network embedding (CENE), which is capable of jointly\nleveraging the network structure and the content information. Our approach\nintegrates text modeling and structure modeling in a general framework by\ntreating the content information as a special kind of node. Experiments on\nseveral real world net- works with application to node classification show that\nour models outperform all existing network embedding methods, demonstrating the\nmerits of content information and joint learning. \n\n"}
{"id": "1610.03317", "contents": "Title: A Greedy Approach for Budgeted Maximum Inner Product Search Abstract: Maximum Inner Product Search (MIPS) is an important task in many machine\nlearning applications such as the prediction phase of a low-rank matrix\nfactorization model for a recommender system. There have been some works on how\nto perform MIPS in sub-linear time recently. However, most of them do not have\nthe flexibility to control the trade-off between search efficient and search\nquality. In this paper, we study the MIPS problem with a computational budget.\nBy carefully studying the problem structure of MIPS, we develop a novel\nGreedy-MIPS algorithm, which can handle budgeted MIPS by design. While simple\nand intuitive, Greedy-MIPS yields surprisingly superior performance compared to\nstate-of-the-art approaches. As a specific example, on a candidate set\ncontaining half a million vectors of dimension 200, Greedy-MIPS runs 200x\nfaster than the naive approach while yielding search results with the top-5\nprecision greater than 75\\%. \n\n"}
{"id": "1610.03483", "contents": "Title: Learning in Implicit Generative Models Abstract: Generative adversarial networks (GANs) provide an algorithmic framework for\nconstructing generative models with several appealing properties: they do not\nrequire a likelihood function to be specified, only a generating procedure;\nthey provide samples that are sharp and compelling; and they allow us to\nharness our knowledge of building highly accurate neural network classifiers.\nHere, we develop our understanding of GANs with the aim of forming a rich view\nof this growing area of machine learning---to build connections to the diverse\nset of statistical thinking on this topic, of which much can be gained by a\nmutual exchange of ideas. We frame GANs within the wider landscape of\nalgorithms for learning in implicit generative models--models that only specify\na stochastic procedure with which to generate data--and relate these ideas to\nmodelling problems in related fields, such as econometrics and approximate\nBayesian computation. We develop likelihood-free inference methods and\nhighlight hypothesis testing as a principle for learning in implicit generative\nmodels, using which we are able to derive the objective function used by GANs,\nand many other related objectives. The testing viewpoint directs our focus to\nthe general problem of density ratio estimation. There are four approaches for\ndensity ratio estimation, one of which is a solution using classifiers to\ndistinguish real from generated data. Other approaches such as divergence\nminimisation and moment matching have also been explored in the GAN literature,\nand we synthesise these views to form an understanding in terms of the\nrelationships between them and the wider literature, highlighting avenues for\nfuture exploration and cross-pollination. \n\n"}
{"id": "1610.05120", "contents": "Title: Lazifying Conditional Gradient Algorithms Abstract: Conditional gradient algorithms (also often called Frank-Wolfe algorithms)\nare popular due to their simplicity of only requiring a linear optimization\noracle and more recently they also gained significant traction for online\nlearning. While simple in principle, in many cases the actual implementation of\nthe linear optimization oracle is costly. We show a general method to lazify\nvarious conditional gradient algorithms, which in actual computations leads to\nseveral orders of magnitude of speedup in wall-clock time. This is achieved by\nusing a faster separation oracle instead of a linear optimization oracle,\nrelying only on few linear optimization oracle calls. \n\n"}
{"id": "1610.05710", "contents": "Title: Feasibility Based Large Margin Nearest Neighbor Metric Learning Abstract: Large margin nearest neighbor (LMNN) is a metric learner which optimizes the\nperformance of the popular $k$NN classifier. However, its resulting metric\nrelies on pre-selected target neighbors. In this paper, we address the\nfeasibility of LMNN's optimization constraints regarding these target points,\nand introduce a mathematical measure to evaluate the size of the feasible\nregion of the optimization problem. We enhance the optimization framework of\nLMNN by a weighting scheme which prefers data triplets which yield a larger\nfeasible region. This increases the chances to obtain a good metric as the\nsolution of LMNN's problem. We evaluate the performance of the resulting\nfeasibility-based LMNN algorithm using synthetic and real datasets. The\nempirical results show an improved accuracy for different types of datasets in\ncomparison to regular LMNN. \n\n"}
{"id": "1610.05773", "contents": "Title: RedQueen: An Online Algorithm for Smart Broadcasting in Social Networks Abstract: Users in social networks whose posts stay at the top of their followers'{}\nfeeds the longest time are more likely to be noticed. Can we design an online\nalgorithm to help them decide when to post to stay at the top? In this paper,\nwe address this question as a novel optimal control problem for jump stochastic\ndifferential equations. For a wide variety of feed dynamics, we show that the\noptimal broadcasting intensity for any user is surprisingly simple -- it is\ngiven by the position of her most recent post on each of her follower's feeds.\nAs a consequence, we are able to develop a simple and highly efficient online\nalgorithm, RedQueen, to sample the optimal times for the user to post.\nExperiments on both synthetic and real data gathered from Twitter show that our\nalgorithm is able to consistently make a user's posts more visible over time,\nis robust to volume changes on her followers' feeds, and significantly\noutperforms the state of the art. \n\n"}
{"id": "1610.06447", "contents": "Title: Regularized Optimal Transport and the Rot Mover's Distance Abstract: This paper presents a unified framework for smooth convex regularization of\ndiscrete optimal transport problems. In this context, the regularized optimal\ntransport turns out to be equivalent to a matrix nearness problem with respect\nto Bregman divergences. Our framework thus naturally generalizes a previously\nproposed regularization based on the Boltzmann-Shannon entropy related to the\nKullback-Leibler divergence, and solved with the Sinkhorn-Knopp algorithm. We\ncall the regularized optimal transport distance the rot mover's distance in\nreference to the classical earth mover's distance. We develop two generic\nschemes that we respectively call the alternate scaling algorithm and the\nnon-negative alternate scaling algorithm, to compute efficiently the\nregularized optimal plans depending on whether the domain of the regularizer\nlies within the non-negative orthant or not. These schemes are based on\nDykstra's algorithm with alternate Bregman projections, and further exploit the\nNewton-Raphson method when applied to separable divergences. We enhance the\nseparable case with a sparse extension to deal with high data dimensions. We\nalso instantiate our proposed framework and discuss the inherent specificities\nfor well-known regularizers and statistical divergences in the machine learning\nand information geometry communities. Finally, we demonstrate the merits of our\nmethods with experiments using synthetic data to illustrate the effect of\ndifferent regularizers and penalties on the solutions, as well as real-world\ndata for a pattern recognition application to audio scene classification. \n\n"}
{"id": "1610.06539", "contents": "Title: Linear separation of connected dominating sets in graphs Abstract: A connected dominating set in a graph is a dominating set of vertices that\ninduces a connected subgraph. Following analogous studies in the literature\nrelated to independent sets, dominating sets, and total dominating sets, we\nstudy in this paper the class of graphs in which the connected dominating sets\ncan be separated from the other vertex subsets by a linear weight function.\nMore precisely, we say that a graph is connected-domishold if it admits\nnon-negative real weights associated to its vertices such that a set of\nvertices is a connected dominating set if and only if the sum of the\ncorresponding weights exceeds a certain threshold. We characterize the graphs\nin this non-hereditary class in terms of a property of the set of minimal\ncutsets of the graph. We give several characterizations for the hereditary\ncase, that is, when each connected induced subgraph is required to be\nconnected-domishold. The characterization by forbidden induced subgraphs\nimplies that the class properly generalizes two well known classes of chordal\ngraphs, the block graphs and the trivially perfect graphs. Finally, we study\ncertain algorithmic aspects of connected-domishold graphs. Building on\nconnections with minimal cutsets and properties of the derived hypergraphs and\nBoolean functions, we show that our approach leads to new polynomially solvable\ncases of the weighted connected dominating set problem. \n\n"}
{"id": "1610.06656", "contents": "Title: Single Pass PCA of Matrix Products Abstract: In this paper we present a new algorithm for computing a low rank\napproximation of the product $A^TB$ by taking only a single pass of the two\nmatrices $A$ and $B$. The straightforward way to do this is to (a) first sketch\n$A$ and $B$ individually, and then (b) find the top components using PCA on the\nsketch. Our algorithm in contrast retains additional summary information about\n$A,B$ (e.g. row and column norms etc.) and uses this additional information to\nobtain an improved approximation from the sketches. Our main analytical result\nestablishes a comparable spectral norm guarantee to existing two-pass methods;\nin addition we also provide results from an Apache Spark implementation that\nshows better computational and statistical performance on real-world and\nsynthetic evaluation datasets. \n\n"}
{"id": "1610.06664", "contents": "Title: Stochastic Gradient MCMC with Stale Gradients Abstract: Stochastic gradient MCMC (SG-MCMC) has played an important role in\nlarge-scale Bayesian learning, with well-developed theoretical convergence\nproperties. In such applications of SG-MCMC, it is becoming increasingly\npopular to employ distributed systems, where stochastic gradients are computed\nbased on some outdated parameters, yielding what are termed stale gradients.\nWhile stale gradients could be directly used in SG-MCMC, their impact on\nconvergence properties has not been well studied. In this paper we develop\ntheory to show that while the bias and MSE of an SG-MCMC algorithm depend on\nthe staleness of stochastic gradients, its estimation variance (relative to the\nexpected estimate, based on a prescribed number of samples) is independent of\nit. In a simple Bayesian distributed system with SG-MCMC, where stale gradients\nare computed asynchronously by a set of workers, our theory indicates a linear\nspeedup on the decrease of estimation variance w.r.t. the number of workers.\nExperiments on synthetic data and deep neural networks validate our theory,\ndemonstrating the effectiveness and scalability of SG-MCMC with stale\ngradients. \n\n"}
{"id": "1610.07031", "contents": "Title: Exercise Motion Classification from Large-Scale Wearable Sensor Data\n  Using Convolutional Neural Networks Abstract: The ability to accurately identify human activities is essential for\ndeveloping automatic rehabilitation and sports training systems. In this paper,\nlarge-scale exercise motion data obtained from a forearm-worn wearable sensor\nare classified with a convolutional neural network (CNN). Time-series data\nconsisting of accelerometer and orientation measurements are formatted as\nimages, allowing the CNN to automatically extract discriminative features. A\ncomparative study on the effects of image formatting and different CNN\narchitectures is also presented. The best performing configuration classifies\n50 gym exercises with 92.1% accuracy. \n\n"}
{"id": "1610.07116", "contents": "Title: Online Classification with Complex Metrics Abstract: We present a framework and analysis of consistent binary classification for\ncomplex and non-decomposable performance metrics such as the F-measure and the\nJaccard measure. The proposed framework is general, as it applies to both batch\nand online learning, and to both linear and non-linear models. Our work follows\nrecent results showing that the Bayes optimal classifier for many complex\nmetrics is given by a thresholding of the conditional probability of the\npositive class. This manuscript extends this thresholding characterization --\nshowing that the utility is strictly locally quasi-concave with respect to the\nthreshold for a wide range of models and performance metrics. This, in turn,\nmotivates simple normalized gradient ascent updates for threshold estimation.\nWe present a finite-sample regret analysis for the resulting procedure. In\nparticular, the risk for the batch case converges to the Bayes risk at the same\nrate as that of the underlying conditional probability estimation, and the risk\nof proposed online algorithm converges at a rate that depends on the\nconditional probability estimation risk. For instance, in the special case\nwhere the conditional probability model is logistic regression, our procedure\nachieves $O(\\frac{1}{\\sqrt{n}})$ sample complexity, both for batch and online\ntraining. Empirical evaluation shows that the proposed algorithms out-perform\nalternatives in practice, with comparable or better prediction performance and\nreduced run time for various metrics and datasets. \n\n"}
{"id": "1610.08611", "contents": "Title: Causal Network Learning from Multiple Interventions of Unknown\n  Manipulated Targets Abstract: In this paper, we discuss structure learning of causal networks from multiple\ndata sets obtained by external intervention experiments where we do not know\nwhat variables are manipulated. For example, the conditions in these\nexperiments are changed by changing temperature or using drugs, but we do not\nknow what target variables are manipulated by the external interventions. From\nsuch data sets, the structure learning becomes more difficult. For this case,\nwe first discuss the identifiability of causal structures. Next we present a\ngraph-merging method for learning causal networks for the case that the sample\nsizes are large for these interventions. Then for the case that the sample\nsizes of these interventions are relatively small, we propose a data-pooling\nmethod for learning causal networks in which we pool all data sets of these\ninterventions together for the learning. Further we propose a re-sampling\napproach to evaluate the edges of the causal network learned by the\ndata-pooling method. Finally we illustrate the proposed learning methods by\nsimulations. \n\n"}
{"id": "1610.09127", "contents": "Title: Adaptive regularization for Lasso models in the context of\n  non-stationary data streams Abstract: Large scale, streaming datasets are ubiquitous in modern machine learning.\nStreaming algorithms must be scalable, amenable to incremental training and\nrobust to the presence of non-stationarity. In this work consider the problem\nof learning $\\ell_1$ regularized linear models in the context of streaming\ndata. In particular, the focus of this work revolves around how to select the\nregularization parameter when data arrives sequentially and the underlying\ndistribution is non-stationary (implying the choice of optimal regularization\nparameter is itself time-varying). We propose a framework through which to\ninfer an adaptive regularization parameter. Our approach employs an $\\ell_1$\npenalty constraint where the corresponding sparsity parameter is iteratively\nupdated via stochastic gradient descent. This serves to reformulate the choice\nof regularization parameter in a principled framework for online learning. The\nproposed method is derived for linear regression and subsequently extended to\ngeneralized linear models. We validate our approach using simulated and real\ndatasets and present an application to a neuroimaging dataset. \n\n"}
{"id": "1610.09730", "contents": "Title: Active Learning from Imperfect Labelers Abstract: We study active learning where the labeler can not only return incorrect\nlabels but also abstain from labeling. We consider different noise and\nabstention conditions of the labeler. We propose an algorithm which utilizes\nabstention responses, and analyze its statistical consistency and query\ncomplexity under fairly natural assumptions on the noise and abstention rate of\nthe labeler. This algorithm is adaptive in a sense that it can automatically\nrequest less queries with a more informed or less noisy labeler. We couple our\nalgorithm with lower bounds to show that under some technical conditions, it\nachieves nearly optimal query complexity. \n\n"}
{"id": "1610.09900", "contents": "Title: Inference Compilation and Universal Probabilistic Programming Abstract: We introduce a method for using deep neural networks to amortize the cost of\ninference in models from the family induced by universal probabilistic\nprogramming languages, establishing a framework that combines the strengths of\nprobabilistic programming and deep learning methods. We call what we do\n\"compilation of inference\" because our method transforms a denotational\nspecification of an inference problem in the form of a probabilistic program\nwritten in a universal programming language into a trained neural network\ndenoted in a neural network specification language. When at test time this\nneural network is fed observational data and executed, it performs approximate\ninference in the original model specified by the probabilistic program. Our\ntraining objective and learning procedure are designed to allow the trained\nneural network to be used as a proposal distribution in a sequential importance\nsampling inference engine. We illustrate our method on mixture models and\nCaptcha solving and show significant speedups in the efficiency of inference. \n\n"}
{"id": "1611.00035", "contents": "Title: Full-Capacity Unitary Recurrent Neural Networks Abstract: Recurrent neural networks are powerful models for processing sequential data,\nbut they are generally plagued by vanishing and exploding gradient problems.\nUnitary recurrent neural networks (uRNNs), which use unitary recurrence\nmatrices, have recently been proposed as a means to avoid these issues.\nHowever, in previous experiments, the recurrence matrices were restricted to be\na product of parameterized unitary matrices, and an open question remains: when\ndoes such a parameterization fail to represent all unitary matrices, and how\ndoes this restricted representational capacity limit what can be learned? To\naddress this question, we propose full-capacity uRNNs that optimize their\nrecurrence matrix over all unitary matrices, leading to significantly improved\nperformance over uRNNs that use a restricted-capacity recurrence matrix. Our\ncontribution consists of two main components. First, we provide a theoretical\nargument to determine if a unitary parameterization has restricted capacity.\nUsing this argument, we show that a recently proposed unitary parameterization\nhas restricted capacity for hidden state dimension greater than 7. Second, we\nshow how a complete, full-capacity unitary recurrence matrix can be optimized\nover the differentiable manifold of unitary matrices. The resulting\nmultiplicative gradient step is very simple and does not require gradient\nclipping or learning rate adaptation. We confirm the utility of our claims by\nempirically evaluating our new full-capacity uRNNs on both synthetic and\nnatural data, achieving superior performance compared to both LSTMs and the\noriginal restricted-capacity uRNNs. \n\n"}
{"id": "1611.00065", "contents": "Title: Bayesian Adaptive Data Analysis Guarantees from Subgaussianity Abstract: The new field of adaptive data analysis seeks to provide algorithms and\nprovable guarantees for models of machine learning that allow researchers to\nreuse their data, which normally falls outside of the usual statistical\nparadigm of static data analysis. In 2014, Dwork, Feldman, Hardt, Pitassi,\nReingold and Roth introduced one potential model and proposed several solutions\nbased on differential privacy. In previous work in 2016, we described a problem\nwith this model and instead proposed a Bayesian variant, but also found that\nthe analogous Bayesian methods cannot achieve the same statistical guarantees\nas in the static case.\n  In this paper, we prove the first positive results for the Bayesian model,\nshowing that with a Dirichlet prior, the posterior mean algorithm indeed\nmatches the statistical guarantees of the static case. The main ingredient is a\nnew theorem showing that the $\\mathrm{Beta}(\\alpha,\\beta)$ distribution is\nsubgaussian with variance proxy $O(1/(\\alpha+\\beta+1))$, a concentration result\nalso of independent interest. We provide two proofs of this result: a\nprobabilistic proof utilizing a simple condition for the raw moments of a\npositive random variable and a learning-theoretic proof based on considering\nthe beta distribution as a posterior, both of which have implications to other\nrelated problems. \n\n"}
{"id": "1611.00129", "contents": "Title: Submodular Maximization over Sliding Windows Abstract: In this paper we study the extraction of representative elements in the data\nstream model in the form of submodular maximization. Different from the\nprevious work on streaming submodular maximization, we are interested only in\nthe recent data, and study the maximization problem over sliding windows. We\nprovide a general reduction from the sliding window model to the standard\nstreaming model, and thus our approach works for general constraints as long as\nthere is a corresponding streaming algorithm in the standard streaming model.\nAs a consequence, we obtain the first algorithms in the sliding window model\nfor maximizing a monotone/non-monotone submodular function under cardinality\nand matroid constraints. We also propose several heuristics and show their\nefficiency in real-world datasets. \n\n"}
{"id": "1611.01186", "contents": "Title: Demystifying ResNet Abstract: The Residual Network (ResNet), proposed in He et al. (2015), utilized\nshortcut connections to significantly reduce the difficulty of training, which\nresulted in great performance boosts in terms of both training and\ngeneralization error.\n  It was empirically observed in He et al. (2015) that stacking more layers of\nresidual blocks with shortcut 2 results in smaller training error, while it is\nnot true for shortcut of length 1 or 3. We provide a theoretical explanation\nfor the uniqueness of shortcut 2.\n  We show that with or without nonlinearities, by adding shortcuts that have\ndepth two, the condition number of the Hessian of the loss function at the zero\ninitial point is depth-invariant, which makes training very deep models no more\ndifficult than shallow ones. Shortcuts of higher depth result in an extremely\nflat (high-order) stationary point initially, from which the optimization\nalgorithm is hard to escape. The shortcut 1, however, is essentially equivalent\nto no shortcuts, which has a condition number exploding to infinity as the\nnumber of layers grows. We further argue that as the number of layers tends to\ninfinity, it suffices to only look at the loss function at the zero initial\npoint.\n  Extensive experiments are provided accompanying our theoretical results. We\nshow that initializing the network to small weights with shortcut 2 achieves\nsignificantly better results than random Gaussian (Xavier) initialization,\northogonal initialization, and shortcuts of deeper depth, from various\nperspectives ranging from final loss, learning dynamics and stability, to the\nbehavior of the Hessian along the learning process. \n\n"}
{"id": "1611.01190", "contents": "Title: Conspiracies between Learning Algorithms, Circuit Lower Bounds and\n  Pseudorandomness Abstract: We prove several results giving new and stronger connections between\nlearning, circuit lower bounds and pseudorandomness. Among other results, we\nshow a generic learning speedup lemma, equivalences between various learning\nmodels in the exponential time and subexponential time regimes, a dichotomy\nbetween learning and pseudorandomness, consequences of non-trivial learning for\ncircuit lower bounds, Karp-Lipton theorems for probabilistic exponential time,\nand NC$^1$-hardness for the Minimum Circuit Size Problem. \n\n"}
{"id": "1611.01353", "contents": "Title: Information Dropout: Learning Optimal Representations Through Noisy\n  Computation Abstract: The cross-entropy loss commonly used in deep learning is closely related to\nthe defining properties of optimal representations, but does not enforce some\nof the key properties. We show that this can be solved by adding a\nregularization term, which is in turn related to injecting multiplicative noise\nin the activations of a Deep Neural Network, a special case of which is the\ncommon practice of dropout. We show that our regularized loss function can be\nefficiently minimized using Information Dropout, a generalization of dropout\nrooted in information theoretic principles that automatically adapts to the\ndata and can better exploit architectures of limited capacity. When the task is\nthe reconstruction of the input, we show that our loss function yields a\nVariational Autoencoder as a special case, thus providing a link between\nrepresentation learning, information theory and variational inference. Finally,\nwe prove that we can promote the creation of disentangled representations\nsimply by enforcing a factorized prior, a fact that has been observed\nempirically in recent work. Our experiments validate the theoretical intuitions\nbehind our method, and we find that information dropout achieves a comparable\nor better generalization performance than binary dropout, especially on smaller\nmodels, since it can automatically adapt the noise to the structure of the\nnetwork, as well as to the test sample. \n\n"}
{"id": "1611.01462", "contents": "Title: Tying Word Vectors and Word Classifiers: A Loss Framework for Language\n  Modeling Abstract: Recurrent neural networks have been very successful at predicting sequences\nof words in tasks such as language modeling. However, all such models are based\non the conventional classification framework, where the model is trained\nagainst one-hot targets, and each word is represented both as an input and as\nan output in isolation. This causes inefficiencies in learning both in terms of\nutilizing all of the information and in terms of the number of parameters\nneeded to train. We introduce a novel theoretical framework that facilitates\nbetter learning in language modeling, and show that our framework leads to\ntying together the input embedding and the output projection matrices, greatly\nreducing the number of trainable variables. Our framework leads to state of the\nart performance on the Penn Treebank with a variety of network models. \n\n"}
{"id": "1611.01491", "contents": "Title: Understanding Deep Neural Networks with Rectified Linear Units Abstract: In this paper we investigate the family of functions representable by deep\nneural networks (DNN) with rectified linear units (ReLU). We give an algorithm\nto train a ReLU DNN with one hidden layer to *global optimality* with runtime\npolynomial in the data size albeit exponential in the input dimension. Further,\nwe improve on the known lower bounds on size (from exponential to super\nexponential) for approximating a ReLU deep net function by a shallower ReLU\nnet. Our gap theorems hold for smoothly parametrized families of \"hard\"\nfunctions, contrary to countable, discrete families known in the literature. An\nexample consequence of our gap theorems is the following: for every natural\nnumber $k$ there exists a function representable by a ReLU DNN with $k^2$\nhidden layers and total size $k^3$, such that any ReLU DNN with at most $k$\nhidden layers will require at least $\\frac{1}{2}k^{k+1}-1$ total nodes.\nFinally, for the family of $\\mathbb{R}^n\\to \\mathbb{R}$ DNNs with ReLU\nactivations, we show a new lowerbound on the number of affine pieces, which is\nlarger than previous constructions in certain regimes of the network\narchitecture and most distinctively our lowerbound is demonstrated by an\nexplicit construction of a *smoothly parameterized* family of functions\nattaining this scaling. Our construction utilizes the theory of zonotopes from\npolyhedral theory. \n\n"}
{"id": "1611.01688", "contents": "Title: Oracle-Efficient Online Learning and Auction Design Abstract: We consider the design of computationally efficient online learning\nalgorithms in an adversarial setting in which the learner has access to an\noffline optimization oracle. We present an algorithm called Generalized\nFollow-the-Perturbed-Leader and provide conditions under which it is\noracle-efficient while achieving vanishing regret. Our results make significant\nprogress on an open problem raised by Hazan and Koren, who showed that\noracle-efficient algorithms do not exist in general and asked whether one can\nidentify properties under which oracle-efficient online learning may be\npossible.\n  Our auction-design framework considers an auctioneer learning an optimal\nauction for a sequence of adversarially selected valuations with the goal of\nachieving revenue that is almost as good as the optimal auction in hindsight,\namong a class of auctions. We give oracle-efficient learning results for: (1)\nVCG auctions with bidder-specific reserves in single-parameter settings, (2)\nenvy-free item pricing in multi-item auctions, and (3) s-level auctions of\nMorgenstern and Roughgarden for single-item settings. The last result leads to\nan approximation of the overall optimal Myerson auction when bidders'\nvaluations are drawn according to a fast-mixing Markov process, extending prior\nwork that only gave such guarantees for the i.i.d. setting.\n  Finally, we derive various extensions, including: (1) oracle-efficient\nalgorithms for the contextual learning setting in which the learner has access\nto side information (such as bidder demographics), (2) learning with\napproximate oracles such as those based on Maximal-in-Range algorithms, and (3)\nno-regret bidding in simultaneous auctions, resolving an open problem of\nDaskalakis and Syrgkanis. \n\n"}
{"id": "1611.03220", "contents": "Title: Faster Kernel Ridge Regression Using Sketching and Preconditioning Abstract: Kernel Ridge Regression (KRR) is a simple yet powerful technique for\nnon-parametric regression whose computation amounts to solving a linear system.\nThis system is usually dense and highly ill-conditioned. In addition, the\ndimensions of the matrix are the same as the number of data points, so direct\nmethods are unrealistic for large-scale datasets. In this paper, we propose a\npreconditioning technique for accelerating the solution of the aforementioned\nlinear system. The preconditioner is based on random feature maps, such as\nrandom Fourier features, which have recently emerged as a powerful technique\nfor speeding up and scaling the training of kernel-based methods, such as\nkernel ridge regression, by resorting to approximations. However, random\nfeature maps only provide crude approximations to the kernel function, so\ndelivering state-of-the-art results by directly solving the approximated system\nrequires the number of random features to be very large. We show that random\nfeature maps can be much more effective in forming preconditioners, since under\ncertain conditions a not-too-large number of random features is sufficient to\nyield an effective preconditioner. We empirically evaluate our method and show\nit is highly effective for datasets of up to one million training examples. \n\n"}
{"id": "1611.04149", "contents": "Title: Accelerated Variance Reduced Block Coordinate Descent Abstract: Algorithms with fast convergence, small number of data access, and low\nper-iteration complexity are particularly favorable in the big data era, due to\nthe demand for obtaining \\emph{highly accurate solutions} to problems with\n\\emph{a large number of samples} in \\emph{ultra-high} dimensional space.\nExisting algorithms lack at least one of these qualities, and thus are\ninefficient in handling such big data challenge. In this paper, we propose a\nmethod enjoying all these merits with an accelerated convergence rate\n$O(\\frac{1}{k^2})$. Empirical studies on large scale datasets with more than\none million features are conducted to show the effectiveness of our methods in\npractice. \n\n"}
{"id": "1611.04361", "contents": "Title: Attending to Characters in Neural Sequence Labeling Models Abstract: Sequence labeling architectures use word embeddings for capturing similarity,\nbut suffer when handling previously unseen or rare words. We investigate\ncharacter-level extensions to such models and propose a novel architecture for\ncombining alternative word representations. By using an attention mechanism,\nthe model is able to dynamically decide how much information to use from a\nword- or character-level component. We evaluated different architectures on a\nrange of sequence labeling datasets, and character-level extensions were found\nto improve performance on every benchmark. In addition, the proposed\nattention-based architecture delivered the best results even with a smaller\nnumber of trainable parameters. \n\n"}
{"id": "1611.05209", "contents": "Title: Deep Variational Inference Without Pixel-Wise Reconstruction Abstract: Variational autoencoders (VAEs), that are built upon deep neural networks\nhave emerged as popular generative models in computer vision. Most of the work\ntowards improving variational autoencoders has focused mainly on making the\napproximations to the posterior flexible and accurate, leading to tremendous\nprogress. However, there have been limited efforts to replace pixel-wise\nreconstruction, which have known shortcomings. In this work, we use real-valued\nnon-volume preserving transformations (real NVP) to exactly compute the\nconditional likelihood of the data given the latent distribution. We show that\na simple VAE with this form of reconstruction is competitive with complicated\nVAE structures, on image modeling tasks. As part of our model, we develop\npowerful conditional coupling layers that enable real NVP to learn with fewer\nintermediate layers. \n\n"}
{"id": "1611.06189", "contents": "Title: Query Complexity of Tournament Solutions Abstract: A directed graph where there is exactly one edge between every pair of\nvertices is called a {\\em tournament}. Finding the \"best\" set of vertices of a\ntournament is a well studied problem in social choice theory. A {\\em tournament\nsolution} takes a tournament as input and outputs a subset of vertices of the\ninput tournament. However, in many applications, for example, choosing the best\nset of drugs from a given set of drugs, the edges of the tournament are given\nonly implicitly and knowing the orientation of an edge is costly. In such\nscenarios, we would like to know the best set of vertices (according to some\ntournament solution) by \"querying\" as few edges as possible. We, in this paper,\nprecisely study this problem for commonly used tournament solutions: given an\noracle access to the edges of a tournament T, find $f(T)$ by querying as few\nedges as possible, for a tournament solution f. We first show that the set of\nCondorcet non-losers in a tournament can be found by querying $2n-\\lfloor \\log\nn \\rfloor -2$ edges only and this is tight in the sense that every algorithm\nfor finding the set of Condorcet non-losers needs to query at least $2n-\\lfloor\n\\log n \\rfloor -2$ edges in the worst case, where $n$ is the number of vertices\nin the input tournament. We then move on to study other popular tournament\nsolutions and show that any algorithm for finding the Copeland set, the Slater\nset, the Markov set, the bipartisan set, the uncovered set, the Banks set, and\nthe top cycle must query $\\Omega(n^2)$ edges in the worst case. On the positive\nside, we are able to circumvent our strong query complexity lower bound results\nby proving that, if the size of the top cycle of the input tournament is at\nmost $k$, then we can find all the tournament solutions mentioned above by\nquerying $O(nk + \\frac{n\\log n}{\\log(1-\\frac{1}{k})})$ edges only. \n\n"}
{"id": "1611.06221", "contents": "Title: Foundations of Structural Causal Models with Cycles and Latent Variables Abstract: Structural causal models (SCMs), also known as (nonparametric) structural\nequation models (SEMs), are widely used for causal modeling purposes. In\nparticular, acyclic SCMs, also known as recursive SEMs, form a well-studied\nsubclass of SCMs that generalize causal Bayesian networks to allow for latent\nconfounders. In this paper, we investigate SCMs in a more general setting,\nallowing for the presence of both latent confounders and cycles. We show that\nin the presence of cycles, many of the convenient properties of acyclic SCMs do\nnot hold in general: they do not always have a solution; they do not always\ninduce unique observational, interventional and counterfactual distributions; a\nmarginalization does not always exist, and if it exists the marginal model does\nnot always respect the latent projection; they do not always satisfy a Markov\nproperty; and their graphs are not always consistent with their causal\nsemantics. We prove that for SCMs in general each of these properties does hold\nunder certain solvability conditions. Our work generalizes results for SCMs\nwith cycles that were only known for certain special cases so far. We introduce\nthe class of simple SCMs that extends the class of acyclic SCMs to the cyclic\nsetting, while preserving many of the convenient properties of acyclic SCMs.\nWith this paper we aim to provide the foundations for a general theory of\nstatistical causal modeling with SCMs. \n\n"}
{"id": "1611.06815", "contents": "Title: Uniquely restricted matchings and edge colorings Abstract: A matching in a graph is uniquely restricted if no other matching covers\nexactly the same set of vertices. This notion was defined by Golumbic, Hirst,\nand Lewenstein and studied in a number of articles. Our contribution is\ntwofold. We provide approximation algorithms for computing a uniquely\nrestricted matching of maximum size in some bipartite graphs. In particular, we\nachieve a ratio of $9/5$ for subcubic bipartite graphs, improving over a\n$2$-approximation algorithm proposed by Mishra. Furthermore, we study the\nuniquely restricted chromatic index of a graph, defined as the minimum number\nof uniquely restricted matchings into which its edge set can be partitioned. We\nprovide tight upper bounds in terms of the maximum degree and characterize all\nextremal graphs. Our constructive proofs yield efficient algorithms to\ndetermine the corresponding edge colorings. \n\n"}
{"id": "1611.07056", "contents": "Title: The Recycling Gibbs Sampler for Efficient Learning Abstract: Monte Carlo methods are essential tools for Bayesian inference. Gibbs\nsampling is a well-known Markov chain Monte Carlo (MCMC) algorithm, extensively\nused in signal processing, machine learning, and statistics, employed to draw\nsamples from complicated high-dimensional posterior distributions. The key\npoint for the successful application of the Gibbs sampler is the ability to\ndraw efficiently samples from the full-conditional probability density\nfunctions. Since in the general case this is not possible, in order to speed up\nthe convergence of the chain, it is required to generate auxiliary samples\nwhose information is eventually disregarded. In this work, we show that these\nauxiliary samples can be recycled within the Gibbs estimators, improving their\nefficiency with no extra cost. This novel scheme arises naturally after\npointing out the relationship between the standard Gibbs sampler and the chain\nrule used for sampling purposes. Numerical simulations involving simple and\nreal inference problems confirm the excellent performance of the proposed\nscheme in terms of accuracy and computational efficiency. In particular we give\nempirical evidence of performance in a toy example, inference of Gaussian\nprocesses hyperparameters, and learning dependence graphs through regression. \n\n"}
{"id": "1611.07252", "contents": "Title: Interpretable Recurrent Neural Networks Using Sequential Sparse Recovery Abstract: Recurrent neural networks (RNNs) are powerful and effective for processing\nsequential data. However, RNNs are usually considered \"black box\" models whose\ninternal structure and learned parameters are not interpretable. In this paper,\nwe propose an interpretable RNN based on the sequential iterative\nsoft-thresholding algorithm (SISTA) for solving the sequential sparse recovery\nproblem, which models a sequence of correlated observations with a sequence of\nsparse latent vectors. The architecture of the resulting SISTA-RNN is\nimplicitly defined by the computational structure of SISTA, which results in a\nnovel stacked RNN architecture. Furthermore, the weights of the SISTA-RNN are\nperfectly interpretable as the parameters of a principled statistical model,\nwhich in this case include a sparsifying dictionary, iterative step size, and\nregularization parameters. In addition, on a particular sequential compressive\nsensing task, the SISTA-RNN trains faster and achieves better performance than\nconventional state-of-the-art black box RNNs, including long-short term memory\n(LSTM) RNNs. \n\n"}
{"id": "1611.07661", "contents": "Title: Multigrid Neural Architectures Abstract: We propose a multigrid extension of convolutional neural networks (CNNs).\nRather than manipulating representations living on a single spatial grid, our\nnetwork layers operate across scale space, on a pyramid of grids. They consume\nmultigrid inputs and produce multigrid outputs; convolutional filters\nthemselves have both within-scale and cross-scale extent. This aspect is\ndistinct from simple multiscale designs, which only process the input at\ndifferent scales. Viewed in terms of information flow, a multigrid network\npasses messages across a spatial pyramid. As a consequence, receptive field\nsize grows exponentially with depth, facilitating rapid integration of context.\nMost critically, multigrid structure enables networks to learn internal\nattention and dynamic routing mechanisms, and use them to accomplish tasks on\nwhich modern CNNs fail.\n  Experiments demonstrate wide-ranging performance advantages of multigrid. On\nCIFAR and ImageNet classification tasks, flipping from a single grid to\nmultigrid within the standard CNN paradigm improves accuracy, while being\ncompute and parameter efficient. Multigrid is independent of other\narchitectural choices; we show synergy in combination with residual\nconnections. Multigrid yields dramatic improvement on a synthetic semantic\nsegmentation dataset. Most strikingly, relatively shallow multigrid networks\ncan learn to directly perform spatial transformation tasks, where, in contrast,\ncurrent CNNs fail. Together, our results suggest that continuous evolution of\nfeatures on a multigrid pyramid is a more powerful alternative to existing CNN\ndesigns on a flat grid. \n\n"}
{"id": "1611.09482", "contents": "Title: Fast Wavenet Generation Algorithm Abstract: This paper presents an efficient implementation of the Wavenet generation\nprocess called Fast Wavenet. Compared to a naive implementation that has\ncomplexity O(2^L) (L denotes the number of layers in the network), our proposed\napproach removes redundant convolution operations by caching previous\ncalculations, thereby reducing the complexity to O(L) time. Timing experiments\nshow significant advantages of our fast implementation over a naive one. While\nthis method is presented for Wavenet, the same scheme can be applied anytime\none wants to perform autoregressive generation or online prediction using a\nmodel with dilated convolution layers. The code for our method is publicly\navailable. \n\n"}
{"id": "1612.00100", "contents": "Title: Noise-Tolerant Life-Long Matrix Completion via Adaptive Sampling Abstract: We study the problem of recovering an incomplete $m\\times n$ matrix of rank\n$r$ with columns arriving online over time. This is known as the problem of\nlife-long matrix completion, and is widely applied to recommendation system,\ncomputer vision, system identification, etc. The challenge is to design\nprovable algorithms tolerant to a large amount of noises, with small sample\ncomplexity. In this work, we give algorithms achieving strong guarantee under\ntwo realistic noise models. In bounded deterministic noise, an adversary can\nadd any bounded yet unstructured noise to each column. For this problem, we\npresent an algorithm that returns a matrix of a small error, with sample\ncomplexity almost as small as the best prior results in the noiseless case. For\nsparse random noise, where the corrupted columns are sparse and drawn randomly,\nwe give an algorithm that exactly recovers an $\\mu_0$-incoherent matrix by\nprobability at least $1-\\delta$ with sample complexity as small as\n$O\\left(\\mu_0rn\\log (r/\\delta)\\right)$. This result advances the\nstate-of-the-art work and matches the lower bound in a worst case. We also\nstudy the scenario where the hidden matrix lies on a mixture of subspaces and\nshow that the sample complexity can be even smaller. Our proposed algorithms\nperform well experimentally in both synthetic and real-world datasets. \n\n"}
{"id": "1612.00393", "contents": "Title: Hypervolume-based Multi-objective Bayesian Optimization with Student-t\n  Processes Abstract: Student-$t$ processes have recently been proposed as an appealing alternative\nnon-parameteric function prior. They feature enhanced flexibility and\npredictive variance. In this work the use of Student-$t$ processes are explored\nfor multi-objective Bayesian optimization. In particular, an analytical\nexpression for the hypervolume-based probability of improvement is developed\nfor independent Student-$t$ process priors of the objectives. Its effectiveness\nis shown on a multi-objective optimization problem which is known to be\ndifficult with traditional Gaussian processes. \n\n"}
{"id": "1612.00817", "contents": "Title: Summary - TerpreT: A Probabilistic Programming Language for Program\n  Induction Abstract: We study machine learning formulations of inductive program synthesis; that\nis, given input-output examples, synthesize source code that maps inputs to\ncorresponding outputs. Our key contribution is TerpreT, a domain-specific\nlanguage for expressing program synthesis problems. A TerpreT model is composed\nof a specification of a program representation and an interpreter that\ndescribes how programs map inputs to outputs. The inference task is to observe\na set of input-output examples and infer the underlying program. From a TerpreT\nmodel we automatically perform inference using four different back-ends:\ngradient descent (thus each TerpreT model can be seen as defining a\ndifferentiable interpreter), linear program (LP) relaxations for graphical\nmodels, discrete satisfiability solving, and the Sketch program synthesis\nsystem. TerpreT has two main benefits. First, it enables rapid exploration of a\nrange of domains, program representations, and interpreter models. Second, it\nseparates the model specification from the inference algorithm, allowing proper\ncomparisons between different approaches to inference.\n  We illustrate the value of TerpreT by developing several interpreter models\nand performing an extensive empirical comparison between alternative inference\nalgorithms on a variety of program models. To our knowledge, this is the first\nwork to compare gradient-based search over program space to traditional\nsearch-based alternatives. Our key empirical finding is that constraint solvers\ndominate the gradient descent and LP-based formulations.\n  This is a workshop summary of a longer report at arXiv:1608.04428 \n\n"}
{"id": "1612.01086", "contents": "Title: Deep Learning of Robotic Tasks without a Simulator using Strong and Weak\n  Human Supervision Abstract: We propose a scheme for training a computerized agent to perform complex\nhuman tasks such as highway steering. The scheme is designed to follow a\nnatural learning process whereby a human instructor teaches a computerized\ntrainee. The learning process consists of five elements: (i) unsupervised\nfeature learning; (ii) supervised imitation learning; (iii) supervised reward\ninduction; (iv) supervised safety module construction; and (v) reinforcement\nlearning. We implemented the last four elements of the scheme using deep\nconvolutional networks and applied it to successfully create a computerized\nagent capable of autonomous highway steering over the well-known racing game\nAssetto Corsa. We demonstrate that the use of the last four elements is\nessential to effectively carry out the steering task using vision alone,\nwithout access to a driving simulator internals, and operating in wall-clock\ntime. This is made possible also through the introduction of a safety network,\na novel way for preventing the agent from performing catastrophic mistakes\nduring the reinforcement learning stage. \n\n"}
{"id": "1612.01663", "contents": "Title: Efficient Non-oblivious Randomized Reduction for Risk Minimization with\n  Improved Excess Risk Guarantee Abstract: In this paper, we address learning problems for high dimensional data.\nPreviously, oblivious random projection based approaches that project high\ndimensional features onto a random subspace have been used in practice for\ntackling high-dimensionality challenge in machine learning. Recently, various\nnon-oblivious randomized reduction methods have been developed and deployed for\nsolving many numerical problems such as matrix product approximation, low-rank\nmatrix approximation, etc. However, they are less explored for the machine\nlearning tasks, e.g., classification. More seriously, the theoretical analysis\nof excess risk bounds for risk minimization, an important measure of\ngeneralization performance, has not been established for non-oblivious\nrandomized reduction methods. It therefore remains an open problem what is the\nbenefit of using them over previous oblivious random projection based\napproaches. To tackle these challenges, we propose an algorithmic framework for\nemploying non-oblivious randomized reduction method for general empirical risk\nminimizing in machine learning tasks, where the original high-dimensional\nfeatures are projected onto a random subspace that is derived from the data\nwith a small matrix approximation error. We then derive the first excess risk\nbound for the proposed non-oblivious randomized reduction approach without\nrequiring strong assumptions on the training data. The established excess risk\nbound exhibits that the proposed approach provides much better generalization\nperformance and it also sheds more insights about different randomized\nreduction approaches. Finally, we conduct extensive experiments on both\nsynthetic and real-world benchmark datasets, whose dimension scales to\n$O(10^7)$, to demonstrate the efficacy of our proposed approach. \n\n"}
{"id": "1612.01817", "contents": "Title: Pseudodeterministic Constructions in Subexponential Time Abstract: We study pseudodeterministic constructions, i.e., randomized algorithms which\noutput the same solution on most computation paths. We establish\nunconditionally that there is an infinite sequence $\\{p_n\\}_{n \\in \\mathbb{N}}$\nof increasing primes and a randomized algorithm $A$ running in expected\nsub-exponential time such that for each $n$, on input $1^{|p_n|}$, $A$ outputs\n$p_n$ with probability $1$. In other words, our result provides a\npseudodeterministic construction of primes in sub-exponential time which works\ninfinitely often.\n  This result follows from a much more general theorem about\npseudodeterministic constructions. A property $Q \\subseteq \\{0,1\\}^{*}$ is\n$\\gamma$-dense if for large enough $n$, $|Q \\cap \\{0,1\\}^n| \\geq \\gamma 2^n$.\nWe show that for each $c > 0$ at least one of the following holds: (1) There is\na pseudodeterministic polynomial time construction of a family $\\{H_n\\}$ of\nsets, $H_n \\subseteq \\{0,1\\}^n$, such that for each $(1/n^c)$-dense property $Q\n\\in \\mathsf{DTIME}(n^c)$ and every large enough $n$, $H_n \\cap Q \\neq\n\\emptyset$; or (2) There is a deterministic sub-exponential time construction\nof a family $\\{H'_n\\}$ of sets, $H'_n \\subseteq \\{0,1\\}^n$, such that for each\n$(1/n^c)$-dense property $Q \\in \\mathsf{DTIME}(n^c)$ and for infinitely many\nvalues of $n$, $H'_n \\cap Q \\neq \\emptyset$.\n  We provide further algorithmic applications that might be of independent\ninterest. Perhaps intriguingly, while our main results are unconditional, they\nhave a non-constructive element, arising from a sequence of applications of the\nhardness versus randomness paradigm. \n\n"}
{"id": "1612.02136", "contents": "Title: Mode Regularized Generative Adversarial Networks Abstract: Although Generative Adversarial Networks achieve state-of-the-art results on\na variety of generative tasks, they are regarded as highly unstable and prone\nto miss modes. We argue that these bad behaviors of GANs are due to the very\nparticular functional shape of the trained discriminators in high dimensional\nspaces, which can easily make training stuck or push probability mass in the\nwrong direction, towards that of higher concentration than that of the data\ngenerating distribution. We introduce several ways of regularizing the\nobjective, which can dramatically stabilize the training of GAN models. We also\nshow that our regularizers can help the fair distribution of probability mass\nacross the modes of the data generating distribution, during the early phases\nof training and thus providing a unified solution to the missing modes problem. \n\n"}
{"id": "1612.02712", "contents": "Title: Scalable Influence Maximization for Multiple Products in Continuous-Time\n  Diffusion Networks Abstract: A typical viral marketing model identifies influential users in a social\nnetwork to maximize a single product adoption assuming unlimited user\nattention, campaign budgets, and time. In reality, multiple products need\ncampaigns, users have limited attention, convincing users incurs costs, and\nadvertisers have limited budgets and expect the adoptions to be maximized soon.\nFacing these user, monetary, and timing constraints, we formulate the problem\nas a submodular maximization task in a continuous-time diffusion model under\nthe intersection of a matroid and multiple knapsack constraints. We propose a\nrandomized algorithm estimating the user influence in a network\n($|\\mathcal{V}|$ nodes, $|\\mathcal{E}|$ edges) to an accuracy of $\\epsilon$\nwith $n=\\mathcal{O}(1/\\epsilon^2)$ randomizations and\n$\\tilde{\\mathcal{O}}(n|\\mathcal{E}|+n|\\mathcal{V}|)$ computations. By\nexploiting the influence estimation algorithm as a subroutine, we develop an\nadaptive threshold greedy algorithm achieving an approximation factor $k_a/(2+2\nk)$ of the optimal when $k_a$ out of the $k$ knapsack constraints are active.\nExtensive experiments on networks of millions of nodes demonstrate that the\nproposed algorithms achieve the state-of-the-art in terms of effectiveness and\nscalability. \n\n"}
{"id": "1612.02803", "contents": "Title: The Physical Systems Behind Optimization Algorithms Abstract: We use differential equations based approaches to provide some {\\it\n\\textbf{physics}} insights into analyzing the dynamics of popular optimization\nalgorithms in machine learning. In particular, we study gradient descent,\nproximal gradient descent, coordinate gradient descent, proximal coordinate\ngradient, and Newton's methods as well as their Nesterov's accelerated variants\nin a unified framework motivated by a natural connection of optimization\nalgorithms to physical systems. Our analysis is applicable to more general\nalgorithms and optimization problems {\\it \\textbf{beyond}} convexity and strong\nconvexity, e.g. Polyak-\\L ojasiewicz and error bound conditions (possibly\nnonconvex). \n\n"}
{"id": "1612.03164", "contents": "Title: Square Hellinger Subadditivity for Bayesian Networks and its\n  Applications to Identity Testing Abstract: We show that the square Hellinger distance between two Bayesian networks on\nthe same directed graph, $G$, is subadditive with respect to the neighborhoods\nof $G$. Namely, if $P$ and $Q$ are the probability distributions defined by two\nBayesian networks on the same DAG, our inequality states that the square\nHellinger distance, $H^2(P,Q)$, between $P$ and $Q$ is upper bounded by the\nsum, $\\sum_v H^2(P_{\\{v\\} \\cup \\Pi_v}, Q_{\\{v\\} \\cup \\Pi_v})$, of the square\nHellinger distances between the marginals of $P$ and $Q$ on every node $v$ and\nits parents $\\Pi_v$ in the DAG. Importantly, our bound does not involve the\nconditionals but the marginals of $P$ and $Q$. We derive a similar inequality\nfor more general Markov Random Fields.\n  As an application of our inequality, we show that distinguishing whether two\nBayesian networks $P$ and $Q$ on the same (but potentially unknown) DAG satisfy\n$P=Q$ vs $d_{\\rm TV}(P,Q)>\\epsilon$ can be performed from\n$\\tilde{O}(|\\Sigma|^{3/4(d+1)} \\cdot n/\\epsilon^2)$ samples, where $d$ is the\nmaximum in-degree of the DAG and $\\Sigma$ the domain of each variable of the\nBayesian networks. If $P$ and $Q$ are defined on potentially different and\npotentially unknown trees, the sample complexity becomes\n$\\tilde{O}(|\\Sigma|^{4.5} n/\\epsilon^2)$, whose dependence on $n, \\epsilon$ is\noptimal up to logarithmic factors. Lastly, if $P$ and $Q$ are product\ndistributions over $\\{0,1\\}^n$ and $Q$ is known, the sample complexity becomes\n$O(\\sqrt{n}/\\epsilon^2)$, which is optimal up to constant factors. \n\n"}
{"id": "1612.03441", "contents": "Title: Lock-Free Optimization for Non-Convex Problems Abstract: Stochastic gradient descent~(SGD) and its variants have attracted much\nattention in machine learning due to their efficiency and effectiveness for\noptimization. To handle large-scale problems, researchers have recently\nproposed several lock-free strategy based parallel SGD~(LF-PSGD) methods for\nmulti-core systems. However, existing works have only proved the convergence of\nthese LF-PSGD methods for convex problems. To the best of our knowledge, no\nwork has proved the convergence of the LF-PSGD methods for non-convex problems.\nIn this paper, we provide the theoretical proof about the convergence of two\nrepresentative LF-PSGD methods, Hogwild! and AsySVRG, for non-convex problems.\nEmpirical results also show that both Hogwild! and AsySVRG are convergent on\nnon-convex problems, which successfully verifies our theoretical results. \n\n"}
{"id": "1612.05222", "contents": "Title: Multivariate Submodular Optimization Abstract: Submodular functions have found a wealth of new applications in data science\nand machine learning models in recent years. This has been coupled with many\nalgorithmic advances in the area of submodular optimization: (SO)\n$\\min/\\max~f(S): S \\in \\mathcal{F}$, where $\\mathcal{F}$ is a given family of\nfeasible sets over a ground set $V$ and $f:2^V \\rightarrow \\mathbb{R}$ is\nsubmodular. In this work we focus on a more general class of \\emph{multivariate\nsubmodular optimization} (MVSO) problems: $\\min/\\max~f (S_1,S_2,\\ldots,S_k):\nS_1 \\uplus S_2 \\uplus \\cdots \\uplus S_k \\in \\mathcal{F}$. Here we use $\\uplus$\nto denote disjoint union and hence this model is attractive where resources are\nbeing allocated across $k$ agents, who share a `joint' multivariate nonnegative\nobjective $f(S_1,S_2,\\ldots,S_k)$ that captures some type of submodularity\n(i.e. diminishing returns) property. We provide some explicit examples and\npotential applications for this new framework.\n  For maximization, we show that practical algorithms such as accelerated\ngreedy variants and distributed algorithms achieve good approximation\nguarantees for very general families (such as matroids and $p$-systems). For\narbitrary families, we show that monotone (resp. nonmonotone) MVSO admits an\n$\\alpha (1-1/e)$ (resp. $\\alpha \\cdot 0.385$) approximation whenever monotone\n(resp. nonmonotone) SO admits an $\\alpha$-approximation over the multilinear\nformulation. This substantially expands the family of tractable models for\nsubmodular maximization. For minimization, we show that if SO admits a\n$\\beta$-approximation over \\emph{modular} functions, then MVSO admits a\n$\\frac{\\beta \\cdot n}{1+(n-1)(1-c)}$-approximation where $c\\in [0,1]$ denotes\nthe curvature of $f$, and this is essentially tight. Finally, we prove that\nMVSO has an $\\alpha k$-approximation whenever SO admits an\n$\\alpha$-approximation over the convex formulation. \n\n"}
{"id": "1612.05369", "contents": "Title: Neural networks based EEG-Speech Models Abstract: In this paper, we propose an end-to-end neural network (NN) based EEG-speech\n(NES) modeling framework, in which three network structures are developed to\nmap imagined EEG signals to phonemes. The proposed NES models incorporate a\nlanguage model based EEG feature extraction layer, an acoustic feature mapping\nlayer, and a restricted Boltzmann machine (RBM) based the feature learning\nlayer. The NES models can jointly realize the representation of multichannel\nEEG signals and the projection of acoustic speech signals. Among three proposed\nNES models, two augmented networks utilize spoken EEG signals as either bias or\ngate information to strengthen the feature learning and translation of imagined\nEEG signals. Experimental results show that all three proposed NES models\noutperform the baseline support vector machine (SVM) method on EEG-speech\nclassification. With respect to binary classification, our approach achieves\ncomparable results relative to deep believe network approach. \n\n"}
{"id": "1612.05688", "contents": "Title: A User Simulator for Task-Completion Dialogues Abstract: Despite widespread interests in reinforcement-learning for task-oriented\ndialogue systems, several obstacles can frustrate research and development\nprogress. First, reinforcement learners typically require interaction with the\nenvironment, so conventional dialogue corpora cannot be used directly. Second,\neach task presents specific challenges, requiring separate corpus of\ntask-specific annotated data. Third, collecting and annotating human-machine or\nhuman-human conversations for task-oriented dialogues requires extensive domain\nknowledge. Because building an appropriate dataset can be both financially\ncostly and time-consuming, one popular approach is to build a user simulator\nbased upon a corpus of example dialogues. Then, one can train reinforcement\nlearning agents in an online fashion as they interact with the simulator.\nDialogue agents trained on these simulators can serve as an effective starting\npoint. Once agents master the simulator, they may be deployed in a real\nenvironment to interact with humans, and continue to be trained online. To ease\nempirical algorithmic comparisons in dialogues, this paper introduces a new,\npublicly available simulation framework, where our simulator, designed for the\nmovie-booking domain, leverages both rules and collected data. The simulator\nsupports two tasks: movie ticket booking and movie seeking. Finally, we\ndemonstrate several agents and detail the procedure to add and test your own\nagent in the proposed framework. \n\n"}
{"id": "1612.05968", "contents": "Title: Deep Multi-instance Networks with Sparse Label Assignment for Whole\n  Mammogram Classification Abstract: Mammogram classification is directly related to computer-aided diagnosis of\nbreast cancer. Traditional methods requires great effort to annotate the\ntraining data by costly manual labeling and specialized computational models to\ndetect these annotations during test. Inspired by the success of using deep\nconvolutional features for natural image analysis and multi-instance learning\nfor labeling a set of instances/patches, we propose end-to-end trained deep\nmulti-instance networks for mass classification based on whole mammogram\nwithout the aforementioned costly need to annotate the training data. We\nexplore three different schemes to construct deep multi-instance networks for\nwhole mammogram classification. Experimental results on the INbreast dataset\ndemonstrate the robustness of proposed deep networks compared to previous work\nusing segmentation and detection annotations in the training. \n\n"}
{"id": "1701.01325", "contents": "Title: Outlier Detection for Text Data : An Extended Version Abstract: The problem of outlier detection is extremely challenging in many domains\nsuch as text, in which the attribute values are typically non-negative, and\nmost values are zero. In such cases, it often becomes difficult to separate the\noutliers from the natural variations in the patterns in the underlying data. In\nthis paper, we present a matrix factorization method, which is naturally able\nto distinguish the anomalies with the use of low rank approximations of the\nunderlying data. Our iterative algorithm TONMF is based on block coordinate\ndescent (BCD) framework. We define blocks over the term-document matrix such\nthat the function becomes solvable. Given most recently updated values of other\nmatrix blocks, we always update one block at a time to its optimal. Our\napproach has significant advantages over traditional methods for text outlier\ndetection. Finally, we present experimental results illustrating the\neffectiveness of our method over competing methods. \n\n"}
{"id": "1701.01394", "contents": "Title: On spectral partitioning of signed graphs Abstract: We argue that the standard graph Laplacian is preferable for spectral\npartitioning of signed graphs compared to the signed Laplacian. Simple examples\ndemonstrate that partitioning based on signs of components of the leading\neigenvectors of the signed Laplacian may be meaningless, in contrast to\npartitioning based on the Fiedler vector of the standard graph Laplacian for\nsigned graphs. We observe that negative eigenvalues are beneficial for spectral\npartitioning of signed graphs, making the Fiedler vector easier to compute. \n\n"}
{"id": "1701.02804", "contents": "Title: Similarity Function Tracking using Pairwise Comparisons Abstract: Recent work in distance metric learning has focused on learning\ntransformations of data that best align with specified pairwise similarity and\ndissimilarity constraints, often supplied by a human observer. The learned\ntransformations lead to improved retrieval, classification, and clustering\nalgorithms due to the better adapted distance or similarity measures. Here, we\naddress the problem of learning these transformations when the underlying\nconstraint generation process is nonstationary. This nonstationarity can be due\nto changes in either the ground-truth clustering used to generate constraints\nor changes in the feature subspaces in which the class structure is apparent.\nWe propose Online Convex Ensemble StrongLy Adaptive Dynamic Learning (OCELAD),\na general adaptive, online approach for learning and tracking optimal metrics\nas they change over time that is highly robust to a variety of nonstationary\nbehaviors in the changing metric. We apply the OCELAD framework to an ensemble\nof online learners. Specifically, we create a retro-initialized composite\nobjective mirror descent (COMID) ensemble (RICE) consisting of a set of\nparallel COMID learners with different learning rates, and demonstrate\nparameter-free RICE-OCELAD metric learning on both synthetic data and a highly\nnonstationary Twitter dataset. We show significant performance improvements and\nincreased robustness to nonstationary effects relative to previously proposed\nbatch and online distance metric learning algorithms. \n\n"}
{"id": "1701.03493", "contents": "Title: Subgaussian Tail Bounds via Stability Arguments Abstract: Sums of independent, bounded random variables concentrate around their\nexpectation approximately as well a Gaussian of the same variance. Well known\nresults of this form include the Bernstein, Hoeffding, and Chernoff\ninequalities and many others. We present an alternative proof of these tail\nbounds based on what we call a stability argument, which avoids bounding the\nmoment generating function or higher-order moments of the distribution. Our\nstability argument is inspired by recent work on the generalization properties\nof differential privacy and their connection to adaptive data analysis (Bassily\net al., STOC 2016). \n\n"}
{"id": "1701.03856", "contents": "Title: The flip Markov chain for connected regular graphs Abstract: Mahlmann and Schindelhauer (2005) defined a Markov chain which they called\n$k$-Flipper, and showed that it is irreducible on the set of all connected\nregular graphs of a given degree (at least 3). We study the 1-Flipper chain,\nwhich we call the flip chain, and prove that the flip chain converges rapidly\nto the uniform distribution over connected $2r$-regular graphs with $n$\nvertices, where $n\\geq 8$ and $r = r(n)\\geq 2$. Formally, we prove that the\ndistribution of the flip chain will be within $\\varepsilon$ of uniform in total\nvariation distance after $\\text{poly}(n,r,\\log(\\varepsilon^{-1}))$ steps. This\npolynomial upper bound on the mixing time is given explicitly, and improves\nmarkedly on a previous bound given by Feder et al.(2006). We achieve this\nimprovement by using a direct two-stage canonical path construction, which we\ndefine in a general setting.\n  This work has applications to decentralised networks based on random regular\nconnected graphs of even degree, as a self-stabilising protocol in which nodes\nspontaneously perform random flips in order to repair the network. \n\n"}
{"id": "1701.04739", "contents": "Title: Summoning Demons: The Pursuit of Exploitable Bugs in Machine Learning Abstract: Governments and businesses increasingly rely on data analytics and machine\nlearning (ML) for improving their competitive edge in areas such as consumer\nsatisfaction, threat intelligence, decision making, and product efficiency.\nHowever, by cleverly corrupting a subset of data used as input to a target's ML\nalgorithms, an adversary can perturb outcomes and compromise the effectiveness\nof ML technology. While prior work in the field of adversarial machine learning\nhas studied the impact of input manipulation on correct ML algorithms, we\nconsider the exploitation of bugs in ML implementations. In this paper, we\ncharacterize the attack surface of ML programs, and we show that malicious\ninputs exploiting implementation bugs enable strictly more powerful attacks\nthan the classic adversarial machine learning techniques. We propose a\nsemi-automated technique, called steered fuzzing, for exploring this attack\nsurface and for discovering exploitable bugs in machine learning programs, in\norder to demonstrate the magnitude of this threat. As a result of our work, we\nresponsibly disclosed five vulnerabilities, established three new CVE-IDs, and\nilluminated a common insecure practice across many machine learning systems.\nFinally, we outline several research directions for further understanding and\nmitigating this threat. \n\n"}
{"id": "1701.04862", "contents": "Title: Towards Principled Methods for Training Generative Adversarial Networks Abstract: The goal of this paper is not to introduce a single algorithm or method, but\nto make theoretical steps towards fully understanding the training dynamics of\ngenerative adversarial networks. In order to substantiate our theoretical\nanalysis, we perform targeted experiments to verify our assumptions, illustrate\nour claims, and quantify the phenomena. This paper is divided into three\nsections. The first section introduces the problem at hand. The second section\nis dedicated to studying and proving rigorously the problems including\ninstability and saturation that arize when training generative adversarial\nnetworks. The third section examines a practical and theoretically grounded\ndirection towards solving these problems, while introducing new tools to study\nthem. \n\n"}
{"id": "1701.06937", "contents": "Title: Optimizing tree decompositions in MSO Abstract: The classic algorithm of Bodlaender and Kloks [J. Algorithms, 1996] solves\nthe following problem in linear fixed-parameter time: given a tree\ndecomposition of a graph of (possibly suboptimal) width k, compute an\noptimum-width tree decomposition of the graph. In this work, we prove that this\nproblem can also be solved in mso in the following sense: for every positive\ninteger k, there is an mso transduction from tree decompositions of width k to\ntree decompositions of optimum width. Together with our recent results [LICS\n2016], this implies that for every k there exists an mso transduction which\ninputs a graph of treewidth k, and nondeterministically outputs its tree\ndecomposition of optimum width. We also show that mso transductions can be\nimplemented in linear fixed-parameter time, which enables us to derive the\nalgorithmic result of Bodlaender and Kloks as a corollary of our main result. \n\n"}
{"id": "1701.08074", "contents": "Title: Model-Free Control of Thermostatically Controlled Loads Connected to a\n  District Heating Network Abstract: Optimal control of thermostatically controlled loads connected to a district\nheating network is considered a sequential decision- making problem under\nuncertainty. The practicality of a direct model-based approach is compromised\nby two challenges, namely scalability due to the large dimensionality of the\nproblem and the system identification required to identify an accurate model.\nTo help in mitigating these problems, this paper leverages on recent\ndevelopments in reinforcement learning in combination with a market-based\nmulti-agent system to obtain a scalable solution that obtains a significant\nperformance improvement in a practical learning time. The control approach is\napplied on a scenario comprising 100 thermostatically controlled loads\nconnected to a radial district heating network supplied by a central combined\nheat and power plant. Both for an energy arbitrage and a peak shaving\nobjective, the control approach requires 60 days to obtain a performance within\n65% of a theoretical lower bound on the cost. \n\n"}
{"id": "1701.08810", "contents": "Title: Reinforcement Learning Algorithm Selection Abstract: This paper formalises the problem of online algorithm selection in the\ncontext of Reinforcement Learning. The setup is as follows: given an episodic\ntask and a finite number of off-policy RL algorithms, a meta-algorithm has to\ndecide which RL algorithm is in control during the next episode so as to\nmaximize the expected return. The article presents a novel meta-algorithm,\ncalled Epochal Stochastic Bandit Algorithm Selection (ESBAS). Its principle is\nto freeze the policy updates at each epoch, and to leave a rebooted stochastic\nbandit in charge of the algorithm selection. Under some assumptions, a thorough\ntheoretical analysis demonstrates its near-optimality considering the\nstructural sampling budget limitations. ESBAS is first empirically evaluated on\na dialogue task where it is shown to outperform each individual algorithm in\nmost configurations. ESBAS is then adapted to a true online setting where\nalgorithms update their policies after each transition, which we call SSBAS.\nSSBAS is evaluated on a fruit collection task where it is shown to adapt the\nstepsize parameter more efficiently than the classical hyperbolic decay, and on\nan Atari game, where it improves the performance by a wide margin. \n\n"}
{"id": "1701.08939", "contents": "Title: Deep Submodular Functions Abstract: We start with an overview of a class of submodular functions called SCMMs\n(sums of concave composed with non-negative modular functions plus a final\narbitrary modular). We then define a new class of submodular functions we call\n{\\em deep submodular functions} or DSFs. We show that DSFs are a flexible\nparametric family of submodular functions that share many of the properties and\nadvantages of deep neural networks (DNNs). DSFs can be motivated by considering\na hierarchy of descriptive concepts over ground elements and where one wishes\nto allow submodular interaction throughout this hierarchy. Results in this\npaper show that DSFs constitute a strictly larger class of submodular functions\nthan SCMMs. We show that, for any integer $k>0$, there are $k$-layer DSFs that\ncannot be represented by a $k'$-layer DSF for any $k'<k$. This implies that,\nlike DNNs, there is a utility to depth, but unlike DNNs, the family of DSFs\nstrictly increase with depth. Despite this, we show (using a \"backpropagation\"\nlike method) that DSFs, even with arbitrarily large $k$, do not comprise all\nsubmodular functions. In offering the above results, we also define the notion\nof an antitone superdifferential of a concave function and show how this\nrelates to submodular functions (in general), DSFs (in particular), negative\nsecond-order partial derivatives, continuous submodularity, and concave\nextensions. To further motivate our analysis, we provide various special case\nresults from matroid theory, comparing DSFs with forms of matroid rank, in\nparticular the laminar matroid. Lastly, we discuss strategies to learn DSFs,\nand define the classes of deep supermodular functions, deep difference of\nsubmodular functions, and deep multivariate submodular functions, and discuss\nwhere these can be useful in applications. \n\n"}
{"id": "1702.00196", "contents": "Title: Communication-Optimal Distributed Clustering Abstract: Clustering large datasets is a fundamental problem with a number of\napplications in machine learning. Data is often collected on different sites\nand clustering needs to be performed in a distributed manner with low\ncommunication. We would like the quality of the clustering in the distributed\nsetting to match that in the centralized setting for which all the data resides\non a single site. In this work, we study both graph and geometric clustering\nproblems in two distributed models: (1) a point-to-point model, and (2) a model\nwith a broadcast channel. We give protocols in both models which we show are\nnearly optimal by proving almost matching communication lower bounds. Our work\nhighlights the surprising power of a broadcast channel for clustering problems;\nroughly speaking, to spectrally cluster $n$ points or $n$ vertices in a graph\ndistributed across $s$ servers, for a worst-case partitioning the communication\ncomplexity in a point-to-point model is $n \\cdot s$, while in the broadcast\nmodel it is $n + s$. A similar phenomenon holds for the geometric setting as\nwell. We implement our algorithms and demonstrate this phenomenon on real life\ndatasets, showing that our algorithms are also very efficient in practice. \n\n"}
{"id": "1702.00763", "contents": "Title: Natasha: Faster Non-Convex Stochastic Optimization Via Strongly\n  Non-Convex Parameter Abstract: Given a nonconvex function that is an average of $n$ smooth functions, we\ndesign stochastic first-order methods to find its approximate stationary\npoints. The convergence of our new methods depends on the smallest (negative)\neigenvalue $-\\sigma$ of the Hessian, a parameter that describes how nonconvex\nthe function is.\n  Our methods outperform known results for a range of parameter $\\sigma$, and\ncan be used to find approximate local minima. Our result implies an interesting\ndichotomy: there exists a threshold $\\sigma_0$ so that the currently fastest\nmethods for $\\sigma>\\sigma_0$ and for $\\sigma<\\sigma_0$ have different\nbehaviors: the former scales with $n^{2/3}$ and the latter scales with\n$n^{3/4}$. \n\n"}
{"id": "1702.00887", "contents": "Title: Structured Attention Networks Abstract: Attention networks have proven to be an effective approach for embedding\ncategorical inference within a deep neural network. However, for many tasks we\nmay want to model richer structural dependencies without abandoning end-to-end\ntraining. In this work, we experiment with incorporating richer structural\ndistributions, encoded using graphical models, within deep networks. We show\nthat these structured attention networks are simple extensions of the basic\nattention procedure, and that they allow for extending attention beyond the\nstandard soft-selection approach, such as attending to partial segmentations or\nto subtrees. We experiment with two different classes of structured attention\nnetworks: a linear-chain conditional random field and a graph-based parsing\nmodel, and describe how these models can be practically implemented as neural\nnetwork layers. Experiments show that this approach is effective for\nincorporating structural biases, and structured attention networks outperform\nbaseline attention models on a variety of synthetic and real tasks: tree\ntransduction, neural machine translation, question answering, and natural\nlanguage inference. We further find that models trained in this way learn\ninteresting unsupervised hidden representations that generalize simple\nattention. \n\n"}
{"id": "1702.01293", "contents": "Title: Latent Hinge-Minimax Risk Minimization for Inference from a Small Number\n  of Training Samples Abstract: Deep Learning (DL) methods show very good performance when trained on large,\nbalanced data sets. However, many practical problems involve imbalanced data\nsets, or/and classes with a small number of training samples. The performance\nof DL methods as well as more traditional classifiers drops significantly in\nsuch settings. Most of the existing solutions for imbalanced problems focus on\ncustomizing the data for training. A more principled solution is to use mixed\nHinge-Minimax risk [19] specifically designed to solve binary problems with\nimbalanced training sets. Here we propose a Latent Hinge Minimax (LHM) risk and\na training algorithm that generalizes this paradigm to an ensemble of\nhyperplanes that can form arbitrary complex, piecewise linear boundaries. To\nextract good features, we combine LHM model with CNN via transfer learning. To\nsolve multi-class problem we map pre-trained category-specific LHM classifiers\nto a multi-class neural network and adjust the weights with very fast tuning.\nLHM classifier enables the use of unlabeled data in its training and the\nmapping allows for multi-class inference, resulting in a classifier that\nperforms better than alternatives when trained on a small number of training\nsamples. \n\n"}
{"id": "1702.02267", "contents": "Title: Matrix Completion from $O(n)$ Samples in Linear Time Abstract: We consider the problem of reconstructing a rank-$k$ $n \\times n$ matrix $M$\nfrom a sampling of its entries. Under a certain incoherence assumption on $M$\nand for the case when both the rank and the condition number of $M$ are\nbounded, it was shown in \\cite{CandesRecht2009, CandesTao2010, keshavan2010,\nRecht2011, Jain2012, Hardt2014} that $M$ can be recovered exactly or\napproximately (depending on some trade-off between accuracy and computational\ncomplexity) using $O(n \\, \\text{poly}(\\log n))$ samples in super-linear time\n$O(n^{a} \\, \\text{poly}(\\log n))$ for some constant $a \\geq 1$.\n  In this paper, we propose a new matrix completion algorithm using a novel\nsampling scheme based on a union of independent sparse random regular bipartite\ngraphs. We show that under the same conditions w.h.p. our algorithm recovers an\n$\\epsilon$-approximation of $M$ in terms of the Frobenius norm using $O(n\n\\log^2(1/\\epsilon))$ samples and in linear time $O(n \\log^2(1/\\epsilon))$. This\nprovides the best known bounds both on the sample complexity and computational\ncomplexity for reconstructing (approximately) an unknown low-rank matrix.\n  The novelty of our algorithm is two new steps of thresholding singular values\nand rescaling singular vectors in the application of the \"vanilla\" alternating\nminimization algorithm. The structure of sparse random regular graphs is used\nheavily for controlling the impact of these regularization steps. \n\n"}
{"id": "1702.02640", "contents": "Title: Character-level Deep Conflation for Business Data Analytics Abstract: Connecting different text attributes associated with the same entity\n(conflation) is important in business data analytics since it could help merge\ntwo different tables in a database to provide a more comprehensive profile of\nan entity. However, the conflation task is challenging because two text strings\nthat describe the same entity could be quite different from each other for\nreasons such as misspelling. It is therefore critical to develop a conflation\nmodel that is able to truly understand the semantic meaning of the strings and\nmatch them at the semantic level. To this end, we develop a character-level\ndeep conflation model that encodes the input text strings from character level\ninto finite dimension feature vectors, which are then used to compute the\ncosine similarity between the text strings. The model is trained in an\nend-to-end manner using back propagation and stochastic gradient descent to\nmaximize the likelihood of the correct association. Specifically, we propose\ntwo variants of the deep conflation model, based on long-short-term memory\n(LSTM) recurrent neural network (RNN) and convolutional neural network (CNN),\nrespectively. Both models perform well on a real-world business analytics\ndataset and significantly outperform the baseline bag-of-character (BoC) model. \n\n"}
{"id": "1702.04121", "contents": "Title: Practical Learning of Predictive State Representations Abstract: Over the past decade there has been considerable interest in spectral\nalgorithms for learning Predictive State Representations (PSRs). Spectral\nalgorithms have appealing theoretical guarantees; however, the resulting models\ndo not always perform well on inference tasks in practice. One reason for this\nbehavior is the mismatch between the intended task (accurate filtering or\nprediction) and the loss function being optimized by the algorithm (estimation\nerror in model parameters).\n  A natural idea is to improve performance by refining PSRs using an algorithm\nsuch as EM. Unfortunately it is not obvious how to apply apply an EM style\nalgorithm in the context of PSRs as the Log Likelihood is not well defined for\nall PSRs. We show that it is possible to overcome this problem using ideas from\nPredictive State Inference Machines.\n  We combine spectral algorithms for PSRs as a consistent and efficient\ninitialization with PSIM-style updates to refine the resulting model\nparameters. By combining these two ideas we develop Inference Gradients, a\nsimple, fast, and robust method for practical learning of PSRs. Inference\nGradients performs gradient descent in the PSR parameter space to optimize an\ninference-based loss function like PSIM. Because Inference Gradients uses a\nspectral initialization we get the same consistency benefits as PSRs. We show\nthat Inference Gradients outperforms both PSRs and PSIMs on real and synthetic\ndata sets. \n\n"}
{"id": "1702.04126", "contents": "Title: Gaussian-Dirichlet Posterior Dominance in Sequential Learning Abstract: We consider the problem of sequential learning from categorical observations\nbounded in [0,1]. We establish an ordering between the Dirichlet posterior over\ncategorical outcomes and a Gaussian posterior under observations with N(0,1)\nnoise. We establish that, conditioned upon identical data with at least two\nobservations, the posterior mean of the categorical distribution will always\nsecond-order stochastically dominate the posterior mean of the Gaussian\ndistribution. These results provide a useful tool for the analysis of\nsequential learning under categorical outcomes. \n\n"}
{"id": "1702.04649", "contents": "Title: Generative Temporal Models with Memory Abstract: We consider the general problem of modeling temporal data with long-range\ndependencies, wherein new observations are fully or partially predictable based\non temporally-distant, past observations. A sufficiently powerful temporal\nmodel should separate predictable elements of the sequence from unpredictable\nelements, express uncertainty about those unpredictable elements, and rapidly\nidentify novel elements that may help to predict the future. To create such\nmodels, we introduce Generative Temporal Models augmented with external memory\nsystems. They are developed within the variational inference framework, which\nprovides both a practical training methodology and methods to gain insight into\nthe models' operation. We show, on a range of problems with sparse, long-term\ntemporal dependencies, that these models store information from early in a\nsequence, and reuse this stored information efficiently. This allows them to\nperform substantially better than existing models based on well-known recurrent\nneural networks, like LSTMs. \n\n"}
{"id": "1702.05419", "contents": "Title: A Random Matrix Approach to Neural Networks Abstract: This article studies the Gram random matrix model $G=\\frac1T\\Sigma^{\\rm\nT}\\Sigma$, $\\Sigma=\\sigma(WX)$, classically found in the analysis of random\nfeature maps and random neural networks, where $X=[x_1,\\ldots,x_T]\\in{\\mathbb\nR}^{p\\times T}$ is a (data) matrix of bounded norm, $W\\in{\\mathbb R}^{n\\times\np}$ is a matrix of independent zero-mean unit variance entries, and\n$\\sigma:{\\mathbb R}\\to{\\mathbb R}$ is a Lipschitz continuous (activation)\nfunction --- $\\sigma(WX)$ being understood entry-wise. By means of a key\nconcentration of measure lemma arising from non-asymptotic random matrix\narguments, we prove that, as $n,p,T$ grow large at the same rate, the resolvent\n$Q=(G+\\gamma I_T)^{-1}$, for $\\gamma>0$, has a similar behavior as that met in\nsample covariance matrix models, involving notably the moment\n$\\Phi=\\frac{T}n{\\mathbb E}[G]$, which provides in passing a deterministic\nequivalent for the empirical spectral measure of $G$. Application-wise, this\nresult enables the estimation of the asymptotic performance of single-layer\nrandom neural networks. This in turn provides practical insights into the\nunderlying mechanisms into play in random neural networks, entailing several\nunexpected consequences, as well as a fast practical means to tune the network\nhyperparameters. \n\n"}
{"id": "1702.06280", "contents": "Title: On the (Statistical) Detection of Adversarial Examples Abstract: Machine Learning (ML) models are applied in a variety of tasks such as\nnetwork intrusion detection or Malware classification. Yet, these models are\nvulnerable to a class of malicious inputs known as adversarial examples. These\nare slightly perturbed inputs that are classified incorrectly by the ML model.\nThe mitigation of these adversarial inputs remains an open problem. As a step\ntowards understanding adversarial examples, we show that they are not drawn\nfrom the same distribution than the original data, and can thus be detected\nusing statistical tests. Using thus knowledge, we introduce a complimentary\napproach to identify specific inputs that are adversarial. Specifically, we\naugment our ML model with an additional output, in which the model is trained\nto classify all adversarial inputs. We evaluate our approach on multiple\nadversarial example crafting methods (including the fast gradient sign and\nsaliency map methods) with several datasets. The statistical test flags sample\nsets containing adversarial inputs confidently at sample sizes between 10 and\n100 data points. Furthermore, our augmented model either detects adversarial\nexamples as outliers with high accuracy (> 80%) or increases the adversary's\ncost - the perturbation added - by more than 150%. In this way, we show that\nstatistical properties of adversarial examples are essential to their\ndetection. \n\n"}
{"id": "1702.06329", "contents": "Title: Towards a Common Implementation of Reinforcement Learning for Multiple\n  Robotic Tasks Abstract: Mobile robots are increasingly being employed for performing complex tasks in\ndynamic environments. Reinforcement learning (RL) methods are recognized to be\npromising for specifying such tasks in a relatively simple manner. However, the\nstrong dependency between the learning method and the task to learn is a\nwell-known problem that restricts practical implementations of RL in robotics,\noften requiring major modifications of parameters and adding other techniques\nfor each particular task. In this paper we present a practical core\nimplementation of RL which enables the learning process for multiple robotic\ntasks with minimal per-task tuning or none. Based on value iteration methods,\nthis implementation includes a novel approach for action selection, called\nQ-biased softmax regression (QBIASSR), which avoids poor performance of the\nlearning process when the robot reaches new unexplored states. Our approach\ntakes advantage of the structure of the state space by attending the physical\nvariables involved (e.g., distances to obstacles, X,Y,{\\theta} pose, etc.),\nthus experienced sets of states may favor the decision-making process of\nunexplored or rarely-explored states. This improvement has a relevant role in\nreducing the tuning of the algorithm for particular tasks. Experiments with\nreal and simulated robots, performed with the software framework also\nintroduced here, show that our implementation is effectively able to learn\ndifferent robotic tasks without tuning the learning method. Results also\nsuggest that the combination of true online SARSA({\\lambda}) with QBIASSR can\noutperform the existing RL core algorithms in low-dimensional robotic tasks. \n\n"}
{"id": "1702.06818", "contents": "Title: Stochastic Approximation for Canonical Correlation Analysis Abstract: We propose novel first-order stochastic approximation algorithms for\ncanonical correlation analysis (CCA). Algorithms presented are instances of\ninexact matrix stochastic gradient (MSG) and inexact matrix exponentiated\ngradient (MEG), and achieve $\\epsilon$-suboptimality in the population\nobjective in $\\operatorname{poly}(\\frac{1}{\\epsilon})$ iterations. We also\nconsider practical variants of the proposed algorithms and compare them with\nother methods for CCA both theoretically and empirically. \n\n"}
{"id": "1702.07709", "contents": "Title: Computationally Efficient Robust Estimation of Sparse Functionals Abstract: Many conventional statistical procedures are extremely sensitive to seemingly\nminor deviations from modeling assumptions. This problem is exacerbated in\nmodern high-dimensional settings, where the problem dimension can grow with and\npossibly exceed the sample size. We consider the problem of robust estimation\nof sparse functionals, and provide a computationally and statistically\nefficient algorithm in the high-dimensional setting. Our theory identifies a\nunified set of deterministic conditions under which our algorithm guarantees\naccurate recovery. By further establishing that these deterministic conditions\nhold with high-probability for a wide range of statistical models, our theory\napplies to many problems of considerable interest including sparse mean and\ncovariance estimation; sparse linear regression; and sparse generalized linear\nmodels. \n\n"}
{"id": "1702.08503", "contents": "Title: SGD Learns the Conjugate Kernel Class of the Network Abstract: We show that the standard stochastic gradient decent (SGD) algorithm is\nguaranteed to learn, in polynomial time, a function that is competitive with\nthe best function in the conjugate kernel space of the network, as defined in\nDaniely, Frostig and Singer. The result holds for log-depth networks from a\nrich family of architectures. To the best of our knowledge, it is the first\npolynomial-time guarantee for the standard neural network learning algorithm\nfor networks of depth more that two.\n  As corollaries, it follows that for neural networks of any depth between $2$\nand $\\log(n)$, SGD is guaranteed to learn, in polynomial time, constant degree\npolynomials with polynomially bounded coefficients. Likewise, it follows that\nSGD on large enough networks can learn any continuous function (not in\npolynomial time), complementing classical expressivity results. \n\n"}
{"id": "1702.08567", "contents": "Title: Optimal Experiment Design for Causal Discovery from Fixed Number of\n  Experiments Abstract: We study the problem of causal structure learning over a set of random\nvariables when the experimenter is allowed to perform at most $M$ experiments\nin a non-adaptive manner. We consider the optimal learning strategy in terms of\nminimizing the portions of the structure that remains unknown given the limited\nnumber of experiments in both Bayesian and minimax setting. We characterize the\ntheoretical optimal solution and propose an algorithm, which designs the\nexperiments efficiently in terms of time complexity. We show that for bounded\ndegree graphs, in the minimax case and in the Bayesian case with uniform\npriors, our proposed algorithm is a $\\rho$-approximation algorithm, where\n$\\rho$ is independent of the order of the underlying graph. Simulations on both\nsynthetic and real data show that the performance of our algorithm is very\nclose to the optimal solution. \n\n"}
{"id": "1703.00560", "contents": "Title: An Analytical Formula of Population Gradient for two-layered ReLU\n  network and its Applications in Convergence and Critical Point Analysis Abstract: In this paper, we explore theoretical properties of training a two-layered\nReLU network $g(\\mathbf{x}; \\mathbf{w}) = \\sum_{j=1}^K\n\\sigma(\\mathbf{w}_j^T\\mathbf{x})$ with centered $d$-dimensional spherical\nGaussian input $\\mathbf{x}$ ($\\sigma$=ReLU). We train our network with gradient\ndescent on $\\mathbf{w}$ to mimic the output of a teacher network with the same\narchitecture and fixed parameters $\\mathbf{w}^*$. We show that its population\ngradient has an analytical formula, leading to interesting theoretical analysis\nof critical points and convergence behaviors. First, we prove that critical\npoints outside the hyperplane spanned by the teacher parameters\n(\"out-of-plane\") are not isolated and form manifolds, and characterize in-plane\ncritical-point-free regions for two ReLU case. On the other hand, convergence\nto $\\mathbf{w}^*$ for one ReLU node is guaranteed with at least\n$(1-\\epsilon)/2$ probability, if weights are initialized randomly with standard\ndeviation upper-bounded by $O(\\epsilon/\\sqrt{d})$, consistent with empirical\npractice. For network with many ReLU nodes, we prove that an infinitesimal\nperturbation of weight initialization results in convergence towards\n$\\mathbf{w}^*$ (or its permutation), a phenomenon known as spontaneous\nsymmetric-breaking (SSB) in physics. We assume no independence of ReLU\nactivations. Simulation verifies our findings. \n\n"}
{"id": "1703.01253", "contents": "Title: Machine Learning on Sequential Data Using a Recurrent Weighted Average Abstract: Recurrent Neural Networks (RNN) are a type of statistical model designed to\nhandle sequential data. The model reads a sequence one symbol at a time. Each\nsymbol is processed based on information collected from the previous symbols.\nWith existing RNN architectures, each symbol is processed using only\ninformation from the previous processing step. To overcome this limitation, we\npropose a new kind of RNN model that computes a recurrent weighted average\n(RWA) over every past processing step. Because the RWA can be computed as a\nrunning average, the computational overhead scales like that of any other RNN\narchitecture. The approach essentially reformulates the attention mechanism\ninto a stand-alone model. The performance of the RWA model is assessed on the\nvariable copy problem, the adding problem, classification of artificial\ngrammar, classification of sequences by length, and classification of the MNIST\nimages (where the pixels are read sequentially one at a time). On almost every\ntask, the RWA model is found to outperform a standard LSTM model. \n\n"}
{"id": "1703.01507", "contents": "Title: Machine Learning Friendly Set Version of Johnson-Lindenstrauss Lemma Abstract: In this paper we make a novel use of the Johnson-Lindenstrauss Lemma. The\nLemma has an existential form saying that there exists a JL transformation $f$\nof the data points into lower dimensional space such that all of them fall into\npredefined error range $\\delta$.\n  We formulate in this paper a theorem stating that we can choose the target\ndimensionality in a random projection type JL linear transformation in such a\nway that with probability $1-\\epsilon$ all of them fall into predefined error\nrange $\\delta$ for any user-predefined failure probability $\\epsilon$.\n  This result is important for applications such a data clustering where we\nwant to have a priori dimensionality reducing transformation instead of trying\nout a (large) number of them, as with traditional Johnson-Lindenstrauss Lemma.\nIn particular, we take a closer look at the $k$-means algorithm and prove that\na good solution in the projected space is also a good solution in the original\nspace. Furthermore, under proper assumptions local optima in the original space\nare also ones in the projected space. We define also conditions for which\nclusterability property of the original space is transmitted to the projected\nspace, so that special case algorithms for the original space are also\napplicable in the projected space. \n\n"}
{"id": "1703.02059", "contents": "Title: Cheshire: An Online Algorithm for Activity Maximization in Social\n  Networks Abstract: User engagement in social networks depends critically on the number of online\nactions their users take in the network. Can we design an algorithm that finds\nwhen to incentivize users to take actions to maximize the overall activity in a\nsocial network? In this paper, we model the number of online actions over time\nusing multidimensional Hawkes processes, derive an alternate representation of\nthese processes based on stochastic differential equations (SDEs) with jumps\nand, exploiting this alternate representation, address the above question from\nthe perspective of stochastic optimal control of SDEs with jumps. We find that\nthe optimal level of incentivized actions depends linearly on the current level\nof overall actions. Moreover, the coefficients of this linear relationship can\nbe found by solving a matrix Riccati differential equation, which can be solved\nefficiently, and a first order differential equation, which has a closed form\nsolution. As a result, we are able to design an efficient online algorithm,\nCheshire, to sample the optimal times of the users' incentivized actions.\nExperiments on both synthetic and real data gathered from Twitter show that our\nalgorithm is able to consistently maximize the number of online actions more\neffectively than the state of the art. \n\n"}
{"id": "1703.02100", "contents": "Title: Guarantees for Greedy Maximization of Non-submodular Functions with\n  Applications Abstract: We investigate the performance of the standard Greedy algorithm for\ncardinality constrained maximization of non-submodular nondecreasing set\nfunctions. While there are strong theoretical guarantees on the performance of\nGreedy for maximizing submodular functions, there are few guarantees for\nnon-submodular ones. However, Greedy enjoys strong empirical performance for\nmany important non-submodular functions, e.g., the Bayesian A-optimality\nobjective in experimental design. We prove theoretical guarantees supporting\nthe empirical performance. Our guarantees are characterized by a combination of\nthe (generalized) curvature $\\alpha$ and the submodularity ratio $\\gamma$. In\nparticular, we prove that Greedy enjoys a tight approximation guarantee of\n$\\frac{1}{\\alpha}(1- e^{-\\gamma\\alpha})$ for cardinality constrained\nmaximization. In addition, we bound the submodularity ratio and curvature for\nseveral important real-world objectives, including the Bayesian A-optimality\nobjective, the determinantal function of a square submatrix and certain linear\nprograms with combinatorial constraints. We experimentally validate our\ntheoretical findings for both synthetic and real-world applications. \n\n"}
{"id": "1703.02723", "contents": "Title: Scalable Greedy Feature Selection via Weak Submodularity Abstract: Greedy algorithms are widely used for problems in machine learning such as\nfeature selection and set function optimization. Unfortunately, for large\ndatasets, the running time of even greedy algorithms can be quite high. This is\nbecause for each greedy step we need to refit a model or calculate a function\nusing the previously selected choices and the new candidate.\n  Two algorithms that are faster approximations to the greedy forward selection\nwere introduced recently ([Mirzasoleiman et al. 2013, 2015]). They achieve\nbetter performance by exploiting distributed computation and stochastic\nevaluation respectively. Both algorithms have provable performance guarantees\nfor submodular functions.\n  In this paper we show that divergent from previously held opinion,\nsubmodularity is not required to obtain approximation guarantees for these two\nalgorithms. Specifically, we show that a generalized concept of weak\nsubmodularity suffices to give multiplicative approximation guarantees. Our\nresult extends the applicability of these algorithms to a larger class of\nfunctions. Furthermore, we show that a bounded submodularity ratio can be used\nto provide data dependent bounds that can sometimes be tighter also for\nsubmodular functions. We empirically validate our work by showing superior\nperformance of fast greedy approximations versus several established baselines\non artificial and real datasets. \n\n"}
{"id": "1703.02866", "contents": "Title: The Half-integral Erd\\\"os-P\\'osa Property for Non-null Cycles Abstract: A Group Labeled Graph is a pair $(G,\\Lambda)$ where $G$ is an oriented graph\nand $\\Lambda$ is a mapping from the arcs of $G$ to elements of a group. A (not\nnecessarily directed) cycle $C$ is called non-null if for any cyclic ordering\nof the arcs in $C$, the group element obtained by `adding' the labels on\nforward arcs and `subtracting' the labels on reverse arcs is not the identity\nelement of the group. Non-null cycles in group labeled graphs generalize\nseveral well-known graph structures, including odd cycles.\n  In this paper, we prove that non-null cycles on Group Labeled Graphs have the\nhalf-integral Erd\\\"os-P\\'osa property. That is, there is a function $f:{\\mathbb\nN}\\to {\\mathbb N}$ such that for any $k\\in {\\mathbb N}$, any group labeled\ngraph $(G,\\Lambda)$ has a set of $k$ non-null cycles such that each vertex of\n$G$ appears in at most two of these cycles or there is a set of at most $f(k)$\nvertices that intersects every non-null cycle. Since it is known that non-null\ncycles do not have the integeral Erd\\\"os-P\\'osa property in general, a\nhalf-integral Erd\\\"os-P\\'osa result is the best one could hope for. \n\n"}
{"id": "1703.04664", "contents": "Title: Optimal Densification for Fast and Accurate Minwise Hashing Abstract: Minwise hashing is a fundamental and one of the most successful hashing\nalgorithm in the literature. Recent advances based on the idea of\ndensification~\\cite{Proc:OneHashLSH_ICML14,Proc:Shrivastava_UAI14} have shown\nthat it is possible to compute $k$ minwise hashes, of a vector with $d$\nnonzeros, in mere $(d + k)$ computations, a significant improvement over the\nclassical $O(dk)$. These advances have led to an algorithmic improvement in the\nquery complexity of traditional indexing algorithms based on minwise hashing.\nUnfortunately, the variance of the current densification techniques is\nunnecessarily high, which leads to significantly poor accuracy compared to\nvanilla minwise hashing, especially when the data is sparse. In this paper, we\nprovide a novel densification scheme which relies on carefully tailored\n2-universal hashes. We show that the proposed scheme is variance-optimal, and\nwithout losing the runtime efficiency, it is significantly more accurate than\nexisting densification techniques. As a result, we obtain a significantly\nefficient hashing scheme which has the same variance and collision probability\nas minwise hashing. Experimental evaluations on real sparse and\nhigh-dimensional datasets validate our claims. We believe that given the\nsignificant advantages, our method will replace minwise hashing implementations\nin practice. \n\n"}
{"id": "1703.05593", "contents": "Title: Convolutional neural network architecture for geometric matching Abstract: We address the problem of determining correspondences between two images in\nagreement with a geometric model such as an affine or thin-plate spline\ntransformation, and estimating its parameters. The contributions of this work\nare three-fold. First, we propose a convolutional neural network architecture\nfor geometric matching. The architecture is based on three main components that\nmimic the standard steps of feature extraction, matching and simultaneous\ninlier detection and model parameter estimation, while being trainable\nend-to-end. Second, we demonstrate that the network parameters can be trained\nfrom synthetically generated imagery without the need for manual annotation and\nthat our matching layer significantly increases generalization capabilities to\nnever seen before images. Finally, we show that the same model can perform both\ninstance-level and category-level matching giving state-of-the-art results on\nthe challenging Proposal Flow dataset. \n\n"}
{"id": "1703.06040", "contents": "Title: Towards a Topology-Shape-Metrics Framework for Ortho-Radial Drawings Abstract: Ortho-Radial drawings are a generalization of orthogonal drawings to grids\nthat are formed by concentric circles and straight-line spokes emanating from\nthe circles' center. Such drawings have applications in schematic graph\nlayouts, e.g., for metro maps and destination maps.\n  A plane graph is a planar graph with a fixed planar embedding. We give a\ncombinatorial characterization of the plane graphs that admit a planar\northo-radial drawing without bends. Previously, such a characterization was\nonly known for paths, cycles, and theta graphs, and in the special case of\nrectangular drawings for cubic graphs, where the contour of each face is\nrequired to be a rectangle.\n  The characterization is expressed in terms of an ortho-radial representation\nthat, similar to Tamassia's orthogonal representations for orthogonal drawings\ndescribes such a drawing combinatorially in terms of angles around vertices and\nbends on the edges. In this sense our characterization can be seen as a first\nstep towards generalizing the Topology-Shape-Metrics framework of Tamassia to\northo-radial drawings. \n\n"}
{"id": "1703.06065", "contents": "Title: Block CUR: Decomposing Matrices using Groups of Columns Abstract: A common problem in large-scale data analysis is to approximate a matrix\nusing a combination of specifically sampled rows and columns, known as CUR\ndecomposition. Unfortunately, in many real-world environments, the ability to\nsample specific individual rows or columns of the matrix is limited by either\nsystem constraints or cost. In this paper, we consider matrix approximation by\nsampling predefined \\emph{blocks} of columns (or rows) from the matrix. We\npresent an algorithm for sampling useful column blocks and provide novel\nguarantees for the quality of the approximation. This algorithm has application\nin problems as diverse as biometric data analysis to distributed computing. We\ndemonstrate the effectiveness of the proposed algorithms for computing the\nBlock CUR decomposition of large matrices in a distributed setting with\nmultiple nodes in a compute cluster, where such blocks correspond to columns\n(or rows) of the matrix stored on the same node, which can be retrieved with\nmuch less overhead than retrieving individual columns stored across different\nnodes. In the biometric setting, the rows correspond to different users and\ncolumns correspond to users' biometric reaction to external stimuli, {\\em\ne.g.,}~watching video content, at a particular time instant. There is\nsignificant cost in acquiring each user's reaction to lengthy content so we\nsample a few important scenes to approximate the biometric response. An\nindividual time sample in this use case cannot be queried in isolation due to\nthe lack of context that caused that biometric reaction. Instead, collections\nof time segments ({\\em i.e.,} blocks) must be presented to the user. The\npractical application of these algorithms is shown via experimental results\nusing real-world user biometric data from a content testing environment. \n\n"}
{"id": "1703.06426", "contents": "Title: Semi-Supervised Learning with Competitive Infection Models Abstract: The goal in semi-supervised learning is to effectively combine labeled and\nunlabeled data. One way to do this is by encouraging smoothness across edges in\na graph whose nodes correspond to input examples. In many graph-based methods,\nlabels can be thought of as propagating over the graph, where the underlying\npropagation mechanism is based on random walks or on averaging dynamics. While\ntheoretically elegant, these dynamics suffer from several drawbacks which can\nhurt predictive performance.\n  Our goal in this work is to explore alternative mechanisms for propagating\nlabels. In particular, we propose a method based on dynamic infection\nprocesses, where unlabeled nodes can be \"infected\" with the label of their\nalready infected neighbors. Our algorithm is efficient and scalable, and an\nanalysis of the underlying optimization objective reveals a surprising relation\nto other Laplacian approaches. We conclude with a thorough set of experiments\nacross multiple benchmarks and various learning settings. \n\n"}
{"id": "1703.06726", "contents": "Title: On the effect of pooling on the geometry of representations Abstract: In machine learning and neuroscience, certain computational structures and\nalgorithms are known to yield disentangled representations without us\nunderstanding why, the most striking examples being perhaps convolutional\nneural networks and the ventral stream of the visual cortex in humans and\nprimates. As for the latter, it was conjectured that representations may be\ndisentangled by being flattened progressively and at a local scale. An attempt\nat a formalization of the role of invariance in learning representations was\nmade recently, being referred to as I-theory. In this framework and using the\nlanguage of differential geometry, we show that pooling over a group of\ntransformations of the input contracts the metric and reduces its curvature,\nand provide quantitative bounds, in the aim of moving towards a theoretical\nunderstanding on how to disentangle representations. \n\n"}
{"id": "1703.10034", "contents": "Title: Probabilistic Line Searches for Stochastic Optimization Abstract: In deterministic optimization, line searches are a standard tool ensuring\nstability and efficiency. Where only stochastic gradients are available, no\ndirect equivalent has so far been formulated, because uncertain gradients do\nnot allow for a strict sequence of decisions collapsing the search space. We\nconstruct a probabilistic line search by combining the structure of existing\ndeterministic methods with notions from Bayesian optimization. Our method\nretains a Gaussian process surrogate of the univariate optimization objective,\nand uses a probabilistic belief over the Wolfe conditions to monitor the\ndescent. The algorithm has very low computational cost, and no user-controlled\nparameters. Experiments show that it effectively removes the need to define a\nlearning rate for stochastic gradient descent. \n\n"}
{"id": "1703.10840", "contents": "Title: Treewidth distance on phylogenetic trees Abstract: In this article we study the treewidth of the \\emph{display graph}, an\nauxiliary graph structure obtained from the fusion of phylogenetic (i.e.,\nevolutionary) trees at their leaves. Earlier work has shown that the treewidth\nof the display graph is bounded if the trees are in some formal sense\ntopologically similar. Here we further expand upon this relationship. We\nanalyse a number of reduction rules which are commonly used in the\nphylogenetics literature to obtain fixed parameter tractable algorithms. In\nsome cases (the \\emph{subtree} reduction) the reduction rules behave similarly\nwith respect to treewidth, while others (the \\emph{cluster} reduction) behave\nvery differently, and the behaviour of the \\emph{chain reduction} is\nparticularly intriguing because of its link with graph separators and forbidden\nminors. We also show that the gap between treewidth and Tree Bisection and\nReconnect (TBR) distance can be infinitely large, and that unlike, for example,\nplanar graphs the treewidth of the display graph can be as much as linear in\nits number of vertices. On a slightly different note we show that if a display\ngraph is formed from the fusion of a phylogenetic network and a tree, rather\nthan from two trees, the treewidth of the display graph is bounded whenever the\ntree can be topologically embedded (\"displayed\") within the network. This opens\nthe door to the formulation of the display problem in Monadic Second Order\nLogic (MSOL). A number of other auxiliary results are given. We conclude with a\ndiscussion and list a number of open problems. \n\n"}
{"id": "1703.11000", "contents": "Title: Learning Visual Servoing with Deep Features and Fitted Q-Iteration Abstract: Visual servoing involves choosing actions that move a robot in response to\nobservations from a camera, in order to reach a goal configuration in the\nworld. Standard visual servoing approaches typically rely on manually designed\nfeatures and analytical dynamics models, which limits their generalization\ncapability and often requires extensive application-specific feature and model\nengineering. In this work, we study how learned visual features, learned\npredictive dynamics models, and reinforcement learning can be combined to learn\nvisual servoing mechanisms. We focus on target following, with the goal of\ndesigning algorithms that can learn a visual servo using low amounts of data of\nthe target in question, to enable quick adaptation to new targets. Our approach\nis based on servoing the camera in the space of learned visual features, rather\nthan image pixels or manually-designed keypoints. We demonstrate that standard\ndeep features, in our case taken from a model trained for object\nclassification, can be used together with a bilinear predictive model to learn\nan effective visual servo that is robust to visual variation, changes in\nviewing angle and appearance, and occlusions. A key component of our approach\nis to use a sample-efficient fitted Q-iteration algorithm to learn which\nfeatures are best suited for the task at hand. We show that we can learn an\neffective visual servo on a complex synthetic car following benchmark using\njust 20 training trajectory samples for reinforcement learning. We demonstrate\nsubstantial improvement over a conventional approach based on image pixels or\nhand-designed keypoints, and we show an improvement in sample-efficiency of\nmore than two orders of magnitude over standard model-free deep reinforcement\nlearning algorithms. Videos are available at\nhttp://rll.berkeley.edu/visual_servoing . \n\n"}
{"id": "1704.00899", "contents": "Title: Dynamic Rank Maximal Matchings Abstract: We consider the problem of matching applicants to posts where applicants have\npreferences over posts. Thus the input to our problem is a bipartite graph G =\n(A U P,E), where A denotes a set of applicants, P is a set of posts, and there\nare ranks on edges which denote the preferences of applicants over posts. A\nmatching M in G is called rank-maximal if it matches the maximum number of\napplicants to their rank 1 posts, subject to this the maximum number of\napplicants to their rank 2 posts, and so on.\n  We consider this problem in a dynamic setting, where vertices and edges can\nbe added and deleted at any point. Let n and m be the number of vertices and\nedges in an instance G, and r be the maximum rank used by any rank-maximal\nmatching in G. We give a simple O(r(m+n))-time algorithm to update an existing\nrank-maximal matching under each of these changes. When r = o(n), this is\nfaster than recomputing a rank-maximal matching completely using a known\nalgorithm like that of Irving et al., which takes time O(min((r + n,\nr*sqrt(n))m). \n\n"}
{"id": "1704.01460", "contents": "Title: Comparison Based Nearest Neighbor Search Abstract: We consider machine learning in a comparison-based setting where we are given\na set of points in a metric space, but we have no access to the actual\ndistances between the points. Instead, we can only ask an oracle whether the\ndistance between two points $i$ and $j$ is smaller than the distance between\nthe points $i$ and $k$. We are concerned with data structures and algorithms to\nfind nearest neighbors based on such comparisons. We focus on a simple yet\neffective algorithm that recursively splits the space by first selecting two\nrandom pivot points and then assigning all other points to the closer of the\ntwo (comparison tree). We prove that if the metric space satisfies certain\nexpansion conditions, then with high probability the height of the comparison\ntree is logarithmic in the number of points, leading to efficient search\nperformance. We also provide an upper bound for the failure probability to\nreturn the true nearest neighbor. Experiments show that the comparison tree is\ncompetitive with algorithms that have access to the actual distance values, and\nneeds less triplet comparisons than other competitors. \n\n"}
{"id": "1704.01983", "contents": "Title: A Characterization of Undirected Graphs Admitting Optimal Cost Shares Abstract: In a seminal paper, Chen, Roughgarden and Valiant studied cost sharing\nprotocols for network design with the objective to implement a low-cost Steiner\nforest as a Nash equilibrium of an induced cost-sharing game. One of the most\nintriguing open problems to date is to understand the power of budget-balanced\nand separable cost sharing protocols in order to induce low-cost Steiner\nforests. In this work, we focus on undirected networks and analyze topological\nproperties of the underlying graph so that an optimal Steiner forest can be\nimplemented as a Nash equilibrium (by some separable cost sharing protocol)\nindependent of the edge costs. We term a graph efficient if the above stated\nproperty holds. As our main result, we give a complete characterization of\nefficient undirected graphs for two-player network design games: an undirected\ngraph is efficient if and only if it does not contain (at least) one out of few\nforbidden subgraphs. Our characterization implies that several graph classes\nare efficient: generalized series-parallel graphs, fan and wheel graphs and\ngraphs with small cycles. \n\n"}
{"id": "1704.02147", "contents": "Title: Hierarchical Clustering: Objective Functions and Algorithms Abstract: Hierarchical clustering is a recursive partitioning of a dataset into\nclusters at an increasingly finer granularity. Motivated by the fact that most\nwork on hierarchical clustering was based on providing algorithms, rather than\noptimizing a specific objective, Dasgupta framed similarity-based hierarchical\nclustering as a combinatorial optimization problem, where a `good' hierarchical\nclustering is one that minimizes some cost function. He showed that this cost\nfunction has certain desirable properties.\n  We take an axiomatic approach to defining `good' objective functions for both\nsimilarity and dissimilarity-based hierarchical clustering. We characterize a\nset of \"admissible\" objective functions (that includes Dasgupta's one) that\nhave the property that when the input admits a `natural' hierarchical\nclustering, it has an optimal value.\n  Equipped with a suitable objective function, we analyze the performance of\npractical algorithms, as well as develop better algorithms. For\nsimilarity-based hierarchical clustering, Dasgupta showed that the divisive\nsparsest-cut approach achieves an $O(\\log^{3/2} n)$-approximation. We give a\nrefined analysis of the algorithm and show that it in fact achieves an\n$O(\\sqrt{\\log n})$-approx. (Charikar and Chatziafratis independently proved\nthat it is a $O(\\sqrt{\\log n})$-approx.). This improves upon the LP-based\n$O(\\log n)$-approx. of Roy and Pokutta. For dissimilarity-based hierarchical\nclustering, we show that the classic average-linkage algorithm gives a factor 2\napprox., and provide a simple and better algorithm that gives a factor 3/2\napprox..\n  Finally, we consider `beyond-worst-case' scenario through a generalisation of\nthe stochastic block model for hierarchical clustering. We show that Dasgupta's\ncost function has desirable properties for these inputs and we provide a simple\n1 + o(1)-approximation in this setting. \n\n"}
{"id": "1704.02239", "contents": "Title: \\'Echantillonnage de signaux sur graphes via des processus\n  d\\'eterminantaux Abstract: We consider the problem of sampling k-bandlimited graph signals, ie, linear\ncombinations of the first k graph Fourier modes. We know that a set of k nodes\nembedding all k-bandlimited signals always exists, thereby enabling their\nperfect reconstruction after sampling. Unfortunately, to exhibit such a set,\none needs to partially diagonalize the graph Laplacian, which becomes\nprohibitive at large scale. We propose a novel strategy based on determinantal\npoint processes that side-steps partial diagonalisation and enables\nreconstruction with only O(k) samples. While doing so, we exhibit a new general\nalgorithm to sample determinantal process, faster than the state-of-the-art\nalgorithm by an order k. \n\n"}
{"id": "1704.02958", "contents": "Title: On the Fine-Grained Complexity of Empirical Risk Minimization: Kernel\n  Methods and Neural Networks Abstract: Empirical risk minimization (ERM) is ubiquitous in machine learning and\nunderlies most supervised learning methods. While there has been a large body\nof work on algorithms for various ERM problems, the exact computational\ncomplexity of ERM is still not understood. We address this issue for multiple\npopular ERM problems including kernel SVMs, kernel ridge regression, and\ntraining the final layer of a neural network. In particular, we give\nconditional hardness results for these problems based on complexity-theoretic\nassumptions such as the Strong Exponential Time Hypothesis. Under these\nassumptions, we show that there are no algorithms that solve the aforementioned\nERM problems to high accuracy in sub-quadratic time. We also give similar\nhardness results for computing the gradient of the empirical loss, which is the\nmain computational burden in many non-convex learning tasks. \n\n"}
{"id": "1704.03144", "contents": "Title: Parametric Gaussian Process Regression for Big Data Abstract: This work introduces the concept of parametric Gaussian processes (PGPs),\nwhich is built upon the seemingly self-contradictory idea of making Gaussian\nprocesses parametric. Parametric Gaussian processes, by construction, are\ndesigned to operate in \"big data\" regimes where one is interested in\nquantifying the uncertainty associated with noisy data. The proposed\nmethodology circumvents the well-established need for stochastic variational\ninference, a scalable algorithm for approximating posterior distributions. The\neffectiveness of the proposed approach is demonstrated using an illustrative\nexample with simulated data and a benchmark dataset in the airline industry\nwith approximately 6 million records. \n\n"}
{"id": "1704.03371", "contents": "Title: Sublinear Time Low-Rank Approximation of Positive Semidefinite Matrices Abstract: We show how to compute a relative-error low-rank approximation to any\npositive semidefinite (PSD) matrix in sublinear time, i.e., for any $n \\times\nn$ PSD matrix $A$, in $\\tilde O(n \\cdot poly(k/\\epsilon))$ time we output a\nrank-$k$ matrix $B$, in factored form, for which $\\|A-B\\|_F^2 \\leq\n(1+\\epsilon)\\|A-A_k\\|_F^2$, where $A_k$ is the best rank-$k$ approximation to\n$A$. When $k$ and $1/\\epsilon$ are not too large compared to the sparsity of\n$A$, our algorithm does not need to read all entries of the matrix. Hence, we\nsignificantly improve upon previous $nnz(A)$ time algorithms based on oblivious\nsubspace embeddings, and bypass an $nnz(A)$ time lower bound for general\nmatrices (where $nnz(A)$ denotes the number of non-zero entries in the matrix).\nWe prove time lower bounds for low-rank approximation of PSD matrices, showing\nthat our algorithm is close to optimal. Finally, we extend our techniques to\ngive sublinear time algorithms for low-rank approximation of $A$ in the (often\nstronger) spectral norm metric $\\|A-B\\|_2^2$ and for ridge regression on PSD\nmatrices. \n\n"}
{"id": "1704.03976", "contents": "Title: Virtual Adversarial Training: A Regularization Method for Supervised and\n  Semi-Supervised Learning Abstract: We propose a new regularization method based on virtual adversarial loss: a\nnew measure of local smoothness of the conditional label distribution given\ninput. Virtual adversarial loss is defined as the robustness of the conditional\nlabel distribution around each input data point against local perturbation.\nUnlike adversarial training, our method defines the adversarial direction\nwithout label information and is hence applicable to semi-supervised learning.\nBecause the directions in which we smooth the model are only \"virtually\"\nadversarial, we call our method virtual adversarial training (VAT). The\ncomputational cost of VAT is relatively low. For neural networks, the\napproximated gradient of virtual adversarial loss can be computed with no more\nthan two pairs of forward- and back-propagations. In our experiments, we\napplied VAT to supervised and semi-supervised learning tasks on multiple\nbenchmark datasets. With a simple enhancement of the algorithm based on the\nentropy minimization principle, our VAT achieves state-of-the-art performance\nfor semi-supervised learning tasks on SVHN and CIFAR-10. \n\n"}
{"id": "1704.04163", "contents": "Title: Spectrum Approximation Beyond Fast Matrix Multiplication: Algorithms and\n  Hardness Abstract: Understanding the singular value spectrum of a matrix $A \\in \\mathbb{R}^{n\n\\times n}$ is a fundamental task in countless applications. In matrix\nmultiplication time, it is possible to perform a full SVD and directly compute\nthe singular values $\\sigma_1,...,\\sigma_n$. However, little is known about\nalgorithms that break this runtime barrier.\n  Using tools from stochastic trace estimation, polynomial approximation, and\nfast system solvers, we show how to efficiently isolate different ranges of\n$A$'s spectrum and approximate the number of singular values in these ranges.\nWe thus effectively compute a histogram of the spectrum, which can stand in for\nthe true singular values in many applications.\n  We use this primitive to give the first algorithms for approximating a wide\nclass of symmetric matrix norms in faster than matrix multiplication time. For\nexample, we give a $(1 + \\epsilon)$ approximation algorithm for the\nSchatten-$1$ norm (the nuclear norm) running in just $\\tilde O((nnz(A)n^{1/3} +\nn^2)\\epsilon^{-3})$ time for $A$ with uniform row sparsity or $\\tilde\nO(n^{2.18} \\epsilon^{-3})$ time for dense matrices. The runtime scales smoothly\nfor general Schatten-$p$ norms, notably becoming $\\tilde O (p \\cdot nnz(A)\n\\epsilon^{-3})$ for any $p \\ge 2$.\n  At the same time, we show that the complexity of spectrum approximation is\ninherently tied to fast matrix multiplication in the small $\\epsilon$ regime.\nWe prove that achieving milder $\\epsilon$ dependencies in our algorithms would\nimply faster than matrix multiplication time triangle detection for general\ngraphs. This further implies that highly accurate algorithms running in\nsubcubic time yield subcubic time matrix multiplication. As an application of\nour bounds, we show that precisely computing all effective resistances in a\ngraph in less than matrix multiplication time is likely difficult, barring a\nmajor algorithmic breakthrough. \n\n"}
{"id": "1704.07067", "contents": "Title: Rerouting flows when links fail Abstract: We introduce and investigate reroutable flows, a robust version of network\nflows in which link failures can be mitigated by rerouting the affected flow.\nGiven a capacitated network, a path flow is reroutable if after failure of an\narbitrary arc, we can reroute the interrupted flow from the tail of that arc to\nthe sink, without modifying the flow that is not affected by the failure.\nSimilar types of restoration, which are often termed \"local\", were previously\ninvestigated in the context of network design, such as min-cost capacity\nplanning. In this paper, our interest is in computing maximum flows under this\nrobustness assumption. An important new feature of our model, distinguishing it\nfrom existing max robust flow models, is that no flow can get lost in the\nnetwork.\n  We also study a tightening of reroutable flows, called strictly reroutable\nflows, making more restrictive assumptions on the capacities available for\nrerouting. For both variants, we devise a reroutable-flow equivalent of an\ns-t-cut and show that the corresponding max flow/min cut gap is bounded by 2.\nIt turns out that a strictly reroutable flow of maximum value can be found\nusing a compact LP formulation, whereas the problem of finding a maximum\nreroutable flow is NP-hard, even when all capacities are in {1, 2}. However,\nthe tightening can be used to get a 2-approximation for reroutable flows. This\nratio is tight in general networks, but we show that in the case of unit\ncapacities, every reroutable flow can be transformed into a strictly reroutable\nflow of same value. While it is NP-hard to compute a maximal integral flow even\nfor unit capacities, we devise a surprisingly simple combinatorial algorithm\nthat finds a half-integral strictly reroutable flow of value 1, or certifies\nthat no such solutions exits. Finally, we also give a hardness result for the\ncase of multiple arc failures. \n\n"}
{"id": "1704.07147", "contents": "Title: A Neural Network model with Bidirectional Whitening Abstract: We present here a new model and algorithm which performs an efficient Natural\ngradient descent for Multilayer Perceptrons. Natural gradient descent was\noriginally proposed from a point of view of information geometry, and it\nperforms the steepest descent updates on manifolds in a Riemannian space. In\nparticular, we extend an approach taken by the \"Whitened neural networks\"\nmodel. We make the whitening process not only in feed-forward direction as in\nthe original model, but also in the back-propagation phase. Its efficacy is\nshown by an application of this \"Bidirectional whitened neural networks\" model\nto a handwritten character recognition data (MNIST data). \n\n"}
{"id": "1704.07487", "contents": "Title: Bootstrapping Graph Convolutional Neural Networks for Autism Spectrum\n  Disorder Classification Abstract: Using predictive models to identify patterns that can act as biomarkers for\ndifferent neuropathoglogical conditions is becoming highly prevalent. In this\npaper, we consider the problem of Autism Spectrum Disorder (ASD) classification\nwhere previous work has shown that it can be beneficial to incorporate a wide\nvariety of meta features, such as socio-cultural traits, into predictive\nmodeling. A graph-based approach naturally suits these scenarios, where a\ncontextual graph captures traits that characterize a population, while the\nspecific brain activity patterns are utilized as a multivariate signal at the\nnodes. Graph neural networks have shown improvements in inferencing with\ngraph-structured data. Though the underlying graph strongly dictates the\noverall performance, there exists no systematic way of choosing an appropriate\ngraph in practice, thus making predictive models non-robust. To address this,\nwe propose a bootstrapped version of graph convolutional neural networks\n(G-CNNs) that utilizes an ensemble of weakly trained G-CNNs, and reduce the\nsensitivity of models on the choice of graph construction. We demonstrate its\neffectiveness on the challenging Autism Brain Imaging Data Exchange (ABIDE)\ndataset and show that our approach improves upon recently proposed graph-based\nneural networks. We also show that our method remains more robust to noisy\ngraphs. \n\n"}
{"id": "1704.07669", "contents": "Title: Single-Pass PCA of Large High-Dimensional Data Abstract: Principal component analysis (PCA) is a fundamental dimension reduction tool\nin statistics and machine learning. For large and high-dimensional data,\ncomputing the PCA (i.e., the singular vectors corresponding to a number of\ndominant singular values of the data matrix) becomes a challenging task. In\nthis work, a single-pass randomized algorithm is proposed to compute PCA with\nonly one pass over the data. It is suitable for processing extremely large and\nhigh-dimensional data stored in slow memory (hard disk) or the data generated\nin a streaming fashion. Experiments with synthetic and real data validate the\nalgorithm's accuracy, which has orders of magnitude smaller error than an\nexisting single-pass algorithm. For a set of high-dimensional data stored as a\n150 GB file, the proposed algorithm is able to compute the first 50 principal\ncomponents in just 24 minutes on a typical 24-core computer, with less than 1\nGB memory cost. \n\n"}
{"id": "1704.07820", "contents": "Title: Introspective Generative Modeling: Decide Discriminatively Abstract: We study unsupervised learning by developing introspective generative\nmodeling (IGM) that attains a generator using progressively learned deep\nconvolutional neural networks. The generator is itself a discriminator, capable\nof introspection: being able to self-evaluate the difference between its\ngenerated samples and the given training data. When followed by repeated\ndiscriminative learning, desirable properties of modern discriminative\nclassifiers are directly inherited by the generator. IGM learns a cascade of\nCNN classifiers using a synthesis-by-classification algorithm. In the\nexperiments, we observe encouraging results on a number of applications\nincluding texture modeling, artistic style transferring, face modeling, and\nsemi-supervised learning. \n\n"}
{"id": "1705.00813", "contents": "Title: Transforming Bell's Inequalities into State Classifiers with Machine\n  Learning Abstract: Quantum information science has profoundly changed the ways we understand,\nstore, and process information. A major challenge in this field is to look for\nan efficient means for classifying quantum state. For instance, one may want to\ndetermine if a given quantum state is entangled or not. However, the process of\na complete characterization of quantum states, known as quantum state\ntomography, is a resource-consuming operation in general. An attractive\nproposal would be the use of Bell's inequalities as an entanglement witness,\nwhere only partial information of the quantum state is needed. The problem is\nthat entanglement is necessary but not sufficient for violating Bell's\ninequalities, making it an unreliable state classifier. Here we aim at solving\nthis problem by the methods of machine learning. More precisely, given a family\nof quantum states, we randomly picked a subset of it to construct a\nquantum-state classifier, accepting only partial information of each quantum\nstate. Our results indicated that these transformed Bell-type inequalities can\nperform significantly better than the original Bell's inequalities in\nclassifying entangled states. We further extended our analysis to three-qubit\nand four-qubit systems, performing classification of quantum states into\nmultiple species. These results demonstrate how the tools in machine learning\ncan be applied to solving problems in quantum information science. \n\n"}
{"id": "1705.03557", "contents": "Title: DeepTingle Abstract: DeepTingle is a text prediction and classification system trained on the\ncollected works of the renowned fantastic gay erotica author Chuck Tingle.\nWhereas the writing assistance tools you use everyday (in the form of\npredictive text, translation, grammar checking and so on) are trained on\ngeneric, purportedly \"neutral\" datasets, DeepTingle is trained on a very\nspecific, internally consistent but externally arguably eccentric dataset. This\nallows us to foreground and confront the norms embedded in data-driven\ncreativity and productivity assistance tools. As such tools effectively\nfunction as extensions of our cognition into technology, it is important to\nidentify the norms they embed within themselves and, by extension, us.\nDeepTingle is realized as a web application based on LSTM networks and the\nGloVe word embedding, implemented in JavaScript with Keras-JS. \n\n"}
{"id": "1705.03881", "contents": "Title: Net2Vec: Deep Learning for the Network Abstract: We present Net2Vec, a flexible high-performance platform that allows the\nexecution of deep learning algorithms in the communication network. Net2Vec is\nable to capture data from the network at more than 60Gbps, transform it into\nmeaningful tuples and apply predictions over the tuples in real time. This\nplatform can be used for different purposes ranging from traffic classification\nto network performance analysis.\n  Finally, we showcase the use of Net2Vec by implementing and testing a\nsolution able to profile network users at line rate using traces coming from a\nreal network. We show that the use of deep learning for this case outperforms\nthe baseline method both in terms of accuracy and performance. \n\n"}
{"id": "1705.06319", "contents": "Title: Constrained Submodular Maximization via Greedy Local Search Abstract: We present a simple combinatorial $\\frac{1 -e^{-2}}{2}$-approximation\nalgorithm for maximizing a monotone submodular function subject to a knapsack\nand a matroid constraint.\n  This classic problem is known to be hard to approximate within factor better\nthan $1 - 1/e$. We show that the algorithm can be extended to yield a ratio of\n$\\frac{1 - e^{-(k+1)}}{k+1}$ for the problem with a single knapsack and the\nintersection of $k$ matroid constraints, for any fixed $k > 1$.\n  Our algorithms, which combine the greedy algorithm of [Khuller, Moss and\nNaor, 1999] and [Sviridenko, 2004] with local search, show the power of this\nnatural framework in submodular maximization with combined constraints. \n\n"}
{"id": "1705.06769", "contents": "Title: Feature Control as Intrinsic Motivation for Hierarchical Reinforcement\n  Learning Abstract: The problem of sparse rewards is one of the hardest challenges in\ncontemporary reinforcement learning. Hierarchical reinforcement learning (HRL)\ntackles this problem by using a set of temporally-extended actions, or options,\neach of which has its own subgoal. These subgoals are normally handcrafted for\nspecific tasks. Here, though, we introduce a generic class of subgoals with\nbroad applicability in the visual domain. Underlying our approach (in common\nwith work using \"auxiliary tasks\") is the hypothesis that the ability to\ncontrol aspects of the environment is an inherently useful skill to have. We\nincorporate such subgoals in an end-to-end hierarchical reinforcement learning\nsystem and test two variants of our algorithm on a number of games from the\nAtari suite. We highlight the advantage of our approach in one of the hardest\ngames -- Montezuma's revenge -- for which the ability to handle sparse rewards\nis key. Our agent learns several times faster than the current state-of-the-art\nHRL agent in this game, reaching a similar level of performance. UPDATE\n22/11/17: We found that a standard A3C agent with a simple shaped reward, i.e.\nextrinsic reward + feature control intrinsic reward, has comparable performance\nto our agent in Montezuma Revenge. In light of the new experiments performed,\nthe advantage of our HRL approach can be attributed more to its ability to\nlearn useful features from intrinsic rewards rather than its ability to explore\nand reuse abstracted skills with hierarchical components. This has led us to a\nnew conclusion about the result. \n\n"}
{"id": "1705.07107", "contents": "Title: Gradient Estimators for Implicit Models Abstract: Implicit models, which allow for the generation of samples but not for\npoint-wise evaluation of probabilities, are omnipresent in real-world problems\ntackled by machine learning and a hot topic of current research. Some examples\ninclude data simulators that are widely used in engineering and scientific\nresearch, generative adversarial networks (GANs) for image synthesis, and\nhot-off-the-press approximate inference techniques relying on implicit\ndistributions. The majority of existing approaches to learning implicit models\nrely on approximating the intractable distribution or optimisation objective\nfor gradient-based optimisation, which is liable to produce inaccurate updates\nand thus poor models. This paper alleviates the need for such approximations by\nproposing the Stein gradient estimator, which directly estimates the score\nfunction of the implicitly defined distribution. The efficacy of the proposed\nestimator is empirically demonstrated by examples that include meta-learning\nfor approximate inference, and entropy regularised GANs that provide improved\nsample diversity. \n\n"}
{"id": "1705.07157", "contents": "Title: Clustering under Local Stability: Bridging the Gap between Worst-Case\n  and Beyond Worst-Case Analysis Abstract: Recently, there has been substantial interest in clustering research that\ntakes a beyond worst-case approach to the analysis of algorithms. The typical\nidea is to design a clustering algorithm that outputs a near-optimal solution,\nprovided the data satisfy a natural stability notion. For example, Bilu and\nLinial (2010) and Awasthi et al. (2012) presented algorithms that output\nnear-optimal solutions, assuming the optimal solution is preserved under small\nperturbations to the input distances. A drawback to this approach is that the\nalgorithms are often explicitly built according to the stability assumption and\ngive no guarantees in the worst case; indeed, several recent algorithms output\narbitrarily bad solutions even when just a small section of the data does not\nsatisfy the given stability notion.\n  In this work, we address this concern in two ways. First, we provide\nalgorithms that inherit the worst-case guarantees of clustering approximation\nalgorithms, while simultaneously guaranteeing near-optimal solutions when the\ndata is stable. Our algorithms are natural modifications to existing\nstate-of-the-art approximation algorithms. Second, we initiate the study of\nlocal stability, which is a property of a single optimal cluster rather than an\nentire optimal solution. We show our algorithms output all optimal clusters\nwhich satisfy stability locally. Specifically, we achieve strong positive\nresults in our local framework under recent stability notions including metric\nperturbation resilience (Angelidakis et al. 2017) and robust perturbation\nresilience (Balcan and Liang 2012) for the $k$-median, $k$-means, and\nsymmetric/asymmetric $k$-center objectives. \n\n"}
{"id": "1705.07164", "contents": "Title: Relaxed Wasserstein with Applications to GANs Abstract: Wasserstein Generative Adversarial Networks (WGANs) provide a versatile class\nof models, which have attracted great attention in various applications.\nHowever, this framework has two main drawbacks: (i) Wasserstein-1 (or\nEarth-Mover) distance is restrictive such that WGANs cannot always fit data\ngeometry well; (ii) It is difficult to achieve fast training of WGANs. In this\npaper, we propose a new class of \\textit{Relaxed Wasserstein} (RW) distances by\ngeneralizing Wasserstein-1 distance with Bregman cost functions. We show that\nRW distances achieve nice statistical properties while not sacrificing the\ncomputational tractability. Combined with the GANs framework, we develop\nRelaxed WGANs (RWGANs) which are not only statistically flexible but can be\napproximated efficiently using heuristic approaches. Experiments on real images\ndemonstrate that the RWGAN with Kullback-Leibler (KL) cost function outperforms\nother competing approaches, e.g., WGANs, even with gradient penalty. \n\n"}
{"id": "1705.07208", "contents": "Title: PixColor: Pixel Recursive Colorization Abstract: We propose a novel approach to automatically produce multiple colorized\nversions of a grayscale image. Our method results from the observation that the\ntask of automated colorization is relatively easy given a low-resolution\nversion of the color image. We first train a conditional PixelCNN to generate a\nlow resolution color for a given grayscale image. Then, given the generated\nlow-resolution color image and the original grayscale image as inputs, we train\na second CNN to generate a high-resolution colorization of an image. We\ndemonstrate that our approach produces more diverse and plausible colorizations\nthan existing methods, as judged by human raters in a \"Visual Turing Test\". \n\n"}
{"id": "1705.08922", "contents": "Title: Exploring the Regularity of Sparse Structure in Convolutional Neural\n  Networks Abstract: Sparsity helps reduce the computational complexity of deep neural networks by\nskipping zeros. Taking advantage of sparsity is listed as a high priority in\nnext generation DNN accelerators such as TPU. The structure of sparsity, i.e.,\nthe granularity of pruning, affects the efficiency of hardware accelerator\ndesign as well as the prediction accuracy. Coarse-grained pruning creates\nregular sparsity patterns, making it more amenable for hardware acceleration\nbut more challenging to maintain the same accuracy. In this paper we\nquantitatively measure the trade-off between sparsity regularity and prediction\naccuracy, providing insights in how to maintain accuracy while having more a\nmore structured sparsity pattern. Our experimental results show that\ncoarse-grained pruning can achieve a sparsity ratio similar to unstructured\npruning without loss of accuracy. Moreover, due to the index saving effect,\ncoarse-grained pruning is able to obtain a better compression ratio than\nfine-grained sparsity at the same accuracy threshold. Based on the recent\nsparse convolutional neural network accelerator (SCNN), our experiments further\ndemonstrate that coarse-grained sparsity saves about 2x the memory references\ncompared to fine-grained sparsity. Since memory reference is more than two\norders of magnitude more expensive than arithmetic operations, the regularity\nof sparse structure leads to more efficient hardware design. \n\n"}
{"id": "1705.09700", "contents": "Title: Multi-scale Online Learning and its Applications to Online Auctions Abstract: We consider revenue maximization in online auction/pricing problems. A seller\nsells an identical item in each period to a new buyer, or a new set of buyers.\nFor the online posted pricing problem, we show regret bounds that scale with\nthe best fixed price, rather than the range of the values. We also show regret\nbounds that are almost scale free, and match the offline sample complexity,\nwhen comparing to a benchmark that requires a lower bound on the market share.\nThese results are obtained by generalizing the classical learning from experts\nand multi-armed bandit problems to their multi-scale versions. In this version,\nthe reward of each action is in a different range, and the regret w.r.t. a\ngiven action scales with its own range, rather than the maximum range. \n\n"}
{"id": "1705.09786", "contents": "Title: AMPNet: Asynchronous Model-Parallel Training for Dynamic Neural Networks Abstract: New types of machine learning hardware in development and entering the market\nhold the promise of revolutionizing deep learning in a manner as profound as\nGPUs. However, existing software frameworks and training algorithms for deep\nlearning have yet to evolve to fully leverage the capability of the new wave of\nsilicon. We already see the limitations of existing algorithms for models that\nexploit structured input via complex and instance-dependent control flow, which\nprohibits minibatching. We present an asynchronous model-parallel (AMP)\ntraining algorithm that is specifically motivated by training on networks of\ninterconnected devices. Through an implementation on multi-core CPUs, we show\nthat AMP training converges to the same accuracy as conventional synchronous\ntraining algorithms in a similar number of epochs, but utilizes the available\nhardware more efficiently even for small minibatch sizes, resulting in\nsignificantly shorter overall training times. Our framework opens the door for\nscaling up a new class of deep learning models that cannot be efficiently\ntrained today. \n\n"}
{"id": "1705.10494", "contents": "Title: Joint auto-encoders: a flexible multi-task learning framework Abstract: The incorporation of prior knowledge into learning is essential in achieving\ngood performance based on small noisy samples. Such knowledge is often\nincorporated through the availability of related data arising from domains and\ntasks similar to the one of current interest. Ideally one would like to allow\nboth the data for the current task and for previous related tasks to\nself-organize the learning system in such a way that commonalities and\ndifferences between the tasks are learned in a data-driven fashion. We develop\na framework for learning multiple tasks simultaneously, based on sharing\nfeatures that are common to all tasks, achieved through the use of a modular\ndeep feedforward neural network consisting of shared branches, dealing with the\ncommon features of all tasks, and private branches, learning the specific\nunique aspects of each task. Once an appropriate weight sharing architecture\nhas been established, learning takes place through standard algorithms for\nfeedforward networks, e.g., stochastic gradient descent and its variations. The\nmethod deals with domain adaptation and multi-task learning in a unified\nfashion, and can easily deal with data arising from different types of sources.\nNumerical experiments demonstrate the effectiveness of learning in domain\nadaptation and transfer learning setups, and provide evidence for the flexible\nand task-oriented representations arising in the network. \n\n"}
{"id": "1705.10723", "contents": "Title: Fast Regression with an $\\ell_\\infty$ Guarantee Abstract: Sketching has emerged as a powerful technique for speeding up problems in\nnumerical linear algebra, such as regression. In the overconstrained regression\nproblem, one is given an $n \\times d$ matrix $A$, with $n \\gg d$, as well as an\n$n \\times 1$ vector $b$, and one wants to find a vector $\\hat{x}$ so as to\nminimize the residual error $\\|Ax-b\\|_2$. Using the sketch and solve paradigm,\none first computes $S \\cdot A$ and $S \\cdot b$ for a randomly chosen matrix\n$S$, then outputs $x' = (SA)^{\\dagger} Sb$ so as to minimize $\\|SAx' - Sb\\|_2$.\n  The sketch-and-solve paradigm gives a bound on $\\|x'-x^*\\|_2$ when $A$ is\nwell-conditioned. Our main result is that, when $S$ is the subsampled\nrandomized Fourier/Hadamard transform, the error $x' - x^*$ behaves as if it\nlies in a \"random\" direction within this bound: for any fixed direction $a\\in\n\\mathbb{R}^d$, we have with $1 - d^{-c}$ probability that\n  \\[\n  \\langle a, x'-x^*\\rangle \\lesssim\n\\frac{\\|a\\|_2\\|x'-x^*\\|_2}{d^{\\frac{1}{2}-\\gamma}}, \\quad (1)\n  \\]\n  where $c, \\gamma > 0$ are arbitrary constants.\n  This implies $\\|x'-x^*\\|_{\\infty}$ is a factor $d^{\\frac{1}{2}-\\gamma}$\nsmaller than $\\|x'-x^*\\|_2$. It also gives a better bound on the generalization\nof $x'$ to new examples: if rows of $A$ correspond to examples and columns to\nfeatures, then our result gives a better bound for the error introduced by\nsketch-and-solve when classifying fresh examples. We show that not all\noblivious subspace embeddings $S$ satisfy these properties. In particular, we\ngive counterexamples showing that matrices based on Count-Sketch or leverage\nscore sampling do not satisfy these properties.\n  We also provide lower bounds, both on how small $\\|x'-x^*\\|_2$ can be, and\nfor our new guarantee (1), showing that the subsampled randomized\nFourier/Hadamard transform is nearly optimal. \n\n"}
{"id": "1706.00400", "contents": "Title: Learning Disentangled Representations with Semi-Supervised Deep\n  Generative Models Abstract: Variational autoencoders (VAEs) learn representations of data by jointly\ntraining a probabilistic encoder and decoder network. Typically these models\nencode all features of the data into a single variable. Here we are interested\nin learning disentangled representations that encode distinct aspects of the\ndata into separate variables. We propose to learn such representations using\nmodel architectures that generalise from standard VAEs, employing a general\ngraphical model structure in the encoder and decoder. This allows us to train\npartially-specified models that make relatively strong assumptions about a\nsubset of interpretable variables and rely on the flexibility of neural\nnetworks to learn representations for the remaining variables. We further\ndefine a general objective for semi-supervised learning in this model class,\nwhich can be approximated using an importance sampling procedure. We evaluate\nour framework's ability to learn disentangled representations, both by\nqualitative exploration of its generative capacity, and quantitative evaluation\nof its discriminative ability on a variety of models and datasets. \n\n"}
{"id": "1706.02409", "contents": "Title: A Convex Framework for Fair Regression Abstract: We introduce a flexible family of fairness regularizers for (linear and\nlogistic) regression problems. These regularizers all enjoy convexity,\npermitting fast optimization, and they span the rang from notions of group\nfairness to strong individual fairness. By varying the weight on the fairness\nregularizer, we can compute the efficient frontier of the accuracy-fairness\ntrade-off on any given dataset, and we measure the severity of this trade-off\nvia a numerical quantity we call the Price of Fairness (PoF). The centerpiece\nof our results is an extensive comparative study of the PoF across six\ndifferent datasets in which fairness is a primary consideration. \n\n"}
{"id": "1706.02899", "contents": "Title: Assessing the Performance of Deep Learning Algorithms for Newsvendor\n  Problem Abstract: In retailer management, the Newsvendor problem has widely attracted attention\nas one of basic inventory models. In the traditional approach to solving this\nproblem, it relies on the probability distribution of the demand. In theory, if\nthe probability distribution is known, the problem can be considered as fully\nsolved. However, in any real world scenario, it is almost impossible to even\napproximate or estimate a better probability distribution for the demand. In\nrecent years, researchers start adopting machine learning approach to learn a\ndemand prediction model by using other feature information. In this paper, we\npropose a supervised learning that optimizes the demand quantities for products\nbased on feature information. We demonstrate that the original Newsvendor loss\nfunction as the training objective outperforms the recently suggested quadratic\nloss function. The new algorithm has been assessed on both the synthetic data\nand real-world data, demonstrating better performance. \n\n"}
{"id": "1706.03583", "contents": "Title: Streaming Non-monotone Submodular Maximization: Personalized Video\n  Summarization on the Fly Abstract: The need for real time analysis of rapidly producing data streams (e.g.,\nvideo and image streams) motivated the design of streaming algorithms that can\nefficiently extract and summarize useful information from massive data \"on the\nfly\". Such problems can often be reduced to maximizing a submodular set\nfunction subject to various constraints. While efficient streaming methods have\nbeen recently developed for monotone submodular maximization, in a wide range\nof applications, such as video summarization, the underlying utility function\nis non-monotone, and there are often various constraints imposed on the\noptimization problem to consider privacy or personalization. We develop the\nfirst efficient single pass streaming algorithm, Streaming Local Search, that\nfor any streaming monotone submodular maximization algorithm with approximation\nguarantee $\\alpha$ under a collection of independence systems ${\\cal I}$,\nprovides a constant $1/\\big(1+2/\\sqrt{\\alpha}+1/\\alpha\n+2d(1+\\sqrt{\\alpha})\\big)$ approximation guarantee for maximizing a\nnon-monotone submodular function under the intersection of ${\\cal I}$ and $d$\nknapsack constraints. Our experiments show that for video summarization, our\nmethod runs more than 1700 times faster than previous work, while maintaining\npractically the same performance. \n\n"}
{"id": "1706.04115", "contents": "Title: Zero-Shot Relation Extraction via Reading Comprehension Abstract: We show that relation extraction can be reduced to answering simple reading\ncomprehension questions, by associating one or more natural-language questions\nwith each relation slot. This reduction has several advantages: we can (1)\nlearn relation-extraction models by extending recent neural\nreading-comprehension techniques, (2) build very large training sets for those\nmodels by combining relation-specific crowd-sourced questions with distant\nsupervision, and even (3) do zero-shot learning by extracting new relation\ntypes that are only specified at test-time, for which we have no labeled\ntraining examples. Experiments on a Wikipedia slot-filling task demonstrate\nthat the approach can generalize to new questions for known relation types with\nhigh accuracy, and that zero-shot generalization to unseen relation types is\npossible, at lower accuracy levels, setting the bar for future work on this\ntask. \n\n"}
{"id": "1706.07881", "contents": "Title: On Sampling Strategies for Neural Network-based Collaborative Filtering Abstract: Recent advances in neural networks have inspired people to design hybrid\nrecommendation algorithms that can incorporate both (1) user-item interaction\ninformation and (2) content information including image, audio, and text.\nDespite their promising results, neural network-based recommendation algorithms\npose extensive computational costs, making it challenging to scale and improve\nupon. In this paper, we propose a general neural network-based recommendation\nframework, which subsumes several existing state-of-the-art recommendation\nalgorithms, and address the efficiency issue by investigating sampling\nstrategies in the stochastic gradient descent training for the framework. We\ntackle this issue by first establishing a connection between the loss functions\nand the user-item interaction bipartite graph, where the loss function terms\nare defined on links while major computation burdens are located at nodes. We\ncall this type of loss functions \"graph-based\" loss functions, for which varied\nmini-batch sampling strategies can have different computational costs. Based on\nthe insight, three novel sampling strategies are proposed, which can\nsignificantly improve the training efficiency of the proposed framework (up to\n$\\times 30$ times speedup in our experiments), as well as improving the\nrecommendation performance. Theoretical analysis is also provided for both the\ncomputational cost and the convergence. We believe the study of sampling\nstrategies have further implications on general graph-based loss functions, and\nwould also enable more research under the neural network-based recommendation\nframework. \n\n"}
{"id": "1706.09293", "contents": "Title: Concentration of tempered posteriors and of their variational\n  approximations Abstract: While Bayesian methods are extremely popular in statistics and machine\nlearning, their application to massive datasets is often challenging, when\npossible at all. Indeed, the classical MCMC algorithms are prohibitively slow\nwhen both the model dimension and the sample size are large. Variational\nBayesian methods aim at approximating the posterior by a distribution in a\ntractable family. Thus, MCMC are replaced by an optimization algorithm which is\norders of magnitude faster. VB methods have been applied in such\ncomputationally demanding applications as including collaborative filtering,\nimage and video processing, NLP and text processing... However, despite very\nnice results in practice, the theoretical properties of these approximations\nare usually not known. In this paper, we propose a general approach to prove\nthe concentration of variational approximations of fractional posteriors. We\napply our theory to two examples: matrix completion, and Gaussian VB. \n\n"}
{"id": "1707.00300", "contents": "Title: Stochastic Configuration Networks Ensemble for Large-Scale Data\n  Analytics Abstract: This paper presents a fast decorrelated neuro-ensemble with heterogeneous\nfeatures for large-scale data analytics, where stochastic configuration\nnetworks (SCNs) are employed as base learner models and the well-known negative\ncorrelation learning (NCL) strategy is adopted to evaluate the output weights.\nBy feeding a large number of samples into the SCN base models, we obtain a huge\nsized linear equation system which is difficult to be solved by means of\ncomputing a pseudo-inverse used in the least squares method. Based on the group\nof heterogeneous features, the block Jacobi and Gauss-Seidel methods are\nemployed to iteratively evaluate the output weights, and a convergence analysis\nis given with a demonstration on the uniqueness of these iterative solutions.\nExperiments with comparisons on two large-scale datasets are carried out, and\nthe system robustness with respect to the regularizing factor used in NCL is\ngiven. Results indicate that the proposed ensemble learning techniques have\ngood potential for resolving large-scale data modelling problems. \n\n"}
{"id": "1707.00389", "contents": "Title: Convolutional Dictionary Learning: Acceleration and Convergence Abstract: Convolutional dictionary learning (CDL or sparsifying CDL) has many\napplications in image processing and computer vision. There has been growing\ninterest in developing efficient algorithms for CDL, mostly relying on the\naugmented Lagrangian (AL) method or the variant alternating direction method of\nmultipliers (ADMM). When their parameters are properly tuned, AL methods have\nshown fast convergence in CDL. However, the parameter tuning process is not\ntrivial due to its data dependence and, in practice, the convergence of AL\nmethods depends on the AL parameters for nonconvex CDL problems. To moderate\nthese problems, this paper proposes a new practically feasible and convergent\nBlock Proximal Gradient method using a Majorizer (BPG-M) for CDL. The\nBPG-M-based CDL is investigated with different block updating schemes and\nmajorization matrix designs, and further accelerated by incorporating some\nmomentum coefficient formulas and restarting techniques. All of the methods\ninvestigated incorporate a boundary artifacts removal (or, more generally,\nsampling) operator in the learning model. Numerical experiments show that,\nwithout needing any parameter tuning process, the proposed BPG-M approach\nconverges more stably to desirable solutions of lower objective values than the\nexisting state-of-the-art ADMM algorithm and its memory-efficient variant do.\nCompared to the ADMM approaches, the BPG-M method using a multi-block updating\nscheme is particularly useful in single-threaded CDL algorithm handling large\ndatasets, due to its lower memory requirement and no polynomial computational\ncomplexity. Image denoising experiments show that, for relatively strong\nadditive white Gaussian noise, the filters learned by BPG-M-based CDL\noutperform those trained by the ADMM approach. \n\n"}
{"id": "1707.01945", "contents": "Title: Simple Classification using Binary Data Abstract: Binary, or one-bit, representations of data arise naturally in many\napplications, and are appealing in both hardware implementations and algorithm\ndesign. In this work, we study the problem of data classification from binary\ndata and propose a framework with low computation and resource costs. We\nillustrate the utility of the proposed approach through stylized and realistic\nnumerical experiments, and provide a theoretical analysis for a simple case. We\nhope that our framework and analysis will serve as a foundation for studying\nsimilar types of approaches. \n\n"}
{"id": "1707.02038", "contents": "Title: A Tutorial on Thompson Sampling Abstract: Thompson sampling is an algorithm for online decision problems where actions\nare taken sequentially in a manner that must balance between exploiting what is\nknown to maximize immediate performance and investing to accumulate new\ninformation that may improve future performance. The algorithm addresses a\nbroad range of problems in a computationally efficient manner and is therefore\nenjoying wide use. This tutorial covers the algorithm and its application,\nillustrating concepts through a range of examples, including Bernoulli bandit\nproblems, shortest path problems, product recommendation, assortment, active\nlearning with neural networks, and reinforcement learning in Markov decision\nprocesses. Most of these problems involve complex information structures, where\ninformation revealed by taking an action informs beliefs about other actions.\nWe will also discuss when and why Thompson sampling is or is not effective and\nrelations to alternative algorithms. \n\n"}
{"id": "1707.02657", "contents": "Title: PELESent: Cross-domain polarity classification using distant supervision Abstract: The enormous amount of texts published daily by Internet users has fostered\nthe development of methods to analyze this content in several natural language\nprocessing areas, such as sentiment analysis. The main goal of this task is to\nclassify the polarity of a message. Even though many approaches have been\nproposed for sentiment analysis, some of the most successful ones rely on the\navailability of large annotated corpus, which is an expensive and\ntime-consuming process. In recent years, distant supervision has been used to\nobtain larger datasets. So, inspired by these techniques, in this paper we\nextend such approaches to incorporate popular graphic symbols used in\nelectronic messages, the emojis, in order to create a large sentiment corpus\nfor Portuguese. Trained on almost one million tweets, several models were\ntested in both same domain and cross-domain corpora. Our methods obtained very\ncompetitive results in five annotated corpora from mixed domains (Twitter and\nproduct reviews), which proves the domain-independent property of such\napproach. In addition, our results suggest that the combination of emoticons\nand emojis is able to properly capture the sentiment of a message. \n\n"}
{"id": "1707.02670", "contents": "Title: Accelerated Stochastic Power Iteration Abstract: Principal component analysis (PCA) is one of the most powerful tools in\nmachine learning. The simplest method for PCA, the power iteration, requires\n$\\mathcal O(1/\\Delta)$ full-data passes to recover the principal component of a\nmatrix with eigen-gap $\\Delta$. Lanczos, a significantly more complex method,\nachieves an accelerated rate of $\\mathcal O(1/\\sqrt{\\Delta})$ passes. Modern\napplications, however, motivate methods that only ingest a subset of available\ndata, known as the stochastic setting. In the online stochastic setting, simple\nalgorithms like Oja's iteration achieve the optimal sample complexity $\\mathcal\nO(\\sigma^2/\\Delta^2)$. Unfortunately, they are fully sequential, and also\nrequire $\\mathcal O(\\sigma^2/\\Delta^2)$ iterations, far from the $\\mathcal\nO(1/\\sqrt{\\Delta})$ rate of Lanczos. We propose a simple variant of the power\niteration with an added momentum term, that achieves both the optimal sample\nand iteration complexity. In the full-pass setting, standard analysis shows\nthat momentum achieves the accelerated rate, $\\mathcal O(1/\\sqrt{\\Delta})$. We\ndemonstrate empirically that naively applying momentum to a stochastic method,\ndoes not result in acceleration. We perform a novel, tight variance analysis\nthat reveals the \"breaking-point variance\" beyond which this acceleration does\nnot occur. By combining this insight with modern variance reduction techniques,\nwe construct stochastic PCA algorithms, for the online and offline setting,\nthat achieve an accelerated iteration complexity $\\mathcal O(1/\\sqrt{\\Delta})$.\nDue to the embarassingly parallel nature of our methods, this acceleration\ntranslates directly to wall-clock time if deployed in a parallel environment.\nOur approach is very general, and applies to many non-convex optimization\nproblems that can now be accelerated using the same technique. \n\n"}
{"id": "1707.03092", "contents": "Title: A Separation-Based Design to Data-Driven Control for Large-Scale\n  Partially Observed Systems Abstract: This paper studies the partially observed stochastic optimal control problem\nfor systems with state dynamics governed by Partial Differential Equations\n(PDEs) that leads to an extremely large problem. First, an open-loop\ndeterministic trajectory optimization problem is solved using a black box\nsimulation model of the dynamical system. Next, a Linear Quadratic Gaussian\n(LQG) controller is designed for the nominal trajectory-dependent linearized\nsystem, which is identified using input-output experimental data consisting of\nthe impulse responses of the optimized nominal system. A computational\nnonlinear heat example is used to illustrate the performance of the approach. \n\n"}
{"id": "1707.03303", "contents": "Title: A characterization of testable hypergraph properties Abstract: We provide a combinatorial characterization of all testable properties of\n$k$-uniform hypergraphs ($k$-graphs for short). Here, a $k$-graph property $P$\nis testable if there is a randomized algorithm which makes a bounded number of\nedge queries and distinguishes with probability $2/3$ between $k$-graphs that\nsatisfy $P$ and those that are far from satisfying $P$. For the $2$-graph case,\nsuch a combinatorial characterization was obtained by Alon, Fischer, Newman and\nShapira. Our results for the $k$-graph setting are in contrast to those of\nAustin and Tao, who showed that for the somewhat stronger concept of local\nrepairability, the testability results for graphs do not extend to the\n$3$-graph setting. Our proof relies on a random subhypergraph sampling result\nproved in a companion paper. \n\n"}
{"id": "1707.03340", "contents": "Title: Deep Learning for Real Time Crime Forecasting Abstract: Accurate real time crime prediction is a fundamental issue for public safety,\nbut remains a challenging problem for the scientific community. Crime\noccurrences depend on many complex factors. Compared to many predictable\nevents, crime is sparse. At different spatio-temporal scales, crime\ndistributions display dramatically different patterns. These distributions are\nof very low regularity in both space and time. In this work, we adapt the\nstate-of-the-art deep learning spatio-temporal predictor, ST-ResNet [Zhang et\nal, AAAI, 2017], to collectively predict crime distribution over the Los\nAngeles area. Our models are two staged. First, we preprocess the raw crime\ndata. This includes regularization in both space and time to enhance\npredictable signals. Second, we adapt hierarchical structures of residual\nconvolutional units to train multi-factor crime prediction models. Experiments\nover a half year period in Los Angeles reveal highly accurate predictive power\nof our models. \n\n"}
{"id": "1707.04324", "contents": "Title: Tensor-Based Backpropagation in Neural Networks with Non-Sequential\n  Input Abstract: Neural networks have been able to achieve groundbreaking accuracy at tasks\nconventionally considered only doable by humans. Using stochastic gradient\ndescent, optimization in many dimensions is made possible, albeit at a\nrelatively high computational cost. By splitting training data into batches,\nnetworks can be distributed and trained vastly more efficiently and with\nminimal accuracy loss. We have explored the mathematics behind efficiently\nimplementing tensor-based batch backpropagation algorithms. A common approach\nto batch training is iterating over batch items individually. Explicitly using\ntensor operations to backpropagate allows training to be performed\nnon-linearly, increasing computational efficiency. \n\n"}
{"id": "1707.04347", "contents": "Title: Weakly Submodular Maximization Beyond Cardinality Constraints: Does\n  Randomization Help Greedy? Abstract: Submodular functions are a broad class of set functions, which naturally\narise in diverse areas. Many algorithms have been suggested for the\nmaximization of these functions. Unfortunately, once the function deviates from\nsubmodularity, the known algorithms may perform arbitrarily poorly. Amending\nthis issue, by obtaining approximation results for set functions generalizing\nsubmodular functions, has been the focus of recent works.\n  One such class, known as weakly submodular functions, has received a lot of\nattention. A key result proved by Das and Kempe (2011) showed that the\napproximation ratio of the greedy algorithm for weakly submodular maximization\nsubject to a cardinality constraint degrades smoothly with the distance from\nsubmodularity. However, no results have been obtained for maximization subject\nto constraints beyond cardinality. In particular, it is not known whether the\ngreedy algorithm achieves any non-trivial approximation ratio for such\nconstraints.\n  In this paper, we prove that a randomized version of the greedy algorithm\n(previously used by Buchbinder et al. (2014) for a different problem) achieves\nan approximation ratio of $(1 + 1/\\gamma)^{-2}$ for the maximization of a\nweakly submodular function subject to a general matroid constraint, where\n$\\gamma$ is a parameter measuring the distance of the function from\nsubmodularity. Moreover, we also experimentally compare the performance of this\nversion of the greedy algorithm on real world problems against natural\nbenchmarks, and show that the algorithm we study performs well also in\npractice. To the best of our knowledge, this is the first algorithm with a\nnon-trivial approximation guarantee for maximizing a weakly submodular function\nsubject to a constraint other than the simple cardinality constraint. In\nparticular, it is the first algorithm with such a guarantee for the important\nand broad class of matroid constraints. \n\n"}
{"id": "1707.06197", "contents": "Title: Can GAN Learn Topological Features of a Graph? Abstract: This paper is first-line research expanding GANs into graph topology\nanalysis. By leveraging the hierarchical connectivity structure of a graph, we\nhave demonstrated that generative adversarial networks (GANs) can successfully\ncapture topological features of any arbitrary graph, and rank edge sets by\ndifferent stages according to their contribution to topology reconstruction.\nMoreover, in addition to acting as an indicator of graph reconstruction, we\nfind that these stages can also preserve important topological features in a\ngraph. \n\n"}
{"id": "1707.06260", "contents": "Title: Learning Approximate Neural Estimators for Wireless Channel State\n  Information Abstract: Estimation is a critical component of synchronization in wireless and signal\nprocessing systems. There is a rich body of work on estimator derivation,\noptimization, and statistical characterization from analytic system models\nwhich are used pervasively today. We explore an alternative approach to\nbuilding estimators which relies principally on approximate regression using\nlarge datasets and large computationally efficient artificial neural network\nmodels capable of learning non-linear function mappings which provide compact\nand accurate estimates. For single carrier PSK modulation, we explore the\naccuracy and computational complexity of such estimators compared with the\ncurrent gold-standard analytically derived alternatives. We compare performance\nin various wireless operating conditions and consider the trade offs between\nthe two different classes of systems. Our results show the learned estimators\ncan provide improvements in areas such as short-time estimation and estimation\nunder non-trivial real world channel conditions such as fading or other\nnon-linear hardware or propagation effects. \n\n"}
{"id": "1707.07328", "contents": "Title: Adversarial Examples for Evaluating Reading Comprehension Systems Abstract: Standard accuracy metrics indicate that reading comprehension systems are\nmaking rapid progress, but the extent to which these systems truly understand\nlanguage remains unclear. To reward systems with real language understanding\nabilities, we propose an adversarial evaluation scheme for the Stanford\nQuestion Answering Dataset (SQuAD). Our method tests whether systems can answer\nquestions about paragraphs that contain adversarially inserted sentences, which\nare automatically generated to distract computer systems without changing the\ncorrect answer or misleading humans. In this adversarial setting, the accuracy\nof sixteen published models drops from an average of $75\\%$ F1 score to $36\\%$;\nwhen the adversary is allowed to add ungrammatical sequences of words, average\naccuracy on four models decreases further to $7\\%$. We hope our insights will\nmotivate the development of new models that understand language more precisely. \n\n"}
{"id": "1707.07576", "contents": "Title: Interpreting Classifiers through Attribute Interactions in Datasets Abstract: In this work we present the novel ASTRID method for investigating which\nattribute interactions classifiers exploit when making predictions. Attribute\ninteractions in classification tasks mean that two or more attributes together\nprovide stronger evidence for a particular class label. Knowledge of such\ninteractions makes models more interpretable by revealing associations between\nattributes. This has applications, e.g., in pharmacovigilance to identify\ninteractions between drugs or in bioinformatics to investigate associations\nbetween single nucleotide polymorphisms. We also show how the found attribute\npartitioning is related to a factorisation of the data generating distribution\nand empirically demonstrate the utility of the proposed method. \n\n"}
{"id": "1707.08167", "contents": "Title: On The Robustness of a Neural Network Abstract: With the development of neural networks based machine learning and their\nusage in mission critical applications, voices are rising against the\n\\textit{black box} aspect of neural networks as it becomes crucial to\nunderstand their limits and capabilities. With the rise of neuromorphic\nhardware, it is even more critical to understand how a neural network, as a\ndistributed system, tolerates the failures of its computing nodes, neurons, and\nits communication channels, synapses. Experimentally assessing the robustness\nof neural networks involves the quixotic venture of testing all the possible\nfailures, on all the possible inputs, which ultimately hits a combinatorial\nexplosion for the first, and the impossibility to gather all the possible\ninputs for the second.\n  In this paper, we prove an upper bound on the expected error of the output\nwhen a subset of neurons crashes. This bound involves dependencies on the\nnetwork parameters that can be seen as being too pessimistic in the average\ncase. It involves a polynomial dependency on the Lipschitz coefficient of the\nneurons activation function, and an exponential dependency on the depth of the\nlayer where a failure occurs. We back up our theoretical results with\nexperiments illustrating the extent to which our prediction matches the\ndependencies between the network parameters and robustness. Our results show\nthat the robustness of neural networks to the average crash can be estimated\nwithout the need to neither test the network on all failure configurations, nor\naccess the training set used to train the network, both of which are\npractically impossible requirements. \n\n"}
{"id": "1707.08689", "contents": "Title: Multi-Robot Transfer Learning: A Dynamical System Perspective Abstract: Multi-robot transfer learning allows a robot to use data generated by a\nsecond, similar robot to improve its own behavior. The potential advantages are\nreducing the time of training and the unavoidable risks that exist during the\ntraining phase. Transfer learning algorithms aim to find an optimal transfer\nmap between different robots. In this paper, we investigate, through a\ntheoretical study of single-input single-output (SISO) systems, the properties\nof such optimal transfer maps. We first show that the optimal transfer learning\nmap is, in general, a dynamic system. The main contribution of the paper is to\nprovide an algorithm for determining the properties of this optimal dynamic map\nincluding its order and regressors (i.e., the variables it depends on). The\nproposed algorithm does not require detailed knowledge of the robots' dynamics,\nbut relies on basic system properties easily obtainable through simple\nexperimental tests. We validate the proposed algorithm experimentally through\nan example of transfer learning between two different quadrotor platforms.\nExperimental results show that an optimal dynamic map, with correct properties\nobtained from our proposed algorithm, achieves 60-70% reduction of transfer\nlearning error compared to the cases when the data is directly transferred or\ntransferred using an optimal static map. \n\n"}
{"id": "1708.02286", "contents": "Title: Jointly Attentive Spatial-Temporal Pooling Networks for Video-based\n  Person Re-Identification Abstract: Person Re-Identification (person re-id) is a crucial task as its applications\nin visual surveillance and human-computer interaction. In this work, we present\na novel joint Spatial and Temporal Attention Pooling Network (ASTPN) for\nvideo-based person re-identification, which enables the feature extractor to be\naware of the current input video sequences, in a way that interdependency from\nthe matching items can directly influence the computation of each other's\nrepresentation. Specifically, the spatial pooling layer is able to select\nregions from each frame, while the attention temporal pooling performed can\nselect informative frames over the sequence, both pooling guided by the\ninformation from distance matching. Experiments are conduced on the iLIDS-VID,\nPRID-2011 and MARS datasets and the results demonstrate that this approach\noutperforms existing state-of-art methods. We also analyze how the joint\npooling in both dimensions can boost the person re-id performance more\neffectively than using either of them separately. \n\n"}
{"id": "1708.02582", "contents": "Title: Cascade Adversarial Machine Learning Regularized with a Unified\n  Embedding Abstract: Injecting adversarial examples during training, known as adversarial\ntraining, can improve robustness against one-step attacks, but not for unknown\niterative attacks. To address this challenge, we first show iteratively\ngenerated adversarial images easily transfer between networks trained with the\nsame strategy. Inspired by this observation, we propose cascade adversarial\ntraining, which transfers the knowledge of the end results of adversarial\ntraining. We train a network from scratch by injecting iteratively generated\nadversarial images crafted from already defended networks in addition to\none-step adversarial images from the network being trained. We also propose to\nutilize embedding space for both classification and low-level (pixel-level)\nsimilarity learning to ignore unknown pixel level perturbation. During\ntraining, we inject adversarial images without replacing their corresponding\nclean images and penalize the distance between the two embeddings (clean and\nadversarial). Experimental results show that cascade adversarial training\ntogether with our proposed low-level similarity learning efficiently enhances\nthe robustness against iterative attacks, but at the expense of decreased\nrobustness against one-step attacks. We show that combining those two\ntechniques can also improve robustness under the worst case black box attack\nscenario. \n\n"}
{"id": "1708.03020", "contents": "Title: Non-stationary Stochastic Optimization under $L_{p,q}$-Variation\n  Measures Abstract: We consider a non-stationary sequential stochastic optimization problem, in\nwhich the underlying cost functions change over time under a variation budget\nconstraint. We propose an $L_{p,q}$-variation functional to quantify the\nchange, which yields less variation for dynamic function sequences whose\nchanges are constrained to short time periods or small subsets of input domain.\nUnder the $L_{p,q}$-variation constraint, we derive both upper and matching\nlower regret bounds for smooth and strongly convex function sequences, which\ngeneralize previous results in Besbes et al. (2015). Furthermore, we provide an\nupper bound for general convex function sequences with noisy gradient feedback,\nwhich matches the optimal rate as $p\\to\\infty$. Our results reveal some\nsurprising phenomena under this general variation functional, such as the curse\nof dimensionality of the function domain. The key technical novelties in our\nanalysis include affinity lemmas that characterize the distance of the\nminimizers of two convex functions with bounded Lp difference, and a cubic\nspline based construction that attains matching lower bounds. \n\n"}
{"id": "1708.03257", "contents": "Title: Robust polynomial regression up to the information theoretic limit Abstract: We consider the problem of robust polynomial regression, where one receives\nsamples $(x_i, y_i)$ that are usually within $\\sigma$ of a polynomial $y =\np(x)$, but have a $\\rho$ chance of being arbitrary adversarial outliers.\nPreviously, it was known how to efficiently estimate $p$ only when $\\rho <\n\\frac{1}{\\log d}$. We give an algorithm that works for the entire feasible\nrange of $\\rho < 1/2$, while simultaneously improving other parameters of the\nproblem. We complement our algorithm, which gives a factor 2 approximation,\nwith impossibility results that show, for example, that a $1.09$ approximation\nis impossible even with infinitely many samples. \n\n"}
{"id": "1708.03835", "contents": "Title: Training Support Vector Machines using Coresets Abstract: We present a novel coreset construction algorithm for solving classification\ntasks using Support Vector Machines (SVMs) in a computationally efficient\nmanner. A coreset is a weighted subset of the original data points that\nprovably approximates the original set. We show that coresets of size\npolylogarithmic in $n$ and polynomial in $d$ exist for a set of $n$ input\npoints with $d$ features and present an $(\\epsilon,\\delta)$-FPRAS for\nconstructing coresets for scalable SVM training. Our method leverages the\ninsight that data points are often redundant and uses an importance sampling\nscheme based on the sensitivity of each data point to construct coresets\nefficiently. We evaluate the performance of our algorithm in accelerating SVM\ntraining against real-world data sets and compare our algorithm to\nstate-of-the-art coreset approaches. Our empirical results show that our\napproach outperforms a state-of-the-art coreset approach and uniform sampling\nin enabling computational speedups while achieving low approximation error. \n\n"}
{"id": "1708.04312", "contents": "Title: Collaborative Filtering using Denoising Auto-Encoders for Market Basket\n  Data Abstract: Recommender systems (RS) help users navigate large sets of items in the\nsearch for \"interesting\" ones. One approach to RS is Collaborative Filtering\n(CF), which is based on the idea that similar users are interested in similar\nitems. Most model-based approaches to CF seek to train a\nmachine-learning/data-mining model based on sparse data; the model is then used\nto provide recommendations. While most of the proposed approaches are effective\nfor small-size situations, the combinatorial nature of the problem makes it\nimpractical for medium-to-large instances. In this work we present a novel\napproach to CF that works by training a Denoising Auto-Encoder (DAE) on\ncorrupted baskets, i.e., baskets from which one or more items have been\nremoved. The DAE is then forced to learn to reconstruct the original basket\ngiven its corrupted input. Due to recent advancements in optimization and other\ntechnologies for training neural-network models (such as DAE), the proposed\nmethod results in a scalable and practical approach to CF. The contribution of\nthis work is twofold: (1) to identify missing items in observed baskets and,\nthus, directly providing a CF model; and, (2) to construct a generative model\nof baskets which may be used, for instance, in simulation analysis or as part\nof a more complex analytical method. \n\n"}
{"id": "1708.04357", "contents": "Title: Graph Classification via Deep Learning with Virtual Nodes Abstract: Learning representation for graph classification turns a variable-size graph\ninto a fixed-size vector (or matrix). Such a representation works nicely with\nalgebraic manipulations. Here we introduce a simple method to augment an\nattributed graph with a virtual node that is bidirectionally connected to all\nexisting nodes. The virtual node represents the latent aspects of the graph,\nwhich are not immediately available from the attributes and local connectivity\nstructures. The expanded graph is then put through any node representation\nmethod. The representation of the virtual node is then the representation of\nthe entire graph. In this paper, we use the recently introduced Column Network\nfor the expanded graph, resulting in a new end-to-end graph classification\nmodel dubbed Virtual Column Network (VCN). The model is validated on two tasks:\n(i) predicting bio-activity of chemical compounds, and (ii) finding software\nvulnerability from source code. Results demonstrate that VCN is competitive\nagainst well-established rivals. \n\n"}
{"id": "1708.06020", "contents": "Title: Improving Deep Learning using Generic Data Augmentation Abstract: Deep artificial neural networks require a large corpus of training data in\norder to effectively learn, where collection of such training data is often\nexpensive and laborious. Data augmentation overcomes this issue by artificially\ninflating the training set with label preserving transformations. Recently\nthere has been extensive use of generic data augmentation to improve\nConvolutional Neural Network (CNN) task performance. This study benchmarks\nvarious popular data augmentation schemes to allow researchers to make informed\ndecisions as to which training methods are most appropriate for their data\nsets. Various geometric and photometric schemes are evaluated on a\ncoarse-grained data set using a relatively simple CNN. Experimental results,\nrun using 4-fold cross-validation and reported in terms of Top-1 and Top-5\naccuracy, indicate that cropping in geometric augmentation significantly\nincreases CNN task performance. \n\n"}
{"id": "1708.06678", "contents": "Title: Learning Combinations of Sigmoids Through Gradient Estimation Abstract: We develop a new approach to learn the parameters of regression models with\nhidden variables. In a nutshell, we estimate the gradient of the regression\nfunction at a set of random points, and cluster the estimated gradients. The\ncenters of the clusters are used as estimates for the parameters of hidden\nunits. We justify this approach by studying a toy model, whereby the regression\nfunction is a linear combination of sigmoids. We prove that indeed the\nestimated gradients concentrate around the parameter vectors of the hidden\nunits, and provide non-asymptotic bounds on the number of required samples. To\nthe best of our knowledge, no comparable guarantees have been proven for linear\ncombinations of sigmoids. \n\n"}
{"id": "1708.06819", "contents": "Title: Dynamic Input Structure and Network Assembly for Few-Shot Learning Abstract: The ability to learn from a small number of examples has been a difficult\nproblem in machine learning since its inception. While methods have succeeded\nwith large amounts of training data, research has been underway in how to\naccomplish similar performance with fewer examples, known as one-shot or more\ngenerally few-shot learning. This technique has been shown to have promising\nperformance, but in practice requires fixed-size inputs making it impractical\nfor production systems where class sizes can vary. This impedes training and\nthe final utility of few-shot learning systems. This paper describes an\napproach to constructing and training a network that can handle arbitrary\nexample sizes dynamically as the system is used. \n\n"}
{"id": "1708.06832", "contents": "Title: Learning Anytime Predictions in Neural Networks via Adaptive Loss\n  Balancing Abstract: This work considers the trade-off between accuracy and test-time\ncomputational cost of deep neural networks (DNNs) via \\emph{anytime}\npredictions from auxiliary predictions. Specifically, we optimize auxiliary\nlosses jointly in an \\emph{adaptive} weighted sum, where the weights are\ninversely proportional to average of each loss. Intuitively, this balances the\nlosses to have the same scale. We demonstrate theoretical considerations that\nmotivate this approach from multiple viewpoints, including connecting it to\noptimizing the geometric mean of the expectation of each loss, an objective\nthat ignores the scale of losses. Experimentally, the adaptive weights induce\nmore competitive anytime predictions on multiple recognition data-sets and\nmodels than non-adaptive approaches including weighing all losses equally. In\nparticular, anytime neural networks (ANNs) can achieve the same accuracy faster\nusing adaptive weights on a small network than using static constant weights on\na large one. For problems with high performance saturation, we also show a\nsequence of exponentially deepening ANNscan achieve near-optimal anytime\nresults at any budget, at the cost of a const fraction of extra computation. \n\n"}
{"id": "1708.07242", "contents": "Title: GALILEO: A Generalized Low-Entropy Mixture Model Abstract: We present a new method of generating mixture models for data with\ncategorical attributes. The keys to this approach are an entropy-based density\nmetric in categorical space and annealing of high-entropy/low-density\ncomponents from an initial state with many components. Pruning of low-density\ncomponents using the entropy-based density allows GALILEO to consistently find\nhigh-quality clusters and the same optimal number of clusters. GALILEO has\nshown promising results on a range of test datasets commonly used for\ncategorical clustering benchmarks. We demonstrate that the scaling of GALILEO\nis linear in the number of records in the dataset, making this method suitable\nfor very large categorical datasets. \n\n"}
{"id": "1708.07689", "contents": "Title: Understanding and Comparing Deep Neural Networks for Age and Gender\n  Classification Abstract: Recently, deep neural networks have demonstrated excellent performances in\nrecognizing the age and gender on human face images. However, these models were\napplied in a black-box manner with no information provided about which facial\nfeatures are actually used for prediction and how these features depend on\nimage preprocessing, model initialization and architecture choice. We present a\nstudy investigating these different effects.\n  In detail, our work compares four popular neural network architectures,\nstudies the effect of pretraining, evaluates the robustness of the considered\nalignment preprocessings via cross-method test set swapping and intuitively\nvisualizes the model's prediction strategies in given preprocessing conditions\nusing the recent Layer-wise Relevance Propagation (LRP) algorithm. Our\nevaluations on the challenging Adience benchmark show that suitable parameter\ninitialization leads to a holistic perception of the input, compensating\nartefactual data representations. With a combination of simple preprocessing\nsteps, we reach state of the art performance in gender recognition. \n\n"}
{"id": "1708.08694", "contents": "Title: Natasha 2: Faster Non-Convex Optimization Than SGD Abstract: We design a stochastic algorithm to train any smooth neural network to\n$\\varepsilon$-approximate local minima, using $O(\\varepsilon^{-3.25})$\nbackpropagations. The best result was essentially $O(\\varepsilon^{-4})$ by SGD.\n  More broadly, it finds $\\varepsilon$-approximate local minima of any smooth\nnonconvex function in rate $O(\\varepsilon^{-3.25})$, with only oracle access to\nstochastic gradients. \n\n"}
{"id": "1708.08819", "contents": "Title: Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields Abstract: Generative adversarial networks (GANs) evolved into one of the most\nsuccessful unsupervised techniques for generating realistic images. Even though\nit has recently been shown that GAN training converges, GAN models often end up\nin local Nash equilibria that are associated with mode collapse or otherwise\nfail to model the target distribution. We introduce Coulomb GANs, which pose\nthe GAN learning problem as a potential field of charged particles, where\ngenerated samples are attracted to training set samples but repel each other.\nThe discriminator learns a potential field while the generator decreases the\nenergy by moving its samples along the vector (force) field determined by the\ngradient of the potential field. Through decreasing the energy, the GAN model\nlearns to generate samples according to the whole target distribution and does\nnot only cover some of its modes. We prove that Coulomb GANs possess only one\nNash equilibrium which is optimal in the sense that the model distribution\nequals the target distribution. We show the efficacy of Coulomb GANs on a\nvariety of image datasets. On LSUN and celebA, Coulomb GANs set a new state of\nthe art and produce a previously unseen variety of different samples. \n\n"}
{"id": "1708.09811", "contents": "Title: Efficient tracking of a growing number of experts Abstract: We consider a variation on the problem of prediction with expert advice,\nwhere new forecasters that were unknown until then may appear at each round. As\noften in prediction with expert advice, designing an algorithm that achieves\nnear-optimal regret guarantees is straightforward, using aggregation of\nexperts. However, when the comparison class is sufficiently rich, for instance\nwhen the best expert and the set of experts itself changes over time, such\nstrategies naively require to maintain a prohibitive number of weights\n(typically exponential with the time horizon). By contrast, designing\nstrategies that both achieve a near-optimal regret and maintain a reasonable\nnumber of weights is highly non-trivial. We consider three increasingly\nchallenging objectives (simple regret, shifting regret and sparse shifting\nregret) that extend existing notions defined for a fixed expert ensemble; in\neach case, we design strategies that achieve tight regret bounds, adaptive to\nthe parameters of the comparison class, while being computationally\ninexpensive. Moreover, our algorithms are anytime, agnostic to the number of\nincoming experts and completely parameter-free. Such remarkable results are\nmade possible thanks to two simple but highly effective recipes: first the\n\"abstention trick\" that comes from the specialist framework and enables to\nhandle the least challenging notions of regret, but is limited when addressing\nmore sophisticated objectives. Second, the \"muting trick\" that we introduce to\ngive more flexibility. We show how to combine these two tricks in order to\nhandle the most challenging class of comparison strategies. \n\n"}
{"id": "1709.00228", "contents": "Title: Learning Multi-item Auctions with (or without) Samples Abstract: We provide algorithms that learn simple auctions whose revenue is\napproximately optimal in multi-item multi-bidder settings, for a wide range of\nvaluations including unit-demand, additive, constrained additive, XOS, and\nsubadditive. We obtain our learning results in two settings. The first is the\ncommonly studied setting where sample access to the bidders' distributions over\nvaluations is given, for both regular distributions and arbitrary distributions\nwith bounded support. Our algorithms require polynomially many samples in the\nnumber of items and bidders. The second is a more general max-min learning\nsetting that we introduce, where we are given \"approximate distributions,\" and\nwe seek to compute an auction whose revenue is approximately optimal\nsimultaneously for all \"true distributions\" that are close to the given ones.\nThese results are more general in that they imply the sample-based results, and\nare also applicable in settings where we have no sample access to the\nunderlying distributions but have estimated them indirectly via market research\nor by observation of previously run, potentially non-truthful auctions.\n  Our results hold for valuation distributions satisfying the standard (and\nnecessary) independence-across-items property. They also generalize and improve\nupon recent works, which have provided algorithms that learn approximately\noptimal auctions in more restricted settings with additive, subadditive and\nunit-demand valuations using sample access to distributions. We generalize\nthese results to the complete unit-demand, additive, and XOS setting, to i.i.d.\nsubadditive bidders, and to the max-min setting.\n  Our results are enabled by new uniform convergence bounds for hypotheses\nclasses under product measures. Our bounds result in exponential savings in\nsample complexity compared to bounds derived by bounding the VC dimension, and\nare of independent interest. \n\n"}
{"id": "1709.01846", "contents": "Title: Symmetric Variational Autoencoder and Connections to Adversarial\n  Learning Abstract: A new form of the variational autoencoder (VAE) is proposed, based on the\nsymmetric Kullback-Leibler divergence. It is demonstrated that learning of the\nresulting symmetric VAE (sVAE) has close connections to previously developed\nadversarial-learning methods. This relationship helps unify the previously\ndistinct techniques of VAE and adversarially learning, and provides insights\nthat allow us to ameliorate shortcomings with some previously developed\nadversarial methods. In addition to an analysis that motivates and explains the\nsVAE, an extensive set of experiments validate the utility of the approach. \n\n"}
{"id": "1709.01888", "contents": "Title: Language Modeling by Clustering with Word Embeddings for Text\n  Readability Assessment Abstract: We present a clustering-based language model using word embeddings for text\nreadability prediction. Presumably, an Euclidean semantic space hypothesis\nholds true for word embeddings whose training is done by observing word\nco-occurrences. We argue that clustering with word embeddings in the metric\nspace should yield feature representations in a higher semantic space\nappropriate for text regression. Also, by representing features in terms of\nhistograms, our approach can naturally address documents of varying lengths. An\nempirical evaluation using the Common Core Standards corpus reveals that the\nfeatures formed on our clustering-based language model significantly improve\nthe previously known results for the same corpus in readability prediction. We\nalso evaluate the task of sentence matching based on semantic relatedness using\nthe Wiki-SimpleWiki corpus and find that our features lead to superior matching\nperformance. \n\n"}
{"id": "1709.02605", "contents": "Title: Gaussian Quadrature for Kernel Features Abstract: Kernel methods have recently attracted resurgent interest, showing\nperformance competitive with deep neural networks in tasks such as speech\nrecognition. The random Fourier features map is a technique commonly used to\nscale up kernel machines, but employing the randomized feature map means that\n$O(\\epsilon^{-2})$ samples are required to achieve an approximation error of at\nmost $\\epsilon$. We investigate some alternative schemes for constructing\nfeature maps that are deterministic, rather than random, by approximating the\nkernel in the frequency domain using Gaussian quadrature. We show that\ndeterministic feature maps can be constructed, for any $\\gamma > 0$, to achieve\nerror $\\epsilon$ with $O(e^{e^\\gamma} + \\epsilon^{-1/\\gamma})$ samples as\n$\\epsilon$ goes to 0. Our method works particularly well with sparse ANOVA\nkernels, which are inspired by the convolutional layer of CNNs. We validate our\nmethods on datasets in different domains, such as MNIST and TIMIT, showing that\ndeterministic features are faster to generate and achieve accuracy comparable\nto the state-of-the-art kernel methods based on random Fourier features. \n\n"}
{"id": "1709.02753", "contents": "Title: Privacy Loss in Apple's Implementation of Differential Privacy on MacOS\n  10.12 Abstract: In June 2016, Apple announced that it will deploy differential privacy for\nsome user data collection in order to ensure privacy of user data, even from\nApple. The details of Apple's approach remained sparse. Although several\npatents have since appeared hinting at the algorithms that may be used to\nachieve differential privacy, they did not include a precise explanation of the\napproach taken to privacy parameter choice. Such choice and the overall\napproach to privacy budget use and management are key questions for\nunderstanding the privacy protections provided by any deployment of\ndifferential privacy.\n  In this work, through a combination of experiments, static and dynamic code\nanalysis of macOS Sierra (Version 10.12) implementation, we shed light on the\nchoices Apple made for privacy budget management. We discover and describe\nApple's set-up for differentially private data processing, including the\noverall data pipeline, the parameters used for differentially private\nperturbation of each piece of data, and the frequency with which such data is\nsent to Apple's servers.\n  We find that although Apple's deployment ensures that the (differential)\nprivacy loss per each datum submitted to its servers is $1$ or $2$, the overall\nprivacy loss permitted by the system is significantly higher, as high as $16$\nper day for the four initially announced applications of Emojis, New words,\nDeeplinks and Lookup Hints. Furthermore, Apple renews the privacy budget\navailable every day, which leads to a possible privacy loss of 16 times the\nnumber of days since user opt-in to differentially private data collection for\nthose four applications.\n  We advocate that in order to claim the full benefits of differentially\nprivate data collection, Apple must give full transparency of its\nimplementation, enable user choice in areas related to privacy loss, and set\nmeaningful defaults on the privacy loss permitted. \n\n"}
{"id": "1709.02800", "contents": "Title: GOOWE: Geometrically Optimum and Online-Weighted Ensemble Classifier for\n  Evolving Data Streams Abstract: Designing adaptive classifiers for an evolving data stream is a challenging\ntask due to the data size and its dynamically changing nature. Combining\nindividual classifiers in an online setting, the ensemble approach, is a\nwell-known solution. It is possible that a subset of classifiers in the\nensemble outperforms others in a time-varying fashion. However, optimum weight\nassignment for component classifiers is a problem which is not yet fully\naddressed in online evolving environments. We propose a novel data stream\nensemble classifier, called Geometrically Optimum and Online-Weighted Ensemble\n(GOOWE), which assigns optimum weights to the component classifiers using a\nsliding window containing the most recent data instances. We map vote scores of\nindividual classifiers and true class labels into a spatial environment. Based\non the Euclidean distance between vote scores and ideal-points, and using the\nlinear least squares (LSQ) solution, we present a novel, dynamic, and online\nweighting approach. While LSQ is used for batch mode ensemble classifiers, it\nis the first time that we adapt and use it for online environments by providing\na spatial modeling of online ensembles. In order to show the robustness of the\nproposed algorithm, we use real-world datasets and synthetic data generators\nusing the MOA libraries. First, we analyze the impact of our weighting system\non prediction accuracy through two scenarios. Second, we compare GOOWE with 8\nstate-of-the-art ensemble classifiers in a comprehensive experimental\nenvironment. Our experiments show that GOOWE provides improved reactions to\ndifferent types of concept drift compared to our baselines. The statistical\ntests indicate a significant improvement in accuracy, with conservative time\nand memory requirements. \n\n"}
{"id": "1709.03423", "contents": "Title: Ensemble Methods as a Defense to Adversarial Perturbations Against Deep\n  Neural Networks Abstract: Deep learning has become the state of the art approach in many machine\nlearning problems such as classification. It has recently been shown that deep\nlearning is highly vulnerable to adversarial perturbations. Taking the camera\nsystems of self-driving cars as an example, small adversarial perturbations can\ncause the system to make errors in important tasks, such as classifying traffic\nsigns or detecting pedestrians. Hence, in order to use deep learning without\nsafety concerns a proper defense strategy is required. We propose to use\nensemble methods as a defense strategy against adversarial perturbations. We\nfind that an attack leading one model to misclassify does not imply the same\nfor other networks performing the same task. This makes ensemble methods an\nattractive defense strategy against adversarial attacks. We empirically show\nfor the MNIST and the CIFAR-10 data sets that ensemble methods not only improve\nthe accuracy of neural networks on test data but also increase their robustness\nagainst adversarial perturbations. \n\n"}
{"id": "1709.05107", "contents": "Title: Multi-Label Zero-Shot Human Action Recognition via Joint Latent Ranking\n  Embedding Abstract: Human action recognition refers to automatic recognizing human actions from a\nvideo clip. In reality, there often exist multiple human actions in a video\nstream. Such a video stream is often weakly-annotated with a set of relevant\nhuman action labels at a global level rather than assigning each label to a\nspecific video episode corresponding to a single action, which leads to a\nmulti-label learning problem. Furthermore, there are many meaningful human\nactions in reality but it would be extremely difficult to collect/annotate\nvideo clips regarding all of various human actions, which leads to a zero-shot\nlearning scenario. To the best of our knowledge, there is no work that has\naddressed all the above issues together in human action recognition. In this\npaper, we formulate a real-world human action recognition task as a multi-label\nzero-shot learning problem and propose a framework to tackle this problem in a\nholistic way. Our framework holistically tackles the issue of unknown temporal\nboundaries between different actions for multi-label learning and exploits the\nside information regarding the semantic relationship between different human\nactions for knowledge transfer. Consequently, our framework leads to a joint\nlatent ranking embedding for multi-label zero-shot human action recognition. A\nnovel neural architecture of two component models and an alternate learning\nalgorithm are proposed to carry out the joint latent ranking embedding\nlearning. Thus, multi-label zero-shot recognition is done by measuring\nrelatedness scores of action labels to a test video clip in the joint latent\nvisual and semantic embedding spaces. We evaluate our framework with different\nsettings, including a novel data split scheme designed especially for\nevaluating multi-label zero-shot learning, on two datasets: Breakfast and\nCharades. The experimental results demonstrate the effectiveness of our\nframework. \n\n"}
{"id": "1709.06010", "contents": "Title: Learning Neural Networks with Two Nonlinear Layers in Polynomial Time Abstract: We give a polynomial-time algorithm for learning neural networks with one\nlayer of sigmoids feeding into any Lipschitz, monotone activation function\n(e.g., sigmoid or ReLU). We make no assumptions on the structure of the\nnetwork, and the algorithm succeeds with respect to {\\em any} distribution on\nthe unit ball in $n$ dimensions (hidden weight vectors also have unit norm).\nThis is the first assumption-free, provably efficient algorithm for learning\nneural networks with two nonlinear layers.\n  Our algorithm-- {\\em Alphatron}-- is a simple, iterative update rule that\ncombines isotonic regression with kernel methods. It outputs a hypothesis that\nyields efficient oracle access to interpretable features. It also suggests a\nnew approach to Boolean learning problems via real-valued conditional-mean\nfunctions, sidestepping traditional hardness results from computational\nlearning theory.\n  Along these lines, we subsume and improve many longstanding results for PAC\nlearning Boolean functions to the more general, real-valued setting of {\\em\nprobabilistic concepts}, a model that (unlike PAC learning) requires non-i.i.d.\nnoise-tolerance. \n\n"}
{"id": "1709.07308", "contents": "Title: Predicting Positive and Negative Links with Noisy Queries: Theory &\n  Practice Abstract: Social networks involve both positive and negative relationships, which can\nbe captured in signed graphs. The {\\em edge sign prediction problem} aims to\npredict whether an interaction between a pair of nodes will be positive or\nnegative. We provide theoretical results for this problem that motivate natural\nimprovements to recent heuristics.\n  The edge sign prediction problem is related to correlation clustering; a\npositive relationship means being in the same cluster. We consider the\nfollowing model for two clusters: we are allowed to query any pair of nodes\nwhether they belong to the same cluster or not, but the answer to the query is\ncorrupted with some probability $0<q<\\frac{1}{2}$. Let $\\delta=1-2q$ be the\nbias. We provide an algorithm that recovers all signs correctly with high\nprobability in the presence of noise with $O(\\frac{n\\log\nn}{\\delta^2}+\\frac{\\log^2 n}{\\delta^6})$ queries. This is the best known result\nfor this problem for all but tiny $\\delta$, improving on the recent work of\nMazumdar and Saha \\cite{mazumdar2017clustering}. We also provide an algorithm\nthat performs $O(\\frac{n\\log n}{\\delta^4})$ queries, and uses breadth first\nsearch as its main algorithmic primitive. While both the running time and the\nnumber of queries for this algorithm are sub-optimal, our result relies on\nnovel theoretical techniques, and naturally suggests the use of edge-disjoint\npaths as a feature for predicting signs in online social networks.\nCorrespondingly, we experiment with using edge disjoint $s-t$ paths of short\nlength as a feature for predicting the sign of edge $(s,t)$ in real-world\nsigned networks. Empirical findings suggest that the use of such paths improves\nthe classification accuracy, especially for pairs of nodes with no common\nneighbors. \n\n"}
{"id": "1709.07712", "contents": "Title: Polynomial Cases for the Vertex Coloring Problem Abstract: The computational complexity of the Vertex Coloring problem is known for all\nhereditary classes of graphs defined by forbidding two connected five-vertex\ninduced subgraphs, except for seven cases. We prove the polynomial-time\nsolvability of four of these problems: for ($P_5$, dart)-free graphs, ($P_5$,\nbanner)-free graphs, ($P_5$, bull)-free graphs, and (fork, bull)-free graphs. \n\n"}
{"id": "1709.08139", "contents": "Title: Disabling External Influence in Social Networks via Edge Recommendation Abstract: Existing socio-psychological studies suggest that users of a social network\nform their opinions relying on the opinions of their neighbors. According to\nDeGroot opinion formation model, one value of particular importance is the\nasymptotic consensus value---the sum of user opinions weighted by the users'\neigenvector centralities. This value plays the role of an attractor for the\nopinions in the network and is a lucrative target for external influence.\nHowever, since any potentially malicious control of the opinion distribution in\na social network is clearly undesirable, it is important to design methods to\nprevent the external attempts to strategically change the asymptotic consensus\nvalue.\n  In this work, we assume that the adversary wants to maximize the asymptotic\nconsensus value by altering the opinions of some users in a network; we, then,\nstate DIVER---an NP-hard problem of disabling such external influence attempts\nby strategically adding a limited number of edges to the network. Relying on\nthe theory of Markov chains, we provide perturbation analysis that shows how\neigenvector centrality and, hence, DIVER's objective function change in\nresponse to an edge's addition to the network. The latter leads to the design\nof a pseudo-linear-time heuristic for DIVER, whose computation relies on\nefficient estimation of mean first passage times in a Markov chain. We confirm\nour theoretical findings in experiments. \n\n"}
{"id": "1709.08878", "contents": "Title: Generating Sentences by Editing Prototypes Abstract: We propose a new generative model of sentences that first samples a prototype\nsentence from the training corpus and then edits it into a new sentence.\nCompared to traditional models that generate from scratch either left-to-right\nor by first sampling a latent sentence vector, our prototype-then-edit model\nimproves perplexity on language modeling and generates higher quality outputs\naccording to human evaluation. Furthermore, the model gives rise to a latent\nedit vector that captures interpretable semantics such as sentence similarity\nand sentence-level analogies. \n\n"}
{"id": "1709.09069", "contents": "Title: MDP environments for the OpenAI Gym Abstract: The OpenAI Gym provides researchers and enthusiasts with simple to use\nenvironments for reinforcement learning. Even the simplest environment have a\nlevel of complexity that can obfuscate the inner workings of RL approaches and\nmake debugging difficult. This whitepaper describes a Python framework that\nmakes it very easy to create simple Markov-Decision-Process environments\nprogrammatically by specifying state transitions and rewards of deterministic\nand non-deterministic MDPs in a domain-specific language in Python. It then\npresents results and visualizations created with this MDP framework. \n\n"}
{"id": "1709.09603", "contents": "Title: Riemannian approach to batch normalization Abstract: Batch Normalization (BN) has proven to be an effective algorithm for deep\nneural network training by normalizing the input to each neuron and reducing\nthe internal covariate shift. The space of weight vectors in the BN layer can\nbe naturally interpreted as a Riemannian manifold, which is invariant to linear\nscaling of weights. Following the intrinsic geometry of this manifold provides\na new learning rule that is more efficient and easier to analyze. We also\npropose intuitive and effective gradient clipping and regularization methods\nfor the proposed algorithm by utilizing the geometry of the manifold. The\nresulting algorithm consistently outperforms the original BN on various types\nof network architectures and datasets. \n\n"}
{"id": "1710.01878", "contents": "Title: To prune, or not to prune: exploring the efficacy of pruning for model\n  compression Abstract: Model pruning seeks to induce sparsity in a deep neural network's various\nconnection matrices, thereby reducing the number of nonzero-valued parameters\nin the model. Recent reports (Han et al., 2015; Narang et al., 2017) prune deep\nnetworks at the cost of only a marginal loss in accuracy and achieve a sizable\nreduction in model size. This hints at the possibility that the baseline models\nin these experiments are perhaps severely over-parameterized at the outset and\na viable alternative for model compression might be to simply reduce the number\nof hidden units while maintaining the model's dense connection structure,\nexposing a similar trade-off in model size and accuracy. We investigate these\ntwo distinct paths for model compression within the context of energy-efficient\ninference in resource-constrained environments and propose a new gradual\npruning technique that is simple and straightforward to apply across a variety\nof models/datasets with minimal tuning and can be seamlessly incorporated\nwithin the training process. We compare the accuracy of large, but pruned\nmodels (large-sparse) and their smaller, but dense (small-dense) counterparts\nwith identical memory footprint. Across a broad range of neural network\narchitectures (deep CNNs, stacked LSTM, and seq2seq LSTM models), we find\nlarge-sparse models to consistently outperform small-dense models and achieve\nup to 10x reduction in number of non-zero parameters with minimal loss in\naccuracy. \n\n"}
{"id": "1710.02248", "contents": "Title: Learnable Explicit Density for Continuous Latent Space and Variational\n  Inference Abstract: In this paper, we study two aspects of the variational autoencoder (VAE): the\nprior distribution over the latent variables and its corresponding posterior.\nFirst, we decompose the learning of VAEs into layerwise density estimation, and\nargue that having a flexible prior is beneficial to both sample generation and\ninference. Second, we analyze the family of inverse autoregressive flows\n(inverse AF) and show that with further improvement, inverse AF could be used\nas universal approximation to any complicated posterior. Our analysis results\nin a unified approach to parameterizing a VAE, without the need to restrict\nourselves to use factorial Gaussians in the latent real space. \n\n"}
{"id": "1710.04234", "contents": "Title: Maximum Margin Interval Trees Abstract: Learning a regression function using censored or interval-valued output data\nis an important problem in fields such as genomics and medicine. The goal is to\nlearn a real-valued prediction function, and the training output labels\nindicate an interval of possible values. Whereas most existing algorithms for\nthis task are linear models, in this paper we investigate learning nonlinear\ntree models. We propose to learn a tree by minimizing a margin-based\ndiscriminative objective function, and we provide a dynamic programming\nalgorithm for computing the optimal solution in log-linear time. We show\nempirically that this algorithm achieves state-of-the-art speed and prediction\naccuracy in a benchmark of several data sets. \n\n"}
{"id": "1710.05090", "contents": "Title: Burn-In Demonstrations for Multi-Modal Imitation Learning Abstract: Recent work on imitation learning has generated policies that reproduce\nexpert behavior from multi-modal data. However, past approaches have focused\nonly on recreating a small number of distinct, expert maneuvers, or have relied\non supervised learning techniques that produce unstable policies. This work\nextends InfoGAIL, an algorithm for multi-modal imitation learning, to reproduce\nbehavior over an extended period of time. Our approach involves reformulating\nthe typical imitation learning setting to include \"burn-in demonstrations\" upon\nwhich policies are conditioned at test time. We demonstrate that our approach\noutperforms standard InfoGAIL in maximizing the mutual information between\npredicted and unseen style labels in road scene simulations, and we show that\nour method leads to policies that imitate expert autonomous driving systems\nover long time horizons. \n\n"}
{"id": "1710.06169", "contents": "Title: Distill-and-Compare: Auditing Black-Box Models Using Transparent Model\n  Distillation Abstract: Black-box risk scoring models permeate our lives, yet are typically\nproprietary or opaque. We propose Distill-and-Compare, a model distillation and\ncomparison approach to audit such models. To gain insight into black-box\nmodels, we treat them as teachers, training transparent student models to mimic\nthe risk scores assigned by black-box models. We compare the student model\ntrained with distillation to a second un-distilled transparent model trained on\nground-truth outcomes, and use differences between the two models to gain\ninsight into the black-box model. Our approach can be applied in a realistic\nsetting, without probing the black-box model API. We demonstrate the approach\non four public data sets: COMPAS, Stop-and-Frisk, Chicago Police, and Lending\nClub. We also propose a statistical test to determine if a data set is missing\nkey features used to train the black-box model. Our test finds that the\nProPublica data is likely missing key feature(s) used in COMPAS. \n\n"}
{"id": "1710.06832", "contents": "Title: The Origins of Computational Mechanics: A Brief Intellectual History and\n  Several Clarifications Abstract: The principle goal of computational mechanics is to define pattern and\nstructure so that the organization of complex systems can be detected and\nquantified. Computational mechanics developed from efforts in the 1970s and\nearly 1980s to identify strange attractors as the mechanism driving weak fluid\nturbulence via the method of reconstructing attractor geometry from measurement\ntime series and in the mid-1980s to estimate equations of motion directly from\ncomplex time series. In providing a mathematical and operational definition of\nstructure it addressed weaknesses of these early approaches to discovering\npatterns in natural systems.\n  Since then, computational mechanics has led to a range of results from\ntheoretical physics and nonlinear mathematics to diverse applications---from\nclosed-form analysis of Markov and non-Markov stochastic processes that are\nergodic or nonergodic and their measures of information and intrinsic\ncomputation to complex materials and deterministic chaos and intelligence in\nMaxwellian demons to quantum compression of classical processes and the\nevolution of computation and language.\n  This brief review clarifies several misunderstandings and addresses concerns\nrecently raised regarding early works in the field (1980s). We show that\nmisguided evaluations of the contributions of computational mechanics are\ngroundless and stem from a lack of familiarity with its basic goals and from a\nfailure to consider its historical context. For all practical purposes, its\nmodern methods and results largely supersede the early works. This not only\nrenders recent criticism moot and shows the solid ground on which computational\nmechanics stands but, most importantly, shows the significant progress achieved\nover three decades and points to the many intriguing and outstanding challenges\nin understanding the computational nature of complex dynamic systems. \n\n"}
{"id": "1710.07400", "contents": "Title: Ligand Pose Optimization with Atomic Grid-Based Convolutional Neural\n  Networks Abstract: Docking is an important tool in computational drug discovery that aims to\npredict the binding pose of a ligand to a target protein through a combination\nof pose scoring and optimization. A scoring function that is differentiable\nwith respect to atom positions can be used for both scoring and gradient-based\noptimization of poses for docking. Using a differentiable grid-based atomic\nrepresentation as input, we demonstrate that a scoring function learned by\ntraining a convolutional neural network (CNN) to identify binding poses can\nalso be applied to pose optimization. We also show that an iteratively-trained\nCNN that includes poses optimized by the first CNN in its training set performs\neven better at optimizing randomly initialized poses than either the first CNN\nscoring function or AutoDock Vina. \n\n"}
{"id": "1710.07406", "contents": "Title: First-order Methods Almost Always Avoid Saddle Points Abstract: We establish that first-order methods avoid saddle points for almost all\ninitializations. Our results apply to a wide variety of first-order methods,\nincluding gradient descent, block coordinate descent, mirror descent and\nvariants thereof. The connecting thread is that such algorithms can be studied\nfrom a dynamical systems perspective in which appropriate instantiations of the\nStable Manifold Theorem allow for a global stability analysis. Thus, neither\naccess to second-order derivative information nor randomness beyond\ninitialization is necessary to provably avoid saddle points. \n\n"}
{"id": "1710.07601", "contents": "Title: Kernelization Lower Bounds for Finding Constant-Size Subgraphs Abstract: Kernelization is an important tool in parameterized algorithmics. Given an\ninput instance accompanied by a parameter, the goal is to compute in polynomial\ntime an equivalent instance of the same problem such that the size of the\nreduced instance only depends on the parameter and not on the size of the\noriginal instance. In this paper, we provide a first conceptual study on limits\nof kernelization for several polynomial-time solvable problems. For instance,\nwe consider the problem of finding a triangle with negative sum of edge weights\nparameterized by the maximum degree of the input graph. We prove that a\nlinear-time computable strict kernel of truly subcubic size for this problem\nviolates the popular APSP-conjecture. \n\n"}
{"id": "1710.07804", "contents": "Title: Zeroth-Order Online Alternating Direction Method of Multipliers:\n  Convergence Analysis and Applications Abstract: In this paper, we design and analyze a new zeroth-order online algorithm,\nnamely, the zeroth-order online alternating direction method of multipliers\n(ZOO-ADMM), which enjoys dual advantages of being gradient-free operation and\nemploying the ADMM to accommodate complex structured regularizers. Compared to\nthe first-order gradient-based online algorithm, we show that ZOO-ADMM requires\n$\\sqrt{m}$ times more iterations, leading to a convergence rate of\n$O(\\sqrt{m}/\\sqrt{T})$, where $m$ is the number of optimization variables, and\n$T$ is the number of iterations. To accelerate ZOO-ADMM, we propose two\nminibatch strategies: gradient sample averaging and observation averaging,\nresulting in an improved convergence rate of $O(\\sqrt{1+q^{-1}m}/\\sqrt{T})$,\nwhere $q$ is the minibatch size. In addition to convergence analysis, we also\ndemonstrate ZOO-ADMM to applications in signal processing, statistics, and\nmachine learning. \n\n"}
{"id": "1710.08167", "contents": "Title: Interactive Visual Data Exploration with Subjective Feedback: An\n  Information-Theoretic Approach Abstract: Visual exploration of high-dimensional real-valued datasets is a fundamental\ntask in exploratory data analysis (EDA). Existing methods use predefined\ncriteria to choose the representation of data. There is a lack of methods that\n(i) elicit from the user what she has learned from the data and (ii) show\npatterns that she does not know yet. We construct a theoretical model where\nidentified patterns can be input as knowledge to the system. The knowledge\nsyntax here is intuitive, such as \"this set of points forms a cluster\", and\nrequires no knowledge of maths. This background knowledge is used to find a\nMaximum Entropy distribution of the data, after which the system provides the\nuser data projections in which the data and the Maximum Entropy distribution\ndiffer the most, hence showing the user aspects of the data that are maximally\ninformative given the user's current knowledge. We provide an open source EDA\nsystem with tailored interactive visualizations to demonstrate these concepts.\nWe study the performance of the system and present use cases on both synthetic\nand real data. We find that the model and the prototype system allow the user\nto learn information efficiently from various data sources and the system works\nsufficiently fast in practice. We conclude that the information theoretic\napproach to exploratory data analysis where patterns observed by a user are\nformalized as constraints provides a principled, intuitive, and efficient basis\nfor constructing an EDA system. \n\n"}
{"id": "1710.08619", "contents": "Title: Interpretable Deep Learning applied to Plant Stress Phenotyping Abstract: Availability of an explainable deep learning model that can be applied to\npractical real world scenarios and in turn, can consistently, rapidly and\naccurately identify specific and minute traits in applicable fields of\nbiological sciences, is scarce. Here we consider one such real world example\nviz., accurate identification, classification and quantification of biotic and\nabiotic stresses in crop research and production. Up until now, this has been\npredominantly done manually by visual inspection and require specialized\ntraining. However, such techniques are hindered by subjectivity resulting from\ninter- and intra-rater cognitive variability. Here, we demonstrate the ability\nof a machine learning framework to identify and classify a diverse set of\nfoliar stresses in the soybean plant with remarkable accuracy. We also present\nan explanation mechanism using gradient-weighted class activation mapping that\nisolates the visual symptoms used by the model to make predictions. This\nunsupervised identification of unique visual symptoms for each stress provides\na quantitative measure of stress severity, allowing for identification,\nclassification and quantification in one framework. The learnt model appears to\nbe agnostic to species and make good predictions for other (non-soybean)\nspecies, demonstrating an ability of transfer learning. \n\n"}
{"id": "1710.08637", "contents": "Title: Improving Accuracy of Nonparametric Transfer Learning via Vector\n  Segmentation Abstract: Transfer learning using deep neural networks as feature extractors has become\nincreasingly popular over the past few years. It allows to obtain\nstate-of-the-art accuracy on datasets too small to train a deep neural network\non its own, and it provides cutting edge descriptors that, combined with\nnonparametric learning methods, allow rapid and flexible deployment of\nperforming solutions in computationally restricted settings. In this paper, we\nare interested in showing that the features extracted using deep neural\nnetworks have specific properties which can be used to improve accuracy of\ndownstream nonparametric learning methods. Namely, we demonstrate that for some\ndistributions where information is embedded in a few coordinates, segmenting\nfeature vectors can lead to better accuracy. We show how this model can be\napplied to real datasets by performing experiments using three mainstream deep\nneural network feature extractors and four databases, in vision and audio. \n\n"}
{"id": "1710.08937", "contents": "Title: Exact Mean Computation in Dynamic Time Warping Spaces Abstract: Dynamic time warping constitutes a major tool for analyzing time series. In\nparticular, computing a mean series of a given sample of series in dynamic time\nwarping spaces (by minimizing the Fr\\'echet function) is a challenging\ncomputational problem, so far solved by several heuristic and inexact\nstrategies. We spot some inaccuracies in the literature on exact mean\ncomputation in dynamic time warping spaces. Our contributions comprise an exact\ndynamic program computing a mean (useful for benchmarking and evaluating known\nheuristics). Based on this dynamic program, we empirically study properties\nlike uniqueness and length of a mean. Moreover, experimental evaluations reveal\nsubstantial deficits of state-of-the-art heuristics in terms of their output\nquality. We also give an exact polynomial-time algorithm for the special case\nof binary time series. \n\n"}
{"id": "1710.09988", "contents": "Title: Variance Reduced Value Iteration and Faster Algorithms for Solving\n  Markov Decision Processes Abstract: In this paper we provide faster algorithms for approximately solving\ndiscounted Markov Decision Processes in multiple parameter regimes. Given a\ndiscounted Markov Decision Process (DMDP) with $|S|$ states, $|A|$ actions,\ndiscount factor $\\gamma\\in(0,1)$, and rewards in the range $[-M, M]$, we show\nhow to compute an $\\epsilon$-optimal policy, with probability $1 - \\delta$ in\ntime \\[ \\tilde{O}\\left( \\left(|S|^2 |A| + \\frac{|S| |A|}{(1 - \\gamma)^3}\n\\right)\n  \\log\\left( \\frac{M}{\\epsilon} \\right) \\log\\left( \\frac{1}{\\delta} \\right)\n\\right) ~ . \\] This contribution reflects the first nearly linear time, nearly\nlinearly convergent algorithm for solving DMDPs for intermediate values of\n$\\gamma$.\n  We also show how to obtain improved sublinear time algorithms provided we can\nsample from the transition function in $O(1)$ time. Under this assumption we\nprovide an algorithm which computes an $\\epsilon$-optimal policy with\nprobability $1 - \\delta$ in time \\[ \\tilde{O} \\left(\\frac{|S| |A| M^2}{(1 -\n\\gamma)^4 \\epsilon^2} \\log \\left(\\frac{1}{\\delta}\\right) \\right) ~. \\]\n  Lastly, we extend both these algorithms to solve finite horizon MDPs. Our\nalgorithms improve upon the previous best for approximately computing optimal\npolicies for fixed-horizon MDPs in multiple parameter regimes.\n  Interestingly, we obtain our results by a careful modification of approximate\nvalue iteration. We show how to combine classic approximate value iteration\nanalysis with new techniques in variance reduction. Our fastest algorithms\nleverage further insights to ensure that our algorithms make monotonic progress\ntowards the optimal value. This paper is one of few instances in using sampling\nto obtain a linearly convergent linear programming algorithm and we hope that\nthe analysis may be useful more broadly. \n\n"}
{"id": "1710.10547", "contents": "Title: Interpretation of Neural Networks is Fragile Abstract: In order for machine learning to be deployed and trusted in many\napplications, it is crucial to be able to reliably explain why the machine\nlearning algorithm makes certain predictions. For example, if an algorithm\nclassifies a given pathology image to be a malignant tumor, then the doctor may\nneed to know which parts of the image led the algorithm to this classification.\nHow to interpret black-box predictors is thus an important and active area of\nresearch. A fundamental question is: how much can we trust the interpretation\nitself? In this paper, we show that interpretation of deep learning predictions\nis extremely fragile in the following sense: two perceptively indistinguishable\ninputs with the same predicted label can be assigned very different\ninterpretations. We systematically characterize the fragility of several\nwidely-used feature-importance interpretation methods (saliency maps, relevance\npropagation, and DeepLIFT) on ImageNet and CIFAR-10. Our experiments show that\neven small random perturbation can change the feature importance and new\nsystematic perturbations can lead to dramatically different interpretations\nwithout changing the label. We extend these results to show that\ninterpretations based on exemplars (e.g. influence functions) are similarly\nfragile. Our analysis of the geometry of the Hessian matrix gives insight on\nwhy fragility could be a fundamental challenge to the current interpretation\napproaches. \n\n"}
{"id": "1710.10881", "contents": "Title: Fast Linear Model for Knowledge Graph Embeddings Abstract: This paper shows that a simple baseline based on a Bag-of-Words (BoW)\nrepresentation learns surprisingly good knowledge graph embeddings. By casting\nknowledge base completion and question answering as supervised classification\nproblems, we observe that modeling co-occurences of entities and relations\nleads to state-of-the-art performance with a training time of a few minutes\nusing the open sourced library fastText. \n\n"}
{"id": "1710.11052", "contents": "Title: A Connection between Feed-Forward Neural Networks and Probabilistic\n  Graphical Models Abstract: Two of the most popular modelling paradigms in computer vision are\nfeed-forward neural networks (FFNs) and probabilistic graphical models (GMs).\nVarious connections between the two have been studied in recent works, such as\ne.g. expressing mean-field based inference in a GM as an FFN. This paper\nestablishes a new connection between FFNs and GMs. Our key observation is that\nany FFN implements a certain approximation of a corresponding Bayesian network\n(BN). We characterize various benefits of having this connection. In\nparticular, it results in a new learning algorithm for BNs. We validate the\nproposed methods for a classification problem on CIFAR-10 dataset and for\nbinary image segmentation on Weizmann Horse dataset. We show that statistically\nlearned BNs improve performance, having at the same time essentially better\ngeneralization capability, than their FFN counterparts. \n\n"}
{"id": "1710.11070", "contents": "Title: Convergence Rates of Latent Topic Models Under Relaxed Identifiability\n  Conditions Abstract: In this paper we study the frequentist convergence rate for the Latent\nDirichlet Allocation (Blei et al., 2003) topic models. We show that the maximum\nlikelihood estimator converges to one of the finitely many equivalent\nparameters in Wasserstein's distance metric at a rate of $n^{-1/4}$ without\nassuming separability or non-degeneracy of the underlying topics and/or the\nexistence of more than three words per document, thus generalizing the previous\nworks of Anandkumar et al. (2012, 2014) from an information-theoretical\nperspective. We also show that the $n^{-1/4}$ convergence rate is optimal in\nthe worst case. \n\n"}
{"id": "1710.11253", "contents": "Title: Approximation Algorithms for $\\ell_0$-Low Rank Approximation Abstract: We study the $\\ell_0$-Low Rank Approximation Problem, where the goal is,\ngiven an $m \\times n$ matrix $A$, to output a rank-$k$ matrix $A'$ for which\n$\\|A'-A\\|_0$ is minimized. Here, for a matrix $B$, $\\|B\\|_0$ denotes the number\nof its non-zero entries. This NP-hard variant of low rank approximation is\nnatural for problems with no underlying metric, and its goal is to minimize the\nnumber of disagreeing data positions. We provide approximation algorithms which\nsignificantly improve the running time and approximation factor of previous\nwork. For $k > 1$, we show how to find, in poly$(mn)$ time for every $k$, a\nrank $O(k \\log(n/k))$ matrix $A'$ for which $\\|A'-A\\|_0 \\leq O(k^2 \\log(n/k))\n\\mathrm{OPT}$. To the best of our knowledge, this is the first algorithm with\nprovable guarantees for the $\\ell_0$-Low Rank Approximation Problem for $k >\n1$, even for bicriteria algorithms. For the well-studied case when $k = 1$, we\ngive a $(2+\\epsilon)$-approximation in {\\it sublinear time}, which is\nimpossible for other variants of low rank approximation such as for the\nFrobenius norm. We strengthen this for the well-studied case of binary matrices\nto obtain a $(1+O(\\psi))$-approximation in sublinear time, where $\\psi =\n\\mathrm{OPT}/\\lVert A\\rVert_0$. For small $\\psi$, our approximation factor is\n$1+o(1)$. \n\n"}
{"id": "1711.00108", "contents": "Title: Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer\n  Ordering Abstract: Existing deep multitask learning (MTL) approaches align layers shared between\ntasks in a parallel ordering. Such an organization significantly constricts the\ntypes of shared structure that can be learned. The necessity of parallel\nordering for deep MTL is first tested by comparing it with permuted ordering of\nshared layers. The results indicate that a flexible ordering can enable more\neffective sharing, thus motivating the development of a soft ordering approach,\nwhich learns how shared layers are applied in different ways for different\ntasks. Deep MTL with soft ordering outperforms parallel ordering methods across\na series of domains. These results suggest that the power of deep MTL comes\nfrom learning highly general building blocks that can be assembled to meet the\ndemands of each task. \n\n"}
{"id": "1711.01761", "contents": "Title: AdaBatch: Efficient Gradient Aggregation Rules for Sequential and\n  Parallel Stochastic Gradient Methods Abstract: We study a new aggregation operator for gradients coming from a mini-batch\nfor stochastic gradient (SG) methods that allows a significant speed-up in the\ncase of sparse optimization problems. We call this method AdaBatch and it only\nrequires a few lines of code change compared to regular mini-batch SGD\nalgorithms. We provide a theoretical insight to understand how this new class\nof algorithms is performing and show that it is equivalent to an implicit\nper-coordinate rescaling of the gradients, similarly to what Adagrad methods\ncan do. In theory and in practice, this new aggregation allows to keep the same\nsample efficiency of SG methods while increasing the batch size.\nExperimentally, we also show that in the case of smooth convex optimization,\nour procedure can even obtain a better loss when increasing the batch size for\na fixed number of samples. We then apply this new algorithm to obtain a\nparallelizable stochastic gradient method that is synchronous but allows\nspeed-up on par with Hogwild! methods as convergence does not deteriorate with\nthe increase of the batch size. The same approach can be used to make\nmini-batch provably efficient for variance-reduced SG methods such as SVRG. \n\n"}
{"id": "1711.02195", "contents": "Title: Optimality of Approximate Inference Algorithms on Stable Instances Abstract: Approximate algorithms for structured prediction problems---such as LP\nrelaxations and the popular alpha-expansion algorithm (Boykov et al.\n2001)---typically far exceed their theoretical performance guarantees on\nreal-world instances. These algorithms often find solutions that are very close\nto optimal. The goal of this paper is to partially explain the performance of\nalpha-expansion and an LP relaxation algorithm on MAP inference in\nFerromagnetic Potts models (FPMs). Our main results give stability conditions\nunder which these two algorithms provably recover the optimal MAP solution.\nThese theoretical results complement numerous empirical observations of good\nperformance. \n\n"}
{"id": "1711.02653", "contents": "Title: Neural system identification for large populations separating \"what\" and\n  \"where\" Abstract: Neuroscientists classify neurons into different types that perform similar\ncomputations at different locations in the visual field. Traditional methods\nfor neural system identification do not capitalize on this separation of 'what'\nand 'where'. Learning deep convolutional feature spaces that are shared among\nmany neurons provides an exciting path forward, but the architectural design\nneeds to account for data limitations: While new experimental techniques enable\nrecordings from thousands of neurons, experimental time is limited so that one\ncan sample only a small fraction of each neuron's response space. Here, we show\nthat a major bottleneck for fitting convolutional neural networks (CNNs) to\nneural data is the estimation of the individual receptive field locations, a\nproblem that has been scratched only at the surface thus far. We propose a CNN\narchitecture with a sparse readout layer factorizing the spatial (where) and\nfeature (what) dimensions. Our network scales well to thousands of neurons and\nshort recordings and can be trained end-to-end. We evaluate this architecture\non ground-truth data to explore the challenges and limitations of CNN-based\nsystem identification. Moreover, we show that our network model outperforms\ncurrent state-of-the art system identification models of mouse primary visual\ncortex. \n\n"}
{"id": "1711.02741", "contents": "Title: Recurrent Autoregressive Networks for Online Multi-Object Tracking Abstract: The main challenge of online multi-object tracking is to reliably associate\nobject trajectories with detections in each video frame based on their tracking\nhistory. In this work, we propose the Recurrent Autoregressive Network (RAN), a\ntemporal generative modeling framework to characterize the appearance and\nmotion dynamics of multiple objects over time. The RAN couples an external\nmemory and an internal memory. The external memory explicitly stores previous\ninputs of each trajectory in a time window, while the internal memory learns to\nsummarize long-term tracking history and associate detections by processing the\nexternal memory. We conduct experiments on the MOT 2015 and 2016 datasets to\ndemonstrate the robustness of our tracking method in highly crowded and\noccluded scenes. Our method achieves top-ranked results on the two benchmarks. \n\n"}
{"id": "1711.03190", "contents": "Title: Learning Credible Models Abstract: In many settings, it is important that a model be capable of providing\nreasons for its predictions (i.e., the model must be interpretable). However,\nthe model's reasoning may not conform with well-established knowledge. In such\ncases, while interpretable, the model lacks \\textit{credibility}. In this work,\nwe formally define credibility in the linear setting and focus on techniques\nfor learning models that are both accurate and credible. In particular, we\npropose a regularization penalty, expert yielded estimates (EYE), that\nincorporates expert knowledge about well-known relationships among covariates\nand the outcome of interest. We give both theoretical and empirical results\ncomparing our proposed method to several other regularization techniques.\nAcross a range of settings, experiments on both synthetic and real data show\nthat models learned using the EYE penalty are significantly more credible than\nthose learned using other penalties. Applied to a large-scale patient risk\nstratification task, our proposed technique results in a model whose top\nfeatures overlap significantly with known clinical risk factors, while still\nachieving good predictive performance. \n\n"}
{"id": "1711.03321", "contents": "Title: A Separation Principle for Control in the Age of Deep Learning Abstract: We review the problem of defining and inferring a \"state\" for a control\nsystem based on complex, high-dimensional, highly uncertain measurement streams\nsuch as videos. Such a state, or representation, should contain all and only\nthe information needed for control, and discount nuisance variability in the\ndata. It should also have finite complexity, ideally modulated depending on\navailable resources. This representation is what we want to store in memory in\nlieu of the data, as it \"separates\" the control task from the measurement\nprocess. For the trivial case with no dynamics, a representation can be\ninferred by minimizing the Information Bottleneck Lagrangian in a function\nclass realized by deep neural networks. The resulting representation has much\nhigher dimension than the data, already in the millions, but it is smaller in\nthe sense of information content, retaining only what is needed for the task.\nThis process also yields representations that are invariant to nuisance factors\nand having maximally independent components. We extend these ideas to the\ndynamic case, where the representation is the posterior density of the task\nvariable given the measurements up to the current time, which is in general\nmuch simpler than the prediction density maintained by the classical Bayesian\nfilter. Again this can be finitely-parametrized using a deep neural network,\nand already some applications are beginning to emerge. No explicit assumption\nof Markovianity is needed; instead, complexity trades off approximation of an\noptimal representation, including the degree of Markovianity. \n\n"}
{"id": "1711.03577", "contents": "Title: What Really is Deep Learning Doing? Abstract: Deep learning has achieved a great success in many areas, from computer\nvision to natural language processing, to game playing, and much more. Yet,\nwhat deep learning is really doing is still an open question. There are a lot\nof works in this direction. For example, [5] tried to explain deep learning by\ngroup renormalization, and [6] tried to explain deep learning from the view of\nfunctional approximation. In order to address this very crucial question, here\nwe see deep learning from perspective of mechanical learning and learning\nmachine (see [1], [2]). From this particular angle, we can see deep learning\nmuch better and answer with confidence: What deep learning is really doing? why\nit works well, how it works, and how much data is necessary for learning. We\nalso will discuss advantages and disadvantages of deep learning at the end of\nthis work. \n\n"}
{"id": "1711.03591", "contents": "Title: Efficient-UCBV: An Almost Optimal Algorithm using Variance Estimates Abstract: We propose a novel variant of the UCB algorithm (referred to as\nEfficient-UCB-Variance (EUCBV)) for minimizing cumulative regret in the\nstochastic multi-armed bandit (MAB) setting. EUCBV incorporates the arm\nelimination strategy proposed in UCB-Improved \\citep{auer2010ucb}, while taking\ninto account the variance estimates to compute the arms' confidence bounds,\nsimilar to UCBV \\citep{audibert2009exploration}. Through a theoretical analysis\nwe establish that EUCBV incurs a \\emph{gap-dependent} regret bound of\n{\\scriptsize $O\\left( \\dfrac{K\\sigma^2_{\\max} \\log (T\\Delta^2\n/K)}{\\Delta}\\right)$} after $T$ trials, where $\\Delta$ is the minimal gap\nbetween optimal and sub-optimal arms; the above bound is an improvement over\nthat of existing state-of-the-art UCB algorithms (such as UCB1, UCB-Improved,\nUCBV, MOSS). Further, EUCBV incurs a \\emph{gap-independent} regret bound of\n{\\scriptsize $O\\left(\\sqrt{KT}\\right)$} which is an improvement over that of\nUCB1, UCBV and UCB-Improved, while being comparable with that of MOSS and\nOCUCB. Through an extensive numerical study we show that EUCBV significantly\noutperforms the popular UCB variants (like MOSS, OCUCB, etc.) as well as\nThompson sampling and Bayes-UCB algorithms. \n\n"}
{"id": "1711.05828", "contents": "Title: BoostJet: Towards Combining Statistical Aggregates with Neural\n  Embeddings for Recommendations Abstract: Recommenders have become widely popular in recent years because of their\nbroader applicability in many e-commerce applications. These applications rely\non recommenders for generating advertisements for various offers or providing\ncontent recommendations. However, the quality of the generated recommendations\ndepends on user features (like demography, temporality), offer features (like\npopularity, price), and user-offer features (like implicit or explicit\nfeedback). Current state-of-the-art recommenders do not explore such diverse\nfeatures concurrently while generating the recommendations.\n  In this paper, we first introduce the notion of Trackers which enables us to\ncapture the above-mentioned features and thus incorporate users' online\nbehaviour through statistical aggregates of different features (demography,\ntemporality, popularity, price). We also show how to capture offer-to-offer\nrelations, based on their consumption sequence, leveraging neural embeddings\nfor offers in our Offer2Vec algorithm. We then introduce BoostJet, a novel\nrecommender which integrates the Trackers along with the neural embeddings\nusing MatrixNet, an efficient distributed implementation of gradient boosted\ndecision tree, to improve the recommendation quality significantly. We provide\nan in-depth evaluation of BoostJet on Yandex's dataset, collecting online\nbehaviour from tens of millions of online users, to demonstrate the\npracticality of BoostJet in terms of recommendation quality as well as\nscalability. \n\n"}
{"id": "1711.07433", "contents": "Title: Relaxed Oracles for Semi-Supervised Clustering Abstract: Pairwise \"same-cluster\" queries are one of the most widely used forms of\nsupervision in semi-supervised clustering. However, it is impractical to ask\nhuman oracles to answer every query correctly. In this paper, we study the\ninfluence of allowing \"not-sure\" answers from a weak oracle and propose an\neffective algorithm to handle such uncertainties in query responses. Two\nrealistic weak oracle models are considered where ambiguity in answering\ndepends on the distance between two points. We show that a small query\ncomplexity is adequate for effective clustering with high probability by\nproviding better pairs to the weak oracle. Experimental results on synthetic\nand real data show the effectiveness of our approach in overcoming supervision\nuncertainties and yielding high quality clusters. \n\n"}
{"id": "1711.08421", "contents": "Title: Relief-Based Feature Selection: Introduction and Review Abstract: Feature selection plays a critical role in biomedical data mining, driven by\nincreasing feature dimensionality in target problems and growing interest in\nadvanced but computationally expensive methodologies able to model complex\nassociations. Specifically, there is a need for feature selection methods that\nare computationally efficient, yet sensitive to complex patterns of\nassociation, e.g. interactions, so that informative features are not mistakenly\neliminated prior to downstream modeling. This paper focuses on Relief-based\nalgorithms (RBAs), a unique family of filter-style feature selection algorithms\nthat have gained appeal by striking an effective balance between these\nobjectives while flexibly adapting to various data characteristics, e.g.\nclassification vs. regression. First, this work broadly examines types of\nfeature selection and defines RBAs within that context. Next, we introduce the\noriginal Relief algorithm and associated concepts, emphasizing the intuition\nbehind how it works, how feature weights generated by the algorithm can be\ninterpreted, and why it is sensitive to feature interactions without evaluating\ncombinations of features. Lastly, we include an expansive review of RBA\nmethodological research beyond Relief and its popular descendant, ReliefF. In\nparticular, we characterize branches of RBA research, and provide comparative\nsummaries of RBA algorithms including contributions, strategies, functionality,\ntime complexity, adaptation to key data characteristics, and software\navailability. \n\n"}
{"id": "1711.08841", "contents": "Title: Clustering Semi-Random Mixtures of Gaussians Abstract: Gaussian mixture models (GMM) are the most widely used statistical model for\nthe $k$-means clustering problem and form a popular framework for clustering in\nmachine learning and data analysis. In this paper, we propose a natural\nsemi-random model for $k$-means clustering that generalizes the Gaussian\nmixture model, and that we believe will be useful in identifying robust\nalgorithms. In our model, a semi-random adversary is allowed to make arbitrary\n\"monotone\" or helpful changes to the data generated from the Gaussian mixture\nmodel.\n  Our first contribution is a polynomial time algorithm that provably recovers\nthe ground-truth up to small classification error w.h.p., assuming certain\nseparation between the components. Perhaps surprisingly, the algorithm we\nanalyze is the popular Lloyd's algorithm for $k$-means clustering that is the\nmethod-of-choice in practice. Our second result complements the upper bound by\ngiving a nearly matching information-theoretic lower bound on the number of\nmisclassified points incurred by any $k$-means clustering algorithm on the\nsemi-random model. \n\n"}
{"id": "1711.09306", "contents": "Title: Inference of Spatio-Temporal Functions over Graphs via Multi-Kernel\n  Kriged Kalman Filtering Abstract: Inference of space-time varying signals on graphs emerges naturally in a\nplethora of network science related applications. A frequently encountered\nchallenge pertains to reconstructing such dynamic processes, given their values\nover a subset of vertices and time instants. The present paper develops a\ngraph-aware kernel-based kriged Kalman filter that accounts for the\nspatio-temporal variations, and offers efficient online reconstruction, even\nfor dynamically evolving network topologies. The kernel-based learning\nframework bypasses the need for statistical information by capitalizing on the\nsmoothness that graph signals exhibit with respect to the underlying graph. To\naddress the challenge of selecting the appropriate kernel, the proposed filter\nis combined with a multi-kernel selection module. Such a data-driven method\nselects a kernel attuned to the signal dynamics on-the-fly within the linear\nspan of a pre-selected dictionary. The novel multi-kernel learning algorithm\nexploits the eigenstructure of Laplacian kernel matrices to reduce\ncomputational complexity. Numerical tests with synthetic and real data\ndemonstrate the superior reconstruction performance of the novel approach\nrelative to state-of-the-art alternatives. \n\n"}
{"id": "1711.10414", "contents": "Title: When are epsilon-nets small? Abstract: In many interesting situations the size of epsilon-nets depends only on\n$\\epsilon$ together with different complexity measures. The aim of this paper\nis to give a systematic treatment of such complexity measures arising in\nDiscrete and Computational Geometry and Statistical Learning, and to bridge the\ngap between the results appearing in these two fields. As a byproduct, we\nobtain several new upper bounds on the sizes of epsilon-nets that\ngeneralize/improve the best known general guarantees. In particular, our\nresults work with regimes when small epsilon-nets of size\n$o(\\frac{1}{\\epsilon})$ exist, which are not usually covered by standard upper\nbounds. Inspired by results in Statistical Learning we also give a short proof\nof the Haussler's upper bound on packing numbers. \n\n"}
{"id": "1711.11561", "contents": "Title: Measuring the tendency of CNNs to Learn Surface Statistical Regularities Abstract: Deep CNNs are known to exhibit the following peculiarity: on the one hand\nthey generalize extremely well to a test set, while on the other hand they are\nextremely sensitive to so-called adversarial perturbations. The extreme\nsensitivity of high performance CNNs to adversarial examples casts serious\ndoubt that these networks are learning high level abstractions in the dataset.\nWe are concerned with the following question: How can a deep CNN that does not\nlearn any high level semantics of the dataset manage to generalize so well? The\ngoal of this article is to measure the tendency of CNNs to learn surface\nstatistical regularities of the dataset. To this end, we use Fourier filtering\nto construct datasets which share the exact same high level abstractions but\nexhibit qualitatively different surface statistical regularities. For the SVHN\nand CIFAR-10 datasets, we present two Fourier filtered variants: a low\nfrequency variant and a randomly filtered variant. Each of the Fourier\nfiltering schemes is tuned to preserve the recognizability of the objects. Our\nmain finding is that CNNs exhibit a tendency to latch onto the Fourier image\nstatistics of the training dataset, sometimes exhibiting up to a 28%\ngeneralization gap across the various test sets. Moreover, we observe that\nsignificantly increasing the depth of a network has a very marginal impact on\nclosing the aforementioned generalization gap. Thus we provide quantitative\nevidence supporting the hypothesis that deep CNNs tend to learn surface\nstatistical regularities in the dataset rather than higher-level abstract\nconcepts. \n\n"}
{"id": "1712.00424", "contents": "Title: The reparameterization trick for acquisition functions Abstract: Bayesian optimization is a sample-efficient approach to solving global\noptimization problems. Along with a surrogate model, this approach relies on\ntheoretically motivated value heuristics (acquisition functions) to guide the\nsearch process. Maximizing acquisition functions yields the best performance;\nunfortunately, this ideal is difficult to achieve since optimizing acquisition\nfunctions per se is frequently non-trivial. This statement is especially true\nin the parallel setting, where acquisition functions are routinely non-convex,\nhigh-dimensional, and intractable. Here, we demonstrate how many popular\nacquisition functions can be formulated as Gaussian integrals amenable to the\nreparameterization trick and, ensuingly, gradient-based optimization. Further,\nwe use this reparameterized representation to derive an efficient Monte Carlo\nestimator for the upper confidence bound acquisition function in the context of\nparallel selection. \n\n"}
{"id": "1712.00443", "contents": "Title: Deep Neural Network Architectures for Modulation Classification Abstract: In this work, we investigate the value of employing deep learning for the\ntask of wireless signal modulation recognition. Recently in [1], a framework\nhas been introduced by generating a dataset using GNU radio that mimics the\nimperfections in a real wireless channel, and uses 10 different modulation\ntypes. Further, a convolutional neural network (CNN) architecture was developed\nand shown to deliver performance that exceeds that of expert-based approaches.\nHere, we follow the framework of [1] and find deep neural network architectures\nthat deliver higher accuracy than the state of the art. We tested the\narchitecture of [1] and found it to achieve an accuracy of approximately 75% of\ncorrectly recognizing the modulation type. We first tune the CNN architecture\nof [1] and find a design with four convolutional layers and two dense layers\nthat gives an accuracy of approximately 83.8% at high SNR. We then develop\narchitectures based on the recently introduced ideas of Residual Networks\n(ResNet [2]) and Densely Connected Networks (DenseNet [3]) to achieve high SNR\naccuracies of approximately 83.5% and 86.6%, respectively. Finally, we\nintroduce a Convolutional Long Short-term Deep Neural Network (CLDNN [4]) to\nachieve an accuracy of approximately 88.5% at high SNR. \n\n"}
{"id": "1712.00499", "contents": "Title: Prediction-Constrained Topic Models for Antidepressant Recommendation Abstract: Supervisory signals can help topic models discover low-dimensional data\nrepresentations that are more interpretable for clinical tasks. We propose a\nframework for training supervised latent Dirichlet allocation that balances two\ngoals: faithful generative explanations of high-dimensional data and accurate\nprediction of associated class labels. Existing approaches fail to balance\nthese goals by not properly handling a fundamental asymmetry: the intended task\nis always predicting labels from data, not data from labels. Our new\nprediction-constrained objective trains models that predict labels from heldout\ndata well while also producing good generative likelihoods and interpretable\ntopic-word parameters. In a case study on predicting depression medications\nfrom electronic health records, we demonstrate improved recommendations\ncompared to previous supervised topic models and high- dimensional logistic\nregression from words alone. \n\n"}
{"id": "1712.00519", "contents": "Title: An Elementary Analysis of the Probability That a Binomial Random\n  Variable Exceeds Its Expectation Abstract: We give an elementary proof of the fact that a binomial random variable $X$\nwith parameters $n$ and $0.29/n \\le p < 1$ with probability at least $1/4$\nstrictly exceeds its expectation. We also show that for $1/n \\le p < 1 - 1/n$,\n$X$ exceeds its expectation by more than one with probability at least\n$0.0370$. Both probabilities approach $1/2$ when $np$ and $n(1-p)$ tend to\ninfinity. \n\n"}
{"id": "1712.00714", "contents": "Title: Spatial PixelCNN: Generating Images from Patches Abstract: In this paper we propose Spatial PixelCNN, a conditional autoregressive model\nthat generates images from small patches. By conditioning on a grid of pixel\ncoordinates and global features extracted from a Variational Autoencoder (VAE),\nwe are able to train on patches of images, and reproduce the full-sized image.\nWe show that it not only allows for generating high quality samples at the same\nresolution as the underlying dataset, but is also capable of upscaling images\nto arbitrary resolutions (tested at resolutions up to $50\\times$) on the MNIST\ndataset. Compared to a PixelCNN++ baseline, Spatial PixelCNN quantitatively and\nqualitatively achieves similar performance on the MNIST dataset. \n\n"}
{"id": "1712.02488", "contents": "Title: Cost-sensitive detection with variational autoencoders for environmental\n  acoustic sensing Abstract: Environmental acoustic sensing involves the retrieval and processing of audio\nsignals to better understand our surroundings. While large-scale acoustic data\nmake manual analysis infeasible, they provide a suitable playground for machine\nlearning approaches. Most existing machine learning techniques developed for\nenvironmental acoustic sensing do not provide flexible control of the trade-off\nbetween the false positive rate and the false negative rate. This paper\npresents a cost-sensitive classification paradigm, in which the\nhyper-parameters of classifiers and the structure of variational autoencoders\nare selected in a principled Neyman-Pearson framework. We examine the\nperformance of the proposed approach using a dataset from the HumBug project\nwhich aims to detect the presence of mosquitoes using sound collected by simple\nembedded devices. \n\n"}
{"id": "1712.03714", "contents": "Title: Efficient enumeration of solutions produced by closure operations Abstract: In this paper we address the problem of generating all elements obtained by\nthe saturation of an initial set by some operations. More precisely, we prove\nthat we can generate the closure of a boolean relation (a set of boolean\nvectors) by polymorphisms with a polynomial delay. Therefore we can compute\nwith polynomial delay the closure of a family of sets by any set of \"set\noperations\": union, intersection, symmetric difference, subsets, supersets\n$\\dots$). To do so, we study the $Membership_{\\mathcal{F}}$ problem: for a set\nof operations $\\mathcal{F}$, decide whether an element belongs to the closure\nby $\\mathcal{F}$ of a family of elements. In the boolean case, we prove that\n$Membership_{\\mathcal{F}}$ is in P for any set of boolean operations\n$\\mathcal{F}$. When the input vectors are over a domain larger than two\nelements, we prove that the generic enumeration method fails, since\n$Membership_{\\mathcal{F}}$ is NP-hard for some $\\mathcal{F}$. We also study the\nproblem of generating minimal or maximal elements of closures and prove that\nsome of them are related to well known enumeration problems such as the\nenumeration of the circuits of a matroid or the enumeration of maximal\nindependent sets of a hypergraph. This article improves on previous works of\nthe same authors. \n\n"}
{"id": "1712.04043", "contents": "Title: How to navigate through obstacles? Abstract: Given a set of obstacles and two points, is there a path between the two\npoints that does not cross more than $k$ different obstacles? This is a\nfundamental problem that has undergone a tremendous amount of work. It is known\nto be NP-hard, even when the obstacles are very simple geometric shapes (e.g.,\nunit-length line segments). The problem can be generalized into the following\ngraph problem: Given a planar graph $G$ whose vertices are colored by color\nsets, two designated vertices $s, t \\in V(G)$, and $k \\in \\mathbb{N}$, is there\nan $s$-$t$ path in $G$ that uses at most $k$ colors? If each obstacle is\nconnected, the resulting graph satisfies the color-connectivity property,\nnamely that each color induces a connected subgraph.\n  We study the complexity and design algorithms for the above graph problem\nwith an eye on its geometric applications. We prove that without the\ncolor-connectivity property, the problem is W[SAT]-hard parameterized by $k$. A\ncorollary of this result is that, unless W[2] $=$ FPT, the problem cannot be\napproximated in FPT time to within a factor that is a function of $k$. By\ndescribing a generic plane embedding of the graph instances, we show that our\nhardness results translate to the geometric instances of the problem.\n  We then focus on graphs satisfying the color-connectivity property. By\nexploiting the planarity of the graph and the connectivity of the colors, we\ndevelop topological results to \"represent\" the valid $s$-$t$ paths containing\nsubsets of colors from any vertex $v$. We employ these results to design an FPT\nalgorithm for the problem parameterized by both $k$ and the treewidth of the\ngraph, and extend this result to obtain an FPT algorithm for the\nparameterization by both $k$ and the length of the path. The latter result\ndirectly implies previous FPT results for various obstacle shapes, such as unit\ndisks and fat regions. \n\n"}
{"id": "1712.06214", "contents": "Title: Predicting Individual Physiologically Acceptable States for Discharge\n  from a Pediatric Intensive Care Unit Abstract: Objective: Predict patient-specific vitals deemed medically acceptable for\ndischarge from a pediatric intensive care unit (ICU). Design: The means of each\npatient's hr, sbp and dbp measurements between their medical and physical\ndischarge from the ICU were computed as a proxy for their physiologically\nacceptable state space (PASS) for successful ICU discharge. These individual\nPASS values were compared via root mean squared error (rMSE) to population\nage-normal vitals, a polynomial regression through the PASS values of a\nPediatric ICU (PICU) population and predictions from two recurrent neural\nnetwork models designed to predict personalized PASS within the first twelve\nhours following ICU admission. Setting: PICU at Children's Hospital Los Angeles\n(CHLA). Patients: 6,899 PICU episodes (5,464 patients) collected between 2009\nand 2016. Interventions: None. Measurements: Each episode data contained 375\nvariables representing vitals, labs, interventions, and drugs. They also\nincluded a time indicator for PICU medical discharge and physical discharge.\nMain Results: The rMSEs between individual PASS values and population\nage-normals (hr: 25.9 bpm, sbp: 13.4 mmHg, dbp: 13.0 mmHg) were larger than the\nrMSEs corresponding to the polynomial regression (hr: 19.1 bpm, sbp: 12.3 mmHg,\ndbp: 10.8 mmHg). The rMSEs from the best performing RNN model were the lowest\n(hr: 16.4 bpm; sbp: 9.9 mmHg, dbp: 9.0 mmHg). Conclusion: PICU patients are a\nunique subset of the general population, and general age-normal vitals may not\nbe suitable as target values indicating physiologic stability at discharge.\nAge-normal vitals that were specifically derived from the medical-to-physical\ndischarge window of ICU patients may be more appropriate targets for\n'acceptable' physiologic state for critical care patients. Going beyond simple\nage bins, an RNN model can provide more personalized target values. \n\n"}
{"id": "1712.06343", "contents": "Title: Squeezed Convolutional Variational AutoEncoder for Unsupervised Anomaly\n  Detection in Edge Device Industrial Internet of Things Abstract: In this paper, we propose Squeezed Convolutional Variational AutoEncoder\n(SCVAE) for anomaly detection in time series data for Edge Computing in\nIndustrial Internet of Things (IIoT). The proposed model is applied to labeled\ntime series data from UCI datasets for exact performance evaluation, and\napplied to real world data for indirect model performance comparison. In\naddition, by comparing the models before and after applying Fire Modules from\nSqueezeNet, we show that model size and inference times are reduced while\nsimilar levels of performance is maintained. \n\n"}
{"id": "1712.06481", "contents": "Title: Inductive $k$-independent graphs and $c$-colorable subgraphs in\n  scheduling: A review Abstract: Inductive $k$-independent graphs generalize chordal graphs and have recently\nbeen advocated in the context of interference-avoiding wireless communication\nscheduling. The NP-hard problem of finding maximum-weight induced $c$-colorable\nsubgraphs, which is a generalization of finding maximum independent sets,\nnaturally occurs when selecting $c$ sets of pairwise non-conflicting jobs\n(modeled as graph vertices). We investigate the parameterized complexity of\nthis problem on inductive $k$-independent graphs. We show that the Independent\nSet problem is W[1]-hard even on 2-simplicial 3-minoes---a subclass of\ninductive 2-independent graphs. In contrast, we prove that the more general\nMaximum $c$-Colorable Subgraph problem is fixed-parameter tractable on\nedge-wise unions of cluster and chordal graphs, which are 2-simplicial. In both\ncases, the parameter is the solution size. Aside from this, we survey other\ngraph classes between inductive 1-inductive and inductive 2-inductive graphs\nwith applications in scheduling. \n\n"}
{"id": "1712.06793", "contents": "Title: Two-dimensional Anti-jamming Mobile Communication Based on Reinforcement\n  Learning Abstract: By using smart radio devices, a jammer can dynamically change its jamming\npolicy based on opposing security mechanisms; it can even induce the mobile\ndevice to enter a specific communication mode and then launch the jamming\npolicy accordingly. On the other hand, mobile devices can exploit spread\nspectrum and user mobility to address both jamming and interference. In this\npaper, a two-dimensional anti-jamming mobile communication scheme is proposed\nin which a mobile device leaves a heavily jammed/interfered-with frequency or\narea. It is shown that, by applying reinforcement learning techniques, a mobile\ndevice can achieve an optimal communication policy without the need to know the\njamming and interference model and the radio channel model in a dynamic game\nframework. More specifically, a hotbooting deep Q-network based two-dimensional\nmobile communication scheme is proposed that exploits experiences in similar\nscenarios to reduce the exploration time at the beginning of the game, and\napplies deep convolutional neural network and macro-action techniques to\naccelerate the learning speed in dynamic situations. Several real-world\nscenarios are simulated to evaluate the proposed method. These simulation\nresults show that our proposed scheme can improve both the\nsignal-to-interference-plus-noise ratio of the signals and the utility of the\nmobile devices against cooperative jamming compared with benchmark schemes. \n\n"}
{"id": "1712.07102", "contents": "Title: On Data-Dependent Random Features for Improved Generalization in\n  Supervised Learning Abstract: The randomized-feature approach has been successfully employed in large-scale\nkernel approximation and supervised learning. The distribution from which the\nrandom features are drawn impacts the number of features required to\nefficiently perform a learning task. Recently, it has been shown that employing\ndata-dependent randomization improves the performance in terms of the required\nnumber of random features. In this paper, we are concerned with the\nrandomized-feature approach in supervised learning for good generalizability.\nWe propose the Energy-based Exploration of Random Features (EERF) algorithm\nbased on a data-dependent score function that explores the set of possible\nfeatures and exploits the promising regions. We prove that the proposed score\nfunction with high probability recovers the spectrum of the best fit within the\nmodel class. Our empirical results on several benchmark datasets further verify\nthat our method requires smaller number of random features to achieve a certain\ngeneralization error compared to the state-of-the-art while introducing\nnegligible pre-processing overhead. EERF can be implemented in a few lines of\ncode and requires no additional tuning parameters. \n\n"}
{"id": "1712.08708", "contents": "Title: Variational Autoencoders for Learning Latent Representations of Speech\n  Emotion: A Preliminary Study Abstract: Learning the latent representation of data in unsupervised fashion is a very\ninteresting process that provides relevant features for enhancing the\nperformance of a classifier. For speech emotion recognition tasks, generating\neffective features is crucial. Currently, handcrafted features are mostly used\nfor speech emotion recognition, however, features learned automatically using\ndeep learning have shown strong success in many problems, especially in image\nprocessing. In particular, deep generative models such as Variational\nAutoencoders (VAEs) have gained enormous success for generating features for\nnatural images. Inspired by this, we propose VAEs for deriving the latent\nrepresentation of speech signals and use this representation to classify\nemotions. To the best of our knowledge, we are the first to propose VAEs for\nspeech emotion classification. Evaluations on the IEMOCAP dataset demonstrate\nthat features learned by VAEs can produce state-of-the-art results for speech\nemotion classification. \n\n"}
{"id": "1712.08968", "contents": "Title: Spurious Local Minima are Common in Two-Layer ReLU Neural Networks Abstract: We consider the optimization problem associated with training simple ReLU\nneural networks of the form $\\mathbf{x}\\mapsto\n\\sum_{i=1}^{k}\\max\\{0,\\mathbf{w}_i^\\top \\mathbf{x}\\}$ with respect to the\nsquared loss. We provide a computer-assisted proof that even if the input\ndistribution is standard Gaussian, even if the dimension is arbitrarily large,\nand even if the target values are generated by such a network, with orthonormal\nparameter vectors, the problem can still have spurious local minima once $6\\le\nk\\le 20$. By a concentration of measure argument, this implies that in high\ninput dimensions, \\emph{nearly all} target networks of the relevant sizes lead\nto spurious local minima. Moreover, we conduct experiments which show that the\nprobability of hitting such local minima is quite high, and increasing with the\nnetwork size. On the positive side, mild over-parameterization appears to\ndrastically reduce such local minima, indicating that an over-parameterization\nassumption is necessary to get a positive result in this setting. \n\n"}
{"id": "1712.09379", "contents": "Title: IHT dies hard: Provable accelerated Iterative Hard Thresholding Abstract: We study --both in theory and practice-- the use of momentum motions in\nclassic iterative hard thresholding (IHT) methods. By simply modifying plain\nIHT, we investigate its convergence behavior on convex optimization criteria\nwith non-convex constraints, under standard assumptions. In diverse scenaria,\nwe observe that acceleration in IHT leads to significant improvements, compared\nto state of the art projected gradient descent and Frank-Wolfe variants. As a\nbyproduct of our inspection, we study the impact of selecting the momentum\nparameter: similar to convex settings, two modes of behavior are observed\n--\"rippling\" and linear-- depending on the level of momentum. \n\n"}
{"id": "1712.09473", "contents": "Title: Sketching for Kronecker Product Regression and P-splines Abstract: TensorSketch is an oblivious linear sketch introduced in Pagh'13 and later\nused in Pham, Pagh'13 in the context of SVMs for polynomial kernels. It was\nshown in Avron, Nguyen, Woodruff'14 that TensorSketch provides a subspace\nembedding, and therefore can be used for canonical correlation analysis, low\nrank approximation, and principal component regression for the polynomial\nkernel. We take TensorSketch outside of the context of polynomials kernels, and\nshow its utility in applications in which the underlying design matrix is a\nKronecker product of smaller matrices. This allows us to solve Kronecker\nproduct regression and non-negative Kronecker product regression, as well as\nregularized spline regression. Our main technical result is then in extending\nTensorSketch to other norms. That is, TensorSketch only provides input sparsity\ntime for Kronecker product regression with respect to the $2$-norm. We show how\nto solve Kronecker product regression with respect to the $1$-norm in time\nsublinear in the time required for computing the Kronecker product, as well as\nfor more general $p$-norms. \n\n"}
{"id": "1712.10132", "contents": "Title: The Multilinear Structure of ReLU Networks Abstract: We study the loss surface of neural networks equipped with a hinge loss\ncriterion and ReLU or leaky ReLU nonlinearities. Any such network defines a\npiecewise multilinear form in parameter space. By appealing to harmonic\nanalysis we show that all local minima of such network are non-differentiable,\nexcept for those minima that occur in a region of parameter space where the\nloss surface is perfectly flat. Non-differentiable minima are therefore not\ntechnicalities or pathologies; they are heart of the problem when investigating\nthe loss of ReLU networks. As a consequence, we must employ techniques from\nnonsmooth analysis to study these loss surfaces. We show how to apply these\ntechniques in some illustrative cases. \n\n"}
{"id": "1801.01953", "contents": "Title: Adversarial Perturbation Intensity Achieving Chosen Intra-Technique\n  Transferability Level for Logistic Regression Abstract: Machine Learning models have been shown to be vulnerable to adversarial\nexamples, ie. the manipulation of data by a attacker to defeat a defender's\nclassifier at test time. We present a novel probabilistic definition of\nadversarial examples in perfect or limited knowledge setting using prior\nprobability distributions on the defender's classifier. Using the asymptotic\nproperties of the logistic regression, we derive a closed-form expression of\nthe intensity of any adversarial perturbation, in order to achieve a given\nexpected misclassification rate. This technique is relevant in a threat model\nof known model specifications and unknown training data. To our knowledge, this\nis the first method that allows an attacker to directly choose the probability\nof attack success. We evaluate our approach on two real-world datasets. \n\n"}
{"id": "1801.02294", "contents": "Title: Learning Tree-based Deep Model for Recommender Systems Abstract: Model-based methods for recommender systems have been studied extensively in\nrecent years. In systems with large corpus, however, the calculation cost for\nthe learnt model to predict all user-item preferences is tremendous, which\nmakes full corpus retrieval extremely difficult. To overcome the calculation\nbarriers, models such as matrix factorization resort to inner product form\n(i.e., model user-item preference as the inner product of user, item latent\nfactors) and indexes to facilitate efficient approximate k-nearest neighbor\nsearches. However, it still remains challenging to incorporate more expressive\ninteraction forms between user and item features, e.g., interactions through\ndeep neural networks, because of the calculation cost.\n  In this paper, we focus on the problem of introducing arbitrary advanced\nmodels to recommender systems with large corpus. We propose a novel tree-based\nmethod which can provide logarithmic complexity w.r.t. corpus size even with\nmore expressive models such as deep neural networks. Our main idea is to\npredict user interests from coarse to fine by traversing tree nodes in a\ntop-down fashion and making decisions for each user-node pair. We also show\nthat the tree structure can be jointly learnt towards better compatibility with\nusers' interest distribution and hence facilitate both training and prediction.\nExperimental evaluations with two large-scale real-world datasets show that the\nproposed method significantly outperforms traditional methods. Online A/B test\nresults in Taobao display advertising platform also demonstrate the\neffectiveness of the proposed method in production environments. \n\n"}
{"id": "1801.02363", "contents": "Title: Efficient and Effective Quantum Compiling for Entanglement-based Machine\n  Learning on IBM Q Devices Abstract: Quantum compiling means fast, device-aware implementation of quantum\nalgorithms (i.e., quantum circuits, in the quantum circuit model of\ncomputation). In this paper, we present a strategy for compiling IBM Q -aware,\nlow-depth quantum circuits that generate Greenberger-Horne-Zeilinger (GHZ)\nentangled states. The resulting compiler can replace the QISKit compiler for\nthe specific purpose of obtaining improved GHZ circuits. It is well known that\nGHZ states have several practical applications, including quantum machine\nlearning. We illustrate our experience in implementing and querying a uniform\nquantum example oracle based on the GHZ circuit, for solving the classically\nhard problem of learning parity with noise. \n\n"}
{"id": "1801.03329", "contents": "Title: Weakly Supervised One-Shot Detection with Attention Similarity Networks Abstract: Neural network models that are not conditioned on class identities were shown\nto facilitate knowledge transfer between classes and to be well-suited for\none-shot learning tasks. Following this motivation, we further explore and\nestablish such models and present a novel neural network architecture for the\ntask of weakly supervised one-shot detection. Our model is only conditioned on\na single exemplar of an unseen class and a larger target example that may or\nmay not contain an instance of the same class as the exemplar. By pairing a\nSiamese similarity network with an attention mechanism, we design a model that\nmanages to simultaneously identify and localise instances of classes unseen at\ntraining time. In experiments with datasets from the computer vision and audio\ndomains, the proposed method considerably outperforms the baseline methods for\nthe weakly supervised one-shot detection task. \n\n"}
{"id": "1801.04191", "contents": "Title: Computing permanents of complex diagonally dominant matrices and tensors Abstract: We prove that for any $\\lambda > 1$, fixed in advance, the permanent of an $n\n\\times n$ complex matrix, where the absolute value of each diagonal entry is at\nleast $\\lambda$ times bigger than the sum of the absolute values of all other\nentries in the same row, can be approximated within any relative error $0 <\n\\epsilon < 1$ in quasi-polynomial $n^{O(\\ln n - \\ln \\epsilon)}$ time. We extend\nthis result to multidimensional permanents of tensors and discuss its\napplication to weighted counting of perfect matchings in hypergraphs. \n\n"}
{"id": "1801.05411", "contents": "Title: Expectation Propagation for Approximate Inference: Free Probability\n  Framework Abstract: We study asymptotic properties of expectation propagation (EP) -- a method\nfor approximate inference originally developed in the field of machine\nlearning. Applied to generalized linear models, EP iteratively computes a\nmultivariate Gaussian approximation to the exact posterior distribution. The\ncomputational complexity of the repeated update of covariance matrices severely\nlimits the application of EP to large problem sizes. In this study, we present\na rigorous analysis by means of free probability theory that allows us to\novercome this computational bottleneck if specific data matrices in the problem\nfulfill certain properties of asymptotic freeness. We demonstrate the relevance\nof our approach on the gene selection problem of a microarray dataset. \n\n"}
{"id": "1801.06637", "contents": "Title: Deep Hidden Physics Models: Deep Learning of Nonlinear Partial\n  Differential Equations Abstract: A long-standing problem at the interface of artificial intelligence and\napplied mathematics is to devise an algorithm capable of achieving human level\nor even superhuman proficiency in transforming observed data into predictive\nmathematical models of the physical world. In the current era of abundance of\ndata and advanced machine learning capabilities, the natural question arises:\nHow can we automatically uncover the underlying laws of physics from\nhigh-dimensional data generated from experiments? In this work, we put forth a\ndeep learning approach for discovering nonlinear partial differential equations\nfrom scattered and potentially noisy observations in space and time.\nSpecifically, we approximate the unknown solution as well as the nonlinear\ndynamics by two deep neural networks. The first network acts as a prior on the\nunknown solution and essentially enables us to avoid numerical differentiations\nwhich are inherently ill-conditioned and unstable. The second network\nrepresents the nonlinear dynamics and helps us distill the mechanisms that\ngovern the evolution of a given spatiotemporal data-set. We test the\neffectiveness of our approach for several benchmark problems spanning a number\nof scientific domains and demonstrate how the proposed framework can help us\naccurately learn the underlying dynamics and forecast future states of the\nsystem. In particular, we study the Burgers', Korteweg-de Vries (KdV),\nKuramoto-Sivashinsky, nonlinear Schr\\\"{o}dinger, and Navier-Stokes equations. \n\n"}
{"id": "1801.06801", "contents": "Title: Curvature-based Comparison of Two Neural Networks Abstract: In this paper we show the similarities and differences of two deep neural\nnetworks by comparing the manifolds composed of activation vectors in each\nfully connected layer of them. The main contribution of this paper includes 1)\na new data generating algorithm which is crucial for determining the dimension\nof manifolds; 2) a systematic strategy to compare manifolds. Especially, we\ntake Riemann curvature and sectional curvature as part of criterion, which can\nreflect the intrinsic geometric properties of manifolds. Some interesting\nresults and phenomenon are given, which help in specifying the similarities and\ndifferences between the features extracted by two networks and demystifying the\nintrinsic mechanism of deep neural networks. \n\n"}
{"id": "1801.07553", "contents": "Title: Stable gonality is computable Abstract: Stable gonality is a multigraph parameter that measures the complexity of a\ngraph. It is defined using maps to trees. Those maps, in some sense, divide the\nedges equally over the edges of the tree; stable gonality asks for the map with\nthe minimum number of edges mapped to each edge of the tree. This parameter is\nrelated to treewidth, but unlike treewidth, it distinguishes multigraphs from\ntheir underlying simple graphs. Stable gonality is relevant for problems in\nnumber theory. In this paper, we show that deciding whether the stable gonality\nof a given graph is at most a given integer $k$ belongs to the class NP, and we\ngive an algorithm that computes the stable gonality of a graph in\n$O((1.33n)^nm^m \\text{poly}(n,m))$ time. \n\n"}
{"id": "1801.07593", "contents": "Title: Mitigating Unwanted Biases with Adversarial Learning Abstract: Machine learning is a tool for building models that accurately represent\ninput training data. When undesired biases concerning demographic groups are in\nthe training data, well-trained models will reflect those biases. We present a\nframework for mitigating such biases by including a variable for the group of\ninterest and simultaneously learning a predictor and an adversary. The input to\nthe network X, here text or census data, produces a prediction Y, such as an\nanalogy completion or income bracket, while the adversary tries to model a\nprotected variable Z, here gender or zip code.\n  The objective is to maximize the predictor's ability to predict Y while\nminimizing the adversary's ability to predict Z. Applied to analogy completion,\nthis method results in accurate predictions that exhibit less evidence of\nstereotyping Z. When applied to a classification task using the UCI Adult\n(Census) Dataset, it results in a predictive model that does not lose much\naccuracy while achieving very close to equality of odds (Hardt, et al., 2016).\nThe method is flexible and applicable to multiple definitions of fairness as\nwell as a wide range of gradient-based learning models, including both\nregression and classification tasks. \n\n"}
{"id": "1801.09720", "contents": "Title: A Generalized Circuit for the Hamiltonian Dynamics Through the Truncated\n  Series Abstract: In this paper, we present a method for the Hamiltonian simulation in the\ncontext of eigenvalue estimation problems which improves earlier results\ndealing with Hamiltonian simulation through the truncated Taylor series. In\nparticular, we present a fixed-quantum circuit design for the simulation of the\nHamiltonian dynamics, $H(t)$, through the truncated Taylor series method\ndescribed by Berry et al. \\cite{berry2015simulating}. The circuit is general\nand can be used to simulate any given matrix in the phase estimation algorithm\nby only changing the angle values of the quantum gates implementing the time\nvariable $t$ in the series. The circuit complexity depends on the number of\nsummation terms composing the Hamiltonian and requires $O(Ln)$ number of\nquantum gates for the simulation of a molecular Hamiltonian. Here, $n$ is the\nnumber of states of a spin orbital, and $L$ is the number of terms in the\nmolecular Hamiltonian and generally bounded by $O(n^4)$. We also discuss how to\nuse the circuit in adaptive processes and eigenvalue related problems along\nwith a slight modified version of the iterative phase estimation algorithm. In\naddition, a simple divide and conquer method is presented for mapping a matrix\nwhich are not given as sums of unitary matrices into the circuit. The\ncomplexity of the circuit is directly related to the structure of the matrix\nand can be bounded by $O(poly(n))$ for a matrix with $poly(n)-$sparsity. \n\n"}
{"id": "1801.10139", "contents": "Title: Analysis of the Continued Logarithm Algorithm Abstract: The Continued Logarithm Algorithm - CL for short- introduced by Gosper in\n1978 computes the gcd of two integers; it seems very efficient, as it only\nperforms shifts and subtractions. Shallit has studied its worst-case complexity\nin 2016 and showed it to be linear. We here perform the average-case analysis\nof the algorithm: we study its main parameters (number of iterations, total\nnumber of shifts) and obtain precise asymptotics for their mean values. Our\n'dynamical' analysis involves the dynamical system underlying the algorithm,\nthat produces continued fraction expansions whose quotients are powers of 2.\nEven though this CL system has already been studied by Chan (around 2005), the\npresence of powers of 2 in the quotients ingrains into the central parameters a\ndyadic flavour that cannot be grasped solely by studying the CL system. We thus\nintroduce a dyadic component and deal with a two-component system. With this\nnew mixed system at hand, we then provide a complete average-case analysis of\nthe CL algorithm, with explicit constants. \n\n"}
{"id": "1802.00927", "contents": "Title: Memory Fusion Network for Multi-view Sequential Learning Abstract: Multi-view sequential learning is a fundamental problem in machine learning\ndealing with multi-view sequences. In a multi-view sequence, there exists two\nforms of interactions between different views: view-specific interactions and\ncross-view interactions. In this paper, we present a new neural architecture\nfor multi-view sequential learning called the Memory Fusion Network (MFN) that\nexplicitly accounts for both interactions in a neural architecture and\ncontinuously models them through time. The first component of the MFN is called\nthe System of LSTMs, where view-specific interactions are learned in isolation\nthrough assigning an LSTM function to each view. The cross-view interactions\nare then identified using a special attention mechanism called the Delta-memory\nAttention Network (DMAN) and summarized through time with a Multi-view Gated\nMemory. Through extensive experimentation, MFN is compared to various proposed\napproaches for multi-view sequential learning on multiple publicly available\nbenchmark datasets. MFN outperforms all the existing multi-view approaches.\nFurthermore, MFN outperforms all current state-of-the-art models, setting new\nstate-of-the-art results for these multi-view datasets. \n\n"}
{"id": "1802.02500", "contents": "Title: Cadre Modeling: Simultaneously Discovering Subpopulations and Predictive\n  Models Abstract: We consider the problem in regression analysis of identifying subpopulations\nthat exhibit different patterns of response, where each subpopulation requires\na different underlying model. Unlike statistical cohorts, these subpopulations\nare not known a priori; thus, we refer to them as cadres. When the cadres and\ntheir associated models are interpretable, modeling leads to insights about the\nsubpopulations and their associations with the regression target. We introduce\na discriminative model that simultaneously learns cadre assignment and\ntarget-prediction rules. Sparsity-inducing priors are placed on the model\nparameters, under which independent feature selection is performed for both the\ncadre assignment and target-prediction processes. We learn models using\nadaptive step size stochastic gradient descent, and we assess cadre quality\nwith bootstrapped sample analysis. We present simulated results showing that,\nwhen the true clustering rule does not depend on the entire set of features,\nour method significantly outperforms methods that learn subpopulation-discovery\nand target-prediction rules separately. In a materials-by-design case study,\nour model provides state-of-the-art prediction of polymer glass transition\ntemperature. Importantly, the method identifies cadres of polymers that respond\ndifferently to structural perturbations, thus providing design insight for\ntargeting or avoiding specific transition temperature ranges. It identifies\nchemically meaningful cadres, each with interpretable models. Further\nexperimental results show that cadre methods have generalization that is\ncompetitive with linear and nonlinear regression models and can identify robust\nsubpopulations. \n\n"}
{"id": "1802.03050", "contents": "Title: Thompson Sampling for Dynamic Pricing Abstract: In this paper we apply active learning algorithms for dynamic pricing in a\nprominent e-commerce website. Dynamic pricing involves changing the price of\nitems on a regular basis, and uses the feedback from the pricing decisions to\nupdate prices of the items. Most popular approaches to dynamic pricing use a\npassive learning approach, where the algorithm uses historical data to learn\nvarious parameters of the pricing problem, and uses the updated parameters to\ngenerate a new set of prices. We show that one can use active learning\nalgorithms such as Thompson sampling to more efficiently learn the underlying\nparameters in a pricing problem. We apply our algorithms to a real e-commerce\nsystem and show that the algorithms indeed improve revenue compared to pricing\nalgorithms that use passive learning. \n\n"}
{"id": "1802.03235", "contents": "Title: The $b$-bibranching Problem: TDI System, Packing, and Discrete Convexity Abstract: In this paper, we introduce the $b$-bibranching problem in digraphs, which is\na common generalization of the bibranching and $b$-branching problems. The\nbibranching problem, introduced by Schrijver (1982), is a common generalization\nof the branching and bipartite edge cover problems. Previous results on\nbibranchings include polynomial algorithms, a linear programming formulation\nwith total dual integrality, a packing theorem, and an M-convex submodular flow\nformulation. The $b$-branching problem, recently introduced by Kakimura,\nKamiyama, and Takazawa (2018), is a generalization of the branching problem\nadmitting higher indegree, i.e., each vertex $v$ can have indegree at most\n$b(v)$. For $b$-branchings, a combinatorial algorithm, a linear programming\nformulation with total dual integrality, and a packing theorem for branchings\nare extended. A main contribution of this paper is to extend those previous\nresults on bibranchings and $b$-branchings to $b$-bibranchings. That is, we\npresent a linear programming formulation with total dual integrality, a packing\ntheorem, and an M-convex submodular flow formulation for $b$-bibranchings. In\nparticular, the linear program and M-convex submodular flow formulations\nrespectively imply polynomial algorithms for finding a shortest\n$b$-bibranching. \n\n"}
{"id": "1802.03334", "contents": "Title: Learning Localized Spatio-Temporal Models From Streaming Data Abstract: We address the problem of predicting spatio-temporal processes with temporal\npatterns that vary across spatial regions, when data is obtained as a stream.\nThat is, when the training dataset is augmented sequentially. Specifically, we\ndevelop a localized spatio-temporal covariance model of the process that can\ncapture spatially varying temporal periodicities in the data. We then apply a\ncovariance-fitting methodology to learn the model parameters which yields a\npredictor that can be updated sequentially with each new data point. The\nproposed method is evaluated using both synthetic and real climate data which\ndemonstrate its ability to accurately predict data missing in spatial regions\nover time. \n\n"}
{"id": "1802.03337", "contents": "Title: Large Scale Constrained Linear Regression Revisited: Faster Algorithms\n  via Preconditioning Abstract: In this paper, we revisit the large-scale constrained linear regression\nproblem and propose faster methods based on some recent developments in\nsketching and optimization. Our algorithms combine (accelerated) mini-batch SGD\nwith a new method called two-step preconditioning to achieve an approximate\nsolution with a time complexity lower than that of the state-of-the-art\ntechniques for the low precision case. Our idea can also be extended to the\nhigh precision case, which gives an alternative implementation to the Iterative\nHessian Sketch (IHS) method with significantly improved time complexity.\nExperiments on benchmark and synthetic datasets suggest that our methods indeed\noutperform existing ones considerably in both the low and high precision cases. \n\n"}
{"id": "1802.04198", "contents": "Title: client2vec: Towards Systematic Baselines for Banking Applications Abstract: The workflow of data scientists normally involves potentially inefficient\nprocesses such as data mining, feature engineering and model selection. Recent\nresearch has focused on automating this workflow, partly or in its entirety, to\nimprove productivity. We choose the former approach and in this paper share our\nexperience in designing the client2vec: an internal library to rapidly build\nbaselines for banking applications. Client2vec uses marginalized stacked\ndenoising autoencoders on current account transactions data to create vector\nembeddings which represent the behaviors of our clients. These representations\ncan then be used in, and optimized against, a variety of tasks such as client\nsegmentation, profiling and targeting. Here we detail how we selected the\nalgorithmic machinery of client2vec and the data it works on and present\nexperimental results on several business cases. \n\n"}
{"id": "1802.04477", "contents": "Title: A Simple Proximal Stochastic Gradient Method for Nonsmooth Nonconvex\n  Optimization Abstract: We analyze stochastic gradient algorithms for optimizing nonconvex, nonsmooth\nfinite-sum problems. In particular, the objective function is given by the\nsummation of a differentiable (possibly nonconvex) component, together with a\npossibly non-differentiable but convex component. We propose a proximal\nstochastic gradient algorithm based on variance reduction, called ProxSVRG+.\nOur main contribution lies in the analysis of ProxSVRG+. It recovers several\nexisting convergence results and improves/generalizes them (in terms of the\nnumber of stochastic gradient oracle calls and proximal oracle calls). In\nparticular, ProxSVRG+ generalizes the best results given by the SCSG algorithm,\nrecently proposed by [Lei et al., 2017] for the smooth nonconvex case.\nProxSVRG+ is also more straightforward than SCSG and yields simpler analysis.\nMoreover, ProxSVRG+ outperforms the deterministic proximal gradient descent\n(ProxGD) for a wide range of minibatch sizes, which partially solves an open\nproblem proposed in [Reddi et al., 2016b]. Also, ProxSVRG+ uses much less\nproximal oracle calls than ProxSVRG [Reddi et al., 2016b]. Moreover, for\nnonconvex functions satisfied Polyak-\\L{}ojasiewicz condition, we prove that\nProxSVRG+ achieves a global linear convergence rate without restart unlike\nProxSVRG. Thus, it can \\emph{automatically} switch to the faster linear\nconvergence in some regions as long as the objective function satisfies the PL\ncondition locally in these regions. ProxSVRG+ also improves ProxGD and\nProxSVRG/SAGA, and generalizes the results of SCSG in this case. Finally, we\nconduct several experiments and the experimental results are consistent with\nthe theoretical results. \n\n"}
{"id": "1802.04528", "contents": "Title: Deceiving End-to-End Deep Learning Malware Detectors using Adversarial\n  Examples Abstract: In recent years, deep learning has shown performance breakthroughs in many\napplications, such as image detection, image segmentation, pose estimation, and\nspeech recognition. However, this comes with a major concern: deep networks\nhave been found to be vulnerable to adversarial examples. Adversarial examples\nare slightly modified inputs that are intentionally designed to cause a\nmisclassification by the model. In the domains of images and speech, the\nmodifications are so small that they are not seen or heard by humans, but\nnevertheless greatly affect the classification of the model.\n  Deep learning models have been successfully applied to malware detection. In\nthis domain, generating adversarial examples is not straightforward, as small\nmodifications to the bytes of the file could lead to significant changes in its\nfunctionality and validity. We introduce a novel loss function for generating\nadversarial examples specifically tailored for discrete input sets, such as\nexecutable bytes. We modify malicious binaries so that they would be detected\nas benign, while preserving their original functionality, by injecting a small\nsequence of bytes (payload) in the binary file. We applied this approach to an\nend-to-end convolutional deep learning malware detection model and show a high\nrate of detection evasion. Moreover, we show that our generated payload is\nrobust enough to be transferable within different locations of the same file\nand across different files, and that its entropy is low and similar to that of\nbenign data sections. \n\n"}
{"id": "1802.04712", "contents": "Title: Attention-based Deep Multiple Instance Learning Abstract: Multiple instance learning (MIL) is a variation of supervised learning where\na single class label is assigned to a bag of instances. In this paper, we state\nthe MIL problem as learning the Bernoulli distribution of the bag label where\nthe bag label probability is fully parameterized by neural networks.\nFurthermore, we propose a neural network-based permutation-invariant\naggregation operator that corresponds to the attention mechanism. Notably, an\napplication of the proposed attention-based operator provides insight into the\ncontribution of each instance to the bag label. We show empirically that our\napproach achieves comparable performance to the best MIL methods on benchmark\nMIL datasets and it outperforms other methods on a MNIST-based MIL dataset and\ntwo real-life histopathology datasets without sacrificing interpretability. \n\n"}
{"id": "1802.04715", "contents": "Title: Online Variance Reduction for Stochastic Optimization Abstract: Modern stochastic optimization methods often rely on uniform sampling which\nis agnostic to the underlying characteristics of the data. This might degrade\nthe convergence by yielding estimates that suffer from a high variance. A\npossible remedy is to employ non-uniform importance sampling techniques, which\ntake the structure of the dataset into account. In this work, we investigate a\nrecently proposed setting which poses variance reduction as an online\noptimization problem with bandit feedback. We devise a novel and efficient\nalgorithm for this setting that finds a sequence of importance sampling\ndistributions competitive with the best fixed distribution in hindsight, the\nfirst result of this kind. While we present our method for sampling datapoints,\nit naturally extends to selecting coordinates or even blocks of thereof.\nEmpirical validations underline the benefits of our method in several settings. \n\n"}
{"id": "1802.04826", "contents": "Title: Leveraging the Exact Likelihood of Deep Latent Variable Models Abstract: Deep latent variable models (DLVMs) combine the approximation abilities of\ndeep neural networks and the statistical foundations of generative models.\nVariational methods are commonly used for inference; however, the exact\nlikelihood of these models has been largely overlooked. The purpose of this\nwork is to study the general properties of this quantity and to show how they\ncan be leveraged in practice. We focus on important inferential problems that\nrely on the likelihood: estimation and missing data imputation. First, we\ninvestigate maximum likelihood estimation for DLVMs: in particular, we show\nthat most unconstrained models used for continuous data have an unbounded\nlikelihood function. This problematic behaviour is demonstrated to be a source\nof mode collapse. We also show how to ensure the existence of maximum\nlikelihood estimates, and draw useful connections with nonparametric mixture\nmodels. Finally, we describe an algorithm for missing data imputation using the\nexact conditional likelihood of a deep latent variable model. On several data\nsets, our algorithm consistently and significantly outperforms the usual\nimputation scheme used for DLVMs. \n\n"}
{"id": "1802.04893", "contents": "Title: Uncertainty Estimation via Stochastic Batch Normalization Abstract: In this work, we investigate Batch Normalization technique and propose its\nprobabilistic interpretation. We propose a probabilistic model and show that\nBatch Normalization maximazes the lower bound of its marginalized\nlog-likelihood. Then, according to the new probabilistic model, we design an\nalgorithm which acts consistently during train and test. However, inference\nbecomes computationally inefficient. To reduce memory and computational cost,\nwe propose Stochastic Batch Normalization -- an efficient approximation of\nproper inference procedure. This method provides us with a scalable uncertainty\nestimation technique. We demonstrate the performance of Stochastic Batch\nNormalization on popular architectures (including deep convolutional\narchitectures: VGG-like and ResNets) for MNIST and CIFAR-10 datasets. \n\n"}
{"id": "1802.05668", "contents": "Title: Model compression via distillation and quantization Abstract: Deep neural networks (DNNs) continue to make significant advances, solving\ntasks from image classification to translation or reinforcement learning. One\naspect of the field receiving considerable attention is efficiently executing\ndeep models in resource-constrained environments, such as mobile or embedded\ndevices. This paper focuses on this problem, and proposes two new compression\nmethods, which jointly leverage weight quantization and distillation of larger\nteacher networks into smaller student networks. The first method we propose is\ncalled quantized distillation and leverages distillation during the training\nprocess, by incorporating distillation loss, expressed with respect to the\nteacher, into the training of a student network whose weights are quantized to\na limited set of levels. The second method, differentiable quantization,\noptimizes the location of quantization points through stochastic gradient\ndescent, to better fit the behavior of the teacher model. We validate both\nmethods through experiments on convolutional and recurrent architectures. We\nshow that quantized shallow students can reach similar accuracy levels to\nfull-precision teacher models, while providing order of magnitude compression,\nand inference speedup that is linear in the depth reduction. In sum, our\nresults enable DNNs for resource-constrained environments to leverage\narchitecture and accuracy advances developed on more powerful devices. \n\n"}
{"id": "1802.05811", "contents": "Title: Distributed Stochastic Optimization via Adaptive SGD Abstract: Stochastic convex optimization algorithms are the most popular way to train\nmachine learning models on large-scale data. Scaling up the training process of\nthese models is crucial, but the most popular algorithm, Stochastic Gradient\nDescent (SGD), is a serial method that is surprisingly hard to parallelize. In\nthis paper, we propose an efficient distributed stochastic optimization method\nby combining adaptivity with variance reduction techniques. Our analysis yields\na linear speedup in the number of machines, constant memory footprint, and only\na logarithmic number of communication rounds. Critically, our approach is a\nblack-box reduction that parallelizes any serial online learning algorithm,\nstreamlining prior analysis and allowing us to leverage the significant\nprogress that has been made in designing adaptive algorithms. In particular, we\nachieve optimal convergence rates without any prior knowledge of smoothness\nparameters, yielding a more robust algorithm that reduces the need for\nhyperparameter tuning. We implement our algorithm in the Spark distributed\nframework and exhibit dramatic performance gains on large-scale logistic\nregression problems. \n\n"}
{"id": "1802.05905", "contents": "Title: Assigning times to minimise reachability in temporal graphs Abstract: Temporal graphs (in which edges are active at specified times) are of\nparticular relevance for spreading processes on graphs, e.g.~the spread of\ndisease or dissemination of information. Motivated by real-world applications,\nmodification of static graphs to control this spread has proven a rich topic\nfor previous research. Here, we introduce a new type of modification for\ntemporal graphs: the number of active times for each edge is fixed, but we can\nchange the relative order in which (sets of) edges are active. We investigate\nthe problem of determining an ordering of edges that minimises the maximum\nnumber of vertices reachable from any single starting vertex;\nepidemiologically, this corresponds to the worst-case number of vertices\ninfected in a single disease outbreak. We study two versions of this problem,\nboth of which we show to be $\\NP$-hard, and identify cases in which the problem\ncan be solved or approximated efficiently. \n\n"}
{"id": "1802.06175", "contents": "Title: An Alternative View: When Does SGD Escape Local Minima? Abstract: Stochastic gradient descent (SGD) is widely used in machine learning.\nAlthough being commonly viewed as a fast but not accurate version of gradient\ndescent (GD), it always finds better solutions than GD for modern neural\nnetworks.\n  In order to understand this phenomenon, we take an alternative view that SGD\nis working on the convolved (thus smoothed) version of the loss function. We\nshow that, even if the function $f$ has many bad local minima or saddle points,\nas long as for every point $x$, the weighted average of the gradients of its\nneighborhoods is one point convex with respect to the desired solution $x^*$,\nSGD will get close to, and then stay around $x^*$ with constant probability.\nMore specifically, SGD will not get stuck at \"sharp\" local minima with small\ndiameters, as long as the neighborhoods of these regions contain enough\ngradient information. The neighborhood size is controlled by step size and\ngradient noise.\n  Our result identifies a set of functions that SGD provably works, which is\nmuch larger than the set of convex functions. Empirically, we observe that the\nloss surface of neural networks enjoys nice one point convexity properties\nlocally, therefore our theorem helps explain why SGD works so well for neural\nnetworks. \n\n"}
{"id": "1802.06289", "contents": "Title: Faster Algorithms for Integer Programs with Block Structure Abstract: We consider integer programming problems $\\max \\{ c^T x : \\mathcal{A} x = b,\nl \\leq x \\leq u, x \\in \\mathbb{Z}^{nt}\\}$ where $\\mathcal{A}$ has a (recursive)\nblock-structure generalizing \"$n$-fold integer programs\" which recently\nreceived considerable attention in the literature. An $n$-fold IP is an integer\nprogram where $\\mathcal{A}$ consists of $n$ repetitions of submatrices $A \\in\n\\mathbb{Z}^{r \\times t}$ on the top horizontal part and $n$ repetitions of a\nmatrix $B \\in \\mathbb{Z}^{s \\times t}$ on the diagonal below the top part.\nInstead of allowing only two types of block matrices, one for the horizontal\nline and one for the diagonal, we generalize the $n$-fold setting to allow for\narbitrary matrices in every block. We show that such an integer program can be\nsolved in time $n^2 t^2 {\\phi} \\cdot (rs{\\Delta})^{\\mathcal{O}(rs^2+ sr^2)}$\n(ignoring logarithmic factors). Here ${\\Delta}$ is an upper bound on the\nlargest absolute value of an entry of $\\mathcal{A}$ and ${\\phi}$ is the largest\nbinary encoding length of a coefficient of $c$. This improves upon the\npreviously best algorithm of Hemmecke, Onn and Romanchuk that runs in time\n$n^3t^3 {\\phi} \\cdot {\\Delta}^{\\mathcal{O}(t^2s)}$. In particular, our\nalgorithm is not exponential in the number $t$ of columns of $A$ and $B$.\n  Our algorithm is based on a new upper bound on the $l_1$-norm of an element\nof the \"Graver basis\" of an integer matrix and on a proximity bound between the\nLP and IP optimal solutions tailored for IPs with block structure. These new\nbounds rely on the \"Steinitz Lemma\".\n  Furthermore, we extend our techniques to the recently introduced \"tree-fold\nIPs\", where we again present a more efficient algorithm in a generalized\nsetting. \n\n"}
{"id": "1802.06939", "contents": "Title: Estimator of Prediction Error Based on Approximate Message Passing for\n  Penalized Linear Regression Abstract: We propose an estimator of prediction error using an approximate message\npassing (AMP) algorithm that can be applied to a broad range of sparse\npenalties. Following Stein's lemma, the estimator of the generalized degrees of\nfreedom, which is a key quantity for the construction of the estimator of the\nprediction error, is calculated at the AMP fixed point. The resulting form of\nthe AMP-based estimator does not depend on the penalty function, and its value\ncan be further improved by considering the correlation between predictors. The\nproposed estimator is asymptotically unbiased when the components of the\npredictors and response variables are independently generated according to a\nGaussian distribution. We examine the behaviour of the estimator for real data\nunder nonconvex sparse penalties, where Akaike's information criterion does not\ncorrespond to an unbiased estimator of the prediction error. The model selected\nby the proposed estimator is close to that which minimizes the true prediction\nerror. \n\n"}
{"id": "1802.07244", "contents": "Title: Steering Social Activity: A Stochastic Optimal Control Point Of View Abstract: User engagement in online social networking depends critically on the level\nof social activity in the corresponding platform--the number of online actions,\nsuch as posts, shares or replies, taken by their users. Can we design\ndata-driven algorithms to increase social activity? At a user level, such\nalgorithms may increase activity by helping users decide when to take an action\nto be more likely to be noticed by their peers. At a network level, they may\nincrease activity by incentivizing a few influential users to take more\nactions, which in turn will trigger additional actions by other users. In this\npaper, we model social activity using the framework of marked temporal point\nprocesses, derive an alternate representation of these processes using\nstochastic differential equations (SDEs) with jumps and, exploiting this\nalternate representation, develop two efficient online algorithms with provable\nguarantees to steer social activity both at a user and at a network level. In\ndoing so, we establish a previously unexplored connection between optimal\ncontrol of jump SDEs and doubly stochastic marked temporal point processes,\nwhich is of independent interest. Finally, we experiment both with synthetic\nand real data gathered from Twitter and show that our algorithms consistently\nsteer social activity more effectively than the state of the art. \n\n"}
{"id": "1802.07444", "contents": "Title: Scaling-up Split-Merge MCMC with Locality Sensitive Sampling (LSS) Abstract: Split-Merge MCMC (Monte Carlo Markov Chain) is one of the essential and\npopular variants of MCMC for problems when an MCMC state consists of an unknown\nnumber of components. It is well known that state-of-the-art methods for\nsplit-merge MCMC do not scale well. Strategies for rapid mixing requires smart\nand informative proposals to reduce the rejection rate. However, all known\nsmart proposals involve expensive operations to suggest informative\ntransitions. As a result, the cost of each iteration is prohibitive for massive\nscale datasets. It is further known that uninformative but computationally\nefficient proposals, such as random split-merge, leads to extremely slow\nconvergence. This tradeoff between mixing time and per update cost seems hard\nto get around.\n  In this paper, we show a sweet spot. We leverage some unique properties of\nweighted MinHash, which is a popular LSH, to design a novel class of\nsplit-merge proposals which are significantly more informative than random\nsampling but at the same time efficient to compute. Overall, we obtain a\nsuperior tradeoff between convergence and per update cost. As a direct\nconsequence, our proposals are around 6X faster than the state-of-the-art\nsampling methods on two large real datasets KDDCUP and PubMed with several\nmillions of entities and thousands of clusters. \n\n"}
{"id": "1802.08183", "contents": "Title: Projection-Free Online Optimization with Stochastic Gradient: From\n  Convexity to Submodularity Abstract: Online optimization has been a successful framework for solving large-scale\nproblems under computational constraints and partial information. Current\nmethods for online convex optimization require either a projection or exact\ngradient computation at each step, both of which can be prohibitively expensive\nfor large-scale applications. At the same time, there is a growing trend of\nnon-convex optimization in machine learning community and a need for online\nmethods. Continuous DR-submodular functions, which exhibit a natural\ndiminishing returns condition, have recently been proposed as a broad class of\nnon-convex functions which may be efficiently optimized. Although online\nmethods have been introduced, they suffer from similar problems. In this work,\nwe propose Meta-Frank-Wolfe, the first online projection-free algorithm that\nuses stochastic gradient estimates. The algorithm relies on a careful sampling\nof gradients in each round and achieves the optimal $O( \\sqrt{T})$ adversarial\nregret bounds for convex and continuous submodular optimization. We also\npropose One-Shot Frank-Wolfe, a simpler algorithm which requires only a single\nstochastic gradient estimate in each round and achieves an $O(T^{2/3})$\nstochastic regret bound for convex and continuous submodular optimization. We\napply our methods to develop a novel \"lifting\" framework for the online\ndiscrete submodular maximization and also see that they outperform current\nstate-of-the-art techniques on various experiments. \n\n"}
{"id": "1802.09031", "contents": "Title: Functional Gradient Boosting based on Residual Network Perception Abstract: Residual Networks (ResNets) have become state-of-the-art models in deep\nlearning and several theoretical studies have been devoted to understanding why\nResNet works so well. One attractive viewpoint on ResNet is that it is\noptimizing the risk in a functional space by combining an ensemble of effective\nfeatures. In this paper, we adopt this viewpoint to construct a new gradient\nboosting method, which is known to be very powerful in data analysis. To do so,\nwe formalize the gradient boosting perspective of ResNet mathematically using\nthe notion of functional gradients and propose a new method called ResFGB for\nclassification tasks by leveraging ResNet perception. Two types of\ngeneralization guarantees are provided from the optimization perspective: one\nis the margin bound and the other is the expected risk bound by the\nsample-splitting technique. Experimental results show superior performance of\nthe proposed method over state-of-the-art methods such as LightGBM. \n\n"}
{"id": "1802.09127", "contents": "Title: Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep\n  Networks for Thompson Sampling Abstract: Recent advances in deep reinforcement learning have made significant strides\nin performance on applications such as Go and Atari games. However, developing\npractical methods to balance exploration and exploitation in complex domains\nremains largely unsolved. Thompson Sampling and its extension to reinforcement\nlearning provide an elegant approach to exploration that only requires access\nto posterior samples of the model. At the same time, advances in approximate\nBayesian methods have made posterior approximation for flexible neural network\nmodels practical. Thus, it is attractive to consider approximate Bayesian\nneural networks in a Thompson Sampling framework. To understand the impact of\nusing an approximate posterior on Thompson Sampling, we benchmark\nwell-established and recently developed methods for approximate posterior\nsampling combined with Thompson Sampling over a series of contextual bandit\nproblems. We found that many approaches that have been successful in the\nsupervised learning setting underperformed in the sequential decision-making\nscenario. In particular, we highlight the challenge of adapting slowly\nconverging uncertainty estimates to the online setting. \n\n"}
{"id": "1802.10026", "contents": "Title: Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs Abstract: The loss functions of deep neural networks are complex and their geometric\nproperties are not well understood. We show that the optima of these complex\nloss functions are in fact connected by simple curves over which training and\ntest accuracy are nearly constant. We introduce a training procedure to\ndiscover these high-accuracy pathways between modes. Inspired by this new\ngeometric insight, we also propose a new ensembling method entitled Fast\nGeometric Ensembling (FGE). Using FGE we can train high-performing ensembles in\nthe time required to train a single model. We achieve improved performance\ncompared to the recent state-of-the-art Snapshot Ensembles, on CIFAR-10,\nCIFAR-100, and ImageNet. \n\n"}
{"id": "1802.10501", "contents": "Title: Predictive Uncertainty Estimation via Prior Networks Abstract: Estimating how uncertain an AI system is in its predictions is important to\nimprove the safety of such systems. Uncertainty in predictive can result from\nuncertainty in model parameters, irreducible data uncertainty and uncertainty\ndue to distributional mismatch between the test and training data\ndistributions. Different actions might be taken depending on the source of the\nuncertainty so it is important to be able to distinguish between them.\nRecently, baseline tasks and metrics have been defined and several practical\nmethods to estimate uncertainty developed. These methods, however, attempt to\nmodel uncertainty due to distributional mismatch either implicitly through\nmodel uncertainty or as data uncertainty. This work proposes a new framework\nfor modeling predictive uncertainty called Prior Networks (PNs) which\nexplicitly models distributional uncertainty. PNs do this by parameterizing a\nprior distribution over predictive distributions. This work focuses on\nuncertainty for classification and evaluates PNs on the tasks of identifying\nout-of-distribution (OOD) samples and detecting misclassification on the MNIST\ndataset, where they are found to outperform previous methods. Experiments on\nsynthetic and MNIST and CIFAR-10 data show that unlike previous non-Bayesian\nmethods PNs are able to distinguish between data and distributional\nuncertainty. \n\n"}
{"id": "1802.10567", "contents": "Title: Learning by Playing - Solving Sparse Reward Tasks from Scratch Abstract: We propose Scheduled Auxiliary Control (SAC-X), a new learning paradigm in\nthe context of Reinforcement Learning (RL). SAC-X enables learning of complex\nbehaviors - from scratch - in the presence of multiple sparse reward signals.\nTo this end, the agent is equipped with a set of general auxiliary tasks, that\nit attempts to learn simultaneously via off-policy RL. The key idea behind our\nmethod is that active (learned) scheduling and execution of auxiliary policies\nallows the agent to efficiently explore its environment - enabling it to excel\nat sparse reward RL. Our experiments in several challenging robotic\nmanipulation settings demonstrate the power of our approach. \n\n"}
{"id": "1803.00657", "contents": "Title: Evolutionary Generative Adversarial Networks Abstract: Generative adversarial networks (GAN) have been effective for learning\ngenerative models for real-world data. However, existing GANs (GAN and its\nvariants) tend to suffer from training problems such as instability and mode\ncollapse. In this paper, we propose a novel GAN framework called evolutionary\ngenerative adversarial networks (E-GAN) for stable GAN training and improved\ngenerative performance. Unlike existing GANs, which employ a pre-defined\nadversarial objective function alternately training a generator and a\ndiscriminator, we utilize different adversarial training objectives as mutation\noperations and evolve a population of generators to adapt to the environment\n(i.e., the discriminator). We also utilize an evaluation mechanism to measure\nthe quality and diversity of generated samples, such that only well-performing\ngenerator(s) are preserved and used for further training. In this way, E-GAN\novercomes the limitations of an individual adversarial training objective and\nalways preserves the best offspring, contributing to progress in and the\nsuccess of GANs. Experiments on several datasets demonstrate that E-GAN\nachieves convincing generative performance and reduces the training problems\ninherent in existing GANs. \n\n"}
{"id": "1803.00744", "contents": "Title: Clinically Meaningful Comparisons Over Time: An Approach to Measuring\n  Patient Similarity based on Subsequence Alignment Abstract: Longitudinal patient data has the potential to improve clinical risk\nstratification models for disease. However, chronic diseases that progress\nslowly over time are often heterogeneous in their clinical presentation.\nPatients may progress through disease stages at varying rates. This leads to\npathophysiological misalignment over time, making it difficult to consistently\ncompare patients in a clinically meaningful way. Furthermore, patients present\nclinically for the first time at different stages of disease. This eliminates\nthe possibility of simply aligning patients based on their initial\npresentation. Finally, patient data may be sampled at different rates due to\ndifferences in schedules or missed visits. To address these challenges, we\npropose a robust measure of patient similarity based on subsequence alignment.\nCompared to global alignment techniques that do not account for\npathophysiological misalignment, focusing on the most relevant subsequences\nallows for an accurate measure of similarity between patients. We demonstrate\nthe utility of our approach in settings where longitudinal data, while useful,\nare limited and lack a clear temporal alignment for comparison. Applied to the\ntask of stratifying patients for risk of progression to probable Alzheimer's\nDisease, our approach outperforms models that use only snapshot data (AUROC of\n0.839 vs. 0.812) and models that use global alignment techniques (AUROC of\n0.822). Our results support the hypothesis that patients' trajectories are\nuseful for quantifying inter-patient similarities and that using subsequence\nmatching and can help account for heterogeneity and misalignment in\nlongitudinal data. \n\n"}
{"id": "1803.00942", "contents": "Title: Not All Samples Are Created Equal: Deep Learning with Importance\n  Sampling Abstract: Deep neural network training spends most of the computation on examples that\nare properly handled, and could be ignored. We propose to mitigate this\nphenomenon with a principled importance sampling scheme that focuses\ncomputation on \"informative\" examples, and reduces the variance of the\nstochastic gradients during training. Our contribution is twofold: first, we\nderive a tractable upper bound to the per-sample gradient norm, and second we\nderive an estimator of the variance reduction achieved with importance\nsampling, which enables us to switch it on when it will result in an actual\nspeedup. The resulting scheme can be used by changing a few lines of code in a\nstandard SGD procedure, and we demonstrate experimentally, on image\nclassification, CNN fine-tuning, and RNN training, that for a fixed wall-clock\ntime budget, it provides a reduction of the train losses of up to an order of\nmagnitude and a relative improvement of test errors between 5% and 17%. \n\n"}
{"id": "1803.00967", "contents": "Title: Active model learning and diverse action sampling for task and motion\n  planning Abstract: The objective of this work is to augment the basic abilities of a robot by\nlearning to use new sensorimotor primitives to enable the solution of complex\nlong-horizon problems. Solving long-horizon problems in complex domains\nrequires flexible generative planning that can combine primitive abilities in\nnovel combinations to solve problems as they arise in the world. In order to\nplan to combine primitive actions, we must have models of the preconditions and\neffects of those actions: under what circumstances will executing this\nprimitive achieve some particular effect in the world?\n  We use, and develop novel improvements on, state-of-the-art methods for\nactive learning and sampling. We use Gaussian process methods for learning the\nconditions of operator effectiveness from small numbers of expensive training\nexamples collected by experimentation on a robot. We develop adaptive sampling\nmethods for generating diverse elements of continuous sets (such as robot\nconfigurations and object poses) during planning for solving a new task, so\nthat planning is as efficient as possible. We demonstrate these methods in an\nintegrated system, combining newly learned models with an efficient\ncontinuous-space robot task and motion planner to learn to solve long horizon\nproblems more efficiently than was previously possible. \n\n"}
{"id": "1803.01233", "contents": "Title: Fast and Sample Efficient Inductive Matrix Completion via Multi-Phase\n  Procrustes Flow Abstract: We revisit the inductive matrix completion problem that aims to recover a\nrank-$r$ matrix with ambient dimension $d$ given $n$ features as the side prior\ninformation. The goal is to make use of the known $n$ features to reduce sample\nand computational complexities. We present and analyze a new gradient-based\nnon-convex optimization algorithm that converges to the true underlying matrix\nat a linear rate with sample complexity only linearly depending on $n$ and\nlogarithmically depending on $d$. To the best of our knowledge, all previous\nalgorithms either have a quadratic dependency on the number of features in\nsample complexity or a sub-linear computational convergence rate. In addition,\nwe provide experiments on both synthetic and real world data to demonstrate the\neffectiveness of our proposed algorithm. \n\n"}
{"id": "1803.01526", "contents": "Title: Blind Channel Equalization using Variational Autoencoders Abstract: A new maximum likelihood estimation approach for blind channel equalization,\nusing variational autoencoders (VAEs), is introduced. Significant and\nconsistent improvements in the error rate of the reconstructed symbols,\ncompared to constant modulus equalizers, are demonstrated. In fact, for the\nchannels that were examined, the performance of the new VAE blind channel\nequalizer was close to the performance of a nonblind adaptive linear minimum\nmean square error equalizer. The new equalization method enables a\nsignificantly lower latency channel acquisition compared to the constant\nmodulus algorithm (CMA). The VAE uses a convolutional neural network with two\nlayers and a very small number of free parameters. Although the computational\ncomplexity of the new equalizer is higher compared to CMA, it is still\nreasonable, and the number of free parameters to estimate is small. \n\n"}
{"id": "1803.01626", "contents": "Title: Variance-Aware Regret Bounds for Undiscounted Reinforcement Learning in\n  MDPs Abstract: The problem of reinforcement learning in an unknown and discrete Markov\nDecision Process (MDP) under the average-reward criterion is considered, when\nthe learner interacts with the system in a single stream of observations,\nstarting from an initial state without any reset. We revisit the minimax lower\nbound for that problem by making appear the local variance of the bias function\nin place of the diameter of the MDP. Furthermore, we provide a novel analysis\nof the KL-UCRL algorithm establishing a high-probability regret bound scaling\nas $\\widetilde {\\mathcal O}\\Bigl({\\textstyle \\sqrt{S\\sum_{s,a}{\\bf\nV}^\\star_{s,a}T}}\\Big)$ for this algorithm for ergodic MDPs, where $S$ denotes\nthe number of states and where ${\\bf V}^\\star_{s,a}$ is the variance of the\nbias function with respect to the next-state distribution following action $a$\nin state $s$. The resulting bound improves upon the best previously known\nregret bound $\\widetilde {\\mathcal O}(DS\\sqrt{AT})$ for that algorithm, where\n$A$ and $D$ respectively denote the maximum number of actions (per state) and\nthe diameter of MDP. We finally compare the leading terms of the two bounds in\nsome benchmark MDPs indicating that the derived bound can provide an order of\nmagnitude improvement in some cases. Our analysis leverages novel variations of\nthe transportation lemma combined with Kullback-Leibler concentration\ninequalities, that we believe to be of independent interest. \n\n"}
{"id": "1803.01833", "contents": "Title: Marginal Singularity, and the Benefits of Labels in Covariate-Shift Abstract: We present new minimax results that concisely capture the relative benefits\nof source and target labeled data, under covariate-shift. Namely, we show that\nthe benefits of target labels are controlled by a transfer-exponent $\\gamma$\nthat encodes how singular Q is locally w.r.t. P, and interestingly allows\nsituations where transfer did not seem possible under previous insights. In\nfact, our new minimax analysis - in terms of $\\gamma$ - reveals a continuum of\nregimes ranging from situations where target labels have little benefit, to\nregimes where target labels dramatically improve classification. We then show\nthat a recently proposed semi-supervised procedure can be extended to adapt to\nunknown $\\gamma$, and therefore requests labels only when beneficial, while\nachieving minimax transfer rates. \n\n"}
{"id": "1803.02398", "contents": "Title: Visualizing Convolutional Neural Network Protein-Ligand Scoring Abstract: Protein-ligand scoring is an important step in a structure-based drug design\npipeline. Selecting a correct binding pose and predicting the binding affinity\nof a protein-ligand complex enables effective virtual screening. Machine\nlearning techniques can make use of the increasing amounts of structural data\nthat are becoming publicly available. Convolutional neural network (CNN)\nscoring functions in particular have shown promise in pose selection and\naffinity prediction for protein-ligand complexes. Neural networks are known for\nbeing difficult to interpret. Understanding the decisions of a particular\nnetwork can help tune parameters and training data to maximize performance.\nVisualization of neural networks helps decompose complex scoring functions into\npictures that are more easily parsed by humans. Here we present three methods\nfor visualizing how individual protein-ligand complexes are interpreted by 3D\nconvolutional neural networks. We also present a visualization of the\nconvolutional filters and their weights. We describe how the intuition provided\nby these visualizations aids in network design. \n\n"}
{"id": "1803.02603", "contents": "Title: Gaussian Process Latent Variable Alignment Learning Abstract: We present a model that can automatically learn alignments between\nhigh-dimensional data in an unsupervised manner. Our proposed method casts\nalignment learning in a framework where both alignment and data are modelled\nsimultaneously. Further, we automatically infer groupings of different types of\nsequences within the same dataset. We derive a probabilistic model built on\nnon-parametric priors that allows for flexible warps while at the same time\nproviding means to specify interpretable constraints. We demonstrate the\nefficacy of our approach with superior quantitative performance to the\nstate-of-the-art approaches and provide examples to illustrate the versatility\nof our model in automatic inference of sequence groupings, absent from previous\napproaches, as well as easy specification of high level priors for different\nmodalities of data. \n\n"}
{"id": "1803.02661", "contents": "Title: Sketching for Principal Component Regression Abstract: Principal component regression (PCR) is a useful method for regularizing\nlinear regression. Although conceptually simple, straightforward\nimplementations of PCR have high computational costs and so are inappropriate\nwhen learning with large scale data. In this paper, we propose efficient\nalgorithms for computing approximate PCR solutions that are, on one hand, high\nquality approximations to the true PCR solutions (when viewed as minimizer of a\nconstrained optimization problem), and on the other hand entertain rigorous\nrisk bounds (when viewed as statistical estimators). In particular, we propose\nan input sparsity time algorithms for approximate PCR. We also consider\ncomputing an approximate PCR in the streaming model, and kernel PCR. Empirical\nresults demonstrate the excellent performance of our proposed methods. \n\n"}
{"id": "1803.05419", "contents": "Title: Generalised Structural CNNs (SCNNs) for time series data with arbitrary\n  graph topology Abstract: Deep Learning methods, specifically convolutional neural networks (CNNs),\nhave seen a lot of success in the domain of image-based data, where the data\noffers a clearly structured topology in the regular lattice of pixels. This\n4-neighbourhood topological simplicity makes the application of convolutional\nmasks straightforward for time series data, such as video applications, but\nmany high-dimensional time series data are not organised in regular lattices,\nand instead values may have adjacency relationships with non-trivial\ntopologies, such as small-world networks or trees. In our application case,\nhuman kinematics, it is currently unclear how to generalise convolutional\nkernels in a principled manner. Therefore we define and implement here a\nframework for general graph-structured CNNs for time series analysis. Our\nalgorithm automatically builds convolutional layers using the specified\nadjacency matrix of the data dimensions and convolutional masks that scale with\nthe hop distance. In the limit of a lattice-topology our method produces the\nwell-known image convolutional masks. We test our method first on synthetic\ndata of arbitrarily-connected graphs and human hand motion capture data, where\nthe hand is represented by a tree capturing the mechanical dependencies of the\njoints. We are able to demonstrate, amongst other things, that inclusion of the\ngraph structure of the data dimensions improves model prediction significantly,\nwhen compared against a benchmark CNN model with only time convolution layers. \n\n"}
{"id": "1803.05598", "contents": "Title: Large Margin Deep Networks for Classification Abstract: We present a formulation of deep learning that aims at producing a large\nmargin classifier. The notion of margin, minimum distance to a decision\nboundary, has served as the foundation of several theoretically profound and\nempirically successful results for both classification and regression tasks.\nHowever, most large margin algorithms are applicable only to shallow models\nwith a preset feature representation; and conventional margin methods for\nneural networks only enforce margin at the output layer. Such methods are\ntherefore not well suited for deep networks.\n  In this work, we propose a novel loss function to impose a margin on any\nchosen set of layers of a deep network (including input and hidden layers). Our\nformulation allows choosing any norm on the metric measuring the margin. We\ndemonstrate that the decision boundary obtained by our loss has nice properties\ncompared to standard classification loss functions. Specifically, we show\nimproved empirical results on the MNIST, CIFAR-10 and ImageNet datasets on\nmultiple tasks: generalization from small training sets, corrupted labels, and\nrobustness against adversarial perturbations. The resulting loss is general and\ncomplementary to existing data augmentation (such as random/adversarial input\ntransform) and regularization techniques (such as weight decay, dropout, and\nbatch norm). \n\n"}
{"id": "1803.05621", "contents": "Title: Proximal SCOPE for Distributed Sparse Learning: Better Data Partition\n  Implies Faster Convergence Rate Abstract: Distributed sparse learning with a cluster of multiple machines has attracted\nmuch attention in machine learning, especially for large-scale applications\nwith high-dimensional data. One popular way to implement sparse learning is to\nuse $L_1$ regularization. In this paper, we propose a novel method, called\nproximal \\mbox{SCOPE}~(\\mbox{pSCOPE}), for distributed sparse learning with\n$L_1$ regularization. pSCOPE is based on a \\underline{c}ooperative\n\\underline{a}utonomous \\underline{l}ocal \\underline{l}earning~(\\mbox{CALL})\nframework. In the \\mbox{CALL} framework of \\mbox{pSCOPE}, we find that the data\npartition affects the convergence of the learning procedure, and subsequently\nwe define a metric to measure the goodness of a data partition. Based on the\ndefined metric, we theoretically prove that pSCOPE is convergent with a linear\nconvergence rate if the data partition is good enough. We also prove that\nbetter data partition implies faster convergence rate. Furthermore, pSCOPE is\nalso communication efficient. Experimental results on real data sets show that\npSCOPE can outperform other state-of-the-art distributed methods for sparse\nlearning. \n\n"}
{"id": "1803.06111", "contents": "Title: Vulnerability of Deep Learning Abstract: The Renormalisation Group (RG) provides a framework in which it is possible\nto assess whether a deep-learning network is sensitive to small changes in the\ninput data and hence prone to error, or susceptible to adversarial attack.\nDistinct classification outputs are associated with different RG fixed points\nand sensitivity to small changes in the input data is due to the presence of\nrelevant operators at a fixed point. A numerical scheme, based on Monte Carlo\nRG ideas, is proposed for identifying the existence of relevant operators and\nthe corresponding directions of greatest sensitivity in the input data. Thus, a\ntrained deep-learning network may be tested for its robustness and, if it is\nvulnerable to attack, dangerous perturbations of the input data identified. \n\n"}
{"id": "1803.06622", "contents": "Title: Learning recurrent dynamics in spiking networks Abstract: Spiking activity of neurons engaged in learning and performing a task show\ncomplex spatiotemporal dynamics. While the output of recurrent network models\ncan learn to perform various tasks, the possible range of recurrent dynamics\nthat emerge after learning remains unknown. Here we show that modifying the\nrecurrent connectivity with a recursive least squares algorithm provides\nsufficient flexibility for synaptic and spiking rate dynamics of spiking\nnetworks to produce a wide range of spatiotemporal activity. We apply the\ntraining method to learn arbitrary firing patterns, stabilize irregular spiking\nactivity of a balanced network, and reproduce the heterogeneous spiking rate\npatterns of cortical neurons engaged in motor planning and movement. We\nidentify sufficient conditions for successful learning, characterize two types\nof learning errors, and assess the network capacity. Our findings show that\nsynaptically-coupled recurrent spiking networks possess a vast computational\ncapability that can support the diverse activity patterns in the brain. \n\n"}
{"id": "1803.07482", "contents": "Title: Natural Gradient Deep Q-learning Abstract: We present a novel algorithm to train a deep Q-learning agent using\nnatural-gradient techniques. We compare the original deep Q-network (DQN)\nalgorithm to its natural-gradient counterpart, which we refer to as NGDQN, on a\ncollection of classic control domains. Without employing target networks, NGDQN\nsignificantly outperforms DQN without target networks, and performs no worse\nthan DQN with target networks, suggesting that NGDQN stabilizes training and\ncan help reduce the need for additional hyperparameter tuning. We also find\nthat NGDQN is less sensitive to hyperparameter optimization relative to DQN.\nTogether these results suggest that natural-gradient techniques can improve\nvalue-function optimization in deep reinforcement learning. \n\n"}
{"id": "1803.07554", "contents": "Title: Leave-one-out Approach for Matrix Completion: Primal and Dual Analysis Abstract: In this paper, we introduce a powerful technique based on Leave-one-out\nanalysis to the study of low-rank matrix completion problems. Using this\ntechnique, we develop a general approach for obtaining fine-grained, entrywise\nbounds for iterative stochastic procedures in the presence of probabilistic\ndependency. We demonstrate the power of this approach in analyzing two of the\nmost important algorithms for matrix completion: (i) the non-convex approach\nbased on Projected Gradient Descent (PGD) for a rank-constrained formulation,\nalso known as the Singular Value Projection algorithm, and (ii) the convex\nrelaxation approach based on nuclear norm minimization (NNM).\n  Using this approach, we establish the first convergence guarantee for the\noriginal form of PGD without regularization or sample splitting}, and in\nparticular shows that it converges linearly in the infinity norm. For NNM, we\nuse this approach to study a fictitious iterative procedure that arises in the\ndual analysis. Our results show that \\NNM recovers an $ d $-by-$ d $ rank-$ r $\nmatrix with $\\mathcal{O}(\\mu r \\log(\\mu r) d \\log d )$ observed entries. This\nbound has optimal dependence on the matrix dimension and is independent of the\ncondition number. To the best of our knowledge, this is the first sample\ncomplexity result for a tractable matrix completion algorithm that satisfies\nthese two properties simultaneously. \n\n"}
{"id": "1803.07617", "contents": "Title: Online Learning: Sufficient Statistics and the Burkholder Method Abstract: We uncover a fairly general principle in online learning: If regret can be\n(approximately) expressed as a function of certain \"sufficient statistics\" for\nthe data sequence, then there exists a special Burkholder function that 1) can\nbe used algorithmically to achieve the regret bound and 2) only depends on\nthese sufficient statistics, not the entire data sequence, so that the online\nstrategy is only required to keep the sufficient statistics in memory. This\ncharacterization is achieved by bringing the full power of the Burkholder\nMethod --- originally developed for certifying probabilistic martingale\ninequalities --- to bear on the online learning setting.\n  To demonstrate the scope and effectiveness of the Burkholder method, we\ndevelop a novel online strategy for matrix prediction that attains a regret\nbound corresponding to the variance term in matrix concentration inequalities.\nWe also present a linear-time/space prediction strategy for parameter free\nsupervised learning with linear classes and general smooth norms. \n\n"}
{"id": "1803.07859", "contents": "Title: Efficient Sampling and Structure Learning of Bayesian Networks Abstract: Bayesian networks are probabilistic graphical models widely employed to\nunderstand dependencies in high dimensional data, and even to facilitate causal\ndiscovery. Learning the underlying network structure, which is encoded as a\ndirected acyclic graph (DAG) is highly challenging mainly due to the vast\nnumber of possible networks in combination with the acyclicity constraint.\nEfforts have focussed on two fronts: constraint-based methods that perform\nconditional independence tests to exclude edges and score and search approaches\nwhich explore the DAG space with greedy or MCMC schemes. Here we synthesise\nthese two fields in a novel hybrid method which reduces the complexity of MCMC\napproaches to that of a constraint-based method. Individual steps in the MCMC\nscheme only require simple table lookups so that very long chains can be\nefficiently obtained. Furthermore, the scheme includes an iterative procedure\nto correct for errors from the conditional independence tests. The algorithm\noffers markedly superior performance to alternatives, particularly because DAGs\ncan also be sampled from the posterior distribution, enabling full Bayesian\nmodel averaging for much larger Bayesian networks. \n\n"}
{"id": "1803.08118", "contents": "Title: Seglearn: A Python Package for Learning Sequences and Time Series Abstract: Seglearn is an open-source python package for machine learning time series or\nsequences using a sliding window segmentation approach. The implementation\nprovides a flexible pipeline for tackling classification, regression, and\nforecasting problems with multivariate sequence and contextual data. This\npackage is compatible with scikit-learn and is listed under scikit-learn\nRelated Projects. The package depends on numpy, scipy, and scikit-learn.\nSeglearn is distributed under the BSD 3-Clause License. Documentation includes\na detailed API description, user guide, and examples. Unit tests provide a high\ndegree of code coverage. \n\n"}
{"id": "1803.08631", "contents": "Title: SEGEN: Sample-Ensemble Genetic Evolutional Network Model Abstract: Deep learning, a rebranding of deep neural network research works, has\nachieved a remarkable success in recent years. With multiple hidden layers,\ndeep learning models aim at computing the hierarchical feature representations\nof the observational data. Meanwhile, due to its severe disadvantages in data\nconsumption, computational resources, parameter tuning costs and the lack of\nresult explainability, deep learning has also suffered from lots of criticism.\nIn this paper, we will introduce a new representation learning model, namely\n\"Sample-Ensemble Genetic Evolutionary Network\" (SEGEN), which can serve as an\nalternative approach to deep learning models. Instead of building one single\ndeep model, based on a set of sampled sub-instances, SEGEN adopts a\ngenetic-evolutionary learning strategy to build a group of unit models\ngenerations by generations. The unit models incorporated in SEGEN can be either\ntraditional machine learning models or the recent deep learning models with a\nmuch \"narrower\" and \"shallower\" architecture. The learning results of each\ninstance at the final generation will be effectively combined from each unit\nmodel via diffusive propagation and ensemble learning strategies. From the\ncomputational perspective, SEGEN requires far less data, fewer computational\nresources and parameter tuning efforts, but has sound theoretic\ninterpretability of the learning process and results. Extensive experiments\nhave been done on several different real-world benchmark datasets, and the\nexperimental results obtained by SEGEN have demonstrated its advantages over\nthe state-of-the-art representation learning models. \n\n"}
{"id": "1803.09186", "contents": "Title: Finite-Data Performance Guarantees for the Output-Feedback Control of an\n  Unknown System Abstract: As the systems we control become more complex, first-principle modeling\nbecomes either impossible or intractable, motivating the use of machine\nlearning techniques for the control of systems with continuous action spaces.\nAs impressive as the empirical success of these methods have been, strong\ntheoretical guarantees of performance, safety, or robustness are few and far\nbetween. This paper takes a step towards such providing such guarantees by\nestablishing finite-data performance guarantees for the robust output-feedback\ncontrol of an unknown FIR SISO system. In particular, we introduce the\n\"Coarse-ID control\" pipeline, which is composed of a system identification step\nfollowed by a robust controller synthesis procedure, and analyze its end-to-end\nperformance, providing quantitative bounds on the performance degradation\nsuffered due to model uncertainty as a function of the number of experiments\nrun to identify the system. We conclude with numerical examples demonstrating\nthe effectiveness of our method. \n\n"}
{"id": "1803.09383", "contents": "Title: Online Second Order Methods for Non-Convex Stochastic Optimizations Abstract: This paper proposes a family of online second order methods for possibly\nnon-convex stochastic optimizations based on the theory of preconditioned\nstochastic gradient descent (PSGD), which can be regarded as an enhance\nstochastic Newton method with the ability to handle gradient noise and\nnon-convexity simultaneously. We have improved the implementations of the\noriginal PSGD in several ways, e.g., new forms of preconditioners, more\naccurate Hessian vector product calculations, and better numerical stability\nwith vanishing or ill-conditioned Hessian, etc.. We also have unrevealed the\nrelationship between feature normalization and PSGD with Kronecker product\npreconditioners, which explains the excellent performance of Kronecker product\npreconditioners in deep neural network learning. A software package\n(https://github.com/lixilinx/psgd_tf) implemented in Tensorflow is provided to\ncompare variations of stochastic gradient descent (SGD) and PSGD with five\ndifferent preconditioners on a wide range of benchmark problems with commonly\nused neural network architectures, e.g., convolutional and recurrent neural\nnetworks. Experimental results clearly demonstrate the advantages of PSGD in\nterms of generalization performance and convergence speed. \n\n"}
{"id": "1803.10769", "contents": "Title: Network Traffic Anomaly Detection Using Recurrent Neural Networks Abstract: We show that a recurrent neural network is able to learn a model to represent\nsequences of communications between computers on a network and can be used to\nidentify outlier network traffic. Defending computer networks is a challenging\nproblem and is typically addressed by manually identifying known malicious\nactor behavior and then specifying rules to recognize such behavior in network\ncommunications. However, these rule-based approaches often generalize poorly\nand identify only those patterns that are already known to researchers. An\nalternative approach that does not rely on known malicious behavior patterns\ncan potentially also detect previously unseen patterns. We tokenize and\ncompress netflow into sequences of \"words\" that form \"sentences\" representative\nof a conversation between computers. These sentences are then used to generate\na model that learns the semantic and syntactic grammar of the newly generated\nlanguage. We use Long-Short-Term Memory (LSTM) cell Recurrent Neural Networks\n(RNN) to capture the complex relationships and nuances of this language. The\nlanguage model is then used predict the communications between two IPs and the\nprediction error is used as a measurement of how typical or atyptical the\nobserved communication are. By learning a model that is specific to each\nnetwork, yet generalized to typical computer-to-computer traffic within and\noutside the network, a language model is able to identify sequences of network\nactivity that are outliers with respect to the model. We demonstrate positive\nunsupervised attack identification performance (AUC 0.84) on the ISCX IDS\ndataset which contains seven days of network activity with normal traffic and\nfour distinct attack patterns. \n\n"}
{"id": "1803.11008", "contents": "Title: On Hyperparameter Search in Cluster Ensembles Abstract: Quality assessments of models in unsupervised learning and clustering\nverification in particular have been a long-standing problem in the machine\nlearning research. The lack of robust and universally applicable cluster\nvalidity scores often makes the algorithm selection and hyperparameter\nevaluation a tough guess. In this paper, we show that cluster ensemble\naggregation techniques such as consensus clustering may be used to evaluate\nclusterings and their hyperparameter configurations. We use normalized mutual\ninformation to compare individual objects of a clustering ensemble to the\nconstructed consensus of the whole ensemble and show, that the resulting score\ncan serve as an overall quality measure for clustering problems. This method is\ncapable of highlighting the standout clustering and hyperparameter\nconfiguration in the ensemble even in the case of a distorted consensus. We\napply this very general framework to various data sets and give possible\ndirections for future research. \n\n"}
{"id": "1804.00645", "contents": "Title: Universal Planning Networks Abstract: A key challenge in complex visuomotor control is learning abstract\nrepresentations that are effective for specifying goals, planning, and\ngeneralization. To this end, we introduce universal planning networks (UPN).\nUPNs embed differentiable planning within a goal-directed policy. This planning\ncomputation unrolls a forward model in a latent space and infers an optimal\naction plan through gradient descent trajectory optimization. The\nplan-by-gradient-descent process and its underlying representations are learned\nend-to-end to directly optimize a supervised imitation learning objective. We\nfind that the representations learned are not only effective for goal-directed\nvisual imitation via gradient-based trajectory optimization, but can also\nprovide a metric for specifying goals using images. The learned representations\ncan be leveraged to specify distance-based rewards to reach new target states\nfor model-free reinforcement learning, resulting in substantially more\neffective learning when solving new tasks described via image-based goals. We\nwere able to achieve successful transfer of visuomotor planning strategies\nacross robots with significantly different morphologies and actuation\ncapabilities. \n\n"}
{"id": "1804.01466", "contents": "Title: Gaussian Process Subset Scanning for Anomalous Pattern Detection in\n  Non-iid Data Abstract: Identifying anomalous patterns in real-world data is essential for\nunderstanding where, when, and how systems deviate from their expected\ndynamics. Yet methods that separately consider the anomalousness of each\nindividual data point have low detection power for subtle, emerging\nirregularities. Additionally, recent detection techniques based on subset\nscanning make strong independence assumptions and suffer degraded performance\nin correlated data. We introduce methods for identifying anomalous patterns in\nnon-iid data by combining Gaussian processes with novel log-likelihood ratio\nstatistic and subset scanning techniques. Our approaches are powerful,\ninterpretable, and can integrate information across multiple data streams. We\nillustrate their performance on numeric simulations and three open source\nspatiotemporal datasets of opioid overdose deaths, 311 calls, and storm\nreports. \n\n"}
{"id": "1804.01874", "contents": "Title: A Human Mixed Strategy Approach to Deep Reinforcement Learning Abstract: In 2015, Google's DeepMind announced an advancement in creating an autonomous\nagent based on deep reinforcement learning (DRL) that could beat a professional\nplayer in a series of 49 Atari games. However, the current manifestation of DRL\nis still immature, and has significant drawbacks. One of DRL's imperfections is\nits lack of \"exploration\" during the training process, especially when working\nwith high-dimensional problems. In this paper, we propose a mixed strategy\napproach that mimics behaviors of human when interacting with environment, and\ncreate a \"thinking\" agent that allows for more efficient exploration in the DRL\ntraining process. The simulation results based on the Breakout game show that\nour scheme achieves a higher probability of obtaining a maximum score than does\nthe baseline DRL algorithm, i.e., the asynchronous advantage actor-critic\nmethod. The proposed scheme therefore can be applied effectively to solving a\ncomplicated task in a real-world application. \n\n"}
{"id": "1804.02744", "contents": "Title: Unsupervised Learning of GMM with a Uniform Background Component Abstract: Gaussian Mixture Models are one of the most studied and mature models in\nunsupervised learning. However, outliers are often present in the data and\ncould influence the cluster estimation. In this paper, we study a new model\nthat assumes that data comes from a mixture of a number of Gaussians as well as\na uniform ``background'' component assumed to contain outliers and other\nnon-interesting observations. We develop a novel method based on robust loss\nminimization that performs well in clustering such GMM with a uniform\nbackground. We give theoretical guarantees for our clustering algorithm to\nobtain best clustering results with high probability. Besides, we show that the\nresult of our algorithm does not depend on initialization or local optima, and\nthe parameter tuning is an easy task. By numeric simulations, we demonstrate\nthat our algorithm enjoys high accuracy and achieves the best clustering\nresults given a large enough sample size. Finally, experimental comparisons\nwith typical clustering methods on real datasets witness the potential of our\nalgorithm in real applications. \n\n"}
{"id": "1804.02854", "contents": "Title: Tight Hardness Results for Consensus Problems on Circular Strings and\n  Time Series Abstract: Consensus problems for strings and sequences appear in numerous application\ncontexts, ranging from bioinformatics over data mining to machine learning.\nClosing some gaps in the literature, we show that several fundamental problems\nin this context are NP- and W[1]-hard, and that the known (partially\nbrute-force) algorithms are close to optimality assuming the Exponential Time\nHypothesis. Among our main contributions is to settle the complexity status of\ncomputing a mean in dynamic time warping spaces which, as pointed out by Brill\net al. [DMKD 2019], suffered from many unproven or false assumptions in the\nliterature. We prove this problem to be NP-hard and additionally show that a\nrecent dynamic programming algorithm is essentially optimal. In this context,\nwe study a broad family of circular string alignment problems. This family also\nserves as a key for our hardness reductions, and it is of independent\n(practical) interest in molecular biology. In particular, we show tight\nhardness and running time lower bounds for Circular Consensus String; notably,\nthe corresponding non-circular version is easily linear-time solvable. \n\n"}
{"id": "1804.03195", "contents": "Title: Contextual Search via Intrinsic Volumes Abstract: We study the problem of contextual search, a multidimensional generalization\nof binary search that captures many problems in contextual decision-making. In\ncontextual search, a learner is trying to learn the value of a hidden vector $v\n\\in [0,1]^d$. Every round the learner is provided an adversarially-chosen\ncontext $u_t \\in \\mathbb{R}^d$, submits a guess $p_t$ for the value of $\\langle\nu_t, v\\rangle$, learns whether $p_t < \\langle u_t, v\\rangle$, and incurs loss\n$\\ell(\\langle u_t, v\\rangle, p_t)$ (for some loss function $\\ell$). The\nlearner's goal is to minimize their total loss over the course of $T$ rounds.\n  We present an algorithm for the contextual search problem for the symmetric\nloss function $\\ell(\\theta, p) = |\\theta - p|$ that achieves $O_{d}(1)$ total\nloss. We present a new algorithm for the dynamic pricing problem (which can be\nrealized as a special case of the contextual search problem) that achieves\n$O_{d}(\\log \\log T)$ total loss, improving on the previous best known upper\nbounds of $O_{d}(\\log T)$ and matching the known lower bounds (up to a\npolynomial dependence on $d$). Both algorithms make significant use of ideas\nfrom the field of integral geometry, most notably the notion of intrinsic\nvolumes of a convex set. To the best of our knowledge this is the first\napplication of intrinsic volumes to algorithm design. \n\n"}
{"id": "1804.03728", "contents": "Title: Tensor Robust Principal Component Analysis with A New Tensor Nuclear\n  Norm Abstract: In this paper, we consider the Tensor Robust Principal Component Analysis\n(TRPCA) problem, which aims to exactly recover the low-rank and sparse\ncomponents from their sum. Our model is based on the recently proposed\ntensor-tensor product (or t-product). Induced by the t-product, we first\nrigorously deduce the tensor spectral norm, tensor nuclear norm, and tensor\naverage rank, and show that the tensor nuclear norm is the convex envelope of\nthe tensor average rank within the unit ball of the tensor spectral norm. These\ndefinitions, their relationships and properties are consistent with matrix\ncases. Equipped with the new tensor nuclear norm, we then solve the TRPCA\nproblem by solving a convex program and provide the theoretical guarantee for\nthe exact recovery. Our TRPCA model and recovery guarantee include matrix RPCA\nas a special case. Numerical experiments verify our results, and the\napplications to image recovery and background modeling problems demonstrate the\neffectiveness of our method. \n\n"}
{"id": "1804.04053", "contents": "Title: EmoRL: Continuous Acoustic Emotion Classification using Deep\n  Reinforcement Learning Abstract: Acoustically expressed emotions can make communication with a robot more\nefficient. Detecting emotions like anger could provide a clue for the robot\nindicating unsafe/undesired situations. Recently, several deep neural\nnetwork-based models have been proposed which establish new state-of-the-art\nresults in affective state evaluation. These models typically start processing\nat the end of each utterance, which not only requires a mechanism to detect the\nend of an utterance but also makes it difficult to use them in a real-time\ncommunication scenario, e.g. human-robot interaction. We propose the EmoRL\nmodel that triggers an emotion classification as soon as it gains enough\nconfidence while listening to a person speaking. As a result, we minimize the\nneed for segmenting the audio signal for classification and achieve lower\nlatency as the audio signal is processed incrementally. The method is\ncompetitive with the accuracy of a strong baseline model, while allowing much\nearlier prediction. \n\n"}
{"id": "1804.04888", "contents": "Title: Scalable and Interpretable One-class SVMs with Deep Learning and Random\n  Fourier features Abstract: One-class support vector machine (OC-SVM) for a long time has been one of the\nmost effective anomaly detection methods and extensively adopted in both\nresearch as well as industrial applications. The biggest issue for OC-SVM is\nyet the capability to operate with large and high-dimensional datasets due to\noptimization complexity. Those problems might be mitigated via dimensionality\nreduction techniques such as manifold learning or autoencoder. However,\nprevious work often treats representation learning and anomaly prediction\nseparately. In this paper, we propose autoencoder based one-class support\nvector machine (AE-1SVM) that brings OC-SVM, with the aid of random Fourier\nfeatures to approximate the radial basis kernel, into deep learning context by\ncombining it with a representation learning architecture and jointly exploit\nstochastic gradient descent to obtain end-to-end training. Interestingly, this\nalso opens up the possible use of gradient-based attribution methods to explain\nthe decision making for anomaly detection, which has ever been challenging as a\nresult of the implicit mappings between the input space and the kernel space.\nTo the best of our knowledge, this is the first work to study the\ninterpretability of deep learning in anomaly detection. We evaluate our method\non a wide range of unsupervised anomaly detection tasks in which our end-to-end\ntraining architecture achieves a performance significantly better than the\nprevious work using separate training. \n\n"}
{"id": "1804.05436", "contents": "Title: Hidden Hamiltonian Cycle Recovery via Linear Programming Abstract: We introduce the problem of hidden Hamiltonian cycle recovery, where there is\nan unknown Hamiltonian cycle in an $n$-vertex complete graph that needs to be\ninferred from noisy edge measurements. The measurements are independent and\ndistributed according to $\\calP_n$ for edges in the cycle and $\\calQ_n$\notherwise. This formulation is motivated by a problem in genome assembly, where\nthe goal is to order a set of contigs (genome subsequences) according to their\npositions on the genome using long-range linking measurements between the\ncontigs. Computing the maximum likelihood estimate in this model reduces to a\nTraveling Salesman Problem (TSP). Despite the NP-hardness of TSP, we show that\na simple linear programming (LP) relaxation, namely the fractional $2$-factor\n(F2F) LP, recovers the hidden Hamiltonian cycle with high probability as $n \\to\n\\infty$ provided that $\\alpha_n - \\log n \\to \\infty$, where $\\alpha_n\n\\triangleq -2 \\log \\int \\sqrt{d P_n d Q_n}$ is the R\\'enyi divergence of order\n$\\frac{1}{2}$. This condition is information-theoretically optimal in the sense\nthat, under mild distributional assumptions, $\\alpha_n \\geq (1+o(1)) \\log n$ is\nnecessary for any algorithm to succeed regardless of the computational cost.\n  Departing from the usual proof techniques based on dual witness construction,\nthe analysis relies on the combinatorial characterization (in particular, the\nhalf-integrality) of the extreme points of the F2F polytope. Represented as\nbicolored multi-graphs, these extreme points are further decomposed into\nsimpler \"blossom-type\" structures for the large deviation analysis and counting\narguments. Evaluation of the algorithm on real data shows improvements over\nexisting approaches. \n\n"}
{"id": "1804.07091", "contents": "Title: Detecting Regions of Maximal Divergence for Spatio-Temporal Anomaly\n  Detection Abstract: Automatic detection of anomalies in space- and time-varying measurements is\nan important tool in several fields, e.g., fraud detection, climate analysis,\nor healthcare monitoring. We present an algorithm for detecting anomalous\nregions in multivariate spatio-temporal time-series, which allows for spotting\nthe interesting parts in large amounts of data, including video and text data.\nIn opposition to existing techniques for detecting isolated anomalous data\npoints, we propose the \"Maximally Divergent Intervals\" (MDI) framework for\nunsupervised detection of coherent spatial regions and time intervals\ncharacterized by a high Kullback-Leibler divergence compared with all other\ndata given. In this regard, we define an unbiased Kullback-Leibler divergence\nthat allows for ranking regions of different size and show how to enable the\nalgorithm to run on large-scale data sets in reasonable time using an interval\nproposal technique. Experiments on both synthetic and real data from various\ndomains, such as climate analysis, video surveillance, and text forensics,\ndemonstrate that our method is widely applicable and a valuable tool for\nfinding interesting events in different types of data. \n\n"}
{"id": "1804.07431", "contents": "Title: Finding Cliques in Social Networks: A New Distribution-Free Model Abstract: We propose a new distribution-free model of social networks. Our definitions\nare motivated by one of the most universal signatures of social networks,\ntriadic closure---the property that pairs of vertices with common neighbors\ntend to be adjacent. Our most basic definition is that of a \"$c$-closed\" graph,\nwhere for every pair of vertices $u,v$ with at least $c$ common neighbors, $u$\nand $v$ are adjacent. We study the classic problem of enumerating all maximal\ncliques, an important task in social network analysis. We prove that this\nproblem is fixed-parameter tractable with respect to $c$ on $c$-closed graphs.\nOur results carry over to \"weakly $c$-closed graphs\", which only require a\nvertex deletion ordering that avoids pairs of non-adjacent vertices with $c$\ncommon neighbors. Numerical experiments show that well-studied social networks\ntend to be weakly $c$-closed for modest values of $c$. \n\n"}
{"id": "1804.07672", "contents": "Title: Unsupervised learning of the brain connectivity dynamic using residual\n  D-net Abstract: In this paper, we propose a novel unsupervised learning method to learn the\nbrain dynamics using a deep learning architecture named residual D-net. As it\nis often the case in medical research, in contrast to typical deep learning\ntasks, the size of the resting-state functional Magnetic Resonance Image\n(rs-fMRI) datasets for training is limited. Thus, the available data should be\nvery efficiently used to learn the complex patterns underneath the brain\nconnectivity dynamics. To address this issue, we use residual connections to\nalleviate the training complexity through recurrent multi-scale representation.\nWe conduct two classification tasks to differentiate early and late stage Mild\nCognitive Impairment (MCI) from Normal healthy Control (NC) subjects. The\nexperiments verify that our proposed residual D-net indeed learns the brain\nconnectivity dynamics, leading to significantly higher classification accuracy\ncompared to previously published techniques. \n\n"}
{"id": "1804.07795", "contents": "Title: Stochastic subgradient method converges on tame functions Abstract: This work considers the question: what convergence guarantees does the\nstochastic subgradient method have in the absence of smoothness and convexity?\nWe prove that the stochastic subgradient method, on any semialgebraic locally\nLipschitz function, produces limit points that are all first-order stationary.\nMore generally, our result applies to any function with a Whitney stratifiable\ngraph. In particular, this work endows the stochastic subgradient method, and\nits proximal extension, with rigorous convergence guarantees for a wide class\nof problems arising in data science---including all popular deep learning\narchitectures. \n\n"}
{"id": "1804.08111", "contents": "Title: Sampling in Uniqueness from the Potts and Random-Cluster Models on\n  Random Regular Graphs Abstract: We consider the problem of sampling from the Potts model on random regular\ngraphs. It is conjectured that sampling is possible when the temperature of the\nmodel is in the uniqueness regime of the regular tree, but positive algorithmic\nresults have been for the most part elusive. In this paper, for all integers\n$q\\geq 3$ and $\\Delta\\geq 3$, we develop algorithms that produce samples within\nerror $o(1)$ from the $q$-state Potts model on random $\\Delta$-regular graphs,\nwhenever the temperature is in uniqueness, for both the ferromagnetic and\nantiferromagnetic cases.\n  The algorithm for the antiferromagnetic Potts model is based on iteratively\nadding the edges of the graph and resampling a bichromatic class that contains\nthe endpoints of the newly added edge. Key to the algorithm is how to perform\nthe resampling step efficiently since bichromatic classes may induce\nlinear-sized components. To this end, we exploit the tree uniqueness to show\nthat the average growth of bichromatic components is typically small, which\nallows us to use correlation decay algorithms for the resampling step. While\nthe precise uniqueness threshold on the tree is not known for general values of\n$q$ and $\\Delta$ in the antiferromagnetic case, our algorithm works throughout\nuniqueness regardless of its value.\n  In the case of the ferromagnetic Potts model, we simplify the algorithm\nsignificantly by utilising the random-cluster representation of the model. In\nparticular, we show that a percolation-type algorithm succeeds in sampling from\nthe random-cluster model with parameters $p,q$ on random $\\Delta$-regular\ngraphs for all values of $q\\geq 1$ and $p<p_c(q,\\Delta)$, where $p_c(q,\\Delta)$\ncorresponds to a uniqueness threshold for the model on the $\\Delta$-regular\ntree. When restricted to integer values of $q$, this yields a simplified\nalgorithm for the ferromagnetic Potts model on random $\\Delta$-regular graphs. \n\n"}
{"id": "1804.09713", "contents": "Title: End-to-End Multimodal Speech Recognition Abstract: Transcription or sub-titling of open-domain videos is still a challenging\ndomain for Automatic Speech Recognition (ASR) due to the data's challenging\nacoustics, variable signal processing and the essentially unrestricted domain\nof the data. In previous work, we have shown that the visual channel --\nspecifically object and scene features -- can help to adapt the acoustic model\n(AM) and language model (LM) of a recognizer, and we are now expanding this\nwork to end-to-end approaches. In the case of a Connectionist Temporal\nClassification (CTC)-based approach, we retain the separation of AM and LM,\nwhile for a sequence-to-sequence (S2S) approach, both information sources are\nadapted together, in a single model. This paper also analyzes the behavior of\nCTC and S2S models on noisy video data (How-To corpus), and compares it to\nresults on the clean Wall Street Journal (WSJ) corpus, providing insight into\nthe robustness of both approaches. \n\n"}
{"id": "1804.09788", "contents": "Title: Multi-Layer Sparse Coding: The Holistic Way Abstract: The recently proposed multi-layer sparse model has raised insightful\nconnections between sparse representations and convolutional neural networks\n(CNN). In its original conception, this model was restricted to a cascade of\nconvolutional synthesis representations. In this paper, we start by addressing\na more general model, revealing interesting ties to fully connected networks.\nWe then show that this multi-layer construction admits a brand new\ninterpretation in a unique symbiosis between synthesis and analysis models:\nwhile the deepest layer indeed provides a synthesis representation, the\nmid-layers decompositions provide an analysis counterpart. This new perspective\nexposes the suboptimality of previously proposed pursuit approaches, as they do\nnot fully leverage all the information comprised in the model constraints.\nArmed with this understanding, we address fundamental theoretical issues,\nrevisiting previous analysis and expanding it. Motivated by the limitations of\nprevious algorithms, we then propose an integrated - holistic - alternative\nthat estimates all representations in the model simultaneously, and analyze all\nthese different schemes under stochastic noise assumptions. Inspired by the\nsynthesis-analysis duality, we further present a Holistic Pursuit algorithm,\nwhich alternates between synthesis and analysis sparse coding steps, eventually\nsolving for the entire model as a whole, with provable improved performance.\nFinally, we present numerical results that demonstrate the practical advantages\nof our approach. \n\n"}
{"id": "1804.10272", "contents": "Title: Network Transplanting Abstract: This paper focuses on a new task, i.e., transplanting a\ncategory-and-task-specific neural network to a generic, modular network without\nstrong supervision. We design an functionally interpretable structure for the\ngeneric network. Like building LEGO blocks, we teach the generic network a new\ncategory by directly transplanting the module corresponding to the category\nfrom a pre-trained network with a few or even without sample annotations. Our\nmethod incrementally adds new categories to the generic network but does not\naffect representations of existing categories. In this way, our method breaks\nthe typical bottleneck of learning a net for massive tasks and categories, i.e.\nthe requirement of collecting samples for all tasks and categories at the same\ntime before the learning begins. Thus, we use a new distillation algorithm,\nnamely back-distillation, to overcome specific challenges of network\ntransplanting. Our method without training samples even outperformed the\nbaseline with 100 training samples. \n\n"}
{"id": "1804.10470", "contents": "Title: Intersecting edge distinguishing colorings of hypergraphs Abstract: An edge labeling of a graph distinguishes neighbors by sets (multisets,\nresp.), if for any two adjacent vertices $u$ and $v$ the sets (multisets,\nresp.) of labels appearing on edges incident to $u$ and $v$ are different. In\nan analogous way we define total labelings distinguishing neighbors by sets or\nmultisets: for each vertex, we consider labels on incident edges and the label\nof the vertex itself.\n  In this paper we show that these problems, and also other problems of similar\nflavor, admit an elegant and natural generalization as a hypergraph coloring\nproblem. An ieds-coloring (iedm-coloring, resp.) of a hypergraph is a vertex\ncoloring, in which the sets (multisets, resp.) of colors, that appear on every\npair of intersecting edges are different. We show upper bounds on the size of\nlists, which guarantee the existence of an ieds- or iedm-coloring, respecting\nthese lists. The proof is essentially a randomized algorithm, whose expected\ntime complexity is polynomial. As corollaries, we derive new results concerning\nthe list variants of graph labeling problems, distinguishing neighbors by sets\nor multisets. We also show that our method is robust and can be easily extended\nfor different, related problems.\n  We also investigate a close connection between edge labelings of bipartite\ngraphs, distinguishing neighbors by sets, and the so-called property \\textbf{B}\nof hypergraphs. We discuss computational aspects of the problem and present\nsome classes of bipartite graphs, which admit such a labeling using two labels. \n\n"}
{"id": "1804.10653", "contents": "Title: Sparse Group Inductive Matrix Completion Abstract: We consider the problem of matrix completion with side information\n(\\textit{inductive matrix completion}). In real-world applications many\nside-channel features are typically non-informative making feature selection an\nimportant part of the problem. We incorporate feature selection into inductive\nmatrix completion by proposing a matrix factorization framework with\ngroup-lasso regularization on side feature parameter matrices. We demonstrate,\nthat the theoretical sample complexity for the proposed method is much lower\ncompared to its competitors in sparse problems, and propose an efficient\noptimization algorithm for the resulting low-rank matrix completion problem\nwith sparsifying regularizers. Experiments on synthetic and real-world datasets\nshow that the proposed approach outperforms other methods. \n\n"}
{"id": "1804.10827", "contents": "Title: On Euclidean $k$-Means Clustering with $\\alpha$-Center Proximity Abstract: $k$-means clustering is NP-hard in the worst case but previous work has shown\nefficient algorithms assuming the optimal $k$-means clusters are \\emph{stable}\nunder additive or multiplicative perturbation of data. This has two caveats.\nFirst, we do not know how to efficiently verify this property of optimal\nsolutions that are NP-hard to compute in the first place. Second, the stability\nassumptions required for polynomial time $k$-means algorithms are often\nunreasonable when compared to the ground-truth clusters in real-world data. A\nconsequence of multiplicative perturbation resilience is \\emph{center\nproximity}, that is, every point is closer to the center of its own cluster\nthan the center of any other cluster, by some multiplicative factor $\\alpha >\n1$.\n  We study the problem of minimizing the Euclidean $k$-means objective only\nover clusterings that satisfy $\\alpha$-center proximity. We give a simple\nalgorithm to find the optimal $\\alpha$-center-proximal $k$-means clustering in\nrunning time exponential in $k$ and $1/(\\alpha - 1)$ but linear in the number\nof points and the dimension. We define an analogous $\\alpha$-center proximity\ncondition for outliers, and give similar algorithmic guarantees for $k$-means\nwith outliers and $\\alpha$-center proximity. On the hardness side we show that\nfor any $\\alpha' > 1$, there exists an $\\alpha \\leq \\alpha'$, $(\\alpha >1)$,\nand an $\\varepsilon_0 > 0$ such that minimizing the $k$-means objective over\nclusterings that satisfy $\\alpha$-center proximity is NP-hard to approximate\nwithin a multiplicative $(1+\\varepsilon_0)$ factor. \n\n"}
{"id": "1804.10839", "contents": "Title: Learning from multivariate discrete sequential data using a restricted\n  Boltzmann machine model Abstract: A restricted Boltzmann machine (RBM) is a generative neural-network model\nwith many novel applications such as collaborative filtering and acoustic\nmodeling. An RBM lacks the capacity to retain memory, making it inappropriate\nfor dynamic data modeling as in time-series analysis. In this paper we address\nthis issue by proposing the p-RBM model, a generalization of the regular RBM\nmodel, capable of retaining memory of p past states. We further show how to\ntrain the p-RBM model using contrastive divergence and test our model on the\nproblem of predicting the stock market direction considering 100 stocks of the\nNASDAQ-100 index. Obtained results show that the p-RBM offer promising\nprediction potential. \n\n"}
{"id": "1805.00503", "contents": "Title: Machine Learning for Exam Triage Abstract: In this project, we extend the state-of-the-art CheXNet (Rajpurkar et al.\n[2017]) by making use of the additional non-image features in the dataset. Our\nmodel produced better AUROC scores than the original CheXNet. \n\n"}
{"id": "1805.01209", "contents": "Title: Found Graph Data and Planted Vertex Covers Abstract: A typical way in which network data is recorded is to measure all the\ninteractions among a specified set of core nodes; this produces a graph\ncontaining this core together with a potentially larger set of fringe nodes\nthat have links to the core. Interactions between pairs of nodes in the fringe,\nhowever, are not recorded by this process, and hence not present in the\nresulting graph data. For example, a phone service provider may only have\nrecords of calls in which at least one of the participants is a customer; this\ncan include calls between a customer and a non-customer, but not between pairs\nof non-customers.\n  Knowledge of which nodes belong to the core is an important piece of metadata\nthat is crucial for interpreting the network dataset. But in many cases, this\nmetadata is not available, either because it has been lost due to difficulties\nin data provenance, or because the network consists of found data obtained in\nsettings such as counter-surveillance. This leads to a natural algorithmic\nproblem, namely the recovery of the core set. Since the core set forms a vertex\ncover of the graph, we essentially have a planted vertex cover problem, but\nwith an arbitrary underlying graph. We develop a theoretical framework for\nanalyzing this planted vertex cover problem, based on results in the theory of\nfixed-parameter tractability, together with algorithms for recovering the core.\nOur algorithms are fast, simple to implement, and out-perform several methods\nbased on network core-periphery structure on various real-world datasets. \n\n"}
{"id": "1805.01934", "contents": "Title: Learning to See in the Dark Abstract: Imaging in low light is challenging due to low photon count and low SNR.\nShort-exposure images suffer from noise, while long exposure can induce blur\nand is often impractical. A variety of denoising, deblurring, and enhancement\ntechniques have been proposed, but their effectiveness is limited in extreme\nconditions, such as video-rate imaging at night. To support the development of\nlearning-based pipelines for low-light image processing, we introduce a dataset\nof raw short-exposure low-light images, with corresponding long-exposure\nreference images. Using the presented dataset, we develop a pipeline for\nprocessing low-light images, based on end-to-end training of a\nfully-convolutional network. The network operates directly on raw sensor data\nand replaces much of the traditional image processing pipeline, which tends to\nperform poorly on such data. We report promising results on the new dataset,\nanalyze factors that affect performance, and highlight opportunities for future\nwork. The results are shown in the supplementary video at\nhttps://youtu.be/qWKUFK7MWvg \n\n"}
{"id": "1805.01978", "contents": "Title: Unsupervised Feature Learning via Non-Parametric Instance-level\n  Discrimination Abstract: Neural net classifiers trained on data with annotated class labels can also\ncapture apparent visual similarity among categories without being directed to\ndo so. We study whether this observation can be extended beyond the\nconventional domain of supervised learning: Can we learn a good feature\nrepresentation that captures apparent similarity among instances, instead of\nclasses, by merely asking the feature to be discriminative of individual\ninstances? We formulate this intuition as a non-parametric classification\nproblem at the instance-level, and use noise-contrastive estimation to tackle\nthe computational challenges imposed by the large number of instance classes.\nOur experimental results demonstrate that, under unsupervised learning\nsettings, our method surpasses the state-of-the-art on ImageNet classification\nby a large margin. Our method is also remarkable for consistently improving\ntest performance with more training data and better network architectures. By\nfine-tuning the learned feature, we further obtain competitive results for\nsemi-supervised learning and object detection tasks. Our non-parametric model\nis highly compact: With 128 features per image, our method requires only 600MB\nstorage for a million images, enabling fast nearest neighbour retrieval at the\nrun time. \n\n"}
{"id": "1805.02176", "contents": "Title: Predicting clinical significance of BRCA1 and BRCA2 single nucleotide\n  substitution variants with unknown clinical significance using probabilistic\n  neural network and deep neural network-stacked autoencoder Abstract: Non-synonymous single nucleotide polymorphisms (nsSNPs) are single nucleotide\nsubstitution occurring in the coding region of a gene and leads to a change in\namino-acid sequence of protein. The studies have shown these variations may be\nassociated with disease. Thus, investigating the effects of nsSNPs on protein\nfunction will give a greater insight on how nsSNPs can lead into disease.\nBreast cancer is the most common cancer among women causing highest cancer\ndeath every year. BRCA1 and BRCA2 tumor suppressor genes are two main\ncandidates of which, mutations in them can increase the risk of developing\nbreast cancer. For prediction and detection of the cancer one can use\nexperimental or computational methods, but the experimental method is very\ncostly and time consuming in comparison with the computational method. The\ncomputer and computational methods have been used for more than 30 years. Here\nwe try to predict the clinical significance of BRCA1 and BRCA2 nsSNPs as well\nas the unknown clinical significances. Nearly 500 BRCA1 and BRCA2 nsSNPs with\nknown clinical significances retrieved from NCBI database. Based on\nhydrophobicity or hydrophilicity and their role in proteins' second structure,\nthey are divided into 6 groups, each assigned with scores. The data are\nprepared in the acceptable form to the automated prediction mechanisms,\nProbabilistic Neural Network (PNN) and Deep Neural NetworkStacked AutoEncoder\n(DNN). With Jackknife cross validation we show that the prediction accuracy\nachieved for BRCA1 and BRCA2 using PNN are 87.97% and 82.17% respectively,\nwhile 95.41% and 92.80% accuracies achieved using DNN. The total required\nprocessing time for the training and testing the PNN is 0.9 second and DNN\nrequires about 7 hours of training and it can predict instantly. both methods\nshow great improvement in accuracy and speed compared to previous attempts. \n\n"}
{"id": "1805.02489", "contents": "Title: Transformer for Emotion Recognition Abstract: This paper describes the UMONS solution for the OMG-Emotion Challenge. We\nexplore a context-dependent architecture where the arousal and valence of an\nutterance are predicted according to its surrounding context (i.e. the\npreceding and following utterances of the video). We report an improvement when\ntaking into account context for both unimodal and multimodal predictions. \n\n"}
{"id": "1805.02848", "contents": "Title: Identifiability of Generalized Hypergeometric Distribution (GHD)\n  Directed Acyclic Graphical Models Abstract: We introduce a new class of identifiable DAG models where the conditional\ndistribution of each node given its parents belongs to a family of generalized\nhypergeometric distributions (GHD). A family of generalized hypergeometric\ndistributions includes a lot of discrete distributions such as the binomial,\nBeta-binomial, negative binomial, Poisson, hyper-Poisson, and many more. We\nprove that if the data drawn from the new class of DAG models, one can fully\nidentify the graph structure. We further present a reliable and polynomial-time\nalgorithm that recovers the graph from finitely many data. We show through\ntheoretical results and numerical experiments that our algorithm is\nstatistically consistent in high-dimensional settings (p>n) if the indegree of\nthe graph is bounded, and out-performs state-of-the-art DAG learning\nalgorithms. \n\n"}
{"id": "1805.03405", "contents": "Title: Characterizing and decomposing classes of threshold, split, and\n  bipartite graphs via 1-Sperner hypergraphs Abstract: A hypergraph is said to be $1$-Sperner if for every two hyperedges the\nsmallest of their two set differences is of size one. We present several\napplications of $1$-Sperner hypergraphs and their structure to graphs. In\nparticular, we consider the classical characterizations of threshold and\ndomishold graphs and use them to obtain further characterizations of these\nclasses in terms of $1$-Spernerness, thresholdness, and $2$-asummability of\ntheir vertex cover, clique, dominating set, and closed neighborhood\nhypergraphs. Furthermore, we apply a decomposition property of $1$-Sperner\nhypergraphs to derive decomposition theorems for two classes of split graphs, a\nclass of bipartite graphs, and a class of cobipartite graphs. These\ndecomposition theorems are based on certain matrix partitions of the\ncorresponding graphs, giving rise to new classes of graphs of bounded\nclique-width and new polynomially solvable cases of several domination\nproblems. \n\n"}
{"id": "1805.04582", "contents": "Title: TensOrMachine: Probabilistic Boolean Tensor Decomposition Abstract: Boolean tensor decomposition approximates data of multi-way binary\nrelationships as product of interpretable low-rank binary factors, following\nthe rules of Boolean algebra. Here, we present its first probabilistic\ntreatment. We facilitate scalable sampling-based posterior inference by\nexploitation of the combinatorial structure of the factor conditionals. Maximum\na posteriori decompositions feature higher accuracies than existing techniques\nthroughout a wide range of simulated conditions. Moreover, the probabilistic\napproach facilitates the treatment of missing data and enables model selection\nwith much greater accuracy. We investigate three real-world data-sets. First,\ntemporal interaction networks in a hospital ward and behavioural data of\nuniversity students demonstrate the inference of instructive latent patterns.\nNext, we decompose a tensor with more than 10 billion data points, indicating\nrelations of gene expression in cancer patients. Not only does this demonstrate\nscalability, it also provides an entirely novel perspective on relational\nproperties of continuous data and, in the present example, on the molecular\nheterogeneity of cancer. Our implementation is available on GitHub:\nhttps://github.com/TammoR/LogicalFactorisationMachines. \n\n"}
{"id": "1805.05021", "contents": "Title: A One-Class Classification Decision Tree Based on Kernel Density\n  Estimation Abstract: One-class Classification (OCC) is an area of machine learning which addresses\nprediction based on unbalanced datasets. Basically, OCC algorithms achieve\ntraining by means of a single class sample, with potentially some additional\ncounter-examples. The current OCC models give satisfaction in terms of\nperformance, but there is an increasing need for the development of\ninterpretable models. In the present work, we propose a one-class model which\naddresses concerns of both performance and interpretability. Our hybrid OCC\nmethod relies on density estimation as part of a tree-based learning algorithm,\ncalled One-Class decision Tree (OC-Tree). Within a greedy and recursive\napproach, our proposal rests on kernel density estimation to split a data\nsubset on the basis of one or several intervals of interest. Thus, the OC-Tree\nencloses data within hyper-rectangles of interest which can be described by a\nset of rules. Against state-of-the-art methods such as Cluster Support Vector\nData Description (ClusterSVDD), One-Class Support Vector Machine (OCSVM) and\nisolation Forest (iForest), the OC-Tree performs favorably on a range of\nbenchmark datasets. Furthermore, we propose a real medical application for\nwhich the OC-Tree has demonstrated its effectiveness, through the ability to\ntackle interpretable diagnosis aid based on unbalanced datasets. \n\n"}
{"id": "1805.05071", "contents": "Title: KL-UCB-switch: optimal regret bounds for stochastic bandits from both a\n  distribution-dependent and a distribution-free viewpoints Abstract: We consider $K$-armed stochastic bandits and consider cumulative regret\nbounds up to time $T$. We are interested in strategies achieving simultaneously\na distribution-free regret bound of optimal order $\\sqrt{KT}$ and a\ndistribution-dependent regret that is asymptotically optimal, that is, matching\nthe $\\kappa\\ln T$ lower bound by Lai and Robbins (1985) and Burnetas and\nKatehakis (1996), where $\\kappa$ is the optimal problem-dependent constant.\nThis constant $\\kappa$ depends on the model $\\mathcal{D}$ considered (the\nfamily of possible distributions over the arms). M\\'enard and Garivier (2017)\nprovided strategies achieving such a bi-optimality in the parametric case of\nmodels given by one-dimensional exponential families, while Lattimore (2016,\n2018) did so for the family of (sub)Gaussian distributions with variance less\nthan $1$. We extend this result to the non-parametric case of all distributions\nover $[0,1]$. We do so by combining the MOSS strategy by Audibert and Bubeck\n(2009), which enjoys a distribution-free regret bound of optimal order\n$\\sqrt{KT}$, and the KL-UCB strategy by Capp\\'e et al. (2013), for which we\nprovide in passing the first analysis of an optimal distribution-dependent\n$\\kappa\\ln T$ regret bound in the model of all distributions over $[0,1]$. We\nwere able to obtain this non-parametric bi-optimality result while working hard\nto streamline the proofs (of previously known regret bounds and thus of the new\nanalyses carried out); a second merit of the present contribution is therefore\nto provide a review of proofs of classical regret bounds for index-based\nstrategies for $K$-armed stochastic bandits. \n\n"}
{"id": "1805.05827", "contents": "Title: Graph Signal Sampling via Reinforcement Learning Abstract: We formulate the problem of sampling and recovering clustered graph signal as\na multi-armed bandit (MAB) problem. This formulation lends naturally to\nlearning sampling strategies using the well-known gradient MAB algorithm. In\nparticular, the sampling strategy is represented as a probability distribution\nover the individual arms of the MAB and optimized using gradient ascent. Some\nillustrative numerical experiments indicate that the sampling strategies based\non the gradient MAB algorithm outperform existing sampling methods. \n\n"}
{"id": "1805.06619", "contents": "Title: Taxi demand forecasting: A HEDGE based tessellation strategy for\n  improved accuracy Abstract: A key problem in location-based modeling and forecasting lies in identifying\nsuitable spatial and temporal resolutions. In particular, judicious spatial\npartitioning can play a significant role in enhancing the performance of\nlocation-based forecasting models. In this work, we investigate two widely used\ntessellation strategies for partitioning city space, in the context of\nreal-time taxi demand forecasting. Our study compares (i) Geohash tessellation,\nand (ii) Voronoi tessellation, using two distinct taxi demand datasets, over\nmultiple time scales. For the purpose of comparison, we employ classical\ntime-series tools to model the spatio-temporal demand. Our study finds that the\nperformance of each tessellation strategy is highly dependent on the city\ngeography, spatial distribution of the data, and the time of the day, and that\nneither strategy is found to perform optimally across the forecast horizon. We\npropose a hybrid tessellation algorithm that picks the best tessellation\nstrategy at each instant, based on their performance in the recent past. Our\nhybrid algorithm is a non-stationary variant of the well-known HEDGE algorithm\nfor choosing the best advice from multiple experts. We show that the hybrid\ntessellation strategy performs consistently better than either of the two\nstrategies across the data sets considered, at multiple time scales, and with\ndifferent performance metrics. We achieve an average accuracy of above 80% per\nkm^2 for both data sets considered at 60 minute aggregation levels. \n\n"}
{"id": "1805.06627", "contents": "Title: Probabilistic Embedding of Knowledge Graphs with Box Lattice Measures Abstract: Embedding methods which enforce a partial order or lattice structure over the\nconcept space, such as Order Embeddings (OE) (Vendrov et al., 2016), are a\nnatural way to model transitive relational data (e.g. entailment graphs).\nHowever, OE learns a deterministic knowledge base, limiting expressiveness of\nqueries and the ability to use uncertainty for both prediction and learning\n(e.g. learning from expectations). Probabilistic extensions of OE (Lai and\nHockenmaier, 2017) have provided the ability to somewhat calibrate these\ndenotational probabilities while retaining the consistency and inductive bias\nof ordered models, but lack the ability to model the negative correlations\nfound in real-world knowledge. In this work we show that a broad class of\nmodels that assign probability measures to OE can never capture negative\ncorrelation, which motivates our construction of a novel box lattice and\naccompanying probability measure to capture anticorrelation and even disjoint\nconcepts, while still providing the benefits of probabilistic modeling, such as\nthe ability to perform rich joint and conditional queries over arbitrary sets\nof concepts, and both learning from and predicting calibrated uncertainty. We\nshow improvements over previous approaches in modeling the Flickr and WordNet\nentailment graphs, and investigate the power of the model. \n\n"}
{"id": "1805.07193", "contents": "Title: The EuroCity Persons Dataset: A Novel Benchmark for Object Detection Abstract: Big data has had a great share in the success of deep learning in computer\nvision. Recent works suggest that there is significant further potential to\nincrease object detection performance by utilizing even bigger datasets. In\nthis paper, we introduce the EuroCity Persons dataset, which provides a large\nnumber of highly diverse, accurate and detailed annotations of pedestrians,\ncyclists and other riders in urban traffic scenes. The images for this dataset\nwere collected on-board a moving vehicle in 31 cities of 12 European countries.\nWith over 238200 person instances manually labeled in over 47300 images,\nEuroCity Persons is nearly one order of magnitude larger than person datasets\nused previously for benchmarking. The dataset furthermore contains a large\nnumber of person orientation annotations (over 211200). We optimize four\nstate-of-the-art deep learning approaches (Faster R-CNN, R-FCN, SSD and YOLOv3)\nto serve as baselines for the new object detection benchmark. In experiments\nwith previous datasets we analyze the generalization capabilities of these\ndetectors when trained with the new dataset. We furthermore study the effect of\nthe training set size, the dataset diversity (day- vs. night-time, geographical\nregion), the dataset detail (i.e. availability of object orientation\ninformation) and the annotation quality on the detector performance. Finally,\nwe analyze error sources and discuss the road ahead. \n\n"}
{"id": "1805.07474", "contents": "Title: Projection-Free Bandit Convex Optimization Abstract: In this paper, we propose the first computationally efficient projection-free\nalgorithm for bandit convex optimization (BCO). We show that our algorithm\nachieves a sublinear regret of $O(nT^{4/5})$ (where $T$ is the horizon and $n$\nis the dimension) for any bounded convex functions with uniformly bounded\ngradients. We also evaluate the performance of our algorithm against baselines\non both synthetic and real data sets for quadratic programming, portfolio\nselection and matrix completion problems. \n\n"}
{"id": "1805.07513", "contents": "Title: Diverse Few-Shot Text Classification with Multiple Metrics Abstract: We study few-shot learning in natural language domains. Compared to many\nexisting works that apply either metric-based or optimization-based\nmeta-learning to image domain with low inter-task variance, we consider a more\nrealistic setting, where tasks are diverse. However, it imposes tremendous\ndifficulties to existing state-of-the-art metric-based algorithms since a\nsingle metric is insufficient to capture complex task variations in natural\nlanguage domain. To alleviate the problem, we propose an adaptive metric\nlearning approach that automatically determines the best weighted combination\nfrom a set of metrics obtained from meta-training tasks for a newly seen\nfew-shot task. Extensive quantitative evaluations on real-world sentiment\nanalysis and dialog intent classification datasets demonstrate that the\nproposed method performs favorably against state-of-the-art few shot learning\nalgorithms in terms of predictive accuracy. We make our code and data available\nfor further study. \n\n"}
{"id": "1805.07683", "contents": "Title: Learning Graph-Level Representations with Recurrent Neural Networks Abstract: Recently a variety of methods have been developed to encode graphs into\nlow-dimensional vectors that can be easily exploited by machine learning\nalgorithms. The majority of these methods start by embedding the graph nodes\ninto a low-dimensional vector space, followed by using some scheme to aggregate\nthe node embeddings. In this work, we develop a new approach to learn\ngraph-level representations, which includes a combination of unsupervised and\nsupervised learning components. We start by learning a set of node\nrepresentations in an unsupervised fashion. Graph nodes are mapped into node\nsequences sampled from random walk approaches approximated by the\nGumbel-Softmax distribution. Recurrent neural network (RNN) units are modified\nto accommodate both the node representations as well as their neighborhood\ninformation. Experiments on standard graph classification benchmarks\ndemonstrate that our proposed approach achieves superior or comparable\nperformance relative to the state-of-the-art algorithms in terms of convergence\nspeed and classification accuracy. We further illustrate the effectiveness of\nthe different components used by our approach. \n\n"}
{"id": "1805.07816", "contents": "Title: Towards Understanding Limitations of Pixel Discretization Against\n  Adversarial Attacks Abstract: Wide adoption of artificial neural networks in various domains has led to an\nincreasing interest in defending adversarial attacks against them.\nPreprocessing defense methods such as pixel discretization are particularly\nattractive in practice due to their simplicity, low computational overhead, and\napplicability to various systems. It is observed that such methods work well on\nsimple datasets like MNIST, but break on more complicated ones like ImageNet\nunder recently proposed strong white-box attacks. To understand the conditions\nfor success and potentials for improvement, we study the pixel discretization\ndefense method, including more sophisticated variants that take into account\nthe properties of the dataset being discretized. Our results again show poor\nresistance against the strong attacks. We analyze our results in a theoretical\nframework and offer strong evidence that pixel discretization is unlikely to\nwork on all but the simplest of the datasets. Furthermore, our arguments\npresent insights why some other preprocessing defenses may be insecure. \n\n"}
{"id": "1805.07862", "contents": "Title: Featurized Bidirectional GAN: Adversarial Defense via Adversarially\n  Learned Semantic Inference Abstract: Deep neural networks have been demonstrated to be vulnerable to adversarial\nattacks, where small perturbations intentionally added to the original inputs\ncan fool the classifier. In this paper, we propose a defense method, Featurized\nBidirectional Generative Adversarial Networks (FBGAN), to extract the semantic\nfeatures of the input and filter the non-semantic perturbation. FBGAN is\npre-trained on the clean dataset in an unsupervised manner, adversarially\nlearning a bidirectional mapping between the high-dimensional data space and\nthe low-dimensional semantic space; also mutual information is applied to\ndisentangle the semantically meaningful features. After the bidirectional\nmapping, the adversarial data can be reconstructed to denoised data, which\ncould be fed into any pre-trained classifier. We empirically show the quality\nof reconstruction images and the effectiveness of defense. \n\n"}
{"id": "1805.07909", "contents": "Title: Quickshift++: Provably Good Initializations for Sample-Based Mean Shift Abstract: We provide initial seedings to the Quick Shift clustering algorithm, which\napproximate the locally high-density regions of the data. Such seedings act as\nmore stable and expressive cluster-cores than the singleton modes found by\nQuick Shift. We establish statistical consistency guarantees for this\nmodification. We then show strong clustering performance on real datasets as\nwell as promising applications to image segmentation. \n\n"}
{"id": "1805.08187", "contents": "Title: Finding forbidden minors in sublinear time: a $n^{1/2+o(1)}$-query\n  one-sided tester for minor closed properties on bounded degree graphs Abstract: Let $G$ be an undirected, bounded degree graph with $n$ vertices. Fix a\nfinite graph $H$, and suppose one must remove $\\varepsilon n$ edges from $G$ to\nmake it $H$-minor free (for some small constant $\\varepsilon > 0$). We give an\n$n^{1/2+o(1)}$-time randomized procedure that, with high probability, finds an\n$H$-minor in such a graph. As an application, suppose one must remove\n$\\varepsilon n$ edges from a bounded degree graph $G$ to make it planar. This\nresult implies an algorithm, with the same running time, that produces a\n$K_{3,3}$ or $K_5$ minor in $G$. No prior sublinear time bound was known for\nthis problem.\n  By the graph minor theorem, we get an analogous result for any minor-closed\nproperty. Up to $n^{o(1)}$ factors, this resolves a conjecture of\nBenjamini-Schramm-Shapira (STOC 2008) on the existence of one-sided property\ntesters for minor-closed properties. Furthermore, our algorithm is nearly\noptimal, by an $\\Omega(\\sqrt{n})$ lower bound of Czumaj et al (RSA 2014).\n  Prior to this work, the only graphs $H$ for which non-trivial one-sided\nproperty testers were known for $H$-minor freeness are the following: $H$ being\na forest or a cycle (Czumaj et al, RSA 2014), $K_{2,k}$, $(k\\times 2)$-grid,\nand the $k$-circus (Fichtenberger et al, Arxiv 2017). \n\n"}
{"id": "1805.08254", "contents": "Title: Sample Compression for Real-Valued Learners Abstract: We give an algorithmically efficient version of the learner-to-compression\nscheme conversion in Moran and Yehudayoff (2016). In extending this technique\nto real-valued hypotheses, we also obtain an efficient regression-to-bounded\nsample compression converter. To our knowledge, this is the first general\ncompressed regression result (regardless of efficiency or boundedness)\nguaranteeing uniform approximate reconstruction. Along the way, we develop a\ngeneric procedure for constructing weak real-valued learners out of abstract\nregressors; this may be of independent interest. In particular, this result\nsheds new light on an open question of H. Simon (1997). We show applications to\ntwo regression problems: learning Lipschitz and bounded-variation functions. \n\n"}
{"id": "1805.08522", "contents": "Title: Deep learning generalizes because the parameter-function map is biased\n  towards simple functions Abstract: Deep neural networks (DNNs) generalize remarkably well without explicit\nregularization even in the strongly over-parametrized regime where classical\nlearning theory would instead predict that they would severely overfit. While\nmany proposals for some kind of implicit regularization have been made to\nrationalise this success, there is no consensus for the fundamental reason why\nDNNs do not strongly overfit. In this paper, we provide a new explanation. By\napplying a very general probability-complexity bound recently derived from\nalgorithmic information theory (AIT), we argue that the parameter-function map\nof many DNNs should be exponentially biased towards simple functions. We then\nprovide clear evidence for this strong simplicity bias in a model DNN for\nBoolean functions, as well as in much larger fully connected and convolutional\nnetworks applied to CIFAR10 and MNIST. As the target functions in many real\nproblems are expected to be highly structured, this intrinsic simplicity bias\nhelps explain why deep networks generalize well on real world problems. This\npicture also facilitates a novel PAC-Bayes approach where the prior is taken\nover the DNN input-output function space, rather than the more conventional\nprior over parameter space. If we assume that the training algorithm samples\nparameters close to uniformly within the zero-error region then the PAC-Bayes\ntheorem can be used to guarantee good expected generalization for target\nfunctions producing high-likelihood training sets. By exploiting recently\ndiscovered connections between DNNs and Gaussian processes to estimate the\nmarginal likelihood, we produce relatively tight generalization PAC-Bayes error\nbounds which correlate well with the true error on realistic datasets such as\nMNIST and CIFAR10 and for architectures including convolutional and fully\nconnected networks. \n\n"}
{"id": "1805.08571", "contents": "Title: On Coresets for Logistic Regression Abstract: Coresets are one of the central methods to facilitate the analysis of large\ndata sets. We continue a recent line of research applying the theory of\ncoresets to logistic regression. First, we show a negative result, namely, that\nno strongly sublinear sized coresets exist for logistic regression. To deal\nwith intractable worst-case instances we introduce a complexity measure\n$\\mu(X)$, which quantifies the hardness of compressing a data set for logistic\nregression. $\\mu(X)$ has an intuitive statistical interpretation that may be of\nindependent interest. For data sets with bounded $\\mu(X)$-complexity, we show\nthat a novel sensitivity sampling scheme produces the first provably sublinear\n$(1\\pm\\varepsilon)$-coreset. We illustrate the performance of our method by\ncomparing to uniform sampling as well as to state of the art methods in the\narea. The experiments are conducted on real world benchmark data for logistic\nregression. \n\n"}
{"id": "1805.08749", "contents": "Title: A Tropical Approach to Neural Networks with Piecewise Linear Activations Abstract: We present a new, unifying approach following some recent developments on the\ncomplexity of neural networks with piecewise linear activations. We treat\nneural network layers with piecewise linear activations as tropical\npolynomials, which generalize polynomials in the so-called $(\\max, +)$ or\ntropical algebra, with possibly real-valued exponents. Motivated by the\ndiscussion in (arXiv:1402.1869), this approach enables us to refine their upper\nbounds on linear regions of layers with ReLU or leaky ReLU activations to\n$\\min\\left\\{ 2^m, \\sum_{j=0}^n \\binom{m}{j} \\right\\}$, where $n, m$ are the\nnumber of inputs and outputs, respectively. Additionally, we recover their\nupper bounds on maxout layers. Our work follows a novel path, exclusively under\nthe lens of tropical geometry, which is independent of the improvements\nreported in (arXiv:1611.01491, arXiv:1711.02114). Finally, we present a\ngeometric approach for effective counting of linear regions using random\nsampling in order to avoid the computational overhead of exact counting\napproaches \n\n"}
{"id": "1805.08890", "contents": "Title: Step Size Matters in Deep Learning Abstract: Training a neural network with the gradient descent algorithm gives rise to a\ndiscrete-time nonlinear dynamical system. Consequently, behaviors that are\ntypically observed in these systems emerge during training, such as convergence\nto an orbit but not to a fixed point or dependence of convergence on the\ninitialization. Step size of the algorithm plays a critical role in these\nbehaviors: it determines the subset of the local optima that the algorithm can\nconverge to, and it specifies the magnitude of the oscillations if the\nalgorithm converges to an orbit. To elucidate the effects of the step size on\ntraining of neural networks, we study the gradient descent algorithm as a\ndiscrete-time dynamical system, and by analyzing the Lyapunov stability of\ndifferent solutions, we show the relationship between the step size of the\nalgorithm and the solutions that can be obtained with this algorithm. The\nresults provide an explanation for several phenomena observed in practice,\nincluding the deterioration in the training error with increased depth, the\nhardness of estimating linear mappings with large singular values, and the\ndistinct performance of deep residual networks. \n\n"}
{"id": "1805.08966", "contents": "Title: Discovering Blind Spots in Reinforcement Learning Abstract: Agents trained in simulation may make errors in the real world due to\nmismatches between training and execution environments. These mistakes can be\ndangerous and difficult to discover because the agent cannot predict them a\npriori. We propose using oracle feedback to learn a predictive model of these\nblind spots to reduce costly errors in real-world applications. We focus on\nblind spots in reinforcement learning (RL) that occur due to incomplete state\nrepresentation: The agent does not have the appropriate features to represent\nthe true state of the world and thus cannot distinguish among numerous states.\nWe formalize the problem of discovering blind spots in RL as a noisy supervised\nlearning problem with class imbalance. We learn models to predict blind spots\nin unseen regions of the state space by combining techniques for label\naggregation, calibration, and supervised learning. The models take into\nconsideration noise emerging from different forms of oracle feedback, including\ndemonstrations and corrections. We evaluate our approach on two domains and\nshow that it achieves higher predictive performance than baseline methods, and\nthat the learned model can be used to selectively query an oracle at execution\ntime to prevent errors. We also empirically analyze the biases of various\nfeedback types and how they influence the discovery of blind spots. \n\n"}
{"id": "1805.09174", "contents": "Title: Efficient online algorithms for fast-rate regret bounds under sparsity Abstract: We consider the online convex optimization problem. In the setting of\narbitrary sequences and finite set of parameters, we establish a new fast-rate\nquantile regret bound. Then we investigate the optimization into the L1-ball by\ndiscretizing the parameter space. Our algorithm is projection free and we\npropose an efficient solution by restarting the algorithm on adaptive\ndiscretization grids. In the adversarial setting, we develop an algorithm that\nachieves several rates of convergence with different dependencies on the\nsparsity of the objective. In the i.i.d. setting, we establish new risk bounds\nthat are adaptive to the sparsity of the problem and to the regularity of the\nrisk (ranging from a rate 1 / $\\sqrt T$ for general convex risk to 1 /T for\nstrongly convex risk). These results generalize previous works on sparse online\nlearning. They are obtained under a weak assumption on the risk\n({\\L}ojasiewicz's assumption) that allows multiple optima which is crucial when\ndealing with degenerate situations. \n\n"}
{"id": "1805.09281", "contents": "Title: Variational Inference for Data-Efficient Model Learning in POMDPs Abstract: Partially observable Markov decision processes (POMDPs) are a powerful\nabstraction for tasks that require decision making under uncertainty, and\ncapture a wide range of real world tasks. Today, effective planning approaches\nexist that generate effective strategies given black-box models of a POMDP\ntask. Yet, an open question is how to acquire accurate models for complex\ndomains. In this paper we propose DELIP, an approach to model learning for\nPOMDPs that utilizes amortized structured variational inference. We empirically\nshow that our model leads to effective control strategies when coupled with\nstate-of-the-art planners. Intuitively, model-based approaches should be\nparticularly beneficial in environments with changing reward structures, or\nwhere rewards are initially unknown. Our experiments confirm that DELIP is\nparticularly effective in this setting. \n\n"}
{"id": "1805.09450", "contents": "Title: Large Data and Zero Noise Limits of Graph-Based Semi-Supervised Learning\n  Algorithms Abstract: Scalings in which the graph Laplacian approaches a differential operator in\nthe large graph limit are used to develop understanding of a number of\nalgorithms for semi-supervised learning; in particular the extension, to this\ngraph setting, of the probit algorithm, level set and kriging methods, are\nstudied. Both optimization and Bayesian approaches are considered, based around\na regularizing quadratic form found from an affine transformation of the\nLaplacian, raised to a, possibly fractional, exponent. Conditions on the\nparameters defining this quadratic form are identified under which well-defined\nlimiting continuum analogues of the optimization and Bayesian semi-supervised\nlearning problems may be found, thereby shedding light on the design of\nalgorithms in the large graph setting. The large graph limits of the\noptimization formulations are tackled through $\\Gamma-$convergence, using the\nrecently introduced $TL^p$ metric. The small labelling noise limits of the\nBayesian formulations are also identified, and contrasted with pre-existing\nharmonic function approaches to the problem. \n\n"}
{"id": "1805.09613", "contents": "Title: A0C: Alpha Zero in Continuous Action Space Abstract: A core novelty of Alpha Zero is the interleaving of tree search and deep\nlearning, which has proven very successful in board games like Chess, Shogi and\nGo. These games have a discrete action space. However, many real-world\nreinforcement learning domains have continuous action spaces, for example in\nrobotic control, navigation and self-driving cars. This paper presents the\nnecessary theoretical extensions of Alpha Zero to deal with continuous action\nspace. We also provide some preliminary experiments on the Pendulum swing-up\ntask, empirically showing the feasibility of our approach. Thereby, this work\nprovides a first step towards the application of iterated search and learning\nin domains with a continuous action space. \n\n"}
{"id": "1805.09622", "contents": "Title: SOSELETO: A Unified Approach to Transfer Learning and Training with\n  Noisy Labels Abstract: We present SOSELETO (SOurce SELEction for Target Optimization), a new method\nfor exploiting a source dataset to solve a classification problem on a target\ndataset. SOSELETO is based on the following simple intuition: some source\nexamples are more informative than others for the target problem. To capture\nthis intuition, source samples are each given weights; these weights are solved\nfor jointly with the source and target classification problems via a bilevel\noptimization scheme. The target therefore gets to choose the source samples\nwhich are most informative for its own classification task. Furthermore, the\nbilevel nature of the optimization acts as a kind of regularization on the\ntarget, mitigating overfitting. SOSELETO may be applied to both classic\ntransfer learning, as well as the problem of training on datasets with noisy\nlabels; we show state of the art results on both of these problems. \n\n"}
{"id": "1805.09692", "contents": "Title: Been There, Done That: Meta-Learning with Episodic Recall Abstract: Meta-learning agents excel at rapidly learning new tasks from open-ended task\ndistributions; yet, they forget what they learn about each task as soon as the\nnext begins. When tasks reoccur - as they do in natural environments -\nmetalearning agents must explore again instead of immediately exploiting\npreviously discovered solutions. We propose a formalism for generating\nopen-ended yet repetitious environments, then develop a meta-learning\narchitecture for solving these environments. This architecture melds the\nstandard LSTM working memory with a differentiable neural episodic memory. We\nexplore the capabilities of agents with this episodic LSTM in five\nmeta-learning environments with reoccurring tasks, ranging from bandits to\nnavigation and stochastic sequential decision problems. \n\n"}
{"id": "1805.09781", "contents": "Title: Efficient Inference in Multi-task Cox Process Models Abstract: We generalize the log Gaussian Cox process (LGCP) framework to model multiple\ncorrelated point data jointly. The observations are treated as realizations of\nmultiple LGCPs, whose log intensities are given by linear combinations of\nlatent functions drawn from Gaussian process priors. The combination\ncoefficients are also drawn from Gaussian processes and can incorporate\nadditional dependencies. We derive closed-form expressions for the moments of\nthe intensity functions and develop an efficient variational inference\nalgorithm that is orders of magnitude faster than competing deterministic and\nstochastic approximations of multivariate LGCP, coregionalization models, and\nmulti-task permanental processes. Our approach outperforms these benchmarks in\nmultiple problems, offering the current state of the art in modeling\nmultivariate point processes. \n\n"}
{"id": "1805.10498", "contents": "Title: Automatic context window composition for distant speech recognition Abstract: Distant speech recognition is being revolutionized by deep learning, that has\ncontributed to significantly outperform previous HMM-GMM systems. A key aspect\nbehind the rapid rise and success of DNNs is their ability to better manage\nlarge time contexts. With this regard, asymmetric context windows that embed\nmore past than future frames have been recently used with feed-forward neural\nnetworks. This context configuration turns out to be useful not only to address\nlow-latency speech recognition, but also to boost the recognition performance\nunder reverberant conditions. This paper investigates on the mechanisms\noccurring inside DNNs, which lead to an effective application of asymmetric\ncontexts.In particular, we propose a novel method for automatic context window\ncomposition based on a gradient analysis. The experiments, performed with\ndifferent acoustic environments, features, DNN architectures, microphone\nsettings, and recognition tasks show that our simple and efficient strategy\nleads to a less redundant frame configuration, which makes DNN training more\neffective in reverberant scenarios. \n\n"}
{"id": "1805.10662", "contents": "Title: Fingerprint Policy Optimisation for Robust Reinforcement Learning Abstract: Policy gradient methods ignore the potential value of adjusting environment\nvariables: unobservable state features that are randomly determined by the\nenvironment in a physical setting, but are controllable in a simulator. This\ncan lead to slow learning, or convergence to suboptimal policies, if the\nenvironment variable has a large impact on the transition dynamics. In this\npaper, we present fingerprint policy optimisation (FPO), which finds a policy\nthat is optimal in expectation across the distribution of environment\nvariables. The central idea is to use Bayesian optimisation (BO) to actively\nselect the distribution of the environment variable that maximises the\nimprovement generated by each iteration of the policy gradient method. To make\nthis BO practical, we contribute two easy-to-compute low-dimensional\nfingerprints of the current policy. Our experiments show that FPO can\nefficiently learn policies that are robust to significant rare events, which\nare unlikely to be observable under random sampling, but are key to learning\ngood policies. \n\n"}
{"id": "1805.10896", "contents": "Title: Adaptive Network Sparsification with Dependent Variational\n  Beta-Bernoulli Dropout Abstract: While variational dropout approaches have been shown to be effective for\nnetwork sparsification, they are still suboptimal in the sense that they set\nthe dropout rate for each neuron without consideration of the input data. With\nsuch input-independent dropout, each neuron is evolved to be generic across\ninputs, which makes it difficult to sparsify networks without accuracy loss. To\novercome this limitation, we propose adaptive variational dropout whose\nprobabilities are drawn from sparsity-inducing beta Bernoulli prior. It allows\neach neuron to be evolved either to be generic or specific for certain inputs,\nor dropped altogether. Such input-adaptive sparsity-inducing dropout allows the\nresulting network to tolerate larger degree of sparsity without losing its\nexpressive power by removing redundancies among features. We validate our\ndependent variational beta-Bernoulli dropout on multiple public datasets, on\nwhich it obtains significantly more compact networks than baseline methods,\nwith consistent accuracy improvements over the base networks. \n\n"}
{"id": "1805.11233", "contents": "Title: Retraining-Based Iterative Weight Quantization for Deep Neural Networks Abstract: Model compression has gained a lot of attention due to its ability to reduce\nhardware resource requirements significantly while maintaining accuracy of\nDNNs. Model compression is especially useful for memory-intensive recurrent\nneural networks because smaller memory footprint is crucial not only for\nreducing storage requirement but also for fast inference operations.\nQuantization is known to be an effective model compression method and\nresearchers are interested in minimizing the number of bits to represent\nparameters. In this work, we introduce an iterative technique to apply\nquantization, presenting high compression ratio without any modifications to\nthe training algorithm. In the proposed technique, weight quantization is\nfollowed by retraining the model with full precision weights. We show that\niterative retraining generates new sets of weights which can be quantized with\ndecreasing quantization loss at each iteration. We also show that quantization\nis efficiently able to leverage pruning, another effective model compression\nmethod. Implementation issues on combining the two methods are also addressed.\nOur experimental results demonstrate that an LSTM model using 1-bit quantized\nweights is sufficient for PTB dataset without any accuracy degradation while\nprevious methods demand at least 2-4 bits for quantized weights. \n\n"}
{"id": "1805.11703", "contents": "Title: Biologically Motivated Algorithms for Propagating Local Target\n  Representations Abstract: Finding biologically plausible alternatives to back-propagation of errors is\na fundamentally important challenge in artificial neural network research. In\nthis paper, we propose a learning algorithm called error-driven Local\nRepresentation Alignment (LRA-E), which has strong connections to predictive\ncoding, a theory that offers a mechanistic way of describing neurocomputational\nmachinery. In addition, we propose an improved variant of Difference Target\nPropagation, another procedure that comes from the same family of algorithms as\nLRA-E. We compare our procedures to several other biologically-motivated\nalgorithms, including two feedback alignment algorithms and Equilibrium\nPropagation. In two benchmarks, we find that both of our proposed algorithms\nyield stable performance and strong generalization compared to other competing\nback-propagation alternatives when training deeper, highly nonlinear networks,\nwith LRA-E performing the best overall. \n\n"}
{"id": "1806.00035", "contents": "Title: Assessing Generative Models via Precision and Recall Abstract: Recent advances in generative modeling have led to an increased interest in\nthe study of statistical divergences as means of model comparison. Commonly\nused evaluation methods, such as the Frechet Inception Distance (FID),\ncorrelate well with the perceived quality of samples and are sensitive to mode\ndropping. However, these metrics are unable to distinguish between different\nfailure cases since they only yield one-dimensional scores. We propose a novel\ndefinition of precision and recall for distributions which disentangles the\ndivergence into two separate dimensions. The proposed notion is intuitive,\nretains desirable properties, and naturally leads to an efficient algorithm\nthat can be used to evaluate generative models. We relate this notion to total\nvariation as well as to recent evaluation metrics such as Inception Score and\nFID. To demonstrate the practical utility of the proposed approach we perform\nan empirical study on several variants of Generative Adversarial Networks and\nVariational Autoencoders. In an extensive set of experiments we show that the\nproposed metric is able to disentangle the quality of generated samples from\nthe coverage of the target distribution. \n\n"}
{"id": "1806.00088", "contents": "Title: PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks Abstract: Deep learning systems have become ubiquitous in many aspects of our lives.\nUnfortunately, it has been shown that such systems are vulnerable to\nadversarial attacks, making them prone to potential unlawful uses. Designing\ndeep neural networks that are robust to adversarial attacks is a fundamental\nstep in making such systems safer and deployable in a broader variety of\napplications (e.g. autonomous driving), but more importantly is a necessary\nstep to design novel and more advanced architectures built on new computational\nparadigms rather than marginally building on the existing ones. In this paper\nwe introduce PeerNets, a novel family of convolutional networks alternating\nclassical Euclidean convolutions with graph convolutions to harness information\nfrom a graph of peer samples. This results in a form of non-local forward\npropagation in the model, where latent features are conditioned on the global\nstructure induced by the graph, that is up to 3 times more robust to a variety\nof white- and black-box adversarial attacks compared to conventional\narchitectures with almost no drop in accuracy. \n\n"}
{"id": "1806.00370", "contents": "Title: Nonlinear Acceleration of CNNs Abstract: The Regularized Nonlinear Acceleration (RNA) algorithm is an acceleration\nmethod capable of improving the rate of convergence of many optimization\nschemes such as gradient descend, SAGA or SVRG. Until now, its analysis is\nlimited to convex problems, but empirical observations shows that RNA may be\nextended to wider settings. In this paper, we investigate further the benefits\nof RNA when applied to neural networks, in particular for the task of image\nrecognition on CIFAR10 and ImageNet. With very few modifications of exiting\nframeworks, RNA improves slightly the optimization process of CNNs, after\ntraining. \n\n"}
{"id": "1806.00650", "contents": "Title: Signal and Noise Statistics Oblivious Orthogonal Matching Pursuit Abstract: Orthogonal matching pursuit (OMP) is a widely used algorithm for recovering\nsparse high dimensional vectors in linear regression models. The optimal\nperformance of OMP requires \\textit{a priori} knowledge of either the sparsity\nof regression vector or noise statistics. Both these statistics are rarely\nknown \\textit{a priori} and are very difficult to estimate. In this paper, we\npresent a novel technique called residual ratio thresholding (RRT) to operate\nOMP without any \\textit{a priori} knowledge of sparsity and noise statistics\nand establish finite sample and large sample support recovery guarantees for\nthe same. Both analytical results and numerical simulations in real and\nsynthetic data sets indicate that RRT has a performance comparable to OMP with\n\\textit{a priori} knowledge of sparsity and noise statistics. \n\n"}
{"id": "1806.00973", "contents": "Title: Sequential Test for the Lowest Mean: From Thompson to Murphy Sampling Abstract: Learning the minimum/maximum mean among a finite set of distributions is a\nfundamental sub-task in planning, game tree search and reinforcement learning.\nWe formalize this learning task as the problem of sequentially testing how the\nminimum mean among a finite set of distributions compares to a given threshold.\nWe develop refined non-asymptotic lower bounds, which show that optimality\nmandates very different sampling behavior for a low vs high true minimum. We\nshow that Thompson Sampling and the intuitive Lower Confidence Bounds policy\neach nail only one of these cases. We develop a novel approach that we call\nMurphy Sampling. Even though it entertains exclusively low true minima, we\nprove that MS is optimal for both possibilities. We then design advanced\nself-normalized deviation inequalities, fueling more aggressive stopping rules.\nWe complement our theoretical guarantees by experiments showing that MS works\nbest in practice. \n\n"}
{"id": "1806.01265", "contents": "Title: Equivalence Between Wasserstein and Value-Aware Loss for Model-based\n  Reinforcement Learning Abstract: Learning a generative model is a key component of model-based reinforcement\nlearning. Though learning a good model in the tabular setting is a simple task,\nlearning a useful model in the approximate setting is challenging. In this\ncontext, an important question is the loss function used for model learning as\nvarying the loss function can have a remarkable impact on effectiveness of\nplanning. Recently Farahmand et al. (2017) proposed a value-aware model\nlearning (VAML) objective that captures the structure of value function during\nmodel learning. Using tools from Asadi et al. (2018), we show that minimizing\nthe VAML objective is in fact equivalent to minimizing the Wasserstein metric.\nThis equivalence improves our understanding of value-aware models, and also\ncreates a theoretical foundation for applications of Wasserstein in model-based\nreinforcement~learning. \n\n"}
{"id": "1806.01528", "contents": "Title: The universal approximation power of finite-width deep ReLU networks Abstract: We show that finite-width deep ReLU neural networks yield rate-distortion\noptimal approximation (B\\\"olcskei et al., 2018) of polynomials, windowed\nsinusoidal functions, one-dimensional oscillatory textures, and the Weierstrass\nfunction, a fractal function which is continuous but nowhere differentiable.\nTogether with their recently established universal approximation property of\naffine function systems (B\\\"olcskei et al., 2018), this shows that deep neural\nnetworks approximate vastly different signal structures generated by the affine\ngroup, the Weyl-Heisenberg group, or through warping, and even certain\nfractals, all with approximation error decaying exponentially in the number of\nneurons. We also prove that in the approximation of sufficiently smooth\nfunctions finite-width deep networks require strictly smaller connectivity than\nfinite-depth wide networks. \n\n"}
{"id": "1806.01619", "contents": "Title: BOCK : Bayesian Optimization with Cylindrical Kernels Abstract: A major challenge in Bayesian Optimization is the boundary issue (Swersky,\n2017) where an algorithm spends too many evaluations near the boundary of its\nsearch space. In this paper, we propose BOCK, Bayesian Optimization with\nCylindrical Kernels, whose basic idea is to transform the ball geometry of the\nsearch space using a cylindrical transformation. Because of the transformed\ngeometry, the Gaussian Process-based surrogate model spends less budget\nsearching near the boundary, while concentrating its efforts relatively more\nnear the center of the search region, where we expect the solution to be\nlocated. We evaluate BOCK extensively, showing that it is not only more\naccurate and efficient, but it also scales successfully to problems with a\ndimensionality as high as 500. We show that the better accuracy and scalability\nof BOCK even allows optimizing modestly sized neural network layers, as well as\nneural network hyperparameters. \n\n"}
{"id": "1806.01844", "contents": "Title: SBAF: A New Activation Function for Artificial Neural Net based\n  Habitability Classification Abstract: We explore the efficacy of using a novel activation function in Artificial\nNeural Networks (ANN) in characterizing exoplanets into different classes. We\ncall this Saha-Bora Activation Function (SBAF) as the motivation is derived\nfrom long standing understanding of using advanced calculus in modeling\nhabitability score of Exoplanets. The function is demonstrated to possess nice\nanalytical properties and doesn't seem to suffer from local oscillation\nproblems. The manuscript presents the analytical properties of the activation\nfunction and the architecture implemented on the function. Keywords:\nAstroinformatics, Machine Learning, Exoplanets, ANN, Activation Function. \n\n"}
{"id": "1806.01879", "contents": "Title: An explicit analysis of the entropic penalty in linear programming Abstract: Solving linear programs by using entropic penalization has recently attracted\nnew interest in the optimization community, since this strategy forms the basis\nfor the fastest-known algorithms for the optimal transport problem, with many\napplications in modern large-scale machine learning. Crucial to these\napplications has been an analysis of how quickly solutions to the penalized\nprogram approach true optima to the original linear program. More than 20 years\nago, Cominetti and San Mart\\'in showed that this convergence is exponentially\nfast; however, their proof is asymptotic and does not give any indication of\nhow accurately the entropic program approximates the original program for any\nparticular choice of the penalization parameter. We close this long-standing\ngap in the literature regarding entropic penalization by giving a new proof of\nthe exponential convergence, valid for any linear program. Our proof is\nnon-asymptotic, yields explicit constants, and has the virtue of being\nextremely simple. We provide matching lower bounds and show that the entropic\napproach does not lead to a near-linear time approximation scheme for the\nlinear assignment problem. \n\n"}
{"id": "1806.02078", "contents": "Title: Convolutional Sequence to Sequence Non-intrusive Load Monitoring Abstract: A convolutional sequence to sequence non-intrusive load monitoring model is\nproposed in this paper. Gated linear unit convolutional layers are used to\nextract information from the sequences of aggregate electricity consumption.\nResidual blocks are also introduced to refine the output of the neural network.\nThe partially overlapped output sequences of the network are averaged to\nproduce the final output of the model. We apply the proposed model to the REDD\ndataset and compare it with the convolutional sequence to point model in the\nliterature. Results show that the proposed model is able to give satisfactory\ndisaggregation performance for appliances with varied characteristics. \n\n"}
{"id": "1806.02511", "contents": "Title: Exact Low Tubal Rank Tensor Recovery from Gaussian Measurements Abstract: The recent proposed Tensor Nuclear Norm (TNN) [Lu et al., 2016; 2018a] is an\ninteresting convex penalty induced by the tensor SVD [Kilmer and Martin, 2011].\nIt plays a similar role as the matrix nuclear norm which is the convex\nsurrogate of the matrix rank. Considering that the TNN based Tensor Robust PCA\n[Lu et al., 2018a] is an elegant extension of Robust PCA with a similar tight\nrecovery bound, it is natural to solve other low rank tensor recovery problems\nextended from the matrix cases. However, the extensions and proofs are\ngenerally tedious. The general atomic norm provides a unified view of\nlow-complexity structures induced norms, e.g., the $\\ell_1$-norm and nuclear\nnorm. The sharp estimates of the required number of generic measurements for\nexact recovery based on the atomic norm are known in the literature. In this\nwork, with a careful choice of the atomic set, we prove that TNN is a special\natomic norm. Then by computing the Gaussian width of certain cone which is\nnecessary for the sharp estimate, we achieve a simple bound for guaranteed low\ntubal rank tensor recovery from Gaussian measurements. Specifically, we show\nthat by solving a TNN minimization problem, the underlying tensor of size\n$n_1\\times n_2\\times n_3$ with tubal rank $r$ can be exactly recovered when the\ngiven number of Gaussian measurements is $O(r(n_1+n_2-r)n_3)$. It is order\noptimal when comparing with the degrees of freedom $r(n_1+n_2-r)n_3$. Beyond\nthe Gaussian mapping, we also give the recovery guarantee of tensor completion\nbased on the uniform random mapping by TNN minimization. Numerical experiments\nverify our theoretical results. \n\n"}
{"id": "1806.02617", "contents": "Title: Asynchronous Stochastic Quasi-Newton MCMC for Non-Convex Optimization Abstract: Recent studies have illustrated that stochastic gradient Markov Chain Monte\nCarlo techniques have a strong potential in non-convex optimization, where\nlocal and global convergence guarantees can be shown under certain conditions.\nBy building up on this recent theory, in this study, we develop an\nasynchronous-parallel stochastic L-BFGS algorithm for non-convex optimization.\nThe proposed algorithm is suitable for both distributed and shared-memory\nsettings. We provide formal theoretical analysis and show that the proposed\nmethod achieves an ergodic convergence rate of ${\\cal O}(1/\\sqrt{N})$ ($N$\nbeing the total number of iterations) and it can achieve a linear speedup under\ncertain conditions. We perform several experiments on both synthetic and real\ndatasets. The results support our theory and show that the proposed algorithm\nprovides a significant speedup over the recently proposed synchronous\ndistributed L-BFGS algorithm. \n\n"}
{"id": "1806.03143", "contents": "Title: Black Box FDR Abstract: Analyzing large-scale, multi-experiment studies requires scientists to test\neach experimental outcome for statistical significance and then assess the\nresults as a whole. We present Black Box FDR (BB-FDR), an empirical-Bayes\nmethod for analyzing multi-experiment studies when many covariates are gathered\nper experiment. BB-FDR learns a series of black box predictive models to boost\npower and control the false discovery rate (FDR) at two stages of study\nanalysis. In Stage 1, it uses a deep neural network prior to report which\nexperiments yielded significant outcomes. In Stage 2, a separate black box\nmodel of each covariate is used to select features that have significant\npredictive power across all experiments. In benchmarks, BB-FDR outperforms\ncompeting state-of-the-art methods in both stages of analysis. We apply BB-FDR\nto two real studies on cancer drug efficacy. For both studies, BB-FDR increases\nthe proportion of significant outcomes discovered and selects variables that\nreveal key genomic drivers of drug sensitivity and resistance in cancer. \n\n"}
{"id": "1806.03198", "contents": "Title: Spreading vectors for similarity search Abstract: Discretizing multi-dimensional data distributions is a fundamental step of\nmodern indexing methods. State-of-the-art techniques learn parameters of\nquantizers on training data for optimal performance, thus adapting quantizers\nto the data. In this work, we propose to reverse this paradigm and adapt the\ndata to the quantizer: we train a neural net which last layer forms a fixed\nparameter-free quantizer, such as pre-defined points of a hyper-sphere. As a\nproxy objective, we design and train a neural network that favors uniformity in\nthe spherical latent space, while preserving the neighborhood structure after\nthe mapping. We propose a new regularizer derived from the Kozachenko--Leonenko\ndifferential entropy estimator to enforce uniformity and combine it with a\nlocality-aware triplet loss. Experiments show that our end-to-end approach\noutperforms most learned quantization methods, and is competitive with the\nstate of the art on widely adopted benchmarks. Furthermore, we show that\ntraining without the quantization step results in almost no difference in\naccuracy, but yields a generic catalyzer that can be applied with any\nsubsequent quantizer. \n\n"}
{"id": "1806.03287", "contents": "Title: Slalom: Fast, Verifiable and Private Execution of Neural Networks in\n  Trusted Hardware Abstract: As Machine Learning (ML) gets applied to security-critical or sensitive\ndomains, there is a growing need for integrity and privacy for outsourced ML\ncomputations. A pragmatic solution comes from Trusted Execution Environments\n(TEEs), which use hardware and software protections to isolate sensitive\ncomputations from the untrusted software stack. However, these isolation\nguarantees come at a price in performance, compared to untrusted alternatives.\nThis paper initiates the study of high performance execution of Deep Neural\nNetworks (DNNs) in TEEs by efficiently partitioning DNN computations between\ntrusted and untrusted devices. Building upon an efficient outsourcing scheme\nfor matrix multiplication, we propose Slalom, a framework that securely\ndelegates execution of all linear layers in a DNN from a TEE (e.g., Intel SGX\nor Sanctum) to a faster, yet untrusted, co-located processor. We evaluate\nSlalom by running DNNs in an Intel SGX enclave, which selectively delegates\nwork to an untrusted GPU. For canonical DNNs (VGG16, MobileNet and ResNet\nvariants) we obtain 6x to 20x increases in throughput for verifiable inference,\nand 4x to 11x for verifiable and private inference. \n\n"}
{"id": "1806.03664", "contents": "Title: Conditional Noise-Contrastive Estimation of Unnormalised Models Abstract: Many parametric statistical models are not properly normalised and only\nspecified up to an intractable partition function, which renders parameter\nestimation difficult. Examples of unnormalised models are Gibbs distributions,\nMarkov random fields, and neural network models in unsupervised deep learning.\nIn previous work, the estimation principle called noise-contrastive estimation\n(NCE) was introduced where unnormalised models are estimated by learning to\ndistinguish between data and auxiliary noise. An open question is how to best\nchoose the auxiliary noise distribution. We here propose a new method that\naddresses this issue. The proposed method shares with NCE the idea of\nformulating density estimation as a supervised learning problem but in contrast\nto NCE, the proposed method leverages the observed data when generating noise\nsamples. The noise can thus be generated in a semi-automated manner. We first\npresent the underlying theory of the new method, show that score matching\nemerges as a limiting case, validate the method on continuous and discrete\nvalued synthetic data, and show that we can expect an improved performance\ncompared to NCE when the data lie in a lower-dimensional manifold. Then we\ndemonstrate its applicability in unsupervised deep learning by estimating a\nfour-layer neural image model. \n\n"}
{"id": "1806.04522", "contents": "Title: Meta-Learning for Stochastic Gradient MCMC Abstract: Stochastic gradient Markov chain Monte Carlo (SG-MCMC) has become\nincreasingly popular for simulating posterior samples in large-scale Bayesian\nmodeling. However, existing SG-MCMC schemes are not tailored to any specific\nprobabilistic model, even a simple modification of the underlying dynamical\nsystem requires significant physical intuition. This paper presents the first\nmeta-learning algorithm that allows automated design for the underlying\ncontinuous dynamics of an SG-MCMC sampler. The learned sampler generalizes\nHamiltonian dynamics with state-dependent drift and diffusion, enabling fast\ntraversal and efficient exploration of neural network energy landscapes.\nExperiments validate the proposed approach on both Bayesian fully connected\nneural network and Bayesian recurrent neural network tasks, showing that the\nlearned sampler out-performs generic, hand-designed SG-MCMC algorithms, and\ngeneralizes to different datasets and larger architectures. \n\n"}
{"id": "1806.05355", "contents": "Title: Scalable Neural Network Compression and Pruning Using Hard Clustering\n  and L1 Regularization Abstract: We propose a simple and easy to implement neural network compression\nalgorithm that achieves results competitive with more complicated\nstate-of-the-art methods. The key idea is to modify the original optimization\nproblem by adding K independent Gaussian priors (corresponding to the k-means\nobjective) over the network parameters to achieve parameter quantization, as\nwell as an L1 penalty to achieve pruning. Unlike many existing\nquantization-based methods, our method uses hard clustering assignments of\nnetwork parameters, which adds minimal change or overhead to standard network\ntraining. We also demonstrate experimentally that tying neural network\nparameters provides less gain in generalization performance than changing\nnetwork architecture and connectivity patterns entirely. \n\n"}
{"id": "1806.05490", "contents": "Title: Inference in Deep Gaussian Processes using Stochastic Gradient\n  Hamiltonian Monte Carlo Abstract: Deep Gaussian Processes (DGPs) are hierarchical generalizations of Gaussian\nProcesses that combine well calibrated uncertainty estimates with the high\nflexibility of multilayer models. One of the biggest challenges with these\nmodels is that exact inference is intractable. The current state-of-the-art\ninference method, Variational Inference (VI), employs a Gaussian approximation\nto the posterior distribution. This can be a potentially poor unimodal\napproximation of the generally multimodal posterior. In this work, we provide\nevidence for the non-Gaussian nature of the posterior and we apply the\nStochastic Gradient Hamiltonian Monte Carlo method to generate samples. To\nefficiently optimize the hyperparameters, we introduce the Moving Window MCEM\nalgorithm. This results in significantly better predictions at a lower\ncomputational cost than its VI counterpart. Thus our method establishes a new\nstate-of-the-art for inference in DGPs. \n\n"}
{"id": "1806.05791", "contents": "Title: Monaural source enhancement maximizing source-to-distortion ratio via\n  automatic differentiation Abstract: Recently, deep neural network (DNN) has made a breakthrough in monaural\nsource enhancement. Through a training step by using a large amount of data,\nDNN estimates a mapping between mixed signals and clean signals. At this time,\nwe use an objective function that numerically expresses the quality of a\nmapping by DNN. In the conventional methods, L1 norm, L2 norm, and\nItakura-Saito divergence are often used as objective functions. Recently, an\nobjective function based on short-time objective intelligibility (STOI) has\nalso been proposed. However, these functions only indicate similarity between\nthe clean signal and the estimated signal by DNN. In other words, they do not\nshow the quality of noise reduction or source enhancement. Motivated by the\nfact, this paper adopts signal-to-distortion ratio (SDR) as the objective\nfunction. Since SDR virtually shows signal-to-noise ratio (SNR), maximizing SDR\nsolves the above problem. The experimental results revealed that the proposed\nmethod achieved better performance than the conventional methods. \n\n"}
{"id": "1806.05797", "contents": "Title: Polyhedra Circuits and Their Applications Abstract: We introduce polyhedra circuits. Each polyhedra circuit characterizes a\ngeometric region in $\\mathbb{R}^d$. They can be applied to represent a rich\nclass of geometric objects, which include all polyhedra and the union of a\nfinite number of polyhedra. They can be used to approximate a large class of\n$d$-dimensional manifolds in $\\mathbb{R}^d$. Barvinok developed polynomial time\nalgorithms to compute the volume of a rational polyhedra, and to count the\nnumber of lattice points in a rational polyhedra in a fixed dimensional space\n$\\mathbb{R}^d$ with a fix $d$. Define $T_V(d,\\, n)$ be the polynomial time in\n$n$ to compute the volume of one rational polyhedra, $T_L(d,\\, n)$ be the\npolynomial time in $n$ to count the number of lattice points in one rational\npolyhedra with $d$ be a fixed dimensional number, $T_I(d,\\, n)$ be the\npolynomial time in $n$ to solve integer linear programming time with $d$ be the\nfixed dimensional number, where $n$ is the total number of linear inequalities\nfrom input polyhedra. We develop algorithms to count the number of lattice\npoints in the geometric region determined by a polyhedra circuit in\n$O\\left(nd\\cdot r_d(n)\\cdot T_V(d,\\, n)\\right)$ time and to compute the volume\nof the geometric region determined by a polyhedra circuit in $O\\left(n\\cdot\nr_d(n)\\cdot T_I(d,\\, n)+r_d(n)T_L(d,\\, n)\\right)$ time, where $n$ is the number\nof input linear inequalities, $d$ is number of variables and $r_d(n)$ be the\nmaximal number of regions that $n$ linear inequalities with $d$ variables\npartition $\\mathbb{R}^d$. \n\n"}
{"id": "1806.05865", "contents": "Title: Data-Efficient Design Exploration through Surrogate-Assisted\n  Illumination Abstract: Design optimization techniques are often used at the beginning of the design\nprocess to explore the space of possible designs. In these domains illumination\nalgorithms, such as MAP-Elites, are promising alternatives to classic\noptimization algorithms because they produce diverse, high-quality solutions in\na single run, instead of only a single near-optimal solution. Unfortunately,\nthese algorithms currently require a large number of function evaluations,\nlimiting their applicability. In this article we introduce a new illumination\nalgorithm, Surrogate-Assisted Illumination (SAIL), that leverages surrogate\nmodeling techniques to create a map of the design space according to\nuser-defined features while minimizing the number of fitness evaluations. On a\n2-dimensional airfoil optimization problem SAIL produces hundreds of diverse\nbut high-performing designs with several orders of magnitude fewer evaluations\nthan MAP-Elites or CMA-ES. We demonstrate that SAIL is also capable of\nproducing maps of high-performing designs in realistic 3-dimensional\naerodynamic tasks with an accurate flow simulation. Data-efficient design\nexploration with SAIL can help designers understand what is possible, beyond\nwhat is optimal, by considering more than pure objective-based optimization. \n\n"}
{"id": "1806.06176", "contents": "Title: Learning Factorized Multimodal Representations Abstract: Learning multimodal representations is a fundamentally complex research\nproblem due to the presence of multiple heterogeneous sources of information.\nAlthough the presence of multiple modalities provides additional valuable\ninformation, there are two key challenges to address when learning from\nmultimodal data: 1) models must learn the complex intra-modal and cross-modal\ninteractions for prediction and 2) models must be robust to unexpected missing\nor noisy modalities during testing. In this paper, we propose to optimize for a\njoint generative-discriminative objective across multimodal data and labels. We\nintroduce a model that factorizes representations into two sets of independent\nfactors: multimodal discriminative and modality-specific generative factors.\nMultimodal discriminative factors are shared across all modalities and contain\njoint multimodal features required for discriminative tasks such as sentiment\nprediction. Modality-specific generative factors are unique for each modality\nand contain the information required for generating data. Experimental results\nshow that our model is able to learn meaningful multimodal representations that\nachieve state-of-the-art or competitive performance on six multimodal datasets.\nOur model demonstrates flexible generative capabilities by conditioning on\nindependent factors and can reconstruct missing modalities without\nsignificantly impacting performance. Lastly, we interpret our factorized\nrepresentations to understand the interactions that influence multimodal\nlearning. \n\n"}
{"id": "1806.06323", "contents": "Title: Approximate Submodular Functions and Performance Guarantees Abstract: We consider the problem of maximizing non-negative non-decreasing set\nfunctions. Although most of the recent work focus on exploiting submodularity,\nit turns out that several objectives we encounter in practice are not\nsubmodular. Nonetheless, often we leverage the greedy algorithms used in\nsubmodular functions to determine a solution to the non-submodular functions.\nHereafter, we propose to address the original problem by \\emph{approximating}\nthe non-submodular function and analyze the incurred error, as well as the\nperformance trade-offs. To quantify the approximation error, we introduce a\nnovel concept of $\\delta$-approximation of a function, which we used to define\nthe space of submodular functions that lie within an approximation error. We\nprovide necessary conditions on the existence of such $\\delta$-approximation\nfunctions, which might not be unique. Consequently, we characterize this\nsubspace which we refer to as \\emph{region of submodularity}. Furthermore,\nsubmodular functions are known to lead to different sub-optimality guarantees,\nso we generalize those dependencies upon a $\\delta$-approximation into the\nnotion of \\emph{greedy curvature}. Finally, we used this latter notion to\nsimplify some of the existing results and efficiently (i.e., linear complexity)\ndetermine tightened bounds on the sub-optimality guarantees using objective\nfunctions commonly used in practical setups and validate them using real data. \n\n"}
{"id": "1806.06415", "contents": "Title: Feature Learning and Classification in Neuroimaging: Predicting\n  Cognitive Impairment from Magnetic Resonance Imaging Abstract: Due to the rapid innovation of technology and the desire to find and employ\nbiomarkers for neurodegenerative disease, high-dimensional data classification\nproblems are routinely encountered in neuroimaging studies. To avoid\nover-fitting and to explore relationships between disease and potential\nbiomarkers, feature learning and selection plays an important role in\nclassifier construction and is an important area in machine learning. In this\narticle, we review several important feature learning and selection techniques\nincluding lasso-based methods, PCA, the two-sample t-test, and stacked\nauto-encoders. We compare these approaches using a numerical study involving\nthe prediction of Alzheimer's disease from Magnetic Resonance Imaging. \n\n"}
{"id": "1806.06430", "contents": "Title: Subspace Embedding and Linear Regression with Orlicz Norm Abstract: We consider a generalization of the classic linear regression problem to the\ncase when the loss is an Orlicz norm. An Orlicz norm is parameterized by a\nnon-negative convex function $G:\\mathbb{R}_+\\rightarrow\\mathbb{R}_+$ with\n$G(0)=0$: the Orlicz norm of a vector $x\\in\\mathbb{R}^n$ is defined as $\n\\|x\\|_G=\\inf\\left\\{\\alpha>0\\large\\mid\\sum_{i=1}^n G(|x_i|/\\alpha)\\leq\n1\\right\\}. $ We consider the cases where the function $G(\\cdot)$ grows\nsubquadratically. Our main result is based on a new oblivious embedding which\nembeds the column space of a given matrix $A\\in\\mathbb{R}^{n\\times d}$ with\nOrlicz norm into a lower dimensional space with $\\ell_2$ norm. Specifically, we\nshow how to efficiently find an embedding matrix $S\\in\\mathbb{R}^{m\\times\nn},m<n$ such that $\\forall x\\in\\mathbb{R}^{d},\\Omega(1/(d\\log n)) \\cdot\n\\|Ax\\|_G\\leq \\|SAx\\|_2\\leq O(d^2\\log n) \\cdot \\|Ax\\|_G.$ By applying this\nsubspace embedding technique, we show an approximation algorithm for the\nregression problem $\\min_{x\\in\\mathbb{R}^d} \\|Ax-b\\|_G$, up to a $O(d\\log^2 n)$\nfactor. As a further application of our techniques, we show how to also use\nthem to improve on the algorithm for the $\\ell_p$ low rank matrix approximation\nproblem for $1\\leq p<2$. \n\n"}
{"id": "1806.07137", "contents": "Title: Large-Scale Stochastic Sampling from the Probability Simplex Abstract: Stochastic gradient Markov chain Monte Carlo (SGMCMC) has become a popular\nmethod for scalable Bayesian inference. These methods are based on sampling a\ndiscrete-time approximation to a continuous time process, such as the Langevin\ndiffusion. When applied to distributions defined on a constrained space the\ntime-discretization error can dominate when we are near the boundary of the\nspace. We demonstrate that because of this, current SGMCMC methods for the\nsimplex struggle with sparse simplex spaces; when many of the components are\nclose to zero. Unfortunately, many popular large-scale Bayesian models, such as\nnetwork or topic models, require inference on sparse simplex spaces. To avoid\nthe biases caused by this discretization error, we propose the stochastic\nCox-Ingersoll-Ross process (SCIR), which removes all discretization error and\nwe prove that samples from the SCIR process are asymptotically unbiased. We\ndiscuss how this idea can be extended to target other constrained spaces. Use\nof the SCIR process within a SGMCMC algorithm is shown to give substantially\nbetter performance for a topic model and a Dirichlet process mixture model than\nexisting SGMCMC approaches. \n\n"}
{"id": "1806.07492", "contents": "Title: On the Learning of Deep Local Features for Robust Face Spoofing\n  Detection Abstract: Biometrics emerged as a robust solution for security systems. However, given\nthe dissemination of biometric applications, criminals are developing\ntechniques to circumvent them by simulating physical or behavioral traits of\nlegal users (spoofing attacks). Despite face being a promising characteristic\ndue to its universality, acceptability and presence of cameras almost\neverywhere, face recognition systems are extremely vulnerable to such frauds\nsince they can be easily fooled with common printed facial photographs.\nState-of-the-art approaches, based on Convolutional Neural Networks (CNNs),\npresent good results in face spoofing detection. However, these methods do not\nconsider the importance of learning deep local features from each facial\nregion, even though it is known from face recognition that each facial region\npresents different visual aspects, which can also be exploited for face\nspoofing detection. In this work we propose a novel CNN architecture trained in\ntwo steps for such task. Initially, each part of the neural network learns\nfeatures from a given facial region. Afterwards, the whole model is fine-tuned\non the whole facial images. Results show that such pre-training step allows the\nCNN to learn different local spoofing cues, improving the performance and the\nconvergence speed of the final model, outperforming the state-of-the-art\napproaches. \n\n"}
{"id": "1806.07956", "contents": "Title: Reconstructing networks with unknown and heterogeneous errors Abstract: The vast majority of network datasets contains errors and omissions, although\nthis is rarely incorporated in traditional network analysis. Recently, an\nincreasing effort has been made to fill this methodological gap by developing\nnetwork reconstruction approaches based on Bayesian inference. These\napproaches, however, rely on assumptions of uniform error rates and on direct\nestimations of the existence of each edge via repeated measurements, something\nthat is currently unavailable for the majority of network data. Here we develop\na Bayesian reconstruction approach that lifts these limitations by not only\nallowing for heterogeneous errors, but also for single edge measurements\nwithout direct error estimates. Our approach works by coupling the inference\napproach with structured generative network models, which enable the\ncorrelations between edges to be used as reliable uncertainty estimates.\nAlthough our approach is general, we focus on the stochastic block model as the\nbasic generative process, from which efficient nonparametric inference can be\nperformed, and yields a principled method to infer hierarchical community\nstructure from noisy data. We demonstrate the efficacy of our approach with a\nvariety of empirical and artificial networks. \n\n"}
{"id": "1806.08047", "contents": "Title: Flexible Neural Representation for Physics Prediction Abstract: Humans have a remarkable capacity to understand the physical dynamics of\nobjects in their environment, flexibly capturing complex structures and\ninteractions at multiple levels of detail. Inspired by this ability, we propose\na hierarchical particle-based object representation that covers a wide variety\nof types of three-dimensional objects, including both arbitrary rigid\ngeometrical shapes and deformable materials. We then describe the Hierarchical\nRelation Network (HRN), an end-to-end differentiable neural network based on\nhierarchical graph convolution, that learns to predict physical dynamics in\nthis representation. Compared to other neural network baselines, the HRN\naccurately handles complex collisions and nonrigid deformations, generating\nplausible dynamics predictions at long time scales in novel settings, and\nscaling to large scene configurations. These results demonstrate an\narchitecture with the potential to form the basis of next-generation physics\npredictors for use in computer vision, robotics, and quantitative cognitive\nscience. \n\n"}
{"id": "1806.08267", "contents": "Title: Complex Gated Recurrent Neural Networks Abstract: Complex numbers have long been favoured for digital signal processing, yet\ncomplex representations rarely appear in deep learning architectures. RNNs,\nwidely used to process time series and sequence information, could greatly\nbenefit from complex representations. We present a novel complex gated\nrecurrent cell, which is a hybrid cell combining complex-valued and\nnorm-preserving state transitions with a gating mechanism. The resulting RNN\nexhibits excellent stability and convergence properties and performs\ncompetitively on the synthetic memory and adding task, as well as on the\nreal-world tasks of human motion prediction. \n\n"}
{"id": "1806.09046", "contents": "Title: Disease Classification in Metagenomics with 2D Embeddings and Deep\n  Learning Abstract: Deep learning (DL) techniques have shown unprecedented success when applied\nto images, waveforms, and text. Generally, when the sample size ($N$) is much\nbigger than the number of features ($d$), DL often outperforms other machine\nlearning (ML) techniques, often through the use of Convolutional Neural\nNetworks (CNNs). However, in many bioinformatics fields (including\nmetagenomics), we encounter the opposite situation where $d$ is significantly\ngreater than $N$. In these situations, applying DL techniques would lead to\nsevere overfitting.\n  Here we aim to improve classification of various diseases with metagenomic\ndata through the use of CNNs. For this we proposed to represent metagenomic\ndata as images. The proposed Met2Img approach relies on taxonomic and t-SNE\nembeddings to transform abundance data into \"synthetic images\".\n  We applied our approach to twelve benchmark data sets including more than\n1400 metagenomic samples. Our results show significant improvements over the\nstate-of-the-art algorithms (Random Forest (RF), Support Vector Machine (SVM)).\nWe observe that the integration of phylogenetic information alongside abundance\ndata improves classification. The proposed approach is not only important in\nclassification setting but also allows to visualize complex metagenomic data.\nThe Met2Img is implemented in Python. \n\n"}
{"id": "1806.09077", "contents": "Title: Beyond Backprop: Online Alternating Minimization with Auxiliary\n  Variables Abstract: Despite significant recent advances in deep neural networks, training them\nremains a challenge due to the highly non-convex nature of the objective\nfunction. State-of-the-art methods rely on error backpropagation, which suffers\nfrom several well-known issues, such as vanishing and exploding gradients,\ninability to handle non-differentiable nonlinearities and to parallelize\nweight-updates across layers, and biological implausibility. These limitations\ncontinue to motivate exploration of alternative training algorithms, including\nseveral recently proposed auxiliary-variable methods which break the complex\nnested objective function into local subproblems. However, those techniques are\nmainly offline (batch), which limits their applicability to extremely large\ndatasets, as well as to online, continual or reinforcement learning. The main\ncontribution of our work is a novel online (stochastic/mini-batch) alternating\nminimization (AM) approach for training deep neural networks, together with the\nfirst theoretical convergence guarantees for AM in stochastic settings and\npromising empirical results on a variety of architectures and datasets. \n\n"}
{"id": "1806.10410", "contents": "Title: Dynamic Assortment Selection under the Nested Logit Models Abstract: We study a stylized dynamic assortment planning problem during a selling\nseason of finite length $T$. At each time period, the seller offers an arriving\ncustomer an assortment of substitutable products and the customer makes the\npurchase among offered products according to a discrete choice model. The goal\nof the seller is to maximize the expected revenue, or equivalently, to minimize\nthe worst-case expected regret. One key challenge is that utilities of products\nare unknown to the seller and need to be learned. Although the dynamic\nassortment planning problem has received increasing attention in revenue\nmanagement, most existing work is based on the multinomial logit choice models\n(MNL). In this paper, we study the problem of dynamic assortment planning under\na more general choice model -- the nested logit model, which models\nhierarchical choice behavior and is ``the most widely used member of the GEV\n(generalized extreme value) family''. By leveraging the revenue-ordered\nstructure of the optimal assortment within each nest, we develop a novel upper\nconfidence bound (UCB) policy with an aggregated estimation scheme. Our policy\nsimultaneously learns customers' choice behavior and makes dynamic decisions on\nassortments based on the current knowledge. It achieves the accumulated regret\nat the order of $\\tilde{O}(\\sqrt{MNT})$, where $M$ is the number of nests and\n$N$ is the number of products in each nest. We further provide a lower bound\nresult of $\\Omega(\\sqrt{MT})$, which shows the near optimality of the upper\nbound when $T$ is much larger than $M$ and $N$. When the number of items per\nnest $N$ is large, we further provide a discretization heuristic for better\nperformance of our algorithm. Numerical results are presented to demonstrate\nthe empirical performance of our proposed algorithms. \n\n"}
{"id": "1806.11096", "contents": "Title: Recovering Trees with Convex Clustering Abstract: Convex clustering refers, for given $\\left\\{x_1, \\dots, x_n\\right\\} \\subset\n\\mathbb{R}^p$, to the minimization of \\begin{eqnarray*} u(\\gamma) & = &\n\\underset{u_1, \\dots, u_n }{\\arg\\min}\\;\\sum_{i=1}^{n}{\\lVert x_i - u_i\n\\rVert^2} + \\gamma \\sum_{i,j=1}^{n}{w_{ij} \\lVert u_i - u_j\\rVert},\\\\\n\\end{eqnarray*} where $w_{ij} \\geq 0$ is an affinity that quantifies the\nsimilarity between $x_i$ and $x_j$. We prove that if the affinities $w_{ij}$\nreflect a tree structure in the $\\left\\{x_1, \\dots, x_n\\right\\}$, then the\nconvex clustering solution path reconstructs the tree exactly. The main\ntechnical ingredient implies the following combinatorial byproduct: for every\nset $\\left\\{x_1, \\dots, x_n \\right\\} \\subset \\mathbb{R}^p$ of $n \\geq 2$\ndistinct points, there exist at least $n/6$ points with the property that for\nany of these points $x$ there is a unit vector $v \\in \\mathbb{R}^p$ such that,\nwhen viewed from $x$, `most' points lie in the direction $v$ \\begin{eqnarray*}\n\\frac{1}{n-1}\\sum_{i=1 \\atop x_i \\neq x}^{n}{ \\left\\langle \\frac{x_i -\nx}{\\lVert x_i - x \\rVert}, v \\right\\rangle} & \\geq & \\frac{1}{4}.\n\\end{eqnarray*} \n\n"}
{"id": "1807.00804", "contents": "Title: Classifying Data with Local Hamiltonians Abstract: The goal of this work is to define a notion of a quantum neural network to\nclassify data, which exploits the low energy spectrum of a local Hamiltonian.\nAs a concrete application, we build a binary classifier, train it on some\nactual data and then test its performance on a simple classification task. More\nspecifically, we use Microsoft's quantum simulator, Liquid, to construct local\nHamiltonians that can encode trained classifier functions in their ground\nspace, and which can be probed by measuring the overlap with test states\ncorresponding to the data to be classified. To obtain such a classifier\nHamiltonian, we further propose a training scheme based on quantum annealing\nwhich is completely closed-off to the environment and which does not depend on\nexternal measurements until the very end, avoiding unnecessary decoherence\nduring the annealing procedure. For a network of size n, the trained network\ncan be stored as a list of O(n) coupling strengths. We address the question of\nwhich interactions are most suitable for a given classification task, and\ndevelop a qubit-saving optimization for the training procedure on a simulated\nannealing device. Furthermore, a small neural network to classify colors into\nred vs. blue is trained and tested, and benchmarked against the annealing\nparameters. \n\n"}
{"id": "1807.00942", "contents": "Title: Stochastic Layer-Wise Precision in Deep Neural Networks Abstract: Low precision weights, activations, and gradients have been proposed as a way\nto improve the computational efficiency and memory footprint of deep neural\nnetworks. Recently, low precision networks have even shown to be more robust to\nadversarial attacks. However, typical implementations of low precision DNNs use\nuniform precision across all layers of the network. In this work, we explore\nwhether a heterogeneous allocation of precision across a network leads to\nimproved performance, and introduce a learning scheme where a DNN\nstochastically explores multiple precision configurations through learning.\nThis permits a network to learn an optimal precision configuration. We show on\nconvolutional neural networks trained on MNIST and ILSVRC12 that even though\nthese nets learn a uniform or near-uniform allocation strategy respectively,\nstochastic precision leads to a favourable regularization effect improving\ngeneralization. \n\n"}
{"id": "1807.01422", "contents": "Title: Diagonal Discriminant Analysis with Feature Selection for High\n  Dimensional Data Abstract: We introduce a new method of performing high dimensional discriminant\nanalysis, which we call multiDA. We achieve this by constructing a hybrid model\nthat seamlessly integrates a multiclass diagonal discriminant analysis model\nand feature selection components. Our feature selection component naturally\nsimplifies to weights which are simple functions of likelihood ratio statistics\nallowing natural comparisons with traditional hypothesis testing methods. We\nprovide heuristic arguments suggesting desirable asymptotic properties of our\nalgorithm with regards to feature selection. We compare our method with several\nother approaches, showing marked improvements in regard to prediction accuracy,\ninterpretability of chosen features, and algorithm run time. We demonstrate\nsuch strengths of our model by showing strong classification performance on\npublicly available high dimensional datasets, as well as through multiple\nsimulation studies. We make an R package available implementing our approach. \n\n"}
{"id": "1807.01514", "contents": "Title: Generating Synthetic but Plausible Healthcare Record Datasets Abstract: Generating datasets that \"look like\" given real ones is an interesting tasks\nfor healthcare applications of ML and many other fields of science and\nengineering. In this paper we propose a new method of general application to\nbinary datasets based on a method for learning the parameters of a latent\nvariable moment that we have previously used for clustering patient datasets.\nWe compare our method with a recent proposal (MedGan) based on generative\nadversarial methods and find that the synthetic datasets we generate are\nglobally more realistic in at least two senses: real and synthetic instances\nare harder to tell apart by Random Forests, and the MMD statistic. The most\nlikely explanation is that our method does not suffer from the \"mode collapse\"\nwhich is an admitted problem of GANs. Additionally, the generative models we\ngenerate are easy to interpret, unlike the rather obscure GANs. Our experiments\nare performed on two patient datasets containing ICD-9 diagnostic codes: the\npublicly available MIMIC-III dataset and a dataset containing admissions for\ncongestive heart failure during 7 years at Hospital de Sant Pau in Barcelona. \n\n"}
{"id": "1807.01784", "contents": "Title: Program Language Translation Using a Grammar-Driven Tree-to-Tree Model Abstract: The task of translating between programming languages differs from the\nchallenge of translating natural languages in that programming languages are\ndesigned with a far more rigid set of structural and grammatical rules.\nPrevious work has used a tree-to-tree encoder/decoder model to take advantage\nof the inherent tree structure of programs during translation. Neural decoders,\nhowever, by default do not exploit known grammar rules of the target language.\nIn this paper, we describe a tree decoder that leverages knowledge of a\nlanguage's grammar rules to exclusively generate syntactically correct\nprograms. We find that this grammar-based tree-to-tree model outperforms the\nstate of the art tree-to-tree model in translating between two programming\nlanguages on a previously used synthetic task. \n\n"}
{"id": "1807.01961", "contents": "Title: A Boo(n) for Evaluating Architecture Performance Abstract: We point out important problems with the common practice of using the best\nsingle model performance for comparing deep learning architectures, and we\npropose a method that corrects these flaws. Each time a model is trained, one\ngets a different result due to random factors in the training process, which\ninclude random parameter initialization and random data shuffling. Reporting\nthe best single model performance does not appropriately address this\nstochasticity. We propose a normalized expected best-out-of-$n$ performance\n($\\text{Boo}_n$) as a way to correct these problems. \n\n"}
{"id": "1807.02290", "contents": "Title: Differentially Private Online Submodular Optimization Abstract: In this paper we develop the first algorithms for online submodular\nminimization that preserve differential privacy under full information feedback\nand bandit feedback. A sequence of $T$ submodular functions over a collection\nof $n$ elements arrive online, and at each timestep the algorithm must choose a\nsubset of $[n]$ before seeing the function. The algorithm incurs a cost equal\nto the function evaluated on the chosen set, and seeks to choose a sequence of\nsets that achieves low expected regret.\n  Our first result is in the full information setting, where the algorithm can\nobserve the entire function after making its decision at each timestep. We give\nan algorithm in this setting that is $\\epsilon$-differentially private and\nachieves expected regret\n$\\tilde{O}\\left(\\frac{n^{3/2}\\sqrt{T}}{\\epsilon}\\right)$. This algorithm works\nby relaxing submodular function to a convex function using the Lovasz\nextension, and then simulating an algorithm for differentially private online\nconvex optimization.\n  Our second result is in the bandit setting, where the algorithm can only see\nthe cost incurred by its chosen set, and does not have access to the entire\nfunction. This setting is significantly more challenging because the algorithm\ndoes not receive enough information to compute the Lovasz extension or its\nsubgradients. Instead, we construct an unbiased estimate using a single-point\nestimation, and then simulate private online convex optimization using this\nestimate. Our algorithm using bandit feedback is $\\epsilon$-differentially\nprivate and achieves expected regret\n$\\tilde{O}\\left(\\frac{n^{3/2}T^{3/4}}{\\epsilon}\\right)$. \n\n"}
{"id": "1807.03299", "contents": "Title: Optimization of a SSP's Header Bidding Strategy using Thompson Sampling Abstract: Over the last decade, digital media (web or app publishers) generalized the\nuse of real time ad auctions to sell their ad spaces. Multiple auction\nplatforms, also called Supply-Side Platforms (SSP), were created. Because of\nthis multiplicity, publishers started to create competition between SSPs. In\nthis setting, there are two successive auctions: a second price auction in each\nSSP and a secondary, first price auction, called header bidding auction,\nbetween SSPs.In this paper, we consider an SSP competing with other SSPs for ad\nspaces. The SSP acts as an intermediary between an advertiser wanting to buy ad\nspaces and a web publisher wanting to sell its ad spaces, and needs to define a\nbidding strategy to be able to deliver to the advertisers as many ads as\npossible while spending as little as possible. The revenue optimization of this\nSSP can be written as a contextual bandit problem, where the context consists\nof the information available about the ad opportunity, such as properties of\nthe internet user or of the ad placement.Using classical multi-armed bandit\nstrategies (such as the original versions of UCB and EXP3) is inefficient in\nthis setting and yields a low convergence speed, as the arms are very\ncorrelated. In this paper we design and experiment a version of the Thompson\nSampling algorithm that easily takes this correlation into account. We combine\nthis bayesian algorithm with a particle filter, which permits to handle\nnon-stationarity by sequentially estimating the distribution of the highest bid\nto beat in order to win an auction. We apply this methodology on two real\nauction datasets, and show that it significantly outperforms more classical\napproaches.The strategy defined in this paper is being developed to be deployed\non thousands of publishers worldwide. \n\n"}
{"id": "1807.03545", "contents": "Title: Dual optimization for convex constrained objectives without the\n  gradient-Lipschitz assumption Abstract: The minimization of convex objectives coming from linear supervised learning\nproblems, such as penalized generalized linear models, can be formulated as\nfinite sums of convex functions. For such problems, a large set of stochastic\nfirst-order solvers based on the idea of variance reduction are available and\ncombine both computational efficiency and sound theoretical guarantees (linear\nconvergence rates). Such rates are obtained under both gradient-Lipschitz and\nstrong convexity assumptions. Motivated by learning problems that do not meet\nthe gradient-Lipschitz assumption, such as linear Poisson regression, we work\nunder another smoothness assumption, and obtain a linear convergence rate for a\nshifted version of Stochastic Dual Coordinate Ascent (SDCA) that improves the\ncurrent state-of-the-art. Our motivation for considering a solver working on\nthe Fenchel-dual problem comes from the fact that such objectives include many\nlinear constraints, that are easier to deal with in the dual. Our approach and\ntheoretical findings are validated on several datasets, for Poisson regression\nand another objective coming from the negative log-likelihood of the Hawkes\nprocess, which is a family of models which proves extremely useful for the\nmodeling of information propagation in social networks and causality inference. \n\n"}
{"id": "1807.03653", "contents": "Title: Handling Incomplete Heterogeneous Data using VAEs Abstract: Variational autoencoders (VAEs), as well as other generative models, have\nbeen shown to be efficient and accurate for capturing the latent structure of\nvast amounts of complex high-dimensional data. However, existing VAEs can still\nnot directly handle data that are heterogenous (mixed continuous and discrete)\nor incomplete (with missing data at random), which is indeed common in\nreal-world applications. In this paper, we propose a general framework to\ndesign VAEs suitable for fitting incomplete heterogenous data. The proposed\nHI-VAE includes likelihood models for real-valued, positive real valued,\ninterval, categorical, ordinal and count data, and allows accurate estimation\n(and potentially imputation) of missing data. Furthermore, HI-VAE presents\ncompetitive predictive performance in supervised tasks, outperforming\nsupervised models when trained on incomplete data. \n\n"}
{"id": "1807.04098", "contents": "Title: A Recurrent Neural Network Survival Model: Predicting Web User Return\n  Time Abstract: The size of a website's active user base directly affects its value. Thus, it\nis important to monitor and influence a user's likelihood to return to a site.\nEssential to this is predicting when a user will return. Current state of the\nart approaches to solve this problem come in two flavors: (1) Recurrent Neural\nNetwork (RNN) based solutions and (2) survival analysis methods. We observe\nthat both techniques are severely limited when applied to this problem.\nSurvival models can only incorporate aggregate representations of users instead\nof automatically learning a representation directly from a raw time series of\nuser actions. RNNs can automatically learn features, but can not be directly\ntrained with examples of non-returning users who have no target value for their\nreturn time. We develop a novel RNN survival model that removes the limitations\nof the state of the art methods. We demonstrate that this model can\nsuccessfully be applied to return time prediction on a large e-commerce dataset\nwith a superior ability to discriminate between returning and non-returning\nusers than either method applied in isolation. \n\n"}
{"id": "1807.04193", "contents": "Title: Distributed Variational Representation Learning Abstract: The problem of distributed representation learning is one in which multiple\nsources of information $X_1,\\ldots,X_K$ are processed separately so as to learn\nas much information as possible about some ground truth $Y$. We investigate\nthis problem from information-theoretic grounds, through a generalization of\nTishby's centralized Information Bottleneck (IB) method to the distributed\nsetting. Specifically, $K$ encoders, $K \\geq 2$, compress their observations\n$X_1,\\ldots,X_K$ separately in a manner such that, collectively, the produced\nrepresentations preserve as much information as possible about $Y$. We study\nboth discrete memoryless (DM) and memoryless vector Gaussian data models. For\nthe discrete model, we establish a single-letter characterization of the\noptimal tradeoff between complexity (or rate) and relevance (or information)\nfor a class of memoryless sources (the observations $X_1,\\ldots,X_K$ being\nconditionally independent given $Y$). For the vector Gaussian model, we provide\nan explicit characterization of the optimal complexity-relevance tradeoff.\nFurthermore, we develop a variational bound on the complexity-relevance\ntradeoff which generalizes the evidence lower bound (ELBO) to the distributed\nsetting. We also provide two algorithms that allow to compute this bound: i) a\nBlahut-Arimoto type iterative algorithm which enables to compute optimal\ncomplexity-relevance encoding mappings by iterating over a set of\nself-consistent equations, and ii) a variational inference type algorithm in\nwhich the encoding mappings are parametrized by neural networks and the bound\napproximated by Markov sampling and optimized with stochastic gradient descent.\nNumerical results on synthetic and real datasets are provided to support the\nefficiency of the approaches and algorithms developed in this paper. \n\n"}
{"id": "1807.04739", "contents": "Title: When deep learning meets security Abstract: Deep learning is an emerging research field that has proven its effectiveness\ntowards deploying more efficient intelligent systems. Security, on the other\nhand, is one of the most essential issues in modern communication systems.\nRecently many papers have shown that using deep learning models can achieve\npromising results when applied to the security domain. In this work, we provide\nan overview for the recent studies that apply deep learning techniques to the\nfield of security. \n\n"}
{"id": "1807.05748", "contents": "Title: Learning Stochastic Differential Equations With Gaussian Processes\n  Without Gradient Matching Abstract: We introduce a novel paradigm for learning non-parametric drift and diffusion\nfunctions for stochastic differential equation (SDE). The proposed model learns\nto simulate path distributions that match observations with non-uniform time\nincrements and arbitrary sparseness, which is in contrast with gradient\nmatching that does not optimize simulated responses. We formulate sensitivity\nequations for learning and demonstrate that our general stochastic distribution\noptimisation leads to robust and efficient learning of SDE systems. \n\n"}
{"id": "1807.05935", "contents": "Title: Siamese Survival Analysis with Competing Risks Abstract: Survival analysis in the presence of multiple possible adverse events, i.e.,\ncompeting risks, is a pervasive problem in many industries (healthcare,\nfinance, etc.). Since only one event is typically observed, the incidence of an\nevent of interest is often obscured by other related competing events. This\nnonidentifiability, or inability to estimate true cause-specific survival\ncurves from empirical data, further complicates competing risk survival\nanalysis. We introduce Siamese Survival Prognosis Network (SSPN), a novel deep\nlearning architecture for estimating personalized risk scores in the presence\nof competing risks. SSPN circumvents the nonidentifiability problem by avoiding\nthe estimation of cause-specific survival curves and instead determines\npairwise concordant time-dependent risks, where longer event times are assigned\nlower risks. Furthermore, SSPN is able to directly optimize an approximation to\nthe C-discrimination index, rather than relying on well-known metrics which are\nunable to capture the unique requirements of survival analysis with competing\nrisks. \n\n"}
{"id": "1807.06481", "contents": "Title: Dynamic Sampling from Graphical Models Abstract: In this paper, we study the problem of sampling from a graphical model when\nthe model itself is changing dynamically with time. This problem derives its\ninterest from a variety of inference, learning, and sampling settings in\nmachine learning, computer vision, statistical physics, and theoretical\ncomputer science. While the problem of sampling from a static graphical model\nhas received considerable attention, theoretical works for its dynamic variants\nhave been largely lacking. The main contribution of this paper is an algorithm\nthat can sample dynamically from a broad class of graphical models over\ndiscrete random variables. Our algorithm is parallel and Las Vegas: it knows\nwhen to stop and it outputs samples from the exact distribution. We also\nprovide sufficient conditions under which this algorithm runs in time\nproportional to the size of the update, on general graphical models as well as\nwell-studied specific spin systems. In particular we obtain, for the Ising\nmodel (ferromagnetic or anti-ferromagnetic) and for the hardcore model the\nfirst dynamic sampling algorithms that can handle both edge and vertex updates\n(addition, deletion, change of functions), both efficient within regimes that\nare close to the respective uniqueness regimes, beyond which, even for the\nstatic and approximate sampling, no local algorithms were known or the problem\nitself is intractable. Our dynamic sampling algorithm relies on a local\nresampling algorithm and a new \"equilibrium\" property that is shown to be\nsatisfied by our algorithm at each step, and enables us to prove its\ncorrectness. This equilibrium property is robust enough to guarantee the\ncorrectness of our algorithm, helps us improve bounds on fast convergence on\nspecific models, and should be of independent interest. \n\n"}
{"id": "1807.06577", "contents": "Title: Fisher zeros and correlation decay in the Ising model Abstract: We study the complex zeros of the partition function of the Ising model,\nviewed as a polynomial in the \"interaction parameter\"; these are known as\nFisher zeros in light of their introduction by Fisher in 1965. While the zeros\nof the partition function as a polynomial in the \"field\" parameter have been\nextensively studied since the classical work of Lee and Yang, comparatively\nlittle is known about Fisher zeros for general graphs. Our main result shows\nthat the zero-field Ising model has no Fisher zeros in a complex neighborhood\nof the entire region of parameters where the model exhibits correlation decay.\nIn addition to shedding light on Fisher zeros themselves, this result also\nestablishes a formal connection between two distinct notions of phase\ntransition for the Ising model: the absence of complex zeros (analyticity of\nthe free energy, or the logarithm of the partition function) and decay of\ncorrelations with distance. We also discuss the consequences of our result for\nefficient deterministic approximation of the partition function. Our proof\nrelies heavily on algorithmic techniques, notably Weitz's self-avoiding walk\ntree, and as such belongs to a growing body of work that uses algorithmic\nmethods to resolve classical questions in statistical physics. \n\n"}
{"id": "1807.06686", "contents": "Title: Supermodular Locality Sensitive Hashes Abstract: In this work, we show deep connections between Locality Sensitive Hashability\nand submodular analysis. We show that the LSHablility of the most commonly\nanalyzed set similarities is in one-to-one correspondance with the\nsupermodularity of these similarities when taken with respect to the symmetric\ndifference of their arguments. We find that the supermodularity of equivalent\nLSHable similarities can be dependent on the set encoding. While monotonicity\nand supermodularity does not imply the metric condition necessary for\nsupermodularity, this condition is guaranteed for the more restricted class of\nsupermodular Hamming similarities that we introduce. We show moreover that LSH\npreserving transformations are also supermodular-preserving, yielding a way to\ngenerate families of similarities both LSHable and supermodular. Finally, we\nshow that even the more restricted family of cardinality-based supermodular\nHamming similarities presents promising aspects for the study of the link\nbetween LSHability and supermodularity. We hope that the several bridges that\nwe introduce between LSHability and supermodularity paves the way to a better\nunderstanding both of supermodular analysis and LSHability, notably in the\ncontext of large-scale supermodular optimization. \n\n"}
{"id": "1807.06957", "contents": "Title: Discrete linear-complexity reinforcement learning in continuous action\n  spaces for Q-learning algorithms Abstract: In this article, we sketch an algorithm that extends the Q-learning\nalgorithms to the continuous action space domain. Our method is based on the\ndiscretization of the action space. Despite the commonly used discretization\nmethods, our method does not increase the discretized problem dimensionality\nexponentially. We will show that our proposed method is linear in complexity\nwhen the discretization is employed. The variant of the Q-learning algorithm\npresented in this work, labeled as Finite Step Q-Learning (FSQ), can be\ndeployed to both shallow and deep neural network architectures. \n\n"}
{"id": "1807.07013", "contents": "Title: Learning Sums of Independent Random Variables with Sparse Collective\n  Support Abstract: We study the learnability of sums of independent integer random variables\ngiven a bound on the size of the union of their supports. For $\\mathcal{A}\n\\subset \\mathbf{Z}_{+}$, a sum of independent random variables with collective\nsupport $\\mathcal{A}$} (called an $\\mathcal{A}$-sum in this paper) is a\ndistribution $\\mathbf{S} = \\mathbf{X}_1 + \\cdots + \\mathbf{X}_N$ where the\n$\\mathbf{X}_i$'s are mutually independent (but not necessarily identically\ndistributed) integer random variables with $\\cup_i \\mathsf{supp}(\\mathbf{X}_i)\n\\subseteq \\mathcal{A}.$ We give two main algorithmic results for learning such\ndistributions:\n  1. For the case $| \\mathcal{A} | = 3$, we give an algorithm for learning\n$\\mathcal{A}$-sums to accuracy $\\epsilon$ that uses $\\mathsf{poly}(1/\\epsilon)$\nsamples and runs in time $\\mathsf{poly}(1/\\epsilon)$, independent of $N$ and of\nthe elements of $\\mathcal{A}$.\n  2. For an arbitrary constant $k \\geq 4$, if $\\mathcal{A} = \\{ a_1,...,a_k\\}$\nwith $0 \\leq a_1 < ... < a_k$, we give an algorithm that uses\n$\\mathsf{poly}(1/\\epsilon) \\cdot \\log \\log a_k$ samples (independent of $N$)\nand runs in time $\\mathsf{poly}(1/\\epsilon, \\log a_k).$\n  We prove an essentially matching lower bound: if $|\\mathcal{A}| = 4$, then\nany algorithm must use $\\Omega(\\log \\log a_4) $ samples even for learning to\nconstant accuracy. We also give similar-in-spirit (but quantitatively very\ndifferent) algorithmic results, and essentially matching lower bounds, for the\ncase in which $\\mathcal{A}$ is not known to the learner. \n\n"}
{"id": "1807.07965", "contents": "Title: An Efficient End-to-End Neural Model for Handwritten Text Recognition Abstract: Offline handwritten text recognition from images is an important problem for\nenterprises attempting to digitize large volumes of handmarked scanned\ndocuments/reports. Deep recurrent models such as Multi-dimensional LSTMs have\nbeen shown to yield superior performance over traditional Hidden Markov Model\nbased approaches that suffer from the Markov assumption and therefore lack the\nrepresentational power of RNNs. In this paper we introduce a novel approach\nthat combines a deep convolutional network with a recurrent Encoder-Decoder\nnetwork to map an image to a sequence of characters corresponding to the text\npresent in the image. The entire model is trained end-to-end using Focal Loss,\nan improvement over the standard Cross-Entropy loss that addresses the class\nimbalance problem, inherent to text recognition. To enhance the decoding\ncapacity of the model, Beam Search algorithm is employed which searches for the\nbest sequence out of a set of hypotheses based on a joint distribution of\nindividual characters. Our model takes as input a downsampled version of the\noriginal image thereby making it both computationally and memory efficient. The\nexperimental results were benchmarked against two publicly available datasets,\nIAM and RIMES. We surpass the state-of-the-art word level accuracy on the\nevaluation set of both datasets by 3.5% & 1.1%, respectively. \n\n"}
{"id": "1807.08518", "contents": "Title: Implementing Neural Turing Machines Abstract: Neural Turing Machines (NTMs) are an instance of Memory Augmented Neural\nNetworks, a new class of recurrent neural networks which decouple computation\nfrom memory by introducing an external memory unit. NTMs have demonstrated\nsuperior performance over Long Short-Term Memory Cells in several sequence\nlearning tasks. A number of open source implementations of NTMs exist but are\nunstable during training and/or fail to replicate the reported performance of\nNTMs. This paper presents the details of our successful implementation of a\nNTM. Our implementation learns to solve three sequential learning tasks from\nthe original NTM paper. We find that the choice of memory contents\ninitialization scheme is crucial in successfully implementing a NTM. Networks\nwith memory contents initialized to small constant values converge on average 2\ntimes faster than the next best memory contents initialization scheme. \n\n"}
{"id": "1807.09405", "contents": "Title: Efficient algorithms for robust submodular maximization under matroid\n  constraints Abstract: In this work, we consider robust submodular maximization with matroid\nconstraints. We give an efficient bi-criteria approximation algorithm that\noutputs a small family of feasible sets whose union has (nearly) optimal\nobjective value. This algorithm theoretically performs less function calls than\nprevious works at cost of adding more elements to the final solution. We also\nprovide significant implementation improvements showing that our algorithm\noutperforms the algorithms in the existing literature. We finally assess the\nperformance of our contributions in three real-world applications. \n\n"}
{"id": "1807.09870", "contents": "Title: Do Better ImageNet Models Transfer Better... for Image Recommendation? Abstract: Visual embeddings from Convolutional Neural Networks (CNN) trained on the\nImageNet dataset for the ILSVRC challenge have shown consistently good\nperformance for transfer learning and are widely used in several tasks,\nincluding image recommendation. However, some important questions have not yet\nbeen answered in order to use these embeddings for a larger scope of\nrecommendation domains: a) Do CNNs that perform better in ImageNet are also\nbetter for transfer learning in content-based image recommendation?, b) Does\nfine-tuning help to improve performance? and c) Which is the best way to\nperform the fine-tuning?\n  In this paper we compare several CNN models pre-trained with ImageNet to\nevaluate their transfer learning performance to an artwork image recommendation\ntask. Our results indicate that models with better performance in the ImageNet\nchallenge do not always imply better transfer learning for recommendation tasks\n(e.g. NASNet vs. ResNet). Our results also show that fine-tuning can be helpful\neven with a small dataset, but not every fine-tuning works. Our results can\ninform other researchers and practitioners on how to train their CNNs for\nbetter transfer learning towards image recommendation systems. \n\n"}
{"id": "1807.09958", "contents": "Title: Rethinking the Form of Latent States in Image Captioning Abstract: RNNs and their variants have been widely adopted for image captioning. In\nRNNs, the production of a caption is driven by a sequence of latent states.\nExisting captioning models usually represent latent states as vectors, taking\nthis practice for granted. We rethink this choice and study an alternative\nformulation, namely using two-dimensional maps to encode latent states. This is\nmotivated by the curiosity about a question: how the spatial structures in the\nlatent states affect the resultant captions? Our study on MSCOCO and Flickr30k\nleads to two significant observations. First, the formulation with 2D states is\ngenerally more effective in captioning, consistently achieving higher\nperformance with comparable parameter sizes. Second, 2D states preserve spatial\nlocality. Taking advantage of this, we visually reveal the internal dynamics in\nthe process of caption generation, as well as the connections between input\nvisual domain and output linguistic domain. \n\n"}
{"id": "1807.10300", "contents": "Title: Discovering physical concepts with neural networks Abstract: Despite the success of neural networks at solving concrete physics problems,\ntheir use as a general-purpose tool for scientific discovery is still in its\ninfancy. Here, we approach this problem by modelling a neural network\narchitecture after the human physical reasoning process, which has similarities\nto representation learning. This allows us to make progress towards the\nlong-term goal of machine-assisted scientific discovery from experimental data\nwithout making prior assumptions about the system. We apply this method to toy\nexamples and show that the network finds the physically relevant parameters,\nexploits conservation laws to make predictions, and can help to gain conceptual\ninsights, e.g. Copernicus' conclusion that the solar system is heliocentric. \n\n"}
{"id": "1807.10335", "contents": "Title: A general metric for identifying adversarial images Abstract: It is well known that a determined adversary can fool a neural network by\nmaking imperceptible adversarial perturbations to an image. Recent studies have\nshown that these perturbations can be detected even without information about\nthe neural network if the strategy taken by the adversary is known beforehand.\nUnfortunately, these studies suffer from the generalization limitation -- the\ndetection method has to be recalibrated every time the adversary changes his\nstrategy. In this study, we attempt to overcome the generalization limitation\nby deriving a metric which reliably identifies adversarial images even when the\napproach taken by the adversary is unknown. Our metric leverages key\ndifferences between the spectra of clean and adversarial images when an image\nis treated as a matrix. Our metric is able to detect adversarial images across\ndifferent datasets and attack strategies without any additional re-calibration.\nIn addition, our approach provides geometric insights into several unanswered\nquestions about adversarial perturbations. \n\n"}
{"id": "1807.10399", "contents": "Title: Applications of Common Entropy for Causal Inference Abstract: We study the problem of discovering the simplest latent variable that can\nmake two observed discrete variables conditionally independent. The minimum\nentropy required for such a latent is known as common entropy in information\ntheory. We extend this notion to Renyi common entropy by minimizing the Renyi\nentropy of the latent variable. To efficiently compute common entropy, we\npropose an iterative algorithm that can be used to discover the trade-off\nbetween the entropy of the latent variable and the conditional mutual\ninformation of the observed variables. We show two applications of common\nentropy in causal inference: First, under the assumption that there are no\nlow-entropy mediators, it can be used to distinguish causation from spurious\ncorrelation among almost all joint distributions on simple causal graphs with\ntwo observed variables. Second, common entropy can be used to improve\nconstraint-based methods such as PC or FCI algorithms in the small-sample\nregime, where these methods are known to struggle. We propose a modification to\nthese constraint-based methods to assess if a separating set found by these\nalgorithms is valid using common entropy. We finally evaluate our algorithms on\nsynthetic and real data to establish their performance. \n\n"}
{"id": "1807.10707", "contents": "Title: End-to-end Deep Learning from Raw Sensor Data: Atrial Fibrillation\n  Detection using Wearables Abstract: We present a convolutional-recurrent neural network architecture with long\nshort-term memory for real-time processing and classification of digital sensor\ndata. The network implicitly performs typical signal processing tasks such as\nfiltering and peak detection, and learns time-resolved embeddings of the input\nsignal. We use a prototype multi-sensor wearable device to collect over 180h of\nphotoplethysmography (PPG) data sampled at 20Hz, of which 36h are during atrial\nfibrillation (AFib). We use end-to-end learning to achieve state-of-the-art\nresults in detecting AFib from raw PPG data. For classification labels output\nevery 0.8s, we demonstrate an area under ROC curve of 0.9999, with false\npositive and false negative rates both below $2\\times 10^{-3}$. This\nconstitutes a significant improvement on previous results utilising\ndomain-specific feature engineering, such as heart rate extraction, and brings\nlarge-scale atrial fibrillation screenings within imminent reach. \n\n"}
{"id": "1807.11440", "contents": "Title: Comparator Networks Abstract: The objective of this work is set-based verification, e.g. to decide if two\nsets of images of a face are of the same person or not. The traditional\napproach to this problem is to learn to generate a feature vector per image,\naggregate them into one vector to represent the set, and then compute the\ncosine similarity between sets. Instead, we design a neural network\narchitecture that can directly learn set-wise verification. Our contributions\nare: (i) We propose a Deep Comparator Network (DCN) that can ingest a pair of\nsets (each may contain a variable number of images) as inputs, and compute a\nsimilarity between the pair--this involves attending to multiple discriminative\nlocal regions (landmarks), and comparing local descriptors between pairs of\nfaces; (ii) To encourage high-quality representations for each set, internal\ncompetition is introduced for recalibration based on the landmark score; (iii)\nInspired by image retrieval, a novel hard sample mining regime is proposed to\ncontrol the sampling process, such that the DCN is complementary to the\nstandard image classification models. Evaluations on the IARPA Janus face\nrecognition benchmarks show that the comparator networks outperform the\nprevious state-of-the-art results by a large margin. \n\n"}
{"id": "1807.11626", "contents": "Title: MnasNet: Platform-Aware Neural Architecture Search for Mobile Abstract: Designing convolutional neural networks (CNN) for mobile devices is\nchallenging because mobile models need to be small and fast, yet still\naccurate. Although significant efforts have been dedicated to design and\nimprove mobile CNNs on all dimensions, it is very difficult to manually balance\nthese trade-offs when there are so many architectural possibilities to\nconsider. In this paper, we propose an automated mobile neural architecture\nsearch (MNAS) approach, which explicitly incorporate model latency into the\nmain objective so that the search can identify a model that achieves a good\ntrade-off between accuracy and latency. Unlike previous work, where latency is\nconsidered via another, often inaccurate proxy (e.g., FLOPS), our approach\ndirectly measures real-world inference latency by executing the model on mobile\nphones. To further strike the right balance between flexibility and search\nspace size, we propose a novel factorized hierarchical search space that\nencourages layer diversity throughout the network. Experimental results show\nthat our approach consistently outperforms state-of-the-art mobile CNN models\nacross multiple vision tasks. On the ImageNet classification task, our MnasNet\nachieves 75.2% top-1 accuracy with 78ms latency on a Pixel phone, which is 1.8x\nfaster than MobileNetV2 [29] with 0.5% higher accuracy and 2.3x faster than\nNASNet [36] with 1.2% higher accuracy. Our MnasNet also achieves better mAP\nquality than MobileNets for COCO object detection. Code is at\nhttps://github.com/tensorflow/tpu/tree/master/models/official/mnasnet \n\n"}
{"id": "1807.11824", "contents": "Title: t-SNE-CUDA: GPU-Accelerated t-SNE and its Applications to Modern Data Abstract: Modern datasets and models are notoriously difficult to explore and analyze\ndue to their inherent high dimensionality and massive numbers of samples.\nExisting visualization methods which employ dimensionality reduction to two or\nthree dimensions are often inefficient and/or ineffective for these datasets.\nThis paper introduces t-SNE-CUDA, a GPU-accelerated implementation of\nt-distributed Symmetric Neighbor Embedding (t-SNE) for visualizing datasets and\nmodels. t-SNE-CUDA significantly outperforms current implementations with\n50-700x speedups on the CIFAR-10 and MNIST datasets. These speedups enable, for\nthe first time, visualization of the neural network activations on the entire\nImageNet dataset - a feat that was previously computationally intractable. We\nalso demonstrate visualization performance in the NLP domain by visualizing the\nGloVe embedding vectors. From these visualizations, we can draw interesting\nconclusions about using the L2 metric in these embedding spaces. t-SNE-CUDA is\npublicly available athttps://github.com/CannyLab/tsne-cuda \n\n"}
{"id": "1808.01181", "contents": "Title: Robust Spectral Filtering and Anomaly Detection Abstract: We consider a setting, where the output of a linear dynamical system (LDS)\nis, with an unknown but fixed probability, replaced by noise. There, we present\na robust method for the prediction of the outputs of the LDS and identification\nof the samples of noise, and prove guarantees on its statistical performance.\nOne application lies in anomaly detection: the samples of noise, unlikely to\nhave been generated by the dynamics, can be flagged to operators of the system\nfor further study. \n\n"}
{"id": "1808.02078", "contents": "Title: Unbiased Implicit Variational Inference Abstract: We develop unbiased implicit variational inference (UIVI), a method that\nexpands the applicability of variational inference by defining an expressive\nvariational family. UIVI considers an implicit variational distribution\nobtained in a hierarchical manner using a simple reparameterizable distribution\nwhose variational parameters are defined by arbitrarily flexible deep neural\nnetworks. Unlike previous works, UIVI directly optimizes the evidence lower\nbound (ELBO) rather than an approximation to the ELBO. We demonstrate UIVI on\nseveral models, including Bayesian multinomial logistic regression and\nvariational autoencoders, and show that UIVI achieves both tighter ELBO and\nbetter predictive performance than existing approaches at a similar\ncomputational cost. \n\n"}
{"id": "1808.02174", "contents": "Title: Test without Trust: Optimal Locally Private Distribution Testing Abstract: We study the problem of distribution testing when the samples can only be\naccessed using a locally differentially private mechanism and focus on two\nrepresentative testing questions of identity (goodness-of-fit) and independence\ntesting for discrete distributions. We are concerned with two settings: First,\nwhen we insist on using an already deployed, general-purpose locally\ndifferentially private mechanism such as the popular RAPPOR or the recently\nintroduced Hadamard Response for collecting data, and must build our tests\nbased on the data collected via this mechanism; and second, when no such\nrestriction is imposed, and we can design a bespoke mechanism specifically for\ntesting. For the latter purpose, we introduce the Randomized Aggregated Private\nTesting Optimal Response (RAPTOR) mechanism which is remarkably simple and\nrequires only one bit of communication per sample.\n  We propose tests based on these mechanisms and analyze their sample\ncomplexities. Each proposed test can be implemented efficiently. In each case\n(barring one), we complement our performance bounds for algorithms with\ninformation-theoretic lower bounds and establish sample optimality of our\nproposed algorithm. A peculiar feature that emerges is that our sample-optimal\nalgorithm based on RAPTOR uses public-coins, and any test based on RAPPOR or\nHadamard Response, which are both private-coin mechanisms, requires\nsignificantly more samples. \n\n"}
{"id": "1808.03001", "contents": "Title: Compressed Sensing Using Binary Matrices of Nearly Optimal Dimensions Abstract: In this paper, we study the problem of compressed sensing using binary\nmeasurement matrices and $\\ell_1$-norm minimization (basis pursuit) as the\nrecovery algorithm. We derive new upper and lower bounds on the number of\nmeasurements to achieve robust sparse recovery with binary matrices. We\nestablish sufficient conditions for a column-regular binary matrix to satisfy\nthe robust null space property (RNSP) and show that the associated sufficient\nconditions % sparsity bounds for robust sparse recovery obtained using the RNSP\nare better by a factor of $(3 \\sqrt{3})/2 \\approx 2.6$ compared to the\nsufficient conditions obtained using the restricted isometry property (RIP).\nNext we derive universal \\textit{lower} bounds on the number of measurements\nthat any binary matrix needs to have in order to satisfy the weaker sufficient\ncondition based on the RNSP and show that bipartite graphs of girth six are\noptimal. Then we display two classes of binary matrices, namely parity check\nmatrices of array codes and Euler squares, which have girth six and are nearly\noptimal in the sense of almost satisfying the lower bound. In principle,\nrandomly generated Gaussian measurement matrices are \"order-optimal\". So we\ncompare the phase transition behavior of the basis pursuit formulation using\nbinary array codes and Gaussian matrices and show that (i) there is essentially\nno difference between the phase transition boundaries in the two cases and (ii)\nthe CPU time of basis pursuit with binary matrices is hundreds of times faster\nthan with Gaussian matrices and the storage requirements are less. Therefore it\nis suggested that binary matrices are a viable alternative to Gaussian matrices\nfor compressed sensing using basis pursuit. \\end{abstract} \n\n"}
{"id": "1808.03030", "contents": "Title: Policy Optimization as Wasserstein Gradient Flows Abstract: Policy optimization is a core component of reinforcement learning (RL), and\nmost existing RL methods directly optimize parameters of a policy based on\nmaximizing the expected total reward, or its surrogate. Though often achieving\nencouraging empirical success, its underlying mathematical principle on {\\em\npolicy-distribution} optimization is unclear. We place policy optimization into\nthe space of probability measures, and interpret it as Wasserstein gradient\nflows. On the probability-measure space, under specified circumstances, policy\noptimization becomes a convex problem in terms of distribution optimization. To\nmake optimization feasible, we develop efficient algorithms by numerically\nsolving the corresponding discrete gradient flows. Our technique is applicable\nto several RL settings, and is related to many state-of-the-art\npolicy-optimization algorithms. Empirical results verify the effectiveness of\nour framework, often obtaining better performance compared to related\nalgorithms. \n\n"}
{"id": "1808.04362", "contents": "Title: A Domain Guided CNN Architecture for Predicting Age from Structural\n  Brain Images Abstract: Given the wide success of convolutional neural networks (CNNs) applied to\nnatural images, researchers have begun to apply them to neuroimaging data. To\ndate, however, exploration of novel CNN architectures tailored to neuroimaging\ndata has been limited. Several recent works fail to leverage the 3D structure\nof the brain, instead treating the brain as a set of independent 2D slices.\nApproaches that do utilize 3D convolutions rely on architectures developed for\nobject recognition tasks in natural 2D images. Such architectures make\nassumptions about the input that may not hold for neuroimaging. For example,\nexisting architectures assume that patterns in the brain exhibit translation\ninvariance. However, a pattern in the brain may have different meaning\ndepending on where in the brain it is located. There is a need to explore novel\narchitectures that are tailored to brain images. We present two simple\nmodifications to existing CNN architectures based on brain image structure.\nApplied to the task of brain age prediction, our network achieves a mean\nabsolute error (MAE) of 1.4 years and trains 30% faster than a CNN baseline\nthat achieves a MAE of 1.6 years. Our results suggest that lessons learned from\ndeveloping models on natural images may not directly transfer to neuroimaging\ntasks. Instead, there remains a large space of unexplored questions regarding\nmodel development in this area, whose answers may differ from conventional\nwisdom. \n\n"}
{"id": "1808.04888", "contents": "Title: Skill Rating for Generative Models Abstract: We explore a new way to evaluate generative models using insights from\nevaluation of competitive games between human players. We show experimentally\nthat tournaments between generators and discriminators provide an effective way\nto evaluate generative models. We introduce two methods for summarizing\ntournament outcomes: tournament win rate and skill rating. Evaluations are\nuseful in different contexts, including monitoring the progress of a single\nmodel as it learns during the training process, and comparing the capabilities\nof two different fully trained models. We show that a tournament consisting of\na single model playing against past and future versions of itself produces a\nuseful measure of training progress. A tournament containing multiple separate\nmodels (using different seeds, hyperparameters, and architectures) provides a\nuseful relative comparison between different trained GANs. Tournament-based\nrating methods are conceptually distinct from numerous previous categories of\napproaches to evaluation of generative models, and have complementary\nadvantages and disadvantages. \n\n"}
{"id": "1808.06394", "contents": "Title: Faster Support Vector Machines Abstract: The time complexity of support vector machines (SVMs) prohibits training on\nhuge data sets with millions of data points. Recently, multilevel approaches to\ntrain SVMs have been developed to allow for time-efficient training on huge\ndata sets. While regular SVMs perform the entire training in one -- time\nconsuming -- optimization step, multilevel SVMs first build a hierarchy of\nproblems decreasing in size that resemble the original problem and then train\nan SVM model for each hierarchy level, benefiting from the solved models of\nprevious levels. We present a faster multilevel support vector machine that\nuses a label propagation algorithm to construct the problem hierarchy.\nExtensive experiments indicate that our approach is up to orders of magnitude\nfaster than the previous fastest algorithm while having comparable\nclassification quality. For example, already one of our sequential solvers is\non average a factor 15 faster than the parallel ThunderSVM algorithm, while\nhaving similar classification quality. \n\n"}
{"id": "1808.06910", "contents": "Title: Scalable Population Synthesis with Deep Generative Modeling Abstract: Population synthesis is concerned with the generation of synthetic yet\nrealistic representations of populations. It is a fundamental problem in the\nmodeling of transport where the synthetic populations of micro-agents represent\na key input to most agent-based models. In this paper, a new methodological\nframework for how to 'grow' pools of micro-agents is presented. The model\nframework adopts a deep generative modeling approach from machine learning\nbased on a Variational Autoencoder (VAE). Compared to the previous population\nsynthesis approaches, including Iterative Proportional Fitting (IPF), Gibbs\nsampling and traditional generative models such as Bayesian Networks or Hidden\nMarkov Models, the proposed method allows fitting the full joint distribution\nfor high dimensions. The proposed methodology is compared with a conventional\nGibbs sampler and a Bayesian Network by using a large-scale Danish trip diary.\nIt is shown that, while these two methods outperform the VAE in the\nlow-dimensional case, they both suffer from scalability issues when the number\nof modeled attributes increases. It is also shown that the Gibbs sampler\nessentially replicates the agents from the original sample when the required\nconditional distributions are estimated as frequency tables. In contrast, the\nVAE allows addressing the problem of sampling zeros by generating agents that\nare virtually different from those in the original data but have similar\nstatistical properties. The presented approach can support agent-based modeling\nat all levels by enabling richer synthetic populations with smaller zones and\nmore detailed individual characteristics. \n\n"}
{"id": "1808.06918", "contents": "Title: On a New Improvement-Based Acquisition Function for Bayesian\n  Optimization Abstract: Bayesian optimization (BO) is a popular algorithm for solving challenging\noptimization tasks. It is designed for problems where the objective function is\nexpensive to evaluate, perhaps not available in exact form, without gradient\ninformation and possibly returning noisy values. Different versions of the\nalgorithm vary in the choice of the acquisition function, which recommends the\npoint to query the objective at next. Initially, researchers focused on\nimprovement-based acquisitions, while recently the attention has shifted to\nmore computationally expensive information-theoretical measures. In this paper\nwe present two major contributions to the literature. First, we propose a new\nimprovement-based acquisition function that recommends query points where the\nimprovement is expected to be high with high confidence. The proposed algorithm\nis evaluated on a large set of benchmark functions from the global optimization\nliterature, where it turns out to perform at least as well as current\nstate-of-the-art acquisition functions, and often better. This suggests that it\nis a powerful default choice for BO. The novel policy is then compared to\nwidely used global optimization solvers in order to confirm that BO methods\nreduce the computational costs of the optimization by keeping the number of\nfunction evaluations small. The second main contribution represents an\napplication to precision medicine, where the interest lies in the estimation of\nparameters of a partial differential equations model of the human pulmonary\nblood circulation system. Once inferred, these parameters can help clinicians\nin diagnosing a patient with pulmonary hypertension without going through the\nstandard invasive procedure of right heart catheterization, which can lead to\nside effects and complications (e.g. severe pain, internal bleeding,\nthrombosis). \n\n"}
{"id": "1808.07217", "contents": "Title: Don't Use Large Mini-Batches, Use Local SGD Abstract: Mini-batch stochastic gradient methods (SGD) are state of the art for\ndistributed training of deep neural networks. Drastic increases in the\nmini-batch sizes have lead to key efficiency and scalability gains in recent\nyears. However, progress faces a major roadblock, as models trained with large\nbatches often do not generalize well, i.e. they do not show good accuracy on\nnew data. As a remedy, we propose a \\emph{post-local} SGD and show that it\nsignificantly improves the generalization performance compared to large-batch\ntraining on standard benchmarks while enjoying the same efficiency\n(time-to-accuracy) and scalability. We further provide an extensive study of\nthe communication efficiency vs. performance trade-offs associated with a host\nof \\emph{local SGD} variants. \n\n"}
{"id": "1808.07573", "contents": "Title: Approximation Trees: Statistical Stability in Model Distillation Abstract: This paper examines the stability of learned explanations for black-box\npredictions via model distillation with decision trees. One approach to\nintelligibility in machine learning is to use an understandable `student' model\nto mimic the output of an accurate `teacher'. Here, we consider the use of\nregression trees as a student model, in which nodes of the tree can be used as\n`explanations' for particular predictions, and the whole structure of the tree\ncan be used as a global representation of the resulting function. However,\nindividual trees are sensitive to the particular data sets used to train them,\nand an interpretation of a student model may be suspect if small changes in the\ntraining data have a large effect on it. In this context, access to outcomes\nfrom a teacher helps to stabilize the greedy splitting strategy by generating a\nmuch larger corpus of training examples than was originally available. We\ndevelop tests to ensure that enough examples are generated at each split so\nthat the same splitting rule would be chosen with high probability were the\ntree to be re trained. Further, we develop a stopping rule to indicate how deep\nthe tree should be built based on recent results on the variability of Random\nForests when these are used as the teacher. We provide concrete examples of\nthese procedures on the CAD-MDD and COMPAS data sets. \n\n"}
{"id": "1808.09551", "contents": "Title: Explaining Character-Aware Neural Networks for Word-Level Prediction: Do\n  They Discover Linguistic Rules? Abstract: Character-level features are currently used in different neural network-based\nnatural language processing algorithms. However, little is known about the\ncharacter-level patterns those models learn. Moreover, models are often\ncompared only quantitatively while a qualitative analysis is missing. In this\npaper, we investigate which character-level patterns neural networks learn and\nif those patterns coincide with manually-defined word segmentations and\nannotations. To that end, we extend the contextual decomposition technique\n(Murdoch et al. 2018) to convolutional neural networks which allows us to\ncompare convolutional neural networks and bidirectional long short-term memory\nnetworks. We evaluate and compare these models for the task of morphological\ntagging on three morphologically different languages and show that these models\nimplicitly discover understandable linguistic rules. Our implementation can be\nfound at https://github.com/FredericGodin/ContextualDecomposition-NLP . \n\n"}
{"id": "1808.09931", "contents": "Title: Level Planarity: Transitivity vs. Even Crossings Abstract: Recently, Fulek et al. have presented Hanani-Tutte results for (radial) level\nplanarity, i.e., a graph is (radial) level planar if it admits a (radial) level\ndrawing where any two (independent) edges cross an even number of times. We\nshow that the 2-Sat formulation of level planarity testing due to Randerath et\nal. is equivalent to the strong Hanani-Tutte theorem for level planarity.\nFurther, we show that this relationship carries over to radial level planarity,\nwhich yields a novel polynomial-time algorithm for testing radial level\nplanarity. \n\n"}
{"id": "1808.10120", "contents": "Title: ExIt-OOS: Towards Learning from Planning in Imperfect Information Games Abstract: The current state of the art in playing many important perfect information\ngames, including Chess and Go, combines planning and deep reinforcement\nlearning with self-play. We extend this approach to imperfect information games\nand present ExIt-OOS, a novel approach to playing imperfect information games\nwithin the Expert Iteration framework and inspired by AlphaZero. We use Online\nOutcome Sampling, an online search algorithm for imperfect information games in\nplace of MCTS. While training online, our neural strategy is used to improve\nthe accuracy of playouts in OOS, allowing a learning and planning feedback loop\nfor imperfect information games. \n\n"}
{"id": "1808.10532", "contents": "Title: Uniform Inference in High-Dimensional Gaussian Graphical Models Abstract: Graphical models have become a very popular tool for representing\ndependencies within a large set of variables and are key for representing\ncausal structures. We provide results for uniform inference on high-dimensional\ngraphical models with the number of target parameters $d$ being possible much\nlarger than sample size. This is in particular important when certain features\nor structures of a causal model should be recovered. Our results highlight how\nin high-dimensional settings graphical models can be estimated and recovered\nwith modern machine learning methods in complex data sets. To construct\nsimultaneous confidence regions on many target parameters, sufficiently fast\nestimation rates of the nuisance functions are crucial. In this context, we\nestablish uniform estimation rates and sparsity guarantees of the square-root\nestimator in a random design under approximate sparsity conditions that might\nbe of independent interest for related problems in high-dimensions. We also\ndemonstrate in a comprehensive simulation study that our procedure has good\nsmall sample properties. \n\n"}
{"id": "1808.10549", "contents": "Title: Fair Algorithms for Learning in Allocation Problems Abstract: Settings such as lending and policing can be modeled by a centralized agent\nallocating a resource (loans or police officers) amongst several groups, in\norder to maximize some objective (loans given that are repaid or criminals that\nare apprehended). Often in such problems fairness is also a concern. A natural\nnotion of fairness, based on general principles of equality of opportunity,\nasks that conditional on an individual being a candidate for the resource, the\nprobability of actually receiving it is approximately independent of the\nindividual's group. In lending this means that equally creditworthy individuals\nin different racial groups have roughly equal chances of receiving a loan. In\npolicing it means that two individuals committing the same crime in different\ndistricts would have roughly equal chances of being arrested.\n  We formalize this fairness notion for allocation problems and investigate its\nalgorithmic consequences. Our main technical results include an efficient\nlearning algorithm that converges to an optimal fair allocation even when the\nfrequency of candidates (creditworthy individuals or criminals) in each group\nis unknown. The algorithm operates in a censored feedback model in which only\nthe number of candidates who received the resource in a given allocation can be\nobserved, rather than the true number of candidates. This models the fact that\nwe do not learn the creditworthiness of individuals we do not give loans to nor\nlearn about crimes committed if the police presence in a district is low.\n  As an application of our framework, we consider the predictive policing\nproblem. The learning algorithm is trained on arrest data gathered from its own\ndeployments on previous days, resulting in a potential feedback loop that our\nalgorithm provably overcomes. We empirically investigate the performance of our\nalgorithm on the Philadelphia Crime Incidents dataset. \n\n"}
{"id": "1809.00082", "contents": "Title: NEU: A Meta-Algorithm for Universal UAP-Invariant Feature Representation Abstract: Effective feature representation is key to the predictive performance of any\nalgorithm. This paper introduces a meta-procedure, called Non-Euclidean\nUpgrading (NEU), which learns feature maps that are expressive enough to embed\nthe universal approximation property (UAP) into most model classes while only\noutputting feature maps that preserve any model class's UAP. We show that NEU\ncan learn any feature map with these two properties if that feature map is\nasymptotically deformable into the identity. We also find that the\nfeature-representations learned by NEU are always submanifolds of the feature\nspace. NEU's properties are derived from a new deep neural model that is\nuniversal amongst all orientation-preserving homeomorphisms on the input space.\nWe derive qualitative and quantitative approximation guarantees for this\narchitecture. We quantify the number of parameters required for this new\narchitecture to memorize any set of input-output pairs while simultaneously\nfixing every point of the input space lying outside some compact set, and we\nquantify the size of this set as a function of our model's depth. Moreover, we\nshow that no deep feed-forward network with commonly used activation function\nhas all these properties. NEU's performance is evaluated against competing\nmachine learning methods on various regression and dimension reduction tasks\nboth with financial and simulated data. \n\n"}
{"id": "1809.00811", "contents": "Title: A Deep Learning Spatiotemporal Prediction Framework for Mobile\n  Crowdsourced Services Abstract: This papers presents a deep learning-based framework to predict crowdsourced\nservice availability spatially and temporally. A novel two-stage prediction\nmodel is introduced based on historical spatio-temporal traces of mobile\ncrowdsourced services. The prediction model first clusters mobile crowdsourced\nservices into regions. The availability prediction of a mobile crowdsourced\nservice at a certain location and time is then formulated as a classification\nproblem. To determine the availability duration of predicted mobile\ncrowdsourced services, we formulate a forecasting task of time series using the\nGramian Angular Field. We validated the effectiveness of the proposed framework\nthrough multiple experiments. \n\n"}
{"id": "1809.00932", "contents": "Title: Faster Balanced Clusterings in High Dimension Abstract: The problem of constrained clustering has attracted significant attention in\nthe past decades. In this paper, we study the balanced $k$-center, $k$-median,\nand $k$-means clustering problems where the size of each cluster is constrained\nby the given lower and upper bounds. The problems are motivated by the\napplications in processing large-scale data in high dimension. Existing methods\noften need to compute complicated matchings (or min cost flows) to satisfy the\nbalance constraint, and thus suffer from high complexities especially in high\ndimension. We develop an effective framework for the three balanced clustering\nproblems to address this issue, and our method is based on a novel spatial\npartition idea in geometry. For the balanced $k$-center clustering, we provide\na $4$-approximation algorithm that improves the existing approximation factors;\nfor the balanced $k$-median and $k$-means clusterings, our algorithms yield\nconstant and $(1+\\epsilon)$-approximation factors with any $\\epsilon>0$. More\nimportantly, our algorithms achieve linear or nearly linear running times when\n$k$ is a constant, and significantly improve the existing ones. Our results can\nbe easily extended to metric balanced clusterings and the running times are\nsub-linear in terms of the complexity of $n$-point metric. \n\n"}
{"id": "1809.02244", "contents": "Title: Learning Optimal Fair Policies Abstract: Systematic discriminatory biases present in our society influence the way\ndata is collected and stored, the way variables are defined, and the way\nscientific findings are put into practice as policy. Automated decision\nprocedures and learning algorithms applied to such data may serve to perpetuate\nexisting injustice or unfairness in our society. In this paper, we consider how\nto make optimal but fair decisions, which \"break the cycle of injustice\" by\ncorrecting for the unfair dependence of both decisions and outcomes on\nsensitive features (e.g., variables that correspond to gender, race,\ndisability, or other protected attributes). We use methods from causal\ninference and constrained optimization to learn optimal policies in a way that\naddresses multiple potential biases which afflict data analysis in sensitive\ncontexts, extending the approach of (Nabi and Shpitser 2018). Our proposal\ncomes equipped with the theoretical guarantee that the chosen fair policy will\ninduce a joint distribution for new instances that satisfies given fairness\nconstraints. We illustrate our approach with both synthetic data and real\ncriminal justice data. \n\n"}
{"id": "1809.02352", "contents": "Title: Multi-Target Prediction: A Unifying View on Problems and Methods Abstract: Multi-target prediction (MTP) is concerned with the simultaneous prediction\nof multiple target variables of diverse type. Due to its enormous application\npotential, it has developed into an active and rapidly expanding research field\nthat combines several subfields of machine learning, including multivariate\nregression, multi-label classification, multi-task learning, dyadic prediction,\nzero-shot learning, network inference, and matrix completion. In this paper, we\npresent a unifying view on MTP problems and methods. First, we formally discuss\ncommonalities and differences between existing MTP problems. To this end, we\nintroduce a general framework that covers the above subfields as special cases.\nAs a second contribution, we provide a structured overview of MTP methods. This\nis accomplished by identifying a number of key properties, which distinguish\nsuch methods and determine their suitability for different types of problems.\nFinally, we also discuss a few challenges for future research. \n\n"}
{"id": "1809.02591", "contents": "Title: Learning Invariances for Policy Generalization Abstract: While recent progress has spawned very powerful machine learning systems,\nthose agents remain extremely specialized and fail to transfer the knowledge\nthey gain to similar yet unseen tasks. In this paper, we study a simple\nreinforcement learning problem and focus on learning policies that encode the\nproper invariances for generalization to different settings. We evaluate three\npotential methods for policy generalization: data augmentation, meta-learning\nand adversarial training. We find our data augmentation method to be effective,\nand study the potential of meta-learning and adversarial learning as\nalternative task-agnostic approaches. \n\n"}
{"id": "1809.02657", "contents": "Title: dyngraph2vec: Capturing Network Dynamics using Dynamic Graph\n  Representation Learning Abstract: Learning graph representations is a fundamental task aimed at capturing\nvarious properties of graphs in vector space. The most recent methods learn\nsuch representations for static networks. However, real world networks evolve\nover time and have varying dynamics. Capturing such evolution is key to\npredicting the properties of unseen networks. To understand how the network\ndynamics affect the prediction performance, we propose an embedding approach\nwhich learns the structure of evolution in dynamic graphs and can predict\nunseen links with higher precision. Our model, dyngraph2vec, learns the\ntemporal transitions in the network using a deep architecture composed of dense\nand recurrent layers. We motivate the need of capturing dynamics for prediction\non a toy data set created using stochastic block models. We then demonstrate\nthe efficacy of dyngraph2vec over existing state-of-the-art methods on two real\nworld data sets. We observe that learning dynamics can improve the quality of\nembedding and yield better performance in link prediction. \n\n"}
{"id": "1809.02670", "contents": "Title: RetGK: Graph Kernels based on Return Probabilities of Random Walks Abstract: Graph-structured data arise in wide applications, such as computer vision,\nbioinformatics, and social networks. Quantifying similarities among graphs is a\nfundamental problem. In this paper, we develop a framework for computing graph\nkernels, based on return probabilities of random walks. The advantages of our\nproposed kernels are that they can effectively exploit various node attributes,\nwhile being scalable to large datasets. We conduct extensive graph\nclassification experiments to evaluate our graph kernels. The experimental\nresults show that our graph kernels significantly outperform existing\nstate-of-the-art approaches in both accuracy and computational efficiency. \n\n"}
{"id": "1809.02882", "contents": "Title: Cost-Sensitive Active Learning for Intracranial Hemorrhage Detection Abstract: Deep learning for clinical applications is subject to stringent performance\nrequirements, which raises a need for large labeled datasets. However, the\nenormous cost of labeling medical data makes this challenging. In this paper,\nwe build a cost-sensitive active learning system for the problem of\nintracranial hemorrhage detection and segmentation on head computed tomography\n(CT). We show that our ensemble method compares favorably with the\nstate-of-the-art, while running faster and using less memory. Moreover, our\nexperiments are done using a substantially larger dataset than earlier papers\non this topic. Since the labeling time could vary tremendously across examples,\nwe model the labeling time and optimize the return on investment. We validate\nthis idea by core-set selection on our large labeled dataset and by growing it\nwith data from the wild. \n\n"}
{"id": "1809.03400", "contents": "Title: A Moral Framework for Understanding of Fair ML through Economic Models\n  of Equality of Opportunity Abstract: We map the recently proposed notions of algorithmic fairness to economic\nmodels of Equality of opportunity (EOP)---an extensively studied ideal of\nfairness in political philosophy. We formally show that through our conceptual\nmapping, many existing definition of algorithmic fairness, such as predictive\nvalue parity and equality of odds, can be interpreted as special cases of EOP.\nIn this respect, our work serves as a unifying moral framework for\nunderstanding existing notions of algorithmic fairness. Most importantly, this\nframework allows us to explicitly spell out the moral assumptions underlying\neach notion of fairness, and interpret recent fairness impossibility results in\na new light. Last but not least and inspired by luck egalitarian models of EOP,\nwe propose a new family of measures for algorithmic fairness. We illustrate our\nproposal empirically and show that employing a measure of algorithmic\n(un)fairness when its underlying moral assumptions are not satisfied, can have\ndevastating consequences for the disadvantaged group's welfare. \n\n"}
{"id": "1809.04400", "contents": "Title: Learning Deep Mixtures of Gaussian Process Experts Using Sum-Product\n  Networks Abstract: While Gaussian processes (GPs) are the method of choice for regression tasks,\nthey also come with practical difficulties, as inference cost scales cubic in\ntime and quadratic in memory. In this paper, we introduce a natural and\nexpressive way to tackle these problems, by incorporating GPs in sum-product\nnetworks (SPNs), a recently proposed tractable probabilistic model allowing\nexact and efficient inference. In particular, by using GPs as leaves of an SPN\nwe obtain a novel flexible prior over functions, which implicitly represents an\nexponentially large mixture of local GPs. Exact and efficient posterior\ninference in this model can be done in a natural interplay of the inference\nmechanisms in GPs and SPNs. Thereby, each GP is -- similarly as in a mixture of\nexperts approach -- responsible only for a subset of data points, which\neffectively reduces inference cost in a divide and conquer fashion. We show\nthat integrating GPs into the SPN framework leads to a promising probabilistic\nregression model which is: (1) computational and memory efficient, (2) allows\nefficient and exact posterior inference, (3) is flexible enough to mix\ndifferent kernel functions, and (4) naturally accounts for non-stationarities\nin time series. In a variate of experiments, we show that the SPN-GP model can\nlearn input dependent parameters and hyper-parameters and is on par with or\noutperforms the traditional GPs as well as state of the art approximations on\nreal-world data. \n\n"}
{"id": "1809.04618", "contents": "Title: Global Convergence of Stochastic Gradient Hamiltonian Monte Carlo for\n  Non-Convex Stochastic Optimization: Non-Asymptotic Performance Bounds and\n  Momentum-Based Acceleration Abstract: Stochastic gradient Hamiltonian Monte Carlo (SGHMC) is a variant of\nstochastic gradient with momentum where a controlled and properly scaled\nGaussian noise is added to the stochastic gradients to steer the iterates\ntowards a global minimum. Many works reported its empirical success in practice\nfor solving stochastic non-convex optimization problems, in particular it has\nbeen observed to outperform overdamped Langevin Monte Carlo-based methods such\nas stochastic gradient Langevin dynamics (SGLD) in many applications. Although\nasymptotic global convergence properties of SGHMC are well known, its\nfinite-time performance is not well-understood. In this work, we study two\nvariants of SGHMC based on two alternative discretizations of the underdamped\nLangevin diffusion. We provide finite-time performance bounds for the global\nconvergence of both SGHMC variants for solving stochastic non-convex\noptimization problems with explicit constants. Our results lead to\nnon-asymptotic guarantees for both population and empirical risk minimization\nproblems. For a fixed target accuracy level, on a class of non-convex problems,\nwe obtain complexity bounds for SGHMC that can be tighter than those for SGLD.\nThese results show that acceleration with momentum is possible in the context\nof global non-convex optimization. \n\n"}
{"id": "1809.05214", "contents": "Title: Model-Based Reinforcement Learning via Meta-Policy Optimization Abstract: Model-based reinforcement learning approaches carry the promise of being data\nefficient. However, due to challenges in learning dynamics models that\nsufficiently match the real-world dynamics, they struggle to achieve the same\nasymptotic performance as model-free methods. We propose Model-Based\nMeta-Policy-Optimization (MB-MPO), an approach that foregoes the strong\nreliance on accurate learned dynamics models. Using an ensemble of learned\ndynamic models, MB-MPO meta-learns a policy that can quickly adapt to any model\nin the ensemble with one policy gradient step. This steers the meta-policy\ntowards internalizing consistent dynamics predictions among the ensemble while\nshifting the burden of behaving optimally w.r.t. the model discrepancies\ntowards the adaptation step. Our experiments show that MB-MPO is more robust to\nmodel imperfections than previous model-based approaches. Finally, we\ndemonstrate that our approach is able to match the asymptotic performance of\nmodel-free methods while requiring significantly less experience. \n\n"}
{"id": "1809.05398", "contents": "Title: SCORES: Shape Composition with Recursive Substructure Priors Abstract: We introduce SCORES, a recursive neural network for shape composition. Our\nnetwork takes as input sets of parts from two or more source 3D shapes and a\nrough initial placement of the parts. It outputs an optimized part structure\nfor the composed shape, leading to high-quality geometry construction. A unique\nfeature of our composition network is that it is not merely learning how to\nconnect parts. Our goal is to produce a coherent and plausible 3D shape,\ndespite large incompatibilities among the input parts. The network may\nsignificantly alter the geometry and structure of the input parts and\nsynthesize a novel shape structure based on the inputs, while adding or\nremoving parts to minimize a structure plausibility loss. We design SCORES as a\nrecursive autoencoder network. During encoding, the input parts are recursively\ngrouped to generate a root code. During synthesis, the root code is decoded,\nrecursively, to produce a new, coherent part assembly. Assembled shape\nstructures may be novel, with little global resemblance to training exemplars,\nyet have plausible substructures. SCORES therefore learns a hierarchical\nsubstructure shape prior based on per-node losses. It is trained on structured\nshapes from ShapeNet, and is applied iteratively to reduce the plausibility\nloss.We showresults of shape composition from multiple sources over different\ncategories of man-made shapes and compare with state-of-the-art alternatives,\ndemonstrating that our network can significantly expand the range of composable\nshapes for assembly-based modeling. \n\n"}
{"id": "1809.06474", "contents": "Title: Zeroth-order Nonconvex Stochastic Optimization: Handling Constraints,\n  High-Dimensionality and Saddle-Points Abstract: In this paper, we propose and analyze zeroth-order stochastic approximation\nalgorithms for nonconvex and convex optimization, with a focus on addressing\nconstrained optimization, high-dimensional setting and saddle-point avoiding.\nTo handle constrained optimization, we first propose generalizations of the\nconditional gradient algorithm achieving rates similar to the standard\nstochastic gradient algorithm using only zeroth-order information. To\nfacilitate zeroth-order optimization in high-dimensions, we explore the\nadvantages of structural sparsity assumptions. Specifically, (i) we highlight\nan implicit regularization phenomenon where the standard stochastic gradient\nalgorithm with zeroth-order information adapts to the sparsity of the problem\nat hand by just varying the step-size and (ii) propose a truncated stochastic\ngradient algorithm with zeroth-order information, whose rate of convergence\ndepends only poly-logarithmically on the dimensionality. We next focus on\navoiding saddle-points in non-convex setting. Towards that, we interpret the\nGaussian smoothing technique for estimating gradient based on zeroth-order\ninformation as an instantiation of first-order Stein's identity. Based on this,\nwe provide a novel linear-(in dimension) time estimator of the Hessian matrix\nof a function using only zeroth-order information, which is based on\nsecond-order Stein's identity. We then provide an algorithm for avoiding\nsaddle-points, which is based on a zeroth-order cubic regularization Newton's\nmethod and discuss its convergence rates. \n\n"}
{"id": "1809.06784", "contents": "Title: Adversarial Reinforcement Learning for Observer Design in Autonomous\n  Systems under Cyber Attacks Abstract: Complex autonomous control systems are subjected to sensor failures,\ncyber-attacks, sensor noise, communication channel failures, etc. that\nintroduce errors in the measurements. The corrupted information, if used for\nmaking decisions, can lead to degraded performance. We develop a framework for\nusing adversarial deep reinforcement learning to design observer strategies\nthat are robust to adversarial errors in information channels. We further show\nthrough simulation studies that the learned observation strategies perform\nremarkably well when the adversary's injected errors are bounded in some sense.\nWe use neural network as function approximator in our studies with the\nunderstanding that any other suitable function approximating class can be used\nwithin our framework. \n\n"}
{"id": "1809.09143", "contents": "Title: EpiRL: A Reinforcement Learning Agent to Facilitate Epistasis Detection Abstract: Epistasis (gene-gene interaction) is crucial to predicting genetic disease.\nOur work tackles the computational challenges faced by previous works in\nepistasis detection by modeling it as a one-step Markov Decision Process where\nthe state is genome data, the actions are the interacted genes, and the reward\nis an interaction measurement for the selected actions. A reinforcement\nlearning agent using policy gradient method then learns to discover a set of\nhighly interacted genes. \n\n"}
{"id": "1809.09260", "contents": "Title: Low Precision Policy Distillation with Application to Low-Power,\n  Real-time Sensation-Cognition-Action Loop with Neuromorphic Computing Abstract: Low precision networks in the reinforcement learning (RL) setting are\nrelatively unexplored because of the limitations of binary activations for\nfunction approximation. Here, in the discrete action ATARI domain, we\ndemonstrate, for the first time, that low precision policy distillation from a\nhigh precision network provides a principled, practical way to train an RL\nagent. As an application, on 10 different ATARI games, we demonstrate real-time\nend-to-end game playing on low-power neuromorphic hardware by converting a\nsequence of game frames into discrete actions. \n\n"}
{"id": "1809.09345", "contents": "Title: Subexponential algorithms for variants of homomorphism problem in string\n  graphs Abstract: We consider the complexity of finding weighted homomorphisms from\nintersection graphs of curves (string graphs) with $n$ vertices to a fixed\ngraph $H$. We provide a complete dichotomy for the problem: if $H$ has no two\nvertices sharing two common neighbors, then the problem can be solved in time\n$2^{O(n^{2/3} \\log n)}$, otherwise there is no algorithm working in time\n$2^{o(n)}$, even in intersection graphs of segments, unless the ETH fails. This\ngeneralizes several known results concerning the complexity of computatational\nproblems in geometric intersection graphs. Then we consider two variants of\ngraph homomorphism problem, called locally injective homomorphism and locally\nbijective homomorphism, where we require the homomorphism to be injective or\nbijective on the neighborhood of each vertex. We show that for each target\ngraph $H$, both problems can always be solved in time $2^{O(\\sqrt{n} \\log n)}$\nin string graphs. For the locally surjecive homomorphism, defined in an\nanalogous way, the situation seems more complicated. We show the dichotomy\ntheorem for simple connected graphs $H$ with maximum degree 2. If $H$ is\nisomorphic to $P_3$ or $C_4$, then the existence of a locally surjective\nhomomorphism from a string graph with $n$ vertices to $H$ can be decided in\ntime $2^{O(n^{2/3} \\log^{3/2} n)}$, otherwise the problem cannot be solved in\ntime $2^{o(n)}$, unless the ETH fails. As a byproduct, we obtain several\nresults concerning the complexity of variants of homomorphism problem in\n$P_t$-free graphs. In particular, we obtain the dichotomy theorem for weighted\nhomomorphism, analogous to the one for string graphs. \n\n"}
{"id": "1809.10333", "contents": "Title: Using Autoencoders To Learn Interesting Features For Detecting\n  Surveillance Aircraft Abstract: This paper explores using a Long short-term memory (LSTM) based sequence\nautoencoder to learn interesting features for detecting surveillance aircraft\nusing ADS-B flight data. An aircraft periodically broadcasts ADS-B (Automatic\nDependent Surveillance - Broadcast) data to ground receivers. The ability of\nLSTM networks to model varying length time series data and remember\ndependencies that span across events makes it an ideal candidate for\nimplementing a sequence autoencoder for ADS-B data because of its possible\nvariable length time series, irregular sampling and dependencies that span\nacross events. \n\n"}
{"id": "1809.10491", "contents": "Title: On the Regret Minimization of Nonconvex Online Gradient Ascent for\n  Online PCA Abstract: In this paper we focus on the problem of Online Principal Component Analysis\nin the regret minimization framework. For this problem, all existing regret\nminimization algorithms for the fully-adversarial setting are based on a\npositive semidefinite convex relaxation, and hence require quadratic memory and\nSVD computation (either thin of full) on each iteration, which amounts to at\nleast quadratic runtime per iteration. This is in stark contrast to a\ncorresponding stochastic i.i.d. variant of the problem, which was studied\nextensively lately, and admits very efficient gradient ascent algorithms that\nwork directly on the natural non-convex formulation of the problem, and hence\nrequire only linear memory and linear runtime per iteration. This raises the\nquestion: can non-convex online gradient ascent algorithms be shown to minimize\nregret in online adversarial settings? In this paper we take a step forward\ntowards answering this question. We introduce an\n\\textit{adversarially-perturbed spiked-covariance model} in which, each data\npoint is assumed to follow a fixed stochastic distribution with a non-zero\nspectral gap in the covariance matrix, but is then perturbed with some\nadversarial vector. This model is a natural extension of a well studied\nstandard stochastic setting that allows for non-stationary (adversarial)\npatterns to arise in the data and hence, might serve as a significantly better\napproximation for real-world data-streams. We show that in an interesting\nregime of parameters, when the non-convex online gradient ascent algorithm is\ninitialized with a \"warm-start\" vector, it provably minimizes the regret with\nhigh probability. We further discuss the possibility of computing such a\n\"warm-start\" vector, and also the use of regularization to obtain fast regret\nrates. Our theoretical findings are supported by empirical experiments on both\nsynthetic and real-world data. \n\n"}
{"id": "1809.10818", "contents": "Title: Learning Confidence Sets using Support Vector Machines Abstract: The goal of confidence-set learning in the binary classification setting is\nto construct two sets, each with a specific probability guarantee to cover a\nclass. An observation outside the overlap of the two sets is deemed to be from\none of the two classes, while the overlap is an ambiguity region which could\nbelong to either class. Instead of plug-in approaches, we propose a support\nvector classifier to construct confidence sets in a flexible manner.\nTheoretically, we show that the proposed learner can control the non-coverage\nrates and minimize the ambiguity with high probability. Efficient algorithms\nare developed and numerical studies illustrate the effectiveness of the\nproposed method. \n\n"}
{"id": "1809.10889", "contents": "Title: HyperST-Net: Hypernetworks for Spatio-Temporal Forecasting Abstract: Spatio-temporal (ST) data, which represent multiple time series data\ncorresponding to different spatial locations, are ubiquitous in real-world\ndynamic systems, such as air quality readings. Forecasting over ST data is of\ngreat importance but challenging as it is affected by many complex factors,\nincluding spatial characteristics, temporal characteristics and the intrinsic\ncausality between them. In this paper, we propose a general framework\n(HyperST-Net) based on hypernetworks for deep ST models. More specifically, it\nconsists of three major modules: a spatial module, a temporal module and a\ndeduction module. Among them, the deduction module derives the parameter\nweights of the temporal module from the spatial characteristics, which are\nextracted by the spatial module. Then, we design a general form of HyperST\nlayer as well as different forms for several basic layers in neural networks,\nincluding the dense layer (HyperST-Dense) and the convolutional layer\n(HyperST-Conv). Experiments on three types of real-world tasks demonstrate that\nthe predictive models integrated with our framework achieve significant\nimprovements, and outperform the state-of-the-art baselines as well. \n\n"}
{"id": "1809.11084", "contents": "Title: Reuse and Adaptation for Entity Resolution through Transfer Learning Abstract: Entity resolution (ER) is one of the fundamental problems in data\nintegration, where machine learning (ML) based classifiers often provide the\nstate-of-the-art results. Considerable human effort goes into feature\nengineering and training data creation. In this paper, we investigate a new\nproblem: Given a dataset D_T for ER with limited or no training data, is it\npossible to train a good ML classifier on D_T by reusing and adapting the\ntraining data of dataset D_S from same or related domain? Our major\ncontributions include (1) a distributed representation based approach to encode\neach tuple from diverse datasets into a standard feature space; (2)\nidentification of common scenarios where the reuse of training data can be\nbeneficial; and (3) five algorithms for handling each of the aforementioned\nscenarios. We have performed comprehensive experiments on 12 datasets from 5\ndifferent domains (publications, movies, songs, restaurants, and books). Our\nexperiments show that our algorithms provide significant benefits such as\nproviding superior performance for a fixed training data size. \n\n"}
{"id": "1810.00116", "contents": "Title: Improved Gradient-Based Optimization Over Discrete Distributions Abstract: In many applications we seek to maximize an expectation with respect to a\ndistribution over discrete variables. Estimating gradients of such objectives\nwith respect to the distribution parameters is a challenging problem. We\nanalyze existing solutions including finite-difference (FD) estimators and\ncontinuous relaxation (CR) estimators in terms of bias and variance. We show\nthat the commonly used Gumbel-Softmax estimator is biased and propose a simple\nmethod to reduce it. We also derive a simpler piece-wise linear continuous\nrelaxation that also possesses reduced bias. We demonstrate empirically that\nreduced bias leads to a better performance in variational inference and on\nbinary optimization tasks. \n\n"}
{"id": "1810.00789", "contents": "Title: Enumerating minimal dominating sets in $K_t$-free graphs and variants Abstract: It is a long-standing open problem whether the minimal dominating sets of a\ngraph can be enumerated in output-polynomial time. In this paper we investigate\nthis problem in graph classes defined by forbidding an induced subgraph. In\nparticular, we provide output-polynomial time algorithms for $K_t$-free graphs\nand variants. This answers a question of Kant\\'e et al. about enumeration in\nbipartite graphs. \n\n"}
{"id": "1810.01588", "contents": "Title: Interpreting Layered Neural Networks via Hierarchical Modular\n  Representation Abstract: Interpreting the prediction mechanism of complex models is currently one of\nthe most important tasks in the machine learning field, especially with layered\nneural networks, which have achieved high predictive performance with various\npractical data sets. To reveal the global structure of a trained neural network\nin an interpretable way, a series of clustering methods have been proposed,\nwhich decompose the units into clusters according to the similarity of their\ninference roles. The main problems in these studies were that (1) we have no\nprior knowledge about the optimal resolution for the decomposition, or the\nappropriate number of clusters, and (2) there was no method with which to\nacquire knowledge about whether the outputs of each cluster have a positive or\nnegative correlation with the input and output dimension values. In this paper,\nto solve these problems, we propose a method for obtaining a hierarchical\nmodular representation of a layered neural network. The application of a\nhierarchical clustering method to a trained network reveals a tree-structured\nrelationship among hidden layer units, based on their feature vectors defined\nby their correlation with the input and output dimension values. \n\n"}
{"id": "1810.01778", "contents": "Title: A Bayesian model for sparse graphs with flexible degree distribution and\n  overlapping community structure Abstract: We consider a non-projective class of inhomogeneous random graph models with\ninterpretable parameters and a number of interesting asymptotic properties.\nUsing the results of Bollob\\'as et al. [2007], we show that i) the class of\nmodels is sparse and ii) depending on the choice of the parameters, the model\nis either scale-free, with power-law exponent greater than 2, or with an\nasymptotic degree distribution which is power-law with exponential cut-off. We\npropose an extension of the model that can accommodate an overlapping community\nstructure. Scalable posterior inference can be performed due to the specific\nchoice of the link probability. We present experiments on five different\nreal-world networks with up to 100,000 nodes and edges, showing that the model\ncan provide a good fit to the degree distribution and recovers well the latent\ncommunity structure. \n\n"}
{"id": "1810.01864", "contents": "Title: Agnostic Sample Compression Schemes for Regression Abstract: We obtain the first positive results for bounded sample compression in the\nagnostic regression setting with the $\\ell_p$ loss, where $p\\in [1,\\infty]$. We\nconstruct a generic approximate sample compression scheme for real-valued\nfunction classes exhibiting exponential size in the fat-shattering dimension\nbut independent of the sample size. Notably, for linear regression, an\napproximate compression of size linear in the dimension is constructed.\nMoreover, for $\\ell_1$ and $\\ell_\\infty$ losses, we can even exhibit an\nefficient exact sample compression scheme of size linear in the dimension. We\nfurther show that for every other $\\ell_p$ loss, $p\\in (1,\\infty)$, there does\nnot exist an exact agnostic compression scheme of bounded size. This refines\nand generalizes a negative result of David, Moran, and Yehudayoff for the\n$\\ell_2$ loss. We close by posing general open questions: for agnostic\nregression with $\\ell_1$ loss, does every function class admits an exact\ncompression scheme of size equal to its pseudo-dimension? For the $\\ell_2$\nloss, does every function class admit an approximate compression scheme of\npolynomial size in the fat-shattering dimension? These questions generalize\nWarmuth's classic sample compression conjecture for realizable-case\nclassification. \n\n"}
{"id": "1810.02229", "contents": "Title: Italian Event Detection Goes Deep Learning Abstract: This paper reports on a set of experiments with different word embeddings to\ninitialize a state-of-the-art Bi-LSTM-CRF network for event detection and\nclassification in Italian, following the EVENTI evaluation exercise. The net-\nwork obtains a new state-of-the-art result by improving the F1 score for\ndetection of 1.3 points, and of 6.5 points for classification, by using a\nsingle step approach. The results also provide further evidence that embeddings\nhave a major impact on the performance of such architectures. \n\n"}
{"id": "1810.02567", "contents": "Title: Online Learning to Rank with Features Abstract: We introduce a new model for online ranking in which the click probability\nfactors into an examination and attractiveness function and the attractiveness\nfunction is a linear function of a feature vector and an unknown parameter.\nOnly relatively mild assumptions are made on the examination function. A novel\nalgorithm for this setup is analysed, showing that the dependence on the number\nof items is replaced by a dependence on the dimension, allowing the new\nalgorithm to handle a large number of items. When reduced to the orthogonal\ncase, the regret of the algorithm improves on the state-of-the-art. \n\n"}
{"id": "1810.02840", "contents": "Title: Training Complex Models with Multi-Task Weak Supervision Abstract: As machine learning models continue to increase in complexity, collecting\nlarge hand-labeled training sets has become one of the biggest roadblocks in\npractice. Instead, weaker forms of supervision that provide noisier but cheaper\nlabels are often used. However, these weak supervision sources have diverse and\nunknown accuracies, may output correlated labels, and may label different tasks\nor apply at different levels of granularity. We propose a framework for\nintegrating and modeling such weak supervision sources by viewing them as\nlabeling different related sub-tasks of a problem, which we refer to as the\nmulti-task weak supervision setting. We show that by solving a matrix\ncompletion-style problem, we can recover the accuracies of these multi-task\nsources given their dependency structure, but without any labeled data, leading\nto higher-quality supervision for training an end model. Theoretically, we show\nthat the generalization error of models trained with this approach improves\nwith the number of unlabeled data points, and characterize the scaling with\nrespect to the task and dependency structures. On three fine-grained\nclassification problems, we show that our approach leads to average gains of\n20.2 points in accuracy over a traditional supervised approach, 6.8 points over\na majority vote baseline, and 4.1 points over a previously proposed weak\nsupervision method that models tasks separately. \n\n"}
{"id": "1810.02909", "contents": "Title: On the Art and Science of Machine Learning Explanations Abstract: This text discusses several popular explanatory methods that go beyond the\nerror measurements and plots traditionally used to assess machine learning\nmodels. Some of the explanatory methods are accepted tools of the trade while\nothers are rigorously derived and backed by long-standing theory. The methods,\ndecision tree surrogate models, individual conditional expectation (ICE) plots,\nlocal interpretable model-agnostic explanations (LIME), partial dependence\nplots, and Shapley explanations, vary in terms of scope, fidelity, and suitable\napplication domain. Along with descriptions of these methods, this text\npresents real-world usage recommendations supported by a use case and public,\nin-depth software examples for reproducibility. \n\n"}
{"id": "1810.03167", "contents": "Title: Unsupervised Neural Word Segmentation for Chinese via Segmental Language\n  Modeling Abstract: Previous traditional approaches to unsupervised Chinese word segmentation\n(CWS) can be roughly classified into discriminative and generative models. The\nformer uses the carefully designed goodness measures for candidate\nsegmentation, while the latter focuses on finding the optimal segmentation of\nthe highest generative probability. However, while there exists a trivial way\nto extend the discriminative models into neural version by using neural\nlanguage models, those of generative ones are non-trivial. In this paper, we\npropose the segmental language models (SLMs) for CWS. Our approach explicitly\nfocuses on the segmental nature of Chinese, as well as preserves several\nproperties of language models. In SLMs, a context encoder encodes the previous\ncontext and a segment decoder generates each segment incrementally. As far as\nwe know, we are the first to propose a neural model for unsupervised CWS and\nachieve competitive performance to the state-of-the-art statistical models on\nfour different datasets from SIGHAN 2005 bakeoff. \n\n"}
{"id": "1810.03798", "contents": "Title: The Outer Product Structure of Neural Network Derivatives Abstract: In this paper, we show that feedforward and recurrent neural networks exhibit\nan outer product derivative structure but that convolutional neural networks do\nnot. This structure makes it possible to use higher-order information without\nneeding approximations or infeasibly large amounts of memory, and it may also\nprovide insights into the geometry of neural network optima. The ability to\neasily access these derivatives also suggests a new, geometric approach to\nregularization. We then discuss how this structure could be used to improve\ntraining methods, increase network robustness and generalizability, and inform\nnetwork compression methods. \n\n"}
{"id": "1810.03814", "contents": "Title: SNAP: A semismooth Newton algorithm for pathwise optimization with\n  optimal local convergence rate and oracle properties Abstract: We propose a semismooth Newton algorithm for pathwise optimization (SNAP) for\nthe LASSO and Enet in sparse, high-dimensional linear regression. SNAP is\nderived from a suitable formulation of the KKT conditions based on Newton\nderivatives. It solves the semismooth KKT equations efficiently by actively and\ncontinuously seeking the support of the regression coefficients along the\nsolution path with warm start. At each knot in the path, SNAP converges locally\nsuperlinearly for the Enet criterion and achieves an optimal local convergence\nrate for the LASSO criterion, i.e., SNAP converges in one step at the cost of\ntwo matrix-vector multiplication per iteration. Under certain regularity\nconditions on the design matrix and the minimum magnitude of the nonzero\nelements of the target regression coefficients, we show that SNAP hits a\nsolution with the same signs as the regression coefficients and achieves a\nsharp estimation error bound in finite steps with high probability. The\ncomputational complexity of SNAP is shown to be the same as that of LARS and\ncoordinate descent algorithms per iteration. Simulation studies and real data\nanalysis support our theoretical results and demonstrate that SNAP is faster\nand accurate than LARS and coordinate descent algorithms. \n\n"}
{"id": "1810.04065", "contents": "Title: Generalized No Free Lunch Theorem for Adversarial Robustness Abstract: This manuscript presents some new impossibility results on adversarial\nrobustness in machine learning, a very important yet largely open problem. We\nshow that if conditioned on a class label the data distribution satisfies the\n$W_2$ Talagrand transportation-cost inequality (for example, this condition is\nsatisfied if the conditional distribution has density which is log-concave; is\nthe uniform measure on a compact Riemannian manifold with positive Ricci\ncurvature, any classifier can be adversarially fooled with high probability\nonce the perturbations are slightly greater than the natural noise level in the\nproblem. We call this result The Strong \"No Free Lunch\" Theorem as some recent\nresults (Tsipras et al. 2018, Fawzi et al. 2018, etc.) on the subject can be\nimmediately recovered as very particular cases. Our theoretical bounds are\ndemonstrated on both simulated and real data (MNIST). We conclude the\nmanuscript with some speculation on possible future research directions. \n\n"}
{"id": "1810.04303", "contents": "Title: Batch Active Preference-Based Learning of Reward Functions Abstract: Data generation and labeling are usually an expensive part of learning for\nrobotics. While active learning methods are commonly used to tackle the former\nproblem, preference-based learning is a concept that attempts to solve the\nlatter by querying users with preference questions. In this paper, we will\ndevelop a new algorithm, batch active preference-based learning, that enables\nefficient learning of reward functions using as few data samples as possible\nwhile still having short query generation times. We introduce several\napproximations to the batch active learning problem, and provide theoretical\nguarantees for the convergence of our algorithms. Finally, we present our\nexperimental results for a variety of robotics tasks in simulation. Our results\nsuggest that our batch active learning algorithm requires only a few queries\nthat are computed in a short amount of time. We then showcase our algorithm in\na study to learn human users' preferences. \n\n"}
{"id": "1810.05186", "contents": "Title: Bilinear Factor Matrix Norm Minimization for Robust PCA: Algorithms and\n  Applications Abstract: The heavy-tailed distributions of corrupted outliers and singular values of\nall channels in low-level vision have proven effective priors for many\napplications such as background modeling, photometric stereo and image\nalignment. And they can be well modeled by a hyper-Laplacian. However, the use\nof such distributions generally leads to challenging non-convex, non-smooth and\nnon-Lipschitz problems, and makes existing algorithms very slow for large-scale\napplications. Together with the analytic solutions to lp-norm minimization with\ntwo specific values of p, i.e., p=1/2 and p=2/3, we propose two novel bilinear\nfactor matrix norm minimization models for robust principal component analysis.\nWe first define the double nuclear norm and Frobenius/nuclear hybrid norm\npenalties, and then prove that they are in essence the Schatten-1/2 and 2/3\nquasi-norms, respectively, which lead to much more tractable and scalable\nLipschitz optimization problems. Our experimental analysis shows that both our\nmethods yield more accurate solutions than original Schatten quasi-norm\nminimization, even when the number of observations is very limited. Finally, we\napply our penalties to various low-level vision problems, e.g., text removal,\nmoving object detection, image alignment and inpainting, and show that our\nmethods usually outperform the state-of-the-art methods. \n\n"}
{"id": "1810.05206", "contents": "Title: MeshAdv: Adversarial Meshes for Visual Recognition Abstract: Highly expressive models such as deep neural networks (DNNs) have been widely\napplied to various applications. However, recent studies show that DNNs are\nvulnerable to adversarial examples, which are carefully crafted inputs aiming\nto mislead the predictions. Currently, the majority of these studies have\nfocused on perturbation added to image pixels, while such manipulation is not\nphysically realistic. Some works have tried to overcome this limitation by\nattaching printable 2D patches or painting patterns onto surfaces, but can be\npotentially defended because 3D shape features are intact. In this paper, we\npropose meshAdv to generate \"adversarial 3D meshes\" from objects that have rich\nshape features but minimal textural variation. To manipulate the shape or\ntexture of the objects, we make use of a differentiable renderer to compute\naccurate shading on the shape and propagate the gradient. Extensive experiments\nshow that the generated 3D meshes are effective in attacking both classifiers\nand object detectors. We evaluate the attack under different viewpoints. In\naddition, we design a pipeline to perform black-box attack on a photorealistic\nrenderer with unknown rendering parameters. \n\n"}
{"id": "1810.05593", "contents": "Title: Fast Construction of Correcting Ensembles for Legacy Artificial\n  Intelligence Systems: Algorithms and a Case Study Abstract: This paper presents a technology for simple and computationally efficient\nimprovements of a generic Artificial Intelligence (AI) system, including\nMultilayer and Deep Learning neural networks. The improvements are, in essence,\nsmall network ensembles constructed on top of the existing AI architectures.\nTheoretical foundations of the technology are based on Stochastic Separation\nTheorems and the ideas of the concentration of measure. We show that, subject\nto mild technical assumptions on statistical properties of internal signals in\nthe original AI system, the technology enables instantaneous and\ncomputationally efficient removal of spurious and systematic errors with\nprobability close to one on the datasets which are exponentially large in\ndimension. The method is illustrated with numerical examples and a case study\nof ten digits recognition from American Sign Language. \n\n"}
{"id": "1810.05752", "contents": "Title: Global Convergence of EM Algorithm for Mixtures of Two Component Linear\n  Regression Abstract: The Expectation-Maximization algorithm is perhaps the most broadly used\nalgorithm for inference of latent variable problems. A theoretical\nunderstanding of its performance, however, largely remains lacking. Recent\nresults established that EM enjoys global convergence for Gaussian Mixture\nModels. For Mixed Linear Regression, however, only local convergence results\nhave been established, and those only for the high SNR regime. We show here\nthat EM converges for mixed linear regression with two components (it is known\nthat it may fail to converge for three or more), and moreover that this\nconvergence holds for random initialization. Our analysis reveals that EM\nexhibits very different behavior in Mixed Linear Regression from its behavior\nin Gaussian Mixture Models, and hence our proofs require the development of\nseveral new ideas. \n\n"}
{"id": "1810.06060", "contents": "Title: Distributed learning of deep neural network over multiple agents Abstract: In domains such as health care and finance, shortage of labeled data and\ncomputational resources is a critical issue while developing machine learning\nalgorithms. To address the issue of labeled data scarcity in training and\ndeployment of neural network-based systems, we propose a new technique to train\ndeep neural networks over several data sources. Our method allows for deep\nneural networks to be trained using data from multiple entities in a\ndistributed fashion. We evaluate our algorithm on existing datasets and show\nthat it obtains performance which is similar to a regular neural network\ntrained on a single machine. We further extend it to incorporate\nsemi-supervised learning when training with few labeled samples, and analyze\nany security concerns that may arise. Our algorithm paves the way for\ndistributed training of deep neural networks in data sensitive applications\nwhen raw data may not be shared directly. \n\n"}
{"id": "1810.06803", "contents": "Title: Co-manifold learning with missing data Abstract: Representation learning is typically applied to only one mode of a data\nmatrix, either its rows or columns. Yet in many applications, there is an\nunderlying geometry to both the rows and the columns. We propose utilizing this\ncoupled structure to perform co-manifold learning: uncovering the underlying\ngeometry of both the rows and the columns of a given matrix, where we focus on\na missing data setting. Our unsupervised approach consists of three components.\nWe first solve a family of optimization problems to estimate a complete matrix\nat multiple scales of smoothness. We then use this collection of smooth matrix\nestimates to compute pairwise distances on the rows and columns based on a new\nmulti-scale metric that implicitly introduces a coupling between the rows and\nthe columns. Finally, we construct row and column representations from these\nmulti-scale metrics. We demonstrate that our approach outperforms competing\nmethods in both data visualization and clustering. \n\n"}
{"id": "1810.07287", "contents": "Title: Signed iterative random forests to identify enhancer-associated\n  transcription factor binding Abstract: Standard ChIP-seq peak calling pipelines seek to differentiate biochemically\nreproducible signals of individual genomic elements from background noise.\nHowever, reproducibility alone does not imply functional regulation (e.g.,\nenhancer activation, alternative splicing). Here we present a general-purpose,\ninterpretable machine learning method: signed iterative random forests (siRF),\nwhich we use to infer regulatory interactions among transcription factors and\nfunctional binding signatures surrounding enhancer elements in Drosophila\nmelanogaster. \n\n"}
{"id": "1810.07382", "contents": "Title: Analysis of Railway Accidents' Narratives Using Deep Learning Abstract: Automatic understanding of domain specific texts in order to extract useful\nrelationships for later use is a non-trivial task. One such relationship would\nbe between railroad accidents' causes and their correspondent descriptions in\nreports. From 2001 to 2016 rail accidents in the U.S. cost more than $4.6B.\nRailroads involved in accidents are required to submit an accident report to\nthe Federal Railroad Administration (FRA). These reports contain a variety of\nfixed field entries including primary cause of the accidents (a coded variable\nwith 389 values) as well as a narrative field which is a short text description\nof the accident. Although these narratives provide more information than a\nfixed field entry, the terminologies used in these reports are not easy to\nunderstand by a non-expert reader. Therefore, providing an assisting method to\nfill in the primary cause from such domain specific texts(narratives) would\nhelp to label the accidents with more accuracy. Another important question for\ntransportation safety is whether the reported accident cause is consistent with\nnarrative description. To address these questions, we applied deep learning\nmethods together with powerful word embeddings such as Word2Vec and GloVe to\nclassify accident cause values for the primary cause field using the text in\nthe narratives. The results show that such approaches can both accurately\nclassify accident causes based on report narratives and find important\ninconsistencies in accident reporting. \n\n"}
{"id": "1810.07770", "contents": "Title: Small ReLU networks are powerful memorizers: a tight analysis of\n  memorization capacity Abstract: We study finite sample expressivity, i.e., memorization power of ReLU\nnetworks. Recent results require $N$ hidden nodes to memorize/interpolate\narbitrary $N$ data points. In contrast, by exploiting depth, we show that\n3-layer ReLU networks with $\\Omega(\\sqrt{N})$ hidden nodes can perfectly\nmemorize most datasets with $N$ points. We also prove that width\n$\\Theta(\\sqrt{N})$ is necessary and sufficient for memorizing $N$ data points,\nproving tight bounds on memorization capacity. The sufficiency result can be\nextended to deeper networks; we show that an $L$-layer network with $W$\nparameters in the hidden layers can memorize $N$ data points if $W =\n\\Omega(N)$. Combined with a recent upper bound $O(WL\\log W)$ on VC dimension,\nour construction is nearly tight for any fixed $L$. Subsequently, we analyze\nmemorization capacity of residual networks under a general position assumption;\nwe prove results that substantially reduce the known requirement of $N$ hidden\nnodes. Finally, we study the dynamics of stochastic gradient descent (SGD), and\nshow that when initialized near a memorizing global minimum of the empirical\nrisk, SGD quickly finds a nearby point with much smaller empirical risk. \n\n"}
{"id": "1810.07852", "contents": "Title: Distributed $k$-Clustering for Data with Heavy Noise Abstract: In this paper, we consider the $k$-center/median/means clustering with\noutliers problems (or the $(k, z)$-center/median/means problems) in the\ndistributed setting. Most previous distributed algorithms have their\ncommunication costs linearly depending on $z$, the number of outliers. Recently\nGuha et al. overcame this dependence issue by considering bi-criteria\napproximation algorithms that output solutions with $2z$ outliers. For the case\nwhere $z$ is large, the extra $z$ outliers discarded by the algorithms might be\ntoo large, considering that the data gathering process might be costly. In this\npaper, we improve the number of outliers to the best possible $(1+\\epsilon)z$,\nwhile maintaining the $O(1)$-approximation ratio and independence of\ncommunication cost on $z$. The problems we consider include the $(k, z)$-center\nproblem, and $(k, z)$-median/means problems in Euclidean metrics.\nImplementation of the our algorithm for $(k, z)$-center shows that it\noutperforms many previous algorithms, both in terms of the communication cost\nand quality of the output solution. \n\n"}
{"id": "1810.07874", "contents": "Title: A Self-Organizing Tensor Architecture for Multi-View Clustering Abstract: In many real-world applications, data are often unlabeled and comprised of\ndifferent representations/views which often provide information complementary\nto each other. Although several multi-view clustering methods have been\nproposed, most of them routinely assume one weight for one view of features,\nand thus inter-view correlations are only considered at the view-level. These\napproaches, however, fail to explore the explicit correlations between features\nacross multiple views. In this paper, we introduce a tensor-based approach to\nincorporate the higher-order interactions among multiple views as a tensor\nstructure. Specifically, we propose a multi-linear multi-view clustering (MMC)\nmethod that can efficiently explore the full-order structural information among\nall views and reveal the underlying subspace structure embedded within the\ntensor. Extensive experiments on real-world datasets demonstrate that our\nproposed MMC algorithm clearly outperforms other related state-of-the-art\nmethods. \n\n"}
{"id": "1810.07911", "contents": "Title: Domain Adaptation for Semantic Segmentation via Class-Balanced\n  Self-Training Abstract: Recent deep networks achieved state of the art performance on a variety of\nsemantic segmentation tasks. Despite such progress, these models often face\nchallenges in real world `wild tasks' where large difference between labeled\ntraining/source data and unseen test/target data exists. In particular, such\ndifference is often referred to as `domain gap', and could cause significantly\ndecreased performance which cannot be easily remedied by further increasing the\nrepresentation power. Unsupervised domain adaptation (UDA) seeks to overcome\nsuch problem without target domain labels. In this paper, we propose a novel\nUDA framework based on an iterative self-training procedure, where the problem\nis formulated as latent variable loss minimization, and can be solved by\nalternatively generating pseudo labels on target data and re-training the model\nwith these labels. On top of self-training, we also propose a novel\nclass-balanced self-training framework to avoid the gradual dominance of large\nclasses on pseudo-label generation, and introduce spatial priors to refine\ngenerated labels. Comprehensive experiments show that the proposed methods\nachieve state of the art semantic segmentation performance under multiple major\nUDA settings. \n\n"}
{"id": "1810.07924", "contents": "Title: Explaining Machine Learning Models using Entropic Variable Projection Abstract: In this paper, we present a new explainability formalism designed to shed\nlight on how each input variable of a test set impacts the predictions of\nmachine learning models. Hence, we propose a group explainability formalism for\ntrained machine learning decision rules, based on their response to the\nvariability of the input variables distribution. In order to emphasize the\nimpact of each input variable, this formalism uses an information theory\nframework that quantifies the influence of all input-output observations based\non entropic projections. This is thus the first unified and model agnostic\nformalism enabling data scientists to interpret the dependence between the\ninput variables, their impact on the prediction errors, and their influence on\nthe output predictions. Convergence rates of the entropic projections are\nprovided in the large sample case. Most importantly, we prove that computing an\nexplanation in our framework has a low algorithmic complexity, making it\nscalable to real-life large datasets. We illustrate our strategy by explaining\ncomplex decision rules learned by using XGBoost, Random Forest or Deep Neural\nNetwork classifiers on various datasets such as Adult Income, MNIST, CelebA,\nBoston Housing, Iris, as well as synthetic ones. We finally make clear its\ndifferences with the explainability strategies LIME and SHAP, that are based on\nsingle observations. Results can be reproduced by using the freely distributed\nPython toolbox https://gems-ai.aniti.fr/. \n\n"}
{"id": "1810.08171", "contents": "Title: Testing Matrix Rank, Optimally Abstract: We show that for the problem of testing if a matrix $A \\in F^{n \\times n}$\nhas rank at most $d$, or requires changing an $\\epsilon$-fraction of entries to\nhave rank at most $d$, there is a non-adaptive query algorithm making\n$\\widetilde{O}(d^2/\\epsilon)$ queries. Our algorithm works for any field $F$.\nThis improves upon the previous $O(d^2/\\epsilon^2)$ bound (SODA'03), and\nbypasses an $\\Omega(d^2/\\epsilon^2)$ lower bound of (KDD'14) which holds if the\nalgorithm is required to read a submatrix. Our algorithm is the first such\nalgorithm which does not read a submatrix, and instead reads a carefully\nselected non-adaptive pattern of entries in rows and columns of $A$. We\ncomplement our algorithm with a matching query complexity lower bound for\nnon-adaptive testers over any field. We also give tight bounds of\n$\\widetilde{\\Theta}(d^2)$ queries in the sensing model for which query access\ncomes in the form of $\\langle X_i, A\\rangle:=tr(X_i^\\top A)$; perhaps\nsurprisingly these bounds do not depend on $\\epsilon$.\n  We next develop a novel property testing framework for testing numerical\nproperties of a real-valued matrix $A$ more generally, which includes the\nstable rank, Schatten-$p$ norms, and SVD entropy. Specifically, we propose a\nbounded entry model, where $A$ is required to have entries bounded by $1$ in\nabsolute value. We give upper and lower bounds for a wide range of problems in\nthis model, and discuss connections to the sensing model above. \n\n"}
{"id": "1810.08452", "contents": "Title: Multitask Learning for Large-scale Semantic Change Detection Abstract: Change detection is one of the main problems in remote sensing, and is\nessential to the accurate processing and understanding of the large scale Earth\nobservation data available through programs such as Sentinel and Landsat. Most\nof the recently proposed change detection methods bring deep learning to this\ncontext, but openly available change detection datasets are still very scarce,\nwhich limits the methods that can be proposed and tested. In this paper we\npresent the first large scale high resolution semantic change detection (HRSCD)\ndataset, which enables the usage of deep learning methods for semantic change\ndetection. The dataset contains coregistered RGB image pairs, pixel-wise change\ninformation and land cover information. We then propose several methods using\nfully convolutional neural networks to perform semantic change detection. Most\nnotably, we present a network architecture that performs change detection and\nland cover mapping simultaneously, while using the predicted land cover\ninformation to help to predict changes. We also describe a sequential training\nscheme that allows this network to be trained without setting a hyperparameter\nthat balances different loss functions and achieves the best overall results. \n\n"}
{"id": "1810.09098", "contents": "Title: Stochastic Gradient MCMC for State Space Models Abstract: State space models (SSMs) are a flexible approach to modeling complex time\nseries. However, inference in SSMs is often computationally prohibitive for\nlong time series. Stochastic gradient MCMC (SGMCMC) is a popular method for\nscalable Bayesian inference for large independent data. Unfortunately when\napplied to dependent data, such as in SSMs, SGMCMC's stochastic gradient\nestimates are biased as they break crucial temporal dependencies. To alleviate\nthis, we propose stochastic gradient estimators that control this bias by\nperforming additional computation in a `buffer' to reduce breaking\ndependencies. Furthermore, we derive error bounds for this bias and show a\ngeometric decay under mild conditions. Using these estimators, we develop novel\nSGMCMC samplers for discrete, continuous and mixed-type SSMs with analytic\nmessage passing. Our experiments on real and synthetic data demonstrate the\neffectiveness of our SGMCMC algorithms compared to batch MCMC, allowing us to\nscale inference to long time series with millions of time points. \n\n"}
{"id": "1810.09155", "contents": "Title: A Simple Baseline Algorithm for Graph Classification Abstract: Graph classification has recently received a lot of attention from various\nfields of machine learning e.g. kernel methods, sequential modeling or graph\nembedding. All these approaches offer promising results with different\nrespective strengths and weaknesses. However, most of them rely on complex\nmathematics and require heavy computational power to achieve their best\nperformance. We propose a simple and fast algorithm based on the spectral\ndecomposition of graph Laplacian to perform graph classification and get a\nfirst reference score for a dataset. We show that this method obtains\ncompetitive results compared to state-of-the-art algorithms. \n\n"}
{"id": "1810.09274", "contents": "Title: From Hard to Soft: Understanding Deep Network Nonlinearities via Vector\n  Quantization and Statistical Inference Abstract: Nonlinearity is crucial to the performance of a deep (neural) network (DN).\nTo date there has been little progress understanding the menagerie of available\nnonlinearities, but recently progress has been made on understanding the r\\^ole\nplayed by piecewise affine and convex nonlinearities like the ReLU and absolute\nvalue activation functions and max-pooling. In particular, DN layers\nconstructed from these operations can be interpreted as {\\em max-affine spline\noperators} (MASOs) that have an elegant link to vector quantization (VQ) and\n$K$-means. While this is good theoretical progress, the entire MASO approach is\npredicated on the requirement that the nonlinearities be piecewise affine and\nconvex, which precludes important activation functions like the sigmoid,\nhyperbolic tangent, and softmax. {\\em This paper extends the MASO framework to\nthese and an infinitely large class of new nonlinearities by linking\ndeterministic MASOs with probabilistic Gaussian Mixture Models (GMMs).} We show\nthat, under a GMM, piecewise affine, convex nonlinearities like ReLU, absolute\nvalue, and max-pooling can be interpreted as solutions to certain natural\n\"hard\" VQ inference problems, while sigmoid, hyperbolic tangent, and softmax\ncan be interpreted as solutions to corresponding \"soft\" VQ inference problems.\nWe further extend the framework by hybridizing the hard and soft VQ\noptimizations to create a $\\beta$-VQ inference that interpolates between hard,\nsoft, and linear VQ inference. A prime example of a $\\beta$-VQ DN nonlinearity\nis the {\\em swish} nonlinearity, which offers state-of-the-art performance in a\nrange of computer vision tasks but was developed ad hoc by experimentation.\nFinally, we validate with experiments an important assertion of our theory,\nnamely that DN performance can be significantly improved by enforcing\northogonality in its linear filters. \n\n"}
{"id": "1810.09945", "contents": "Title: Analyzing Neuroimaging Data Through Recurrent Deep Learning Models Abstract: The application of deep learning (DL) models to neuroimaging data poses\nseveral challenges, due to the high dimensionality, low sample size and complex\ntemporo-spatial dependency structure of these datasets. Even further, DL models\nact as as black-box models, impeding insight into the association of cognitive\nstate and brain activity. To approach these challenges, we introduce the\nDeepLight framework, which utilizes long short-term memory (LSTM) based DL\nmodels to analyze whole-brain functional Magnetic Resonance Imaging (fMRI)\ndata. To decode a cognitive state (e.g., seeing the image of a house),\nDeepLight separates the fMRI volume into a sequence of axial brain slices,\nwhich is then sequentially processed by an LSTM. To maintain interpretability,\nDeepLight adapts the layer-wise relevance propagation (LRP) technique. Thereby,\ndecomposing its decoding decision into the contributions of the single input\nvoxels to this decision. Importantly, the decomposition is performed on the\nlevel of single fMRI volumes, enabling DeepLight to study the associations\nbetween cognitive state and brain activity on several levels of data\ngranularity, from the level of the group down to the level of single time\npoints. To demonstrate the versatility of DeepLight, we apply it to a large\nfMRI dataset of the Human Connectome Project. We show that DeepLight\noutperforms conventional approaches of uni- and multivariate fMRI analysis in\ndecoding the cognitive states and in identifying the physiologically\nappropriate brain regions associated with these states. We further demonstrate\nDeepLight's ability to study the fine-grained temporo-spatial variability of\nbrain activity over sequences of single fMRI samples. \n\n"}
{"id": "1810.10132", "contents": "Title: Smoothed Online Optimization for Regression and Control Abstract: We consider Online Convex Optimization (OCO) in the setting where the costs\nare $m$-strongly convex and the online learner pays a switching cost for\nchanging decisions between rounds. We show that the recently proposed Online\nBalanced Descent (OBD) algorithm is constant competitive in this setting, with\ncompetitive ratio $3 + O(1/m)$, irrespective of the ambient dimension.\nAdditionally, we show that when the sequence of cost functions is\n$\\epsilon$-smooth, OBD has near-optimal dynamic regret and maintains strong\nper-round accuracy. We demonstrate the generality of our approach by showing\nthat the OBD framework can be used to construct competitive algorithms for a\nvariety of online problems across learning and control, including online\nvariants of ridge regression, logistic regression, maximum likelihood\nestimation, and LQR control. \n\n"}
{"id": "1810.11546", "contents": "Title: Mobile Sensor Data Anonymization Abstract: Motion sensors such as accelerometers and gyroscopes measure the instant\nacceleration and rotation of a device, in three dimensions. Raw data streams\nfrom motion sensors embedded in portable and wearable devices may reveal\nprivate information about users without their awareness. For example, motion\ndata might disclose the weight or gender of a user, or enable their\nre-identification. To address this problem, we propose an on-device\ntransformation of sensor data to be shared for specific applications, such as\nmonitoring selected daily activities, without revealing information that\nenables user identification. We formulate the anonymization problem using an\ninformation-theoretic approach and propose a new multi-objective loss function\nfor training deep autoencoders. This loss function helps minimizing\nuser-identity information as well as data distortion to preserve the\napplication-specific utility. The training process regulates the encoder to\ndisregard user-identifiable patterns and tunes the decoder to shape the output\nindependently of users in the training set. The trained autoencoder can be\ndeployed on a mobile or wearable device to anonymize sensor data even for users\nwho are not included in the training dataset. Data from 24 users transformed by\nthe proposed anonymizing autoencoder lead to a promising trade-off between\nutility and privacy, with an accuracy for activity recognition above 92% and an\naccuracy for user identification below 7%. \n\n"}
{"id": "1810.11829", "contents": "Title: On preserving non-discrimination when combining expert advice Abstract: We study the interplay between sequential decision making and avoiding\ndiscrimination against protected groups, when examples arrive online and do not\nfollow distributional assumptions. We consider the most basic extension of\nclassical online learning: \"Given a class of predictors that are individually\nnon-discriminatory with respect to a particular metric, how can we combine them\nto perform as well as the best predictor, while preserving non-discrimination?\"\nSurprisingly we show that this task is unachievable for the prevalent notion of\n\"equalized odds\" that requires equal false negative rates and equal false\npositive rates across groups. On the positive side, for another notion of\nnon-discrimination, \"equalized error rates\", we show that running separate\ninstances of the classical multiplicative weights algorithm for each group\nachieves this guarantee. Interestingly, even for this notion, we show that\nalgorithms with stronger performance guarantees than multiplicative weights\ncannot preserve non-discrimination. \n\n"}
{"id": "1810.11896", "contents": "Title: Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of\n  Neurons Abstract: We analyze linear independence of rank one tensors produced by tensor powers\nof randomly perturbed vectors. This enables efficient decomposition of sums of\nhigh-order tensors. Our analysis builds upon [BCMV14] but allows for a wider\nrange of perturbation models, including discrete ones. We give an application\nto recovering assemblies of neurons.\n  Assemblies are large sets of neurons representing specific memories or\nconcepts. The size of the intersection of two assemblies has been shown in\nexperiments to represent the extent to which these memories co-occur or these\nconcepts are related; the phenomenon is called association of assemblies. This\nsuggests that an animal's memory is a complex web of associations, and poses\nthe problem of recovering this representation from cognitive data. Motivated by\nthis problem, we study the following more general question: Can we reconstruct\nthe Venn diagram of a family of sets, given the sizes of their $\\ell$-wise\nintersections? We show that as long as the family of sets is randomly\nperturbed, it is enough for the number of measurements to be polynomially\nlarger than the number of nonempty regions of the Venn diagram to fully\nreconstruct the diagram. \n\n"}
{"id": "1810.11971", "contents": "Title: Semi-crowdsourced Clustering with Deep Generative Models Abstract: We consider the semi-supervised clustering problem where crowdsourcing\nprovides noisy information about the pairwise comparisons on a small subset of\ndata, i.e., whether a sample pair is in the same cluster. We propose a new\napproach that includes a deep generative model (DGM) to characterize low-level\nfeatures of the data, and a statistical relational model for noisy pairwise\nannotations on its subset. The two parts share the latent variables. To make\nthe model automatically trade-off between its complexity and fitting data, we\nalso develop its fully Bayesian variant. The challenge of inference is\naddressed by fast (natural-gradient) stochastic variational inference\nalgorithms, where we effectively combine variational message passing for the\nrelational part and amortized learning of the DGM under a unified framework.\nEmpirical results on synthetic and real-world datasets show that our model\noutperforms previous crowdsourced clustering methods. \n\n"}
{"id": "1810.12273", "contents": "Title: Kalman Gradient Descent: Adaptive Variance Reduction in Stochastic\n  Optimization Abstract: We introduce Kalman Gradient Descent, a stochastic optimization algorithm\nthat uses Kalman filtering to adaptively reduce gradient variance in stochastic\ngradient descent by filtering the gradient estimates. We present both a\ntheoretical analysis of convergence in a non-convex setting and experimental\nresults which demonstrate improved performance on a variety of machine learning\nareas including neural networks and black box variational inference. We also\npresent a distributed version of our algorithm that enables large-dimensional\noptimization, and we extend our algorithm to SGD with momentum and RMSProp. \n\n"}
{"id": "1810.12406", "contents": "Title: Learning to Screen for Fast Softmax Inference on Large Vocabulary Neural\n  Networks Abstract: Neural language models have been widely used in various NLP tasks, including\nmachine translation, next word prediction and conversational agents. However,\nit is challenging to deploy these models on mobile devices due to their slow\nprediction speed, where the bottleneck is to compute top candidates in the\nsoftmax layer. In this paper, we introduce a novel softmax layer approximation\nalgorithm by exploiting the clustering structure of context vectors. Our\nalgorithm uses a light-weight screening model to predict a much smaller set of\ncandidate words based on the given context, and then conducts an exact softmax\nonly within that subset. Training such a procedure end-to-end is challenging as\ntraditional clustering methods are discrete and non-differentiable, and thus\nunable to be used with back-propagation in the training process. Using the\nGumbel softmax, we are able to train the screening model end-to-end on the\ntraining set to exploit data distribution. The algorithm achieves an order of\nmagnitude faster inference than the original softmax layer for predicting\ntop-$k$ words in various tasks such as beam search in machine translation or\nnext words prediction. For example, for machine translation task on German to\nEnglish dataset with around 25K vocabulary, we can achieve 20.4 times speed up\nwith 98.9\\% precision@1 and 99.3\\% precision@5 with the original softmax layer\nprediction, while state-of-the-art ~\\citep{MSRprediction} only achieves 6.7x\nspeedup with 98.7\\% precision@1 and 98.1\\% precision@5 for the same task. \n\n"}
{"id": "1810.12558", "contents": "Title: Relative Importance Sampling For Off-Policy Actor-Critic in Deep\n  Reinforcement Learning Abstract: Off-policy learning is more unstable compared to on-policy learning in\nreinforcement learning (RL). One reason for the instability of off-policy\nlearning is a discrepancy between the target ($\\pi$) and behavior (b) policy\ndistributions. The discrepancy between $\\pi$ and b distributions can be\nalleviated by employing a smooth variant of the importance sampling (IS), such\nas the relative importance sampling (RIS). RIS has parameter $\\beta\\in[0, 1]$\nwhich controls smoothness. To cope with instability, we present the first\nrelative importance sampling-off-policy actor-critic (RIS-Off-PAC) model-free\nalgorithms in RL. In our method, the network yields a target policy (the\nactor), a value function (the critic) assessing the current policy ($\\pi$)\nusing samples drawn from behavior policy. We use action value generated from\nthe behavior policy in reward function to train our algorithm rather than from\nthe target policy. We also use deep neural networks to train both actor and\ncritic. We evaluated our algorithm on a number of Open AI Gym benchmark\nproblems and demonstrate better or comparable performance to several\nstate-of-the-art RL baselines. \n\n"}
{"id": "1810.12757", "contents": "Title: Scaling Speech Enhancement in Unseen Environments with Noise Embeddings Abstract: We address the problem of speech enhancement generalisation to unseen\nenvironments by performing two manipulations. First, we embed an additional\nrecording from the environment alone, and use this embedding to alter\nactivations in the main enhancement subnetwork. Second, we scale the number of\nnoise environments present at training time to 16,784 different environments.\nExperiment results show that both manipulations reduce word error rates of a\npretrained speech recognition system and improve enhancement quality according\nto a number of performance measures. Specifically, our best model reduces the\nword error rate from 34.04% on noisy speech to 15.46% on the enhanced speech.\nEnhanced audio samples can be found in\nhttps://speechenhancement.page.link/samples. \n\n"}
{"id": "1811.00454", "contents": "Title: Referenceless Performance Evaluation of Audio Source Separation using\n  Deep Neural Networks Abstract: Current performance evaluation for audio source separation depends on\ncomparing the processed or separated signals with reference signals. Therefore,\ncommon performance evaluation toolkits are not applicable to real-world\nsituations where the ground truth audio is unavailable. In this paper, we\npropose a performance evaluation technique that does not require reference\nsignals in order to assess separation quality. The proposed technique uses a\ndeep neural network (DNN) to map the processed audio into its quality score.\nOur experiment results show that the DNN is capable of predicting the\nsources-to-artifacts ratio from the blind source separation evaluation toolkit\nwithout the need for reference signals. \n\n"}
{"id": "1811.00542", "contents": "Title: Pymc-learn: Practical Probabilistic Machine Learning in Python Abstract: $\\textit{Pymc-learn}$ is a Python package providing a variety of\nstate-of-the-art probabilistic models for supervised and unsupervised machine\nlearning. It is inspired by $\\textit{scikit-learn}$ and focuses on bringing\nprobabilistic machine learning to non-specialists. It uses a general-purpose\nhigh-level language that mimics $\\textit{scikit-learn}$. Emphasis is put on\nease of use, productivity, flexibility, performance, documentation, and an API\nconsistent with $\\textit{scikit-learn}$. It depends on $\\textit{scikit-learn}$\nand $\\textit{pymc3}$ and is distributed under the new BSD-3 license,\nencouraging its use in both academia and industry. Source code, binaries, and\ndocumentation are available on http://github.com/pymc-learn/pymc-learn. \n\n"}
{"id": "1811.01165", "contents": "Title: Convergence of the Deep BSDE Method for Coupled FBSDEs Abstract: The recently proposed numerical algorithm, deep BSDE method, has shown\nremarkable performance in solving high-dimensional forward-backward stochastic\ndifferential equations (FBSDEs) and parabolic partial differential equations\n(PDEs). This article lays a theoretical foundation for the deep BSDE method in\nthe general case of coupled FBSDEs. In particular, a posteriori error\nestimation of the solution is provided and it is proved that the error\nconverges to zero given the universal approximation capability of neural\nnetworks. Numerical results are presented to demonstrate the accuracy of the\nanalyzed algorithm in solving high-dimensional coupled FBSDEs. \n\n"}
{"id": "1811.01177", "contents": "Title: Smoothed Analysis of the Art Gallery Problem Abstract: In the Art Gallery Problem we are given a polygon $P\\subset [0,L]^2$ on $n$\nvertices and a number $k$. We want to find a guard set $G$ of size $k$, such\nthat each point in $P$ is seen by a guard in $G$. Formally, a guard $g$ sees a\npoint $p \\in P$ if the line segment $pg$ is fully contained inside the polygon\n$P$. The history and practical findings indicate that irrational coordinates\nare a \"very rare\" phenomenon. We give a theoretical explanation. Next to worst\ncase analysis, Smoothed Analysis gained popularity to explain the practical\nperformance of algorithms, even if they perform badly in the worst case. The\nidea is to study the expected performance on small perturbations of the worst\ninput. The performance is measured in terms of the magnitude $\\delta$ of the\nperturbation and the input size. We consider four different models of\nperturbation. We show that the expected number of bits to describe optimal\nguard positions per guard is logarithmic in the input and the magnitude of the\nperturbation. This shows from a theoretical perspective that rational guards\nwith small bit-complexity are typical. Note that describing the guard position\nis the bottleneck to show NP-membership. The significance of our results is\nthat algebraic methods are not needed to solve the Art Gallery Problem in\ntypical instances. This is the first time an $\\exists\\mathbb{R}$-complete\nproblem was analyzed by Smoothed Analysis. \n\n"}
{"id": "1811.01305", "contents": "Title: Block-wise Partitioning for Extreme Multi-label Classification Abstract: Extreme multi-label classification aims to learn a classifier that annotates\nan instance with a relevant subset of labels from an extremely large label set.\nMany existing solutions embed the label matrix to a low-dimensional linear\nsubspace, or examine the relevance of a test instance to every label via a\nlinear scan. In practice, however, those approaches can be computationally\nexorbitant. To alleviate this drawback, we propose a Block-wise Partitioning\n(BP) pretreatment that divides all instances into disjoint clusters, to each of\nwhich the most frequently tagged label subset is attached. One multi-label\nclassifier is trained on one pair of instance and label clusters, and the label\nset of a test instance is predicted by first delivering it to the most\nappropriate instance cluster. Experiments on benchmark multi-label data sets\nreveal that BP pretreatment significantly reduces prediction time, and retains\nalmost the same level of prediction accuracy. \n\n"}
{"id": "1811.01382", "contents": "Title: Neural CRF transducers for sequence labeling Abstract: Conditional random fields (CRFs) have been shown to be one of the most\nsuccessful approaches to sequence labeling. Various linear-chain neural CRFs\n(NCRFs) are developed to implement the non-linear node potentials in CRFs, but\nstill keeping the linear-chain hidden structure. In this paper, we propose NCRF\ntransducers, which consists of two RNNs, one extracting features from\nobservations and the other capturing (theoretically infinite) long-range\ndependencies between labels. Different sequence labeling methods are evaluated\nover POS tagging, chunking and NER (English, Dutch). Experiment results show\nthat NCRF transducers achieve consistent improvements over linear-chain NCRFs\nand RNN transducers across all the four tasks, and can improve state-of-the-art\nresults. \n\n"}
{"id": "1811.01885", "contents": "Title: Learning Two Layer Rectified Neural Networks in Polynomial Time Abstract: Consider the following fundamental learning problem: given input examples $x\n\\in \\mathbb{R}^d$ and their vector-valued labels, as defined by an underlying\ngenerative neural network, recover the weight matrices of this network. We\nconsider two-layer networks, mapping $\\mathbb{R}^d$ to $\\mathbb{R}^m$, with $k$\nnon-linear activation units $f(\\cdot)$, where $f(x) = \\max \\{x , 0\\}$ is the\nReLU. Such a network is specified by two weight matrices, $\\mathbf{U}^* \\in\n\\mathbb{R}^{m \\times k}, \\mathbf{V}^* \\in \\mathbb{R}^{k \\times d}$, such that\nthe label of an example $x \\in \\mathbb{R}^{d}$ is given by $\\mathbf{U}^*\nf(\\mathbf{V}^* x)$, where $f(\\cdot)$ is applied coordinate-wise. Given $n$\nsamples as a matrix $\\mathbf{X} \\in \\mathbb{R}^{d \\times n}$ and the (possibly\nnoisy) labels $\\mathbf{U}^* f(\\mathbf{V}^* \\mathbf{X}) + \\mathbf{E}$ of the\nnetwork on these samples, where $\\mathbf{E}$ is a noise matrix, our goal is to\nrecover the weight matrices $\\mathbf{U}^*$ and $\\mathbf{V}^*$.\n  In this work, we develop algorithms and hardness results under varying\nassumptions on the input and noise. Although the problem is NP-hard even for\n$k=2$, by assuming Gaussian marginals over the input $\\mathbf{X}$ we are able\nto develop polynomial time algorithms for the approximate recovery of\n$\\mathbf{U}^*$ and $\\mathbf{V}^*$. Perhaps surprisingly, in the noiseless case\nour algorithms recover $\\mathbf{U}^*,\\mathbf{V}^*$ exactly, i.e., with no\nerror. To the best of the our knowledge, this is the first algorithm to\naccomplish exact recovery. For the noisy case, we give the first polynomial\ntime algorithm that approximately recovers the weights in the presence of\nmean-zero noise $\\mathbf{E}$. Our algorithms generalize to a larger class of\nrectified activation functions, $f(x) = 0$ when $x\\leq 0$, and $f(x) > 0$\notherwise. \n\n"}
{"id": "1811.01903", "contents": "Title: Lower Bounds for Parallel and Randomized Convex Optimization Abstract: We study the question of whether parallelization in the exploration of the\nfeasible set can be used to speed up convex optimization, in the local oracle\nmodel of computation. We show that the answer is negative for both\ndeterministic and randomized algorithms applied to essentially any of the\ninteresting geometries and nonsmooth, weakly-smooth, or smooth objective\nfunctions. In particular, we show that it is not possible to obtain a\npolylogarithmic (in the sequential complexity of the problem) number of\nparallel rounds with a polynomial (in the dimension) number of queries per\nround. In the majority of these settings and when the dimension of the space is\npolynomial in the inverse target accuracy, our lower bounds match the oracle\ncomplexity of sequential convex optimization, up to at most a logarithmic\nfactor in the dimension, which makes them (nearly) tight. Prior to our work,\nlower bounds for parallel convex optimization algorithms were only known in a\nsmall fraction of the settings considered in this paper, mainly applying to\nEuclidean ($\\ell_2$) and $\\ell_\\infty$ spaces. Our work provides a more general\napproach for proving lower bounds in the setting of parallel convex\noptimization. \n\n"}
{"id": "1811.02023", "contents": "Title: Ordered Graph Limits and Their Applications Abstract: The emerging theory of graph limits exhibits an analytic perspective on\ngraphs, showing that many important concepts and tools in graph theory and its\napplications can be described more naturally (and sometimes proved more easily)\nin analytic language. We extend the theory of graph limits to the ordered\nsetting, presenting a limit object for dense vertex-ordered graphs, which we\ncall an orderon. As a special case, this yields limit objects for matrices\nwhose rows and columns are ordered, and for dynamic graphs that expand (via\nvertex insertions) over time. Along the way, we devise an ordered\nlocality-preserving variant of the cut distance between ordered graphs, showing\nthat two graphs are close with respect to this distance if and only if they are\nsimilar in terms of their ordered subgraph frequencies. We show that the space\nof orderons is compact with respect to this distance notion, which is key to a\nsuccessful analysis of combinatorial objects through their limits.\n  We derive several applications of the ordered limit theory in extremal\ncombinatorics, sampling, and property testing in ordered graphs. In particular,\nwe prove a new ordered analogue of the well-known result by Alon and Stav\n[RS\\&A'08] on the furthest graph from a hereditary property; this is the first\nknown result of this type in the ordered setting. Unlike the unordered regime,\nhere the random graph model $G(n, p)$ with an ordering over the vertices is not\nalways asymptotically the furthest from the property for some $p$. However,\nusing our ordered limit theory, we show that random graphs generated by a\nstochastic block model, where the blocks are consecutive in the vertex\nordering, are (approximately) the furthest. Additionally, we describe an\nalternative analytic proof of the ordered graph removal lemma [Alon et al.,\nFOCS'17]. \n\n"}
{"id": "1811.02089", "contents": "Title: Motif and Hypergraph Correlation Clustering Abstract: Motivated by applications in social and biological network analysis, we\nintroduce a new form of agnostic clustering termed~\\emph{motif correlation\nclustering}, which aims to minimize the cost of clustering errors associated\nwith both edges and higher-order network structures. The problem may be\nsuccinctly described as follows: Given a complete graph $G$, partition the\nvertices of the graph so that certain predetermined `important' subgraphs\nmostly lie within the same cluster, while `less relevant' subgraphs are allowed\nto lie across clusters. Our contributions are as follows: We first introduce\nseveral variants of motif correlation clustering and then show that these\nclustering problems are NP-hard. We then proceed to describe polynomial-time\nclustering algorithms that provide constant approximation guarantees for the\nproblems at hand. Despite following the frequently used LP relaxation and\nrounding procedure, the algorithms involve a sophisticated and carefully\ndesigned neighborhood growing step that combines information about both edge\nand motif structures. We conclude with several examples illustrating the\nperformance of the developed algorithms on synthetic and real networks. \n\n"}
{"id": "1811.02166", "contents": "Title: DIAG-NRE: A Neural Pattern Diagnosis Framework for Distantly Supervised\n  Neural Relation Extraction Abstract: Pattern-based labeling methods have achieved promising results in alleviating\nthe inevitable labeling noises of distantly supervised neural relation\nextraction. However, these methods require significant expert labor to write\nrelation-specific patterns, which makes them too sophisticated to generalize\nquickly.To ease the labor-intensive workload of pattern writing and enable the\nquick generalization to new relation types, we propose a neural pattern\ndiagnosis framework, DIAG-NRE, that can automatically summarize and refine\nhigh-quality relational patterns from noise data with human experts in the\nloop. To demonstrate the effectiveness of DIAG-NRE, we apply it to two\nreal-world datasets and present both significant and interpretable improvements\nover state-of-the-art methods. \n\n"}
{"id": "1811.02314", "contents": "Title: Kernel Regression for Graph Signal Prediction in Presence of Sparse\n  Noise Abstract: In presence of sparse noise we propose kernel regression for predicting\noutput vectors which are smooth over a given graph. Sparse noise models the\ntraining outputs being corrupted either with missing samples or large\nperturbations. The presence of sparse noise is handled using appropriate use of\n$\\ell_1$-norm along-with use of $\\ell_2$-norm in a convex cost function. For\noptimization of the cost function, we propose an iteratively reweighted\nleast-squares (IRLS) approach that is suitable for kernel substitution or\nkernel trick due to availability of a closed form solution. Simulations using\nreal-world temperature data show efficacy of our proposed method, mainly for\nlimited-size training datasets. \n\n"}
{"id": "1811.02459", "contents": "Title: Nonlinear Evolution via Spatially-Dependent Linear Dynamics for\n  Electrophysiology and Calcium Data Abstract: Latent variable models have been widely applied for the analysis of time\nseries resulting from experimental neuroscience techniques. In these datasets,\nobservations are relatively smooth and possibly nonlinear. We present\nVariational Inference for Nonlinear Dynamics (VIND), a variational inference\nframework that is able to uncover nonlinear, smooth latent dynamics from\nsequential data. The framework is a direct extension of PfLDS; including a\nstructured approximate posterior describing spatially-dependent linear\ndynamics, as well as an algorithm that relies on the fixed-point iteration\nmethod to achieve convergence. We apply VIND to electrophysiology, single-cell\nvoltage and widefield imaging datasets with state-of-the-art results in\nreconstruction error. In single-cell voltage data, VIND finds a 5D latent\nspace, with variables akin to those of Hodgkin-Huxley-like models. VIND's\nlearned dynamics are further quantified by predicting future neural activity.\nVIND excels in this task, in some cases substantially outperforming current\nmethods. \n\n"}
{"id": "1811.02657", "contents": "Title: A Bayesian Perspective of Convolutional Neural Networks through a\n  Deconvolutional Generative Model Abstract: Inspired by the success of Convolutional Neural Networks (CNNs) for\nsupervised prediction in images, we design the Deconvolutional Generative Model\n(DGM), a new probabilistic generative model whose inference calculations\ncorrespond to those in a given CNN architecture. The DGM uses a CNN to design\nthe prior distribution in the probabilistic model. Furthermore, the DGM\ngenerates images from coarse to finer scales. It introduces a small set of\nlatent variables at each scale, and enforces dependencies among all the latent\nvariables via a conjugate prior distribution. This conjugate prior yields a new\nregularizer based on paths rendered in the generative model for training\nCNNs-the Rendering Path Normalization (RPN). We demonstrate that this\nregularizer improves generalization, both in theory and in practice. In\naddition, likelihood estimation in the DGM yields training losses for CNNs, and\ninspired by this, we design a new loss termed as the Max-Min cross entropy\nwhich outperforms the traditional cross-entropy loss for object classification.\nThe Max-Min cross entropy suggests a new deep network architecture, namely the\nMax-Min network, which can learn from less labeled data while maintaining good\nprediction performance. Our experiments demonstrate that the DGM with the RPN\nand the Max-Min architecture exceeds or matches the-state-of-art on benchmarks\nincluding SVHN, CIFAR10, and CIFAR100 for semi-supervised and supervised\nlearning tasks. \n\n"}
{"id": "1811.03195", "contents": "Title: Performance of Johnson-Lindenstrauss Transform for k-Means and k-Medians\n  Clustering Abstract: Consider an instance of Euclidean $k$-means or $k$-medians clustering. We\nshow that the cost of the optimal solution is preserved up to a factor of\n$(1+\\varepsilon)$ under a projection onto a random $O(\\log(k / \\varepsilon) /\n\\varepsilon^2)$-dimensional subspace. Further, the cost of every clustering is\npreserved within $(1+\\varepsilon)$. More generally, our result applies to any\ndimension reduction map satisfying a mild sub-Gaussian-tail condition. Our\nbound on the dimension is nearly optimal. Additionally, our result applies to\nEuclidean $k$-clustering with the distances raised to the $p$-th power for any\nconstant $p$.\n  For $k$-means, our result resolves an open problem posed by Cohen, Elder,\nMusco, Musco, and Persu (STOC 2015); for $k$-medians, it answers a question\nraised by Kannan. \n\n"}
{"id": "1811.03666", "contents": "Title: Statistical Characteristics of Deep Representations: An Empirical\n  Investigation Abstract: In this study, the effects of eight representation regularization methods are\ninvestigated, including two newly developed rank regularizers (RR). The\ninvestigation shows that the statistical characteristics of representations\nsuch as correlation, sparsity, and rank can be manipulated as intended, during\ntraining. Furthermore, it is possible to improve the baseline performance\nsimply by trying all the representation regularizers and fine-tuning the\nstrength of their effects. In contrast to performance improvement, no\nconsistent relationship between performance and statistical characteristics was\nobservable. The results indicate that manipulation of statistical\ncharacteristics can be helpful for improving performance, but only indirectly\nthrough its influence on learning dynamics or its tuning effects. \n\n"}
{"id": "1811.03804", "contents": "Title: Gradient Descent Finds Global Minima of Deep Neural Networks Abstract: Gradient descent finds a global minimum in training deep neural networks\ndespite the objective function being non-convex. The current paper proves\ngradient descent achieves zero training loss in polynomial time for a deep\nover-parameterized neural network with residual connections (ResNet). Our\nanalysis relies on the particular structure of the Gram matrix induced by the\nneural network architecture. This structure allows us to show the Gram matrix\nis stable throughout the training process and this stability implies the global\noptimality of the gradient descent algorithm. We further extend our analysis to\ndeep residual convolutional neural networks and obtain a similar convergence\nresult. \n\n"}
{"id": "1811.04017", "contents": "Title: A generic framework for privacy preserving deep learning Abstract: We detail a new framework for privacy preserving deep learning and discuss\nits assets. The framework puts a premium on ownership and secure processing of\ndata and introduces a valuable representation based on chains of commands and\ntensors. This abstraction allows one to implement complex privacy preserving\nconstructs such as Federated Learning, Secure Multiparty Computation, and\nDifferential Privacy while still exposing a familiar deep learning API to the\nend-user. We report early results on the Boston Housing and Pima Indian\nDiabetes datasets. While the privacy features apart from Differential Privacy\ndo not impact the prediction accuracy, the current implementation of the\nframework introduces a significant overhead in performance, which will be\naddressed at a later stage of the development. We believe this work is an\nimportant milestone introducing the first reliable, general framework for\nprivacy preserving deep learning. \n\n"}
{"id": "1811.04022", "contents": "Title: Convolutional neural networks in phase space and inverse problems Abstract: We study inverse problems consisting on determining medium properties using\nthe responses to probing waves from the machine learning point of view. Based\non the understanding of propagation of waves and their nonlinear interactions,\nwe construct a deep convolutional neural network in which the parameters are\nused to classify and reconstruct the coefficients of nonlinear wave equations\nthat model the medium properties. Furthermore, for given approximation\naccuracy, we obtain the depth and number of units of the network and their\nquantitative dependence on the complexity of the medium. \n\n"}
{"id": "1811.04064", "contents": "Title: Block Belief Propagation for Parameter Learning in Markov Random Fields Abstract: Traditional learning methods for training Markov random fields require doing\ninference over all variables to compute the likelihood gradient. The iteration\ncomplexity for those methods therefore scales with the size of the graphical\nmodels. In this paper, we propose \\emph{block belief propagation learning}\n(BBPL), which uses block-coordinate updates of approximate marginals to compute\napproximate gradients, removing the need to compute inference on the entire\ngraphical model. Thus, the iteration complexity of BBPL does not scale with the\nsize of the graphs. We prove that the method converges to the same solution as\nthat obtained by using full inference per iteration, despite these\napproximations, and we empirically demonstrate its scalability improvements\nover standard training methods. \n\n"}
{"id": "1811.04852", "contents": "Title: Quantum-inspired sublinear classical algorithms for solving low-rank\n  linear systems Abstract: We present classical sublinear-time algorithms for solving low-rank linear\nsystems of equations. Our algorithms are inspired by the HHL quantum algorithm\nfor solving linear systems and the recent breakthrough by Tang of dequantizing\nthe quantum algorithm for recommendation systems. Let $A \\in \\mathbb{C}^{m\n\\times n}$ be a rank-$k$ matrix, and $b \\in \\mathbb{C}^m$ be a vector. We\npresent two algorithms: a \"sampling\" algorithm that provides a sample from\n$A^{-1}b$ and a \"query\" algorithm that outputs an estimate of an entry of\n$A^{-1}b$, where $A^{-1}$ denotes the Moore-Penrose pseudo-inverse. Both of our\nalgorithms have query and time complexity $O(\\mathrm{poly}(k, \\kappa, \\|A\\|_F,\n1/\\epsilon)\\,\\mathrm{polylog}(m, n))$, where $\\kappa$ is the condition number\nof $A$ and $\\epsilon$ is the precision parameter. Note that the algorithms we\nconsider are sublinear time, so they cannot write and read the whole matrix or\nvectors. In this paper, we assume that $A$ and $b$ come with well-known\nlow-overhead data structures such that entries of $A$ and $b$ can be sampled\naccording to some natural probability distributions. Alternatively, when $A$ is\npositive semidefinite, our algorithms can be adapted so that the sampling\nassumption on $b$ is not required. \n\n"}
{"id": "1811.05121", "contents": "Title: Modeling Local Dependence in Natural Language with Multi-channel\n  Recurrent Neural Networks Abstract: Recurrent Neural Networks (RNNs) have been widely used in processing natural\nlanguage tasks and achieve huge success. Traditional RNNs usually treat each\ntoken in a sentence uniformly and equally. However, this may miss the rich\nsemantic structure information of a sentence, which is useful for understanding\nnatural languages. Since semantic structures such as word dependence patterns\nare not parameterized, it is a challenge to capture and leverage structure\ninformation. In this paper, we propose an improved variant of RNN,\nMulti-Channel RNN (MC-RNN), to dynamically capture and leverage local semantic\nstructure information. Concretely, MC-RNN contains multiple channels, each of\nwhich represents a local dependence pattern at a time. An attention mechanism\nis introduced to combine these patterns at each step, according to the semantic\ninformation. Then we parameterize structure information by adaptively selecting\nthe most appropriate connection structures among channels. In this way, diverse\nlocal structures and dependence patterns in sentences can be well captured by\nMC-RNN. To verify the effectiveness of MC-RNN, we conduct extensive experiments\non typical natural language processing tasks, including neural machine\ntranslation, abstractive summarization, and language modeling. Experimental\nresults on these tasks all show significant improvements of MC-RNN over current\ntop systems. \n\n"}
{"id": "1811.05592", "contents": "Title: Controllability, Multiplexing, and Transfer Learning in Networks using\n  Evolutionary Learning Abstract: Networks are fundamental building blocks for representing data, and\ncomputations. Remarkable progress in learning in structurally defined (shallow\nor deep) networks has recently been achieved. Here we introduce evolutionary\nexploratory search and learning method of topologically flexible networks under\nthe constraint of producing elementary computational steady-state input-output\noperations.\n  Our results include; (1) the identification of networks, over four orders of\nmagnitude, implementing computation of steady-state input-output functions,\nsuch as a band-pass filter, a threshold function, and an inverse band-pass\nfunction. Next, (2) the learned networks are technically controllable as only a\nsmall number of driver nodes are required to move the system to a new state.\nFurthermore, we find that the fraction of required driver nodes is constant\nduring evolutionary learning, suggesting a stable system design. (3), our\nframework allows multiplexing of different computations using the same network.\nFor example, using a binary representation of the inputs, the network can\nreadily compute three different input-output functions. Finally, (4) the\nproposed evolutionary learning demonstrates transfer learning. If the system\nlearns one function A, then learning B requires on average less number of steps\nas compared to learning B from tabula rasa.\n  We conclude that the constrained evolutionary learning produces large robust\ncontrollable circuits, capable of multiplexing and transfer learning. Our study\nsuggests that network-based computations of steady-state functions,\nrepresenting either cellular modules of cell-to-cell communication networks or\ninternal molecular circuits communicating within a cell, could be a powerful\nmodel for biologically inspired computing. This complements conceptualizations\nsuch as attractor based models, or reservoir computing. \n\n"}
{"id": "1811.05852", "contents": "Title: Predicting the time-evolution of multi-physics systems with\n  sequence-to-sequence models Abstract: In this work, sequence-to-sequence (seq2seq) models, originally developed for\nlanguage translation, are used to predict the temporal evolution of complex,\nmulti-physics computer simulations. The predictive performance of seq2seq\nmodels is compared to state transition models for datasets generated with\nmulti-physics codes with varying levels of complexity - from simple 1D\ndiffusion calculations to simulations of inertial confinement fusion\nimplosions. Seq2seq models demonstrate the ability to accurately emulate\ncomplex systems, enabling the rapid estimation of the evolution of quantities\nof interest in computationally expensive simulations. \n\n"}
{"id": "1811.05933", "contents": "Title: Deep Nonlinear Non-Gaussian Filtering for Dynamical Systems Abstract: Filtering is a general name for inferring the states of a dynamical system\ngiven observations. The most common filtering approach is Gaussian Filtering\n(GF) where the distribution of the inferred states is a Gaussian whose mean is\nan affine function of the observations. There are two restrictions in this\nmodel: Gaussianity and Affinity. We propose a model to relax both these\nassumptions based on recent advances in implicit generative models. Empirical\nresults show that the proposed method gives a significant advantage over GF and\nnonlinear methods based on fixed nonlinear kernels. \n\n"}
{"id": "1811.06026", "contents": "Title: Incentivizing Exploration with Selective Data Disclosure Abstract: We propose and design recommendation systems that incentivize efficient\nexploration. Agents arrive sequentially, choose actions and receive rewards,\ndrawn from fixed but unknown action-specific distributions. The recommendation\nsystem presents each agent with actions and rewards from a subsequence of past\nagents, chosen ex ante. Thus, the agents engage in sequential social learning,\nmoderated by these subsequences. We asymptotically attain optimal regret rate\nfor exploration, using a flexible frequentist behavioral model and mitigating\nrationality and commitment assumptions inherent in prior work. We suggest three\ncomponents of effective recommendation systems: independent focus groups, group\naggregators, and interlaced information structures. \n\n"}
{"id": "1811.06580", "contents": "Title: Subspace Clustering through Sub-Clusters Abstract: The problem of dimension reduction is of increasing importance in modern data\nanalysis. In this paper, we consider modeling the collection of points in a\nhigh dimensional space as a union of low dimensional subspaces. In particular\nwe propose a highly scalable sampling based algorithm that clusters the entire\ndata via first spectral clustering of a small random sample followed by\nclassifying or labeling the remaining out of sample points. The key idea is\nthat this random subset borrows information across the entire data set and that\nthe problem of clustering points can be replaced with the more efficient and\nrobust problem of \"clustering sub-clusters\". We provide theoretical guarantees\nfor our procedure. The numerical results indicate we outperform other\nstate-of-the-art subspace clustering algorithms with respect to accuracy and\nspeed. \n\n"}
{"id": "1811.06603", "contents": "Title: Unconstrained Submodular Maximization with Constant Adaptive Complexity Abstract: In this paper, we consider the unconstrained submodular maximization problem.\nWe propose the first algorithm for this problem that achieves a tight\n$(1/2-\\varepsilon)$-approximation guarantee using $\\tilde{O}(\\varepsilon^{-1})$\nadaptive rounds and a linear number of function evaluations. No previously\nknown algorithm for this problem achieves an approximation ratio better than\n$1/3$ using less than $\\Omega(n)$ rounds of adaptivity, where $n$ is the size\nof the ground set. Moreover, our algorithm easily extends to the maximization\nof a non-negative continuous DR-submodular function subject to a box constraint\nand achieves a tight $(1/2-\\varepsilon)$-approximation guarantee for this\nproblem while keeping the same adaptive and query complexities. \n\n"}
{"id": "1811.07051", "contents": "Title: Symmetry constrained machine learning Abstract: Symmetry, a central concept in understanding the laws of nature, has been\nused for centuries in physics, mathematics, and chemistry, to help make\nmathematical models tractable. Yet, despite its power, symmetry has not been\nused extensively in machine learning, until rather recently. In this article we\nshow a general way to incorporate symmetries into machine learning models. We\ndemonstrate this with a detailed analysis on a rather simple real world machine\nlearning system - a neural network for classifying handwritten digits, lacking\nbias terms for every neuron. We demonstrate that ignoring symmetries can have\ndire over-fitting consequences, and that incorporating symmetry into the model\nreduces over-fitting, while at the same time reducing complexity, ultimately\nrequiring less training data, and taking less time and resources to train. \n\n"}
{"id": "1811.07234", "contents": "Title: Improving Automatic Source Code Summarization via Deep Reinforcement\n  Learning Abstract: Code summarization provides a high level natural language description of the\nfunction performed by code, as it can benefit the software maintenance, code\ncategorization and retrieval. To the best of our knowledge, most\nstate-of-the-art approaches follow an encoder-decoder framework which encodes\nthe code into a hidden space and then decode it into natural language space,\nsuffering from two major drawbacks: a) Their encoders only consider the\nsequential content of code, ignoring the tree structure which is also critical\nfor the task of code summarization, b) Their decoders are typically trained to\npredict the next word by maximizing the likelihood of next ground-truth word\nwith previous ground-truth word given. However, it is expected to generate the\nentire sequence from scratch at test time. This discrepancy can cause an\n\\textit{exposure bias} issue, making the learnt decoder suboptimal. In this\npaper, we incorporate an abstract syntax tree structure as well as sequential\ncontent of code snippets into a deep reinforcement learning framework (i.e.,\nactor-critic network). The actor network provides the confidence of predicting\nthe next word according to current state. On the other hand, the critic network\nevaluates the reward value of all possible extensions of the current state and\ncan provide global guidance for explorations. We employ an advantage reward\ncomposed of BLEU metric to train both networks. Comprehensive experiments on a\nreal-world dataset show the effectiveness of our proposed model when compared\nwith some state-of-the-art methods. \n\n"}
{"id": "1811.07253", "contents": "Title: Quantifying Uncertainties in Natural Language Processing Tasks Abstract: Reliable uncertainty quantification is a first step towards building\nexplainable, transparent, and accountable artificial intelligent systems.\nRecent progress in Bayesian deep learning has made such quantification\nrealizable. In this paper, we propose novel methods to study the benefits of\ncharacterizing model and data uncertainties for natural language processing\n(NLP) tasks. With empirical experiments on sentiment analysis, named entity\nrecognition, and language modeling using convolutional and recurrent neural\nnetwork models, we show that explicitly modeling uncertainties is not only\nnecessary to measure output confidence levels, but also useful at enhancing\nmodel performances in various NLP tasks. \n\n"}
{"id": "1811.07484", "contents": "Title: Sharpen Focus: Learning with Attention Separability and Consistency Abstract: Recent developments in gradient-based attention modeling have seen attention\nmaps emerge as a powerful tool for interpreting convolutional neural networks.\nDespite good localization for an individual class of interest, these techniques\nproduce attention maps with substantially overlapping responses among different\nclasses, leading to the problem of visual confusion and the need for\ndiscriminative attention. In this paper, we address this problem by means of a\nnew framework that makes class-discriminative attention a principled part of\nthe learning process. Our key innovations include new learning objectives for\nattention separability and cross-layer consistency, which result in improved\nattention discriminability and reduced visual confusion. Extensive experiments\non image classification benchmarks show the effectiveness of our approach in\nterms of improved classification accuracy, including CIFAR-100 (+3.33%),\nCaltech-256 (+1.64%), ILSVRC2012 (+0.92%), CUB-200-2011 (+4.8%) and PASCAL\nVOC2012 (+5.73%). \n\n"}
{"id": "1811.07579", "contents": "Title: Deep Active Learning with a Neural Architecture Search Abstract: We consider active learning of deep neural networks. Most active learning\nworks in this context have focused on studying effective querying mechanisms\nand assumed that an appropriate network architecture is a priori known for the\nproblem at hand. We challenge this assumption and propose a novel active\nstrategy whereby the learning algorithm searches for effective architectures on\nthe fly, while actively learning. We apply our strategy using three known\nquerying techniques (softmax response, MC-dropout, and coresets) and show that\nthe proposed approach overwhelmingly outperforms active learning using fixed\narchitectures. \n\n"}
{"id": "1811.07624", "contents": "Title: Approximate Eigenvalue Decompositions of Linear Transformations with a\n  Few Householder Reflectors Abstract: The ability to decompose a signal in an orthonormal basis (a set of\northogonal components, each normalized to have unit length) using a fast\nnumerical procedure rests at the heart of many signal processing methods and\napplications. The classic examples are the Fourier and wavelet transforms that\nenjoy numerically efficient implementations (FFT and FWT, respectively).\nUnfortunately, orthonormal transformations are in general unstructured, and\ntherefore they do not enjoy low computational complexity properties. In this\npaper, based on Householder reflectors, we introduce a class of orthonormal\nmatrices that are numerically efficient to manipulate: we control the\ncomplexity of matrix-vector multiplications with these matrices using a given\nparameter. We provide numerical algorithms that approximate any orthonormal or\nsymmetric transform with a new orthonormal or symmetric structure made up of\nproducts of a given number of Householder reflectors. We show analyses and\nnumerical evidence to highlight the accuracy of the proposed approximations and\nprovide an application to the case of learning fast Mahanalobis distance metric\ntransformations. \n\n"}
{"id": "1811.07630", "contents": "Title: SEIGAN: Towards Compositional Image Generation by Simultaneously\n  Learning to Segment, Enhance, and Inpaint Abstract: We present a novel approach to image manipulation and understanding by\nsimultaneously learning to segment object masks, paste objects to another\nbackground image, and remove them from original images. For this purpose, we\ndevelop a novel generative model for compositional image generation, SEIGAN\n(Segment-Enhance-Inpaint Generative Adversarial Network), which learns these\nthree operations together in an adversarial architecture with additional cycle\nconsistency losses. To train, SEIGAN needs only bounding box supervision and\ndoes not require pairing or ground truth masks. SEIGAN produces better\ngenerated images (evaluated by human assessors) than other approaches and\nproduces high-quality segmentation masks, improving over other adversarially\ntrained approaches and getting closer to the results of fully supervised\ntraining. \n\n"}
{"id": "1811.09300", "contents": "Title: Strength in Numbers: Trading-off Robustness and Computation via\n  Adversarially-Trained Ensembles Abstract: While deep learning has led to remarkable results on a number of challenging\nproblems, researchers have discovered a vulnerability of neural networks in\nadversarial settings, where small but carefully chosen perturbations to the\ninput can make the models produce extremely inaccurate outputs. This makes\nthese models particularly unsuitable for safety-critical application domains\n(e.g. self-driving cars) where robustness is extremely important. Recent work\nhas shown that augmenting training with adversarially generated data provides\nsome degree of robustness against test-time attacks. In this paper we\ninvestigate how this approach scales as we increase the computational budget\ngiven to the defender. We show that increasing the number of parameters in\nadversarially-trained models increases their robustness, and in particular that\nensembling smaller models while adversarially training the entire ensemble as a\nsingle model is a more efficient way of spending said budget than simply using\na larger single model. Crucially, we show that it is the adversarial training\nof the ensemble, rather than the ensembling of adversarially trained models,\nwhich provides robustness. \n\n"}
{"id": "1811.09740", "contents": "Title: Connecting the Dots Between MLE and RL for Sequence Prediction Abstract: Sequence prediction models can be learned from example sequences with a\nvariety of training algorithms. Maximum likelihood learning is simple and\nefficient, yet can suffer from compounding error at test time. Reinforcement\nlearning such as policy gradient addresses the issue but can have prohibitively\npoor exploration efficiency. A rich set of other algorithms such as RAML, SPG,\nand data noising, have also been developed from different perspectives. This\npaper establishes a formal connection between these algorithms. We present a\ngeneralized entropy regularized policy optimization formulation, and show that\nthe apparently distinct algorithms can all be reformulated as special instances\nof the framework, with the only difference being the configurations of a reward\nfunction and a couple of hyperparameters. The unified interpretation offers a\nsystematic view of the varying properties of exploration and learning\nefficiency. Besides, inspired from the framework, we present a new algorithm\nthat dynamically interpolates among the family of algorithms for scheduled\nsequence model learning. Experiments on machine translation, text\nsummarization, and game imitation learning demonstrate the superiority of the\nproposed algorithm. \n\n"}
{"id": "1811.09751", "contents": "Title: Characterizing and Avoiding Negative Transfer Abstract: When labeled data is scarce for a specific target task, transfer learning\noften offers an effective solution by utilizing data from a related source\ntask. However, when transferring knowledge from a less related source, it may\ninversely hurt the target performance, a phenomenon known as negative transfer.\nDespite its pervasiveness, negative transfer is usually described in an\ninformal manner, lacking rigorous definition, careful analysis, or systematic\ntreatment. This paper proposes a formal definition of negative transfer and\nanalyzes three important aspects thereof. Stemming from this analysis, a novel\ntechnique is proposed to circumvent negative transfer by filtering out\nunrelated source data. Based on adversarial networks, the technique is highly\ngeneric and can be applied to a wide range of transfer learning algorithms. The\nproposed approach is evaluated on six state-of-the-art deep transfer methods\nvia experiments on four benchmark datasets with varying levels of difficulty.\nEmpirically, the proposed method consistently improves the performance of all\nbaseline methods and largely avoids negative transfer, even when the source\ndata is degenerate. \n\n"}
{"id": "1811.09906", "contents": "Title: Efficient constructions of convex combinations for 2-edge-connected\n  subgraphs on fundamental classes Abstract: Finding the exact integrality gap $\\alpha$ for the LP relaxation of the\n2-edge-connected spanning multigraph problem (2EC) is closely related to the\nsame problem for the Held-Karp relaxation of the metric traveling salesman\nproblem (TSP). While the former problem seems easier than the latter, since it\nis less constrained, currently the upper bounds on the respective integrality\ngaps for the two problems are the same.\n  An approach to proving integrality gaps for both of these problems is to\nconsider fundamental classes of extreme points. For 2EC, better bounds on the\nintegrality gap are known for certain important special cases of these\nfundamental points. For example, for half-integer square points, the\nintegrality gap is between $\\frac{6}{5}$ and $\\frac{4}{3}$. Our main result is\nto improve the approximation factor to $\\frac{9}{7}$ for 2EC for these points.\nOur approach is based on constructing convex combinations and our key tool is\nthe top-down coloring framework for tree augmentation, whose flexibility we\nemploy to exploit beneficial properties in both the initial spanning tree and\nin the input graph. We also show how these tools can be tailored to the closely\nrelated problem of uniform covers for which the proofs of the best-known bounds\ndo not yield polynomial-time algorithms. Another key ingredient is to use a\nrainbow spanning tree decomposition, which allows us to obtain a convex\ncombination of spanning trees with particular properties \n\n"}
{"id": "1811.10154", "contents": "Title: Stop Explaining Black Box Machine Learning Models for High Stakes\n  Decisions and Use Interpretable Models Instead Abstract: Black box machine learning models are currently being used for high stakes\ndecision-making throughout society, causing problems throughout healthcare,\ncriminal justice, and in other domains. People have hoped that creating methods\nfor explaining these black box models will alleviate some of these problems,\nbut trying to \\textit{explain} black box models, rather than creating models\nthat are \\textit{interpretable} in the first place, is likely to perpetuate bad\npractices and can potentially cause catastrophic harm to society. There is a\nway forward -- it is to design models that are inherently interpretable. This\nmanuscript clarifies the chasm between explaining black boxes and using\ninherently interpretable models, outlines several key reasons why explainable\nblack boxes should be avoided in high-stakes decisions, identifies challenges\nto interpretable machine learning, and provides several example applications\nwhere interpretable models could potentially replace black box models in\ncriminal justice, healthcare, and computer vision. \n\n"}
{"id": "1811.11067", "contents": "Title: Learning State Representations in Complex Systems with Multimodal Data Abstract: Representation learning becomes especially important for complex systems with\nmultimodal data sources such as cameras or sensors. Recent advances in\nreinforcement learning and optimal control make it possible to design control\nalgorithms on these latent representations, but the field still lacks a\nlarge-scale standard dataset for unified comparison. In this work, we present a\nlarge-scale dataset and evaluation framework for representation learning for\nthe complex task of landing an airplane. We implement and compare several\napproaches to representation learning on this dataset in terms of the quality\nof simple supervised learning tasks and disentanglement scores. The resulting\nrepresentations can be used for further tasks such as anomaly detection,\noptimal control, model-based reinforcement learning, and other applications. \n\n"}
{"id": "1811.11103", "contents": "Title: Bayesian graph convolutional neural networks for semi-supervised\n  classification Abstract: Recently, techniques for applying convolutional neural networks to\ngraph-structured data have emerged. Graph convolutional neural networks (GCNNs)\nhave been used to address node and graph classification and matrix completion.\nAlthough the performance has been impressive, the current implementations have\nlimited capability to incorporate uncertainty in the graph structure. Almost\nall GCNNs process a graph as though it is a ground-truth depiction of the\nrelationship between nodes, but often the graphs employed in applications are\nthemselves derived from noisy data or modelling assumptions. Spurious edges may\nbe included; other edges may be missing between nodes that have very strong\nrelationships. In this paper we adopt a Bayesian approach, viewing the observed\ngraph as a realization from a parametric family of random graphs. We then\ntarget inference of the joint posterior of the random graph parameters and the\nnode (or graph) labels. We present the Bayesian GCNN framework and develop an\niterative learning procedure for the case of assortative mixed-membership\nstochastic block models. We present the results of experiments that demonstrate\nthat the Bayesian formulation can provide better performance when there are\nvery few labels available during the training process. \n\n"}
{"id": "1811.11210", "contents": "Title: Calibrating Uncertainties in Object Localization Task Abstract: In many safety-critical applications such as autonomous driving and surgical\nrobots, it is desirable to obtain prediction uncertainties from object\ndetection modules to help support safe decision-making. Specifically, such\nmodules need to estimate the probability of each predicted object in a given\nregion and the confidence interval for its bounding box. While recent Bayesian\ndeep learning methods provide a principled way to estimate this uncertainty,\nthe estimates for the bounding boxes obtained using these methods are\nuncalibrated. In this paper, we address this problem for the single-object\nlocalization task by adapting an existing technique for calibrating regression\nmodels. We show, experimentally, that the resulting calibrated model obtains\nmore reliable uncertainty estimates. \n\n"}
{"id": "1811.11368", "contents": "Title: First-order Newton-type Estimator for Distributed Estimation and\n  Inference Abstract: This paper studies distributed estimation and inference for a general\nstatistical problem with a convex loss that could be non-differentiable. For\nthe purpose of efficient computation, we restrict ourselves to stochastic\nfirst-order optimization, which enjoys low per-iteration complexity. To\nmotivate the proposed method, we first investigate the theoretical properties\nof a straightforward Divide-and-Conquer Stochastic Gradient Descent (DC-SGD)\napproach. Our theory shows that there is a restriction on the number of\nmachines and this restriction becomes more stringent when the dimension $p$ is\nlarge. To overcome this limitation, this paper proposes a new multi-round\ndistributed estimation procedure that approximates the Newton step only using\nstochastic subgradient. The key component in our method is the proposal of a\ncomputationally efficient estimator of $\\Sigma^{-1} w$, where $\\Sigma$ is the\npopulation Hessian matrix and $w$ is any given vector. Instead of estimating\n$\\Sigma$ (or $\\Sigma^{-1}$) that usually requires the second-order\ndifferentiability of the loss, the proposed First-Order Newton-type Estimator\n(FONE) directly estimates the vector of interest $\\Sigma^{-1} w$ as a whole and\nis applicable to non-differentiable losses. Our estimator also facilitates the\ninference for the empirical risk minimizer. It turns out that the key term in\nthe limiting covariance has the form of $\\Sigma^{-1} w$, which can be estimated\nby FONE. \n\n"}
{"id": "1811.11419", "contents": "Title: Mixture Martingales Revisited with Applications to Sequential Tests and\n  Confidence Intervals Abstract: This paper presents new deviation inequalities that are valid uniformly in\ntime under adaptive sampling in a multi-armed bandit model. The deviations are\nmeasured using the Kullback-Leibler divergence in a given one-dimensional\nexponential family, and may take into account several arms at a time. They are\nobtained by constructing for each arm a mixture martingale based on a\nhierarchical prior, and by multiplying those martingales. Our deviation\ninequalities allow us to analyze stopping rules based on generalized likelihood\nratios for a large class of sequential identification problems, and to\nconstruct tight confidence intervals for some functions of the means of the\narms. \n\n"}
{"id": "1811.11549", "contents": "Title: $HS^2$: Active Learning over Hypergraphs Abstract: We propose a hypergraph-based active learning scheme which we term $HS^2$,\n$HS^2$ generalizes the previously reported algorithm $S^2$ originally proposed\nfor graph-based active learning with pointwise queries [Dasarathy et al., COLT\n2015]. Our $HS^2$ method can accommodate hypergraph structures and allows one\nto ask both pointwise queries and pairwise queries. Based on a novel parametric\nsystem particularly designed for hypergraphs, we derive theoretical results on\nthe query complexity of $HS^2$ for the above described generalized settings.\nBoth the theoretical and empirical results show that $HS^2$ requires a\nsignificantly fewer number of queries than $S^2$ when one uses $S^2$ over a\ngraph obtained from the corresponding hypergraph via clique expansion. \n\n"}
{"id": "1811.11674", "contents": "Title: Interlacing Personal and Reference Genomes for Machine Learning\n  Disease-Variant Detection Abstract: DNA sequencing to identify genetic variants is becoming increasingly valuable\nin clinical settings. Assessment of variants in such sequencing data is\ncommonly implemented through Bayesian heuristic algorithms. Machine learning\nhas shown great promise in improving on these variant calls, but the input for\nthese is still a standardized \"pile-up\" image, which is not always best suited.\nIn this paper, we present a novel method for generating images from DNA\nsequencing data, which interlaces the human reference genome with personalized\nsequencing output, to maximize usage of sequencing reads and improve machine\nlearning algorithm performance. We demonstrate the success of this in improving\nstandard germline variant calling. We also furthered this approach to include\nsomatic variant calling across tumor/normal data with Siamese networks. These\napproaches can be used in machine learning applications on sequencing data with\nthe hope of improving clinical outcomes, and are freely available for\nnoncommercial use at www.ccg.ai. \n\n"}
{"id": "1811.12081", "contents": "Title: Deep Haar Scattering Networks in Pattern Recognition: A promising\n  approach Abstract: The aim of this paper is to discuss the use of Haar scattering networks,\nwhich is a very simple architecture that naturally supports a large number of\nstacked layers, yet with very few parameters, in a relatively broad set of\npattern recognition problems, including regression and classification tasks.\nThis architecture, basically, consists of stacking convolutional filters, that\ncan be thought as a generalization of Haar wavelets, followed by non-linear\noperators which aim to extract symmetries and invariances that are later fed in\na classification/regression algorithm. We show that good results can be\nobtained with the proposed method for both kind of tasks. We have outperformed\nthe best available algorithms in 4 out of 18 important data classification\nproblems, and have obtained a more robust performance than ARIMA and ETS time\nseries methods in regression problems for data with strong periodicities. \n\n"}
{"id": "1811.12276", "contents": "Title: Improving Hospital Mortality Prediction with Medical Named Entities and\n  Multimodal Learning Abstract: Clinical text provides essential information to estimate the acuity of a\npatient during hospital stays in addition to structured clinical data. In this\nstudy, we explore how clinical text can complement a clinical predictive\nlearning task. We leverage an internal medical natural language processing\nservice to perform named entity extraction and negation detection on clinical\nnotes and compose selected entities into a new text corpus to train document\nrepresentations. We then propose a multimodal neural network to jointly train\ntime series signals and unstructured clinical text representations to predict\nthe in-hospital mortality risk for ICU patients. Our model outperforms the\nbenchmark by 2% AUC. \n\n"}
{"id": "1811.12335", "contents": "Title: Bayesian Adversarial Spheres: Bayesian Inference and Adversarial\n  Examples in a Noiseless Setting Abstract: Modern deep neural network models suffer from adversarial examples, i.e.\nconfidently misclassified points in the input space. It has been shown that\nBayesian neural networks are a promising approach for detecting adversarial\npoints, but careful analysis is problematic due to the complexity of these\nmodels. Recently Gilmer et al. (2018) introduced adversarial spheres, a toy\nset-up that simplifies both practical and theoretical analysis of the problem.\nIn this work, we use the adversarial sphere set-up to understand the properties\nof approximate Bayesian inference methods for a linear model in a noiseless\nsetting. We compare predictions of Bayesian and non-Bayesian methods,\nshowcasing the advantages of the former, although revealing open challenges for\ndeep learning applications. \n\n"}
{"id": "1811.12361", "contents": "Title: Smoothed Analysis in Unsupervised Learning via Decoupling Abstract: Smoothed analysis is a powerful paradigm in overcoming worst-case\nintractability in unsupervised learning and high-dimensional data analysis.\nWhile polynomial time smoothed analysis guarantees have been obtained for\nworst-case intractable problems like tensor decompositions and learning\nmixtures of Gaussians, such guarantees have been hard to obtain for several\nother important problems in unsupervised learning. A core technical challenge\nin analyzing algorithms is obtaining lower bounds on the least singular value\nfor random matrix ensembles with dependent entries, that are given by\nlow-degree polynomials of a few base underlying random variables.\n  In this work, we address this challenge by obtaining high-confidence lower\nbounds on the least singular value of new classes of structured random matrix\nensembles of the above kind. We then use these bounds to design algorithms with\npolynomial time smoothed analysis guarantees for the following three important\nproblems in unsupervised learning:\n  1. Robust subspace recovery, when the fraction $\\alpha$ of inliers in the\nd-dimensional subspace $T \\subset \\mathbb{R}^n$ is at least $\\alpha >\n(d/n)^\\ell$ for any constant integer $\\ell>0$. This contrasts with the known\nworst-case intractability when $\\alpha< d/n$, and the previous smoothed\nanalysis result which needed $\\alpha > d/n$ (Hardt and Moitra, 2013).\n  2. Learning overcomplete hidden markov models, where the size of the state\nspace is any polynomial in the dimension of the observations. This gives the\nfirst polynomial time guarantees for learning overcomplete HMMs in a smoothed\nanalysis model.\n  3. Higher order tensor decompositions, where we generalize the so-called\nFOOBI algorithm of Cardoso to find order-$\\ell$ rank-one tensors in a subspace.\nThis allows us to obtain polynomially robust decomposition algorithms for\n$2\\ell$'th order tensors with rank $O(n^{\\ell})$. \n\n"}
{"id": "1811.12824", "contents": "Title: Runtime Analysis for Self-adaptive Mutation Rates Abstract: We propose and analyze a self-adaptive version of the $(1,\\lambda)$\nevolutionary algorithm in which the current mutation rate is part of the\nindividual and thus also subject to mutation. A rigorous runtime analysis on\nthe OneMax benchmark function reveals that a simple local mutation scheme for\nthe rate leads to an expected optimization time (number of fitness evaluations)\nof $O(n\\lambda/\\log\\lambda+n\\log n)$ when $\\lambda$ is at least $C \\ln n$ for\nsome constant $C > 0$. For all values of $\\lambda \\ge C \\ln n$, this\nperformance is asymptotically best possible among all $\\lambda$-parallel\nmutation-based unbiased black-box algorithms.\n  Our result shows that self-adaptation in evolutionary computation can find\ncomplex optimal parameter settings on the fly. At the same time, it proves that\na relatively complicated self-adjusting scheme for the mutation rate proposed\nby Doerr, Gie{\\ss}en, Witt, and Yang~(GECCO~2017) can be replaced by our simple\nendogenous scheme.\n  On the technical side, the paper contributes new tools for the analysis of\ntwo-dimensional drift processes arising in the analysis of dynamic parameter\nchoices in EAs, including bounds on occupation probabilities in processes with\nnon-constant drift. \n\n"}
{"id": "1811.12932", "contents": "Title: Recurrent machines for likelihood-free inference Abstract: Likelihood-free inference is concerned with the estimation of the parameters\nof a non-differentiable stochastic simulator that best reproduce real\nobservations. In the absence of a likelihood function, most of the existing\ninference methods optimize the simulator parameters through a handcrafted\niterative procedure that tries to make the simulated data more similar to the\nobservations. In this work, we explore whether meta-learning can be used in the\nlikelihood-free context, for learning automatically from data an iterative\noptimization procedure that would solve likelihood-free inference problems. We\ndesign a recurrent inference machine that learns a sequence of parameter\nupdates leading to good parameter estimates, without ever specifying some\nexplicit notion of divergence between the simulated data and the real data\ndistributions. We demonstrate our approach on toy simulators, showing promising\nresults both in terms of performance and robustness. \n\n"}
{"id": "1812.00237", "contents": "Title: Improving robustness of classifiers by training against live traffic Abstract: Deep learning models are known to be overconfident in their predictions on\nout of distribution inputs. This is a challenge when a model is trained on a\nparticular input dataset, but receives out of sample data when deployed in\npractice. Recently, there has been work on building classifiers that are robust\nto out of distribution samples by adding a regularization term that maximizes\nthe entropy of the classifier output on out of distribution data. However,\ngiven the challenge that it is not always possible to obtain out of\ndistribution samples, the authors suggest a GAN based alternative that is\nindependent of specific knowledge of out of distribution samples. From this\nexisting work, we also know that having access to the true out of sample\ndistribution for regularization works significantly better than using samples\nfrom the GAN. In this paper, we make the following observation: in practice,\nthe out of distribution samples are contained in the traffic that hits a\ndeployed classifier. However, the traffic will also contain a unknown\nproportion of in-distribution samples. If the entropy over of all of the\ntraffic data were to be naively maximized, this will hurt the classifier\nperformance on in-distribution data. To effectively leverage this traffic data,\nwe propose an adaptive regularization technique (based on the maximum\npredictive probability score of a sample) which penalizes out of distribution\nsamples more heavily than in distribution samples in the incoming traffic. This\nensures that the overall performance of the classifier does not degrade on\nin-distribution data, while detection of out-of-distribution samples is\nsignificantly improved by leveraging the unlabeled traffic data. We show the\neffectiveness of our method via experiments on natural image datasets. \n\n"}
{"id": "1812.00600", "contents": "Title: Resource Constrained Deep Reinforcement Learning Abstract: In urban environments, supply resources have to be constantly matched to the\n\"right\" locations (where customer demand is present) so as to improve quality\nof life. For instance, ambulances have to be matched to base stations regularly\nso as to reduce response time for emergency incidents in EMS (Emergency\nManagement Systems); vehicles (cars, bikes, scooters etc.) have to be matched\nto docking stations so as to reduce lost demand in shared mobility systems.\nSuch problem domains are challenging owing to the demand uncertainty,\ncombinatorial action spaces (due to allocation) and constraints on allocation\nof resources (e.g., total resources, minimum and maximum number of resources at\nlocations and regions).\n  Existing systems typically employ myopic and greedy optimization approaches\nto optimize allocation of supply resources to locations. Such approaches\ntypically are unable to handle surges or variances in demand patterns well.\nRecent research has demonstrated the ability of Deep RL methods in adapting\nwell to highly uncertain environments. However, existing Deep RL methods are\nunable to handle combinatorial action spaces and constraints on allocation of\nresources. To that end, we have developed three approaches on top of the well\nknown actor critic approach, DDPG (Deep Deterministic Policy Gradient) that are\nable to handle constraints on resource allocation. More importantly, we\ndemonstrate that they are able to outperform leading approaches on simulators\nvalidated on semi-real and real data sets. \n\n"}
{"id": "1812.01495", "contents": "Title: Expanding search in the space of empirical ML Abstract: As researchers and practitioners of applied machine learning, we are given a\nset of requirements on the problem to be solved, the plausibly obtainable data,\nand the computational resources available. We aim to find (within those bounds)\nreliably useful combinations of problem, data, and algorithm. An emphasis on\nalgorithmic or technical novelty in ML conference publications leads to\nexploration of one dimension of this space. Data collection and ML deployment\nat scale in industry settings offers an environment for exploring the others.\nOur conferences and reviewing criteria can better support empirical ML by\nsoliciting and incentivizing experimentation and synthesis independent of\nalgorithmic innovation. \n\n"}
{"id": "1812.01690", "contents": "Title: General-to-Detailed GAN for Infrequent Class Medical Images Abstract: Deep learning has significant potential for medical imaging. However, since\nthe incident rate of each disease varies widely, the frequency of classes in a\nmedical image dataset is imbalanced, leading to poor accuracy for such\ninfrequent classes. One possible solution is data augmentation of infrequent\nclasses using synthesized images created by Generative Adversarial Networks\n(GANs), but conventional GANs also require certain amount of images to learn.\nTo overcome this limitation, here we propose General-to-detailed GAN (GDGAN),\nserially connected two GANs, one for general labels and the other for detailed\nlabels. GDGAN produced diverse medical images, and the network trained with an\naugmented dataset outperformed other networks using existing methods with\nrespect to Area-Under-Curve (AUC) of Receiver Operating Characteristic (ROC)\ncurve. \n\n"}
{"id": "1812.02320", "contents": "Title: Steerable Wavelet Scattering for 3D Atomic Systems with Application to\n  Li-Si Energy Prediction Abstract: A general machine learning architecture is introduced that uses wavelet\nscattering coefficients of an inputted three dimensional signal as features.\nSolid harmonic wavelet scattering transforms of three dimensional signals were\npreviously introduced in a machine learning framework for the regression of\nproperties of small organic molecules. Here this approach is extended for\ngeneral steerable wavelets which are equivariant to translations and rotations,\nresulting in a sparse model of the target function. The scattering coefficients\ninherit from the wavelets invariance to translations and rotations. As an\nillustration of this approach a linear regression model is learned for the\nformation energy of amorphous lithium-silicon material states trained over a\ndatabase generated using plane-wave Density Functional Theory methods.\nState-of-the-art results are produced as compared to other machine learning\napproaches over similarly generated databases. \n\n"}
{"id": "1812.02616", "contents": "Title: Modelling Identity Rules with Neural Networks Abstract: In this paper, we show that standard feed-forward and recurrent neural\nnetworks fail to learn abstract patterns based on identity rules. We propose\nRelation Based Pattern (RBP) extensions to neural network structures that solve\nthis problem and answer, as well as raise, questions about integrating\nstructures for inductive bias into neural networks. Examples of abstract\npatterns are the sequence patterns ABA and ABB where A or B can be any object.\nThese were introduced by Marcus et al (1999) who also found that 7 month old\ninfants recognise these patterns in sequences that use an unfamiliar vocabulary\nwhile simple recurrent neural networks do not.This result has been contested in\nthe literature but it is confirmed by our experiments. We also show that the\ninability to generalise extends to different, previously untested, settings. We\npropose a new approach to modify standard neural network architectures, called\nRelation Based Patterns (RBP) with different variants for classification and\nprediction. Our experiments show that neural networks with the appropriate RBP\nstructure achieve perfect classification and prediction performance on\nsynthetic data, including mixed concrete and abstract patterns. RBP also\nimproves neural network performance in experiments with real-world sequence\nprediction tasks. We discuss these finding in terms of challenges for neural\nnetwork models and identify consequences from this result in terms of\ndeveloping inductive biases for neural network learning. \n\n"}
{"id": "1812.02633", "contents": "Title: MIWAE: Deep Generative Modelling and Imputation of Incomplete Data Abstract: We consider the problem of handling missing data with deep latent variable\nmodels (DLVMs). First, we present a simple technique to train DLVMs when the\ntraining set contains missing-at-random data. Our approach, called MIWAE, is\nbased on the importance-weighted autoencoder (IWAE), and maximises a\npotentially tight lower bound of the log-likelihood of the observed data.\nCompared to the original IWAE, our algorithm does not induce any additional\ncomputational overhead due to the missing data. We also develop Monte Carlo\ntechniques for single and multiple imputation using a DLVM trained on an\nincomplete data set. We illustrate our approach by training a convolutional\nDLVM on a static binarisation of MNIST that contains 50% of missing pixels.\nLeveraging multiple imputation, a convolutional network trained on these\nincomplete digits has a test performance similar to one trained on complete\ndata. On various continuous and binary data sets, we also show that MIWAE\nprovides accurate single imputations, and is highly competitive with\nstate-of-the-art methods. \n\n"}
{"id": "1812.02833", "contents": "Title: Disentangling Disentanglement in Variational Autoencoders Abstract: We develop a generalisation of disentanglement in VAEs---decomposition of the\nlatent representation---characterising it as the fulfilment of two factors: a)\nthe latent encodings of the data having an appropriate level of overlap, and b)\nthe aggregate encoding of the data conforming to a desired structure,\nrepresented through the prior. Decomposition permits disentanglement, i.e.\nexplicit independence between latents, as a special case, but also allows for a\nmuch richer class of properties to be imposed on the learnt representation,\nsuch as sparsity, clustering, independent subspaces, or even intricate\nhierarchical dependency relationships. We show that the $\\beta$-VAE varies from\nthe standard VAE predominantly in its control of latent overlap and that for\nthe standard choice of an isotropic Gaussian prior, its objective is invariant\nto rotations of the latent representation. Viewed from the decomposition\nperspective, breaking this invariance with simple manipulations of the prior\ncan yield better disentanglement with little or no detriment to\nreconstructions. We further demonstrate how other choices of prior can assist\nin producing different decompositions and introduce an alternative training\nobjective that allows the control of both decomposition factors in a principled\nmanner. \n\n"}
{"id": "1812.03511", "contents": "Title: Physics-informed deep generative models Abstract: We consider the application of deep generative models in propagating\nuncertainty through complex physical systems. Specifically, we put forth an\nimplicit variational inference formulation that constrains the generative model\noutput to satisfy given physical laws expressed by partial differential\nequations. Such physics-informed constraints provide a regularization mechanism\nfor effectively training deep probabilistic models for modeling physical\nsystems in which the cost of data acquisition is high and training data-sets\nare typically small. This provides a scalable framework for characterizing\nuncertainty in the outputs of physical systems due to randomness in their\ninputs or noise in their observations. We demonstrate the effectiveness of our\napproach through a canonical example in transport dynamics. \n\n"}
{"id": "1812.03980", "contents": "Title: Building Ethically Bounded AI Abstract: The more AI agents are deployed in scenarios with possibly unexpected\nsituations, the more they need to be flexible, adaptive, and creative in\nachieving the goal we have given them. Thus, a certain level of freedom to\nchoose the best path to the goal is inherent in making AI robust and flexible\nenough. At the same time, however, the pervasive deployment of AI in our life,\nwhether AI is autonomous or collaborating with humans, raises several ethical\nchallenges. AI agents should be aware and follow appropriate ethical principles\nand should thus exhibit properties such as fairness or other virtues. These\nethical principles should define the boundaries of AI's freedom and creativity.\nHowever, it is still a challenge to understand how to specify and reason with\nethical boundaries in AI agents and how to combine them appropriately with\nsubjective preferences and goal specifications. Some initial attempts employ\neither a data-driven example-based approach for both, or a symbolic rule-based\napproach for both. We envision a modular approach where any AI technique can be\nused for any of these essential ingredients in decision making or decision\nsupport systems, paired with a contextual approach to define their combination\nand relative weight. In a world where neither humans nor AI systems work in\nisolation, but are tightly interconnected, e.g., the Internet of Things, we\nalso envision a compositional approach to building ethically bounded AI, where\nthe ethical properties of each component can be fruitfully exploited to derive\nthose of the overall system. In this paper we define and motivate the notion of\nethically-bounded AI, we describe two concrete examples, and we outline some\noutstanding challenges. \n\n"}
{"id": "1812.04155", "contents": "Title: Vision-based Navigation with Language-based Assistance via Imitation\n  Learning with Indirect Intervention Abstract: We present Vision-based Navigation with Language-based Assistance (VNLA), a\ngrounded vision-language task where an agent with visual perception is guided\nvia language to find objects in photorealistic indoor environments. The task\nemulates a real-world scenario in that (a) the requester may not know how to\nnavigate to the target objects and thus makes requests by only specifying\nhigh-level end-goals, and (b) the agent is capable of sensing when it is lost\nand querying an advisor, who is more qualified at the task, to obtain language\nsubgoals to make progress. To model language-based assistance, we develop a\ngeneral framework termed Imitation Learning with Indirect Intervention (I3L),\nand propose a solution that is effective on the VNLA task. Empirical results\nshow that this approach significantly improves the success rate of the learning\nagent over other baselines in both seen and unseen environments. Our code and\ndata are publicly available at https://github.com/debadeepta/vnla . \n\n"}
{"id": "1812.04448", "contents": "Title: seq2graph: Discovering Dynamic Dependencies from Multivariate Time\n  Series with Multi-level Attention Abstract: Discovering temporal lagged and inter-dependencies in multivariate time\nseries data is an important task. However, in many real-world applications,\nsuch as commercial cloud management, manufacturing predictive maintenance, and\nportfolios performance analysis, such dependencies can be non-linear and\ntime-variant, which makes it more challenging to extract such dependencies\nthrough traditional methods such as Granger causality or clustering. In this\nwork, we present a novel deep learning model that uses multiple layers of\ncustomized gated recurrent units (GRUs) for discovering both time lagged\nbehaviors as well as inter-timeseries dependencies in the form of directed\nweighted graphs. We introduce a key component of Dual-purpose recurrent neural\nnetwork that decodes information in the temporal domain to discover lagged\ndependencies within each time series, and encodes them into a set of vectors\nwhich, collected from all component time series, form the informative inputs to\ndiscover inter-dependencies. Though the discovery of two types of dependencies\nare separated at different hierarchical levels, they are tightly connected and\njointly trained in an end-to-end manner. With this joint training, learning of\none type of dependency immediately impacts the learning of the other one,\nleading to overall accurate dependencies discovery. We empirically test our\nmodel on synthetic time series data in which the exact form of (non-linear)\ndependencies is known. We also evaluate its performance on two real-world\napplications, (i) performance monitoring data from a commercial cloud provider,\nwhich exhibit highly dynamic, non-linear, and volatile behavior and, (ii)\nsensor data from a manufacturing plant. We further show how our approach is\nable to capture these dependency behaviors via intuitive and interpretable\ndependency graphs and use them to generate highly accurate forecasts. \n\n"}
{"id": "1812.05189", "contents": "Title: Massively scalable Sinkhorn distances via the Nystr\\\"om method Abstract: The Sinkhorn \"distance\", a variant of the Wasserstein distance with entropic\nregularization, is an increasingly popular tool in machine learning and\nstatistical inference. However, the time and memory requirements of standard\nalgorithms for computing this distance grow quadratically with the size of the\ndata, making them prohibitively expensive on massive data sets. In this work,\nwe show that this challenge is surprisingly easy to circumvent: combining two\nsimple techniques---the Nystr\\\"om method and Sinkhorn scaling---provably yields\nan accurate approximation of the Sinkhorn distance with significantly lower\ntime and memory requirements than other approaches. We prove our results via\nnew, explicit analyses of the Nystr\\\"om method and of the stability properties\nof Sinkhorn scaling. We validate our claims experimentally by showing that our\napproach easily computes Sinkhorn distances on data sets hundreds of times\nlarger than can be handled by other techniques. \n\n"}
{"id": "1812.05316", "contents": "Title: Mind the Independence Gap Abstract: The independence gap of a graph was introduced by Ekim et al. (2018) as a\nmeasure of how far a graph is from being well-covered. It is defined as the\ndifference between the maximum and minimum size of a maximal independent set.\n  We investigate the independence gap of a graph from structural and\nalgorithmic points of view, with a focus on classes of perfect graphs.\nGeneralizing results on well-covered graphs due to Dean and Zito (1994) and\nHujdurovi\\'c et al. (2018), we express the independence gap of a perfect graph\nin terms of clique partitions and use this characterization to develop a\npolynomial-time algorithm for recognizing graphs of constant independence gap\nin any class of perfect graphs of bounded clique number. Next, we introduce a\nhereditary variant of the parameter, which we call hereditary independence gap\nand which measures the maximum independence gap over all induced subgraphs of\nthe graph. We show that determining whether a given graph has hereditary\nindependence gap at most $k$ is polynomial-time solvable if $k$ is fixed and\nco-NP-complete if $k$ is part of input. We also investigate the complexity of\nthe independent set problem in graph classes related to independence gap,\nshowing that the problem is NP-complete in the class of graphs of independence\ngap at most one and polynomial-time solvable in any class of graphs with\nbounded hereditary independence gap. Combined with some known results on\nclaw-free graphs, our results imply that the independent domination problem is\nsolvable in polynomial time in the class of $\\{$claw, 2$P_3\\}$-free graphs. \n\n"}
{"id": "1812.06181", "contents": "Title: Efficient Interpretation of Deep Learning Models Using Graph Structure\n  and Cooperative Game Theory: Application to ASD Biomarker Discovery Abstract: Discovering imaging biomarkers for autism spectrum disorder (ASD) is critical\nto help explain ASD and predict or monitor treatment outcomes. Toward this end,\ndeep learning classifiers have recently been used for identifying ASD from\nfunctional magnetic resonance imaging (fMRI) with higher accuracy than\ntraditional learning strategies. However, a key challenge with deep learning\nmodels is understanding just what image features the network is using, which\ncan in turn be used to define the biomarkers. Current methods extract\nbiomarkers, i.e., important features, by looking at how the prediction changes\nif \"ignoring\" one feature at a time. In this work, we go beyond looking at only\nindividual features by using Shapley value explanation (SVE) from cooperative\ngame theory. Cooperative game theory is advantageous here because it directly\nconsiders the interaction between features and can be applied to any machine\nlearning method, making it a novel, more accurate way of determining\ninstance-wise biomarker importance from deep learning models. A barrier to\nusing SVE is its computational complexity: $2^N$ given $N$ features. We\nexplicitly reduce the complexity of SVE computation by two approaches based on\nthe underlying graph structure of the input data: 1) only consider the\ncentralized coalition of each feature; 2) a hierarchical pipeline which first\nclusters features into small communities, then applies SVE in each community.\nMonte Carlo approximation can be used for large permutation sets. We first\nvalidate our methods on the MNIST dataset and compare to human perception.\nNext, to insure plausibility of our biomarker results, we train a Random Forest\n(RF) to classify ASD/control subjects from fMRI and compare SVE results to\nstandard RF-based feature importance. Finally, we show initial results on\nranked fMRI biomarkers using SVE on a deep learning classifier for the\nASD/control dataset. \n\n"}
{"id": "1812.06227", "contents": "Title: Balanced Linear Contextual Bandits Abstract: Contextual bandit algorithms are sensitive to the estimation method of the\noutcome model as well as the exploration method used, particularly in the\npresence of rich heterogeneity or complex outcome models, which can lead to\ndifficult estimation problems along the path of learning. We develop algorithms\nfor contextual bandits with linear payoffs that integrate balancing methods\nfrom the causal inference literature in their estimation to make it less prone\nto problems of estimation bias. We provide the first regret bound analyses for\nlinear contextual bandits with balancing and show that our algorithms match the\nstate of the art theoretical guarantees. We demonstrate the strong practical\nadvantage of balanced contextual bandits on a large number of supervised\nlearning datasets and on a synthetic example that simulates model\nmisspecification and prejudice in the initial training data. \n\n"}
{"id": "1812.06243", "contents": "Title: Algorithmic Theory of ODEs and Sampling from Well-conditioned Logconcave\n  Densities Abstract: Sampling logconcave functions arising in statistics and machine learning has\nbeen a subject of intensive study. Recent developments include analyses for\nLangevin dynamics and Hamiltonian Monte Carlo (HMC). While both approaches have\ndimension-independent bounds for the underlying $\\mathit{continuous}$ processes\nunder sufficiently strong smoothness conditions, the resulting discrete\nalgorithms have complexity and number of function evaluations growing with the\ndimension. Motivated by this problem, in this paper, we give a general\nalgorithm for solving multivariate ordinary differential equations whose\nsolution is close to the span of a known basis of functions (e.g., polynomials\nor piecewise polynomials). The resulting algorithm has polylogarithmic depth\nand essentially tight runtime - it is nearly linear in the size of the\nrepresentation of the solution.\n  We apply this to the sampling problem to obtain a nearly linear\nimplementation of HMC for a broad class of smooth, strongly logconcave\ndensities, with the number of iterations (parallel depth) and gradient\nevaluations being $\\mathit{polylogarithmic}$ in the dimension (rather than\npolynomial as in previous work). This class includes the widely-used loss\nfunction for logistic regression with incoherent weight matrices and has been\nsubject of much study recently. We also give a faster algorithm with $\n\\mathit{polylogarithmic~depth}$ for the more general and standard class of\nstrongly convex functions with Lipschitz gradient. These results are based on\n(1) an improved contraction bound for the exact HMC process and (2) logarithmic\nbounds on the degree of polynomials that approximate solutions of the\ndifferential equations arising in implementing HMC. \n\n"}
{"id": "1812.06401", "contents": "Title: What's to know? Uncertainty as a Guide to Asking Goal-oriented Questions Abstract: One of the core challenges in Visual Dialogue problems is asking the question\nthat will provide the most useful information towards achieving the required\nobjective. Encouraging an agent to ask the right questions is difficult because\nwe don't know a-priori what information the agent will need to achieve its\ntask, and we don't have an explicit model of what it knows already. We propose\na solution to this problem based on a Bayesian model of the uncertainty in the\nimplicit model maintained by the visual dialogue agent, and in the function\nused to select an appropriate output. By selecting the question that minimises\nthe predicted regret with respect to this implicit model the agent actively\nreduces ambiguity. The Bayesian model of uncertainty also enables a principled\nmethod for identifying when enough information has been acquired, and an action\nshould be selected. We evaluate our approach on two goal-oriented dialogue\ndatasets, one for visual-based collaboration task and the other for a\nnegotiation-based task. Our uncertainty-aware information-seeking model\noutperforms its counterparts in these two challenging problems. \n\n"}
{"id": "1812.06515", "contents": "Title: Higher-Order Spectral Clustering under Superimposed Stochastic Block\n  Model Abstract: Higher-order motif structures and multi-vertex interactions are becoming\nincreasingly important in studies that aim to improve our understanding of\nfunctionalities and evolution patterns of networks. To elucidate the role of\nhigher-order structures in community detection problems over complex networks,\nwe introduce the notion of a Superimposed Stochastic Block Model (SupSBM). The\nmodel is based on a random graph framework in which certain higher-order\nstructures or subgraphs are generated through an independent hyperedge\ngeneration process, and are then replaced with graphs that are superimposed\nwith directed or undirected edges generated by an inhomogeneous random graph\nmodel. Consequently, the model introduces controlled dependencies between edges\nwhich allow for capturing more realistic network phenomena, namely strong local\nclustering in a sparse network, short average path length, and community\nstructure. We proceed to rigorously analyze the performance of a number of\nrecently proposed higher-order spectral clustering methods on the SupSBM. In\nparticular, we prove non-asymptotic upper bounds on the misclustering error of\nspectral community detection for a SupSBM setting in which triangles or\n3-uniform hyperedges are superimposed with undirected edges. As part of our\nanalysis, we also derive new bounds on the misclustering error of higher-order\nspectral clustering methods for the standard SBM and the 3-uniform hypergraph\nSBM. Furthermore, for a non-uniform hypergraph SBM model in which one directly\nobserves both edges and 3-uniform hyperedges, we obtain a criterion that\ndescribes when to perform spectral clustering based on edges and when on\nhyperedges, based on a function of hyperedge density and observation quality. \n\n"}
{"id": "1812.07431", "contents": "Title: Momen(e)t: Flavor the Moments in Learning to Classify Shapes Abstract: A fundamental question in learning to classify 3D shapes is how to treat the\ndata in a way that would allow us to construct efficient and accurate geometric\nprocessing and analysis procedures. Here, we restrict ourselves to networks\nthat operate on point clouds. There were several attempts to treat point clouds\nas non-structured data sets by which a neural network is trained to extract\ndiscriminative properties. The idea of using 3D coordinates as class\nidentifiers motivated us to extend this line of thought to that of shape\nclassification by comparing attributes that could easily account for the shape\nmoments. Here, we propose to add polynomial functions of the coordinates\nallowing the network to account for higher order moments of a given shape.\nExperiments on two benchmarks show that the suggested network is able to\nprovide state of the art results and at the same token learn more efficiently\nin terms of memory and computational complexity. \n\n"}
{"id": "1812.07484", "contents": "Title: Efficient Autotuning of Hyperparameters in Approximate Nearest Neighbor\n  Search Abstract: Approximate nearest neighbor algorithms are used to speed up nearest neighbor\nsearch in a wide array of applications. However, current indexing methods\nfeature several hyperparameters that need to be tuned to reach an acceptable\naccuracy--speed trade-off. A grid search in the parameter space is often\nimpractically slow due to a time-consuming index-building procedure. Therefore,\nwe propose an algorithm for automatically tuning the hyperparameters of\nindexing methods based on randomized space-partitioning trees. In particular,\nwe present results using randomized k-d trees, random projection trees and\nrandomized PCA trees. The tuning algorithm adds minimal overhead to the\nindex-building process but is able to find the optimal hyperparameters\naccurately. We demonstrate that the algorithm is significantly faster than\nexisting approaches, and that the indexing methods used are competitive with\nthe state-of-the-art methods in query time while being faster to build. \n\n"}
{"id": "1812.07520", "contents": "Title: Entropy-Constrained Training of Deep Neural Networks Abstract: We propose a general framework for neural network compression that is\nmotivated by the Minimum Description Length (MDL) principle. For that we first\nderive an expression for the entropy of a neural network, which measures its\ncomplexity explicitly in terms of its bit-size. Then, we formalize the problem\nof neural network compression as an entropy-constrained optimization objective.\nThis objective generalizes many of the compression techniques proposed in the\nliterature, in that pruning or reducing the cardinality of the weight elements\nof the network can be seen special cases of entropy-minimization techniques.\nFurthermore, we derive a continuous relaxation of the objective, which allows\nus to minimize it using gradient based optimization techniques. Finally, we\nshow that we can reach state-of-the-art compression results on different\nnetwork architectures and data sets, e.g. achieving x71 compression gains on a\nVGG-like architecture. \n\n"}
{"id": "1812.08723", "contents": "Title: A Universal Sampling Method for Reconstructing Signals with Simple\n  Fourier Transforms Abstract: Reconstructing continuous signals from a small number of discrete samples is\na fundamental problem across science and engineering. In practice, we are often\ninterested in signals with 'simple' Fourier structure, such as bandlimited,\nmultiband, and Fourier sparse signals. More broadly, any prior knowledge about\na signal's Fourier power spectrum can constrain its complexity. Intuitively,\nsignals with more highly constrained Fourier structure require fewer samples to\nreconstruct.\n  We formalize this intuition by showing that, roughly, a continuous signal\nfrom a given class can be approximately reconstructed using a number of samples\nproportional to the *statistical dimension* of the allowed power spectrum of\nthat class. Further, in nearly all settings, this natural measure tightly\ncharacterizes the sample complexity of signal reconstruction.\n  Surprisingly, we also show that, up to logarithmic factors, a universal\nnon-uniform sampling strategy can achieve this optimal complexity for *any\nclass of signals*. We present a simple and efficient algorithm for recovering a\nsignal from the samples taken. For bandlimited and sparse signals, our method\nmatches the state-of-the-art. At the same time, it gives the first\ncomputationally and sample efficient solution to a broad range of problems,\nincluding multiband signal reconstruction and kriging and Gaussian process\nregression tasks in one dimension.\n  Our work is based on a novel connection between randomized linear algebra and\nsignal reconstruction with constrained Fourier structure. We extend tools based\non statistical leverage score sampling and column-based matrix reconstruction\nto the approximation of continuous linear operators that arise in signal\nreconstruction. We believe that these extensions are of independent interest\nand serve as a foundation for tackling a broad range of continuous time\nproblems using randomized methods. \n\n"}
{"id": "1812.08739", "contents": "Title: Multi-Output Gaussian Processes for Crowdsourced Traffic Data Imputation Abstract: Traffic speed data imputation is a fundamental challenge for data-driven\ntransport analysis. In recent years, with the ubiquity of GPS-enabled devices\nand the widespread use of crowdsourcing alternatives for the collection of\ntraffic data, transportation professionals increasingly look to such\nuser-generated data for many analysis, planning, and decision support\napplications. However, due to the mechanics of the data collection process,\ncrowdsourced traffic data such as probe-vehicle data is highly prone to missing\nobservations, making accurate imputation crucial for the success of any\napplication that makes use of that type of data. In this article, we propose\nthe use of multi-output Gaussian processes (GPs) to model the complex spatial\nand temporal patterns in crowdsourced traffic data. While the Bayesian\nnonparametric formalism of GPs allows us to model observation uncertainty, the\nmulti-output extension based on convolution processes effectively enables us to\ncapture complex spatial dependencies between nearby road segments. Using 6\nmonths of crowdsourced traffic speed data or \"probe vehicle data\" for several\nlocations in Copenhagen, the proposed approach is empirically shown to\nsignificantly outperform popular state-of-the-art imputation methods. \n\n"}
{"id": "1812.09510", "contents": "Title: An Industrial Case Study on Shrinking Code Review Changesets through\n  Remark Prediction Abstract: Change-based code review is used widely in industrial software development.\nThus, research on tools that help the reviewer to achieve better review\nperformance can have a high impact. We analyze one possibility to provide\ncognitive support for the reviewer: Determining the importance of change parts\nfor review, specifically determining which parts of the code change can be left\nout from the review without harm. To determine the importance of change parts,\nwe extract data from software repositories and build prediction models for\nreview remarks based on this data. The approach is discussed in detail. To\ngather the input data, we propose a novel algorithm to trace review remarks to\ntheir triggers. We apply our approach in a medium-sized software company. In\nthis company, we can avoid the review of 25% of the change parts and of 23% of\nthe changed Java source code lines, while missing only about 1% of the review\nremarks. Still, we also observe severe limitations of the tried approach: Much\nof the savings are due to simple syntactic rules, noise in the data hampers the\nsearch for better prediction models, and some developers in the case company\noppose the taken approach. Besides the main results on the mining and\nprediction of triggers for review remarks, we contribute experiences with a\nnovel, multi-objective and interactive rule mining approach. The anonymized\ndataset from the company is made available, as are the implementations for the\ndevised algorithms. \n\n"}
{"id": "1812.09922", "contents": "Title: Dynamic Runtime Feature Map Pruning Abstract: High bandwidth requirements are an obstacle for accelerating the training and\ninference of deep neural networks. Most previous research focuses on reducing\nthe size of kernel maps for inference. We analyze parameter sparsity of six\npopular convolutional neural networks - AlexNet, MobileNet, ResNet-50,\nSqueezeNet, TinyNet, and VGG16. Of the networks considered, those using ReLU\n(AlexNet, SqueezeNet, VGG16) contain a high percentage of 0-valued parameters\nand can be statically pruned. Networks with Non-ReLU activation functions in\nsome cases may not contain any 0-valued parameters (ResNet-50, TinyNet). We\nalso investigate runtime feature map usage and find that input feature maps\ncomprise the majority of bandwidth requirements when depth-wise convolution and\npoint-wise convolutions used. We introduce dynamic runtime pruning of feature\nmaps and show that 10% of dynamic feature map execution can be removed without\nloss of accuracy. We then extend dynamic pruning to allow for values within an\nepsilon of zero and show a further 5% reduction of feature map loading with a\n1% loss of accuracy in top-1. \n\n"}
{"id": "1812.10004", "contents": "Title: Overparameterized Nonlinear Learning: Gradient Descent Takes the\n  Shortest Path? Abstract: Many modern learning tasks involve fitting nonlinear models to data which are\ntrained in an overparameterized regime where the parameters of the model exceed\nthe size of the training dataset. Due to this overparameterization, the\ntraining loss may have infinitely many global minima and it is critical to\nunderstand the properties of the solutions found by first-order optimization\nschemes such as (stochastic) gradient descent starting from different\ninitializations. In this paper we demonstrate that when the loss has certain\nproperties over a minimally small neighborhood of the initial point, first\norder methods such as (stochastic) gradient descent have a few intriguing\nproperties: (1) the iterates converge at a geometric rate to a global optima\neven when the loss is nonconvex, (2) among all global optima of the loss the\niterates converge to one with a near minimal distance to the initial point, (3)\nthe iterates take a near direct route from the initial point to this global\noptima. As part of our proof technique, we introduce a new potential function\nwhich captures the precise tradeoff between the loss function and the distance\nto the initial point as the iterations progress. For Stochastic Gradient\nDescent (SGD), we develop novel martingale techniques that guarantee SGD never\nleaves a small neighborhood of the initialization, even with rather large\nlearning rates. We demonstrate the utility of our general theory for a variety\nof problem domains spanning low-rank matrix recovery to neural network\ntraining. Underlying our analysis are novel insights that may have implications\nfor training and generalization of more sophisticated learning problems\nincluding those involving deep neural network architectures. \n\n"}
{"id": "1812.10687", "contents": "Title: Robustness to Out-of-Distribution Inputs via Task-Aware Generative\n  Uncertainty Abstract: Deep learning provides a powerful tool for machine perception when the\nobservations resemble the training data. However, real-world robotic systems\nmust react intelligently to their observations even in unexpected\ncircumstances. This requires a system to reason about its own uncertainty given\nunfamiliar, out-of-distribution observations. Approximate Bayesian approaches\nare commonly used to estimate uncertainty for neural network predictions, but\ncan struggle with out-of-distribution observations. Generative models can in\nprinciple detect out-of-distribution observations as those with a low estimated\ndensity. However, the mere presence of an out-of-distribution input does not by\nitself indicate an unsafe situation. In this paper, we present a method for\nuncertainty-aware robotic perception that combines generative modeling and\nmodel uncertainty to cope with uncertainty stemming from out-of-distribution\nstates. Our method estimates an uncertainty measure about the model's\nprediction, taking into account an explicit (generative) model of the\nobservation distribution to handle out-of-distribution inputs. This is\naccomplished by probabilistically projecting observations onto the training\ndistribution, such that out-of-distribution inputs map to uncertain\nin-distribution observations, which in turn produce uncertain task-related\npredictions, but only if task-relevant parts of the image change. We evaluate\nour method on an action-conditioned collision prediction task with both\nsimulated and real data, and demonstrate that our method of projecting\nout-of-distribution observations improves the performance of four standard\nBayesian and non-Bayesian neural network approaches, offering more favorable\ntrade-offs between the proportion of time a robot can remain autonomous and the\nproportion of impending crashes successfully avoided. \n\n"}
{"id": "1812.10907", "contents": "Title: Divergence Triangle for Joint Training of Generator Model, Energy-based\n  Model, and Inference Model Abstract: This paper proposes the divergence triangle as a framework for joint training\nof generator model, energy-based model and inference model. The divergence\ntriangle is a compact and symmetric (anti-symmetric) objective function that\nseamlessly integrates variational learning, adversarial learning, wake-sleep\nalgorithm, and contrastive divergence in a unified probabilistic formulation.\nThis unification makes the processes of sampling, inference, energy evaluation\nreadily available without the need for costly Markov chain Monte Carlo methods.\nOur experiments demonstrate that the divergence triangle is capable of learning\n(1) an energy-based model with well-formed energy landscape, (2) direct\nsampling in the form of a generator network, and (3) feed-forward inference\nthat faithfully reconstructs observed as well as synthesized data. The\ndivergence triangle is a robust training method that can learn from incomplete\ndata. \n\n"}
{"id": "1812.11314", "contents": "Title: Meta Reinforcement Learning with Distribution of Exploration Parameters\n  Learned by Evolution Strategies Abstract: In this paper, we propose a novel meta-learning method in a reinforcement\nlearning setting, based on evolution strategies (ES), exploration in parameter\nspace and deterministic policy gradients. ES methods are easy to parallelize,\nwhich is desirable for modern training architectures; however, such methods\ntypically require a huge number of samples for effective training. We use\ndeterministic policy gradients during adaptation and other techniques to\ncompensate for the sample-efficiency problem while maintaining the inherent\nscalability of ES methods. We demonstrate that our method achieves good results\ncompared to gradient-based meta-learning in high-dimensional control tasks in\nthe MuJoCo simulator. In addition, because of gradient-free methods in the\nmeta-training phase, which do not need information about gradients and policies\nin adaptation training, we predict and confirm our algorithm performs better in\ntasks that need multi-step adaptation. \n\n"}
{"id": "1812.11337", "contents": "Title: Quantized Guided Pruning for Efficient Hardware Implementations of\n  Convolutional Neural Networks Abstract: Convolutional Neural Networks (CNNs) are state-of-the-art in numerous\ncomputer vision tasks such as object classification and detection. However, the\nlarge amount of parameters they contain leads to a high computational\ncomplexity and strongly limits their usability in budget-constrained devices\nsuch as embedded devices. In this paper, we propose a combination of a new\npruning technique and a quantization scheme that effectively reduce the\ncomplexity and memory usage of convolutional layers of CNNs, and replace the\ncomplex convolutional operation by a low-cost multiplexer. We perform\nexperiments on the CIFAR10, CIFAR100 and SVHN and show that the proposed method\nachieves almost state-of-the-art accuracy, while drastically reducing the\ncomputational and memory footprints. We also propose an efficient hardware\narchitecture to accelerate CNN operations. The proposed hardware architecture\nis a pipeline and accommodates multiple layers working at the same time to\nspeed up the inference process. \n\n"}
{"id": "1812.11712", "contents": "Title: On the Complexity of the Inverse Semivalue Problem for Weighted Voting\n  Games Abstract: Weighted voting games are a family of cooperative games, typically used to\nmodel voting situations where a number of agents (players) vote against or for\na proposal. In such games, a proposal is accepted if an appropriately weighted\nsum of the votes exceeds a prespecified threshold. As the influence of a player\nover the voting outcome is not in general proportional to her assigned weight,\nvarious power indices have been proposed to measure each player's influence.\nThe inverse power index problem is the problem of designing a weighted voting\ngame that achieves a set of target influences according to a predefined power\nindex. In this work, we study the computational complexity of the inverse\nproblem when the power index belongs to the class of semivalues. We prove that\nthe inverse problem is computationally intractable for a broad family of\nsemivalues, including all regular semivalues. As a special case of our general\nresult, we establish computational hardness of the inverse problem for the\nBanzhaf indices and the Shapley values, arguably the most popular power\nindices. \n\n"}
{"id": "1901.00117", "contents": "Title: An Active Learning Framework for Efficient Robust Policy Search Abstract: Robust Policy Search is the problem of learning policies that do not degrade\nin performance when subject to unseen environment model parameters. It is\nparticularly relevant for transferring policies learned in a simulation\nenvironment to the real world. Several existing approaches involve sampling\nlarge batches of trajectories which reflect the differences in various possible\nenvironments, and then selecting some subset of these to learn robust policies,\nsuch as the ones that result in the worst performance. We propose an active\nlearning based framework, EffAcTS, to selectively choose model parameters for\nthis purpose so as to collect only as much data as necessary to select such a\nsubset. We apply this framework using Linear Bandits, and experimentally\nvalidate the gains in sample efficiency and the performance of our approach on\nstandard continuous control tasks. We also present a Multi-Task Learning\nperspective to the problem of Robust Policy Search, and draw connections from\nour proposed framework to existing work on Multi-Task Learning. \n\n"}
{"id": "1901.00335", "contents": "Title: Clique-Width for Hereditary Graph Classes Abstract: Clique-width is a well-studied graph parameter owing to its use in\nunderstanding algorithmic tractability: if the clique-width of a graph class\n${\\cal G}$ is bounded by a constant, a wide range of problems that are\nNP-complete in general can be shown to be polynomial-time solvable on ${\\cal\nG}$. For this reason, the boundedness or unboundedness of clique-width has been\ninvestigated and determined for many graph classes. We survey these results for\nhereditary graph classes, which are the graph classes closed under taking\ninduced subgraphs. We then discuss the algorithmic consequences of these\nresults, in particular for the Colouring and Graph Isomorphism problems. We\nalso explain a possible strong connection between results on boundedness of\nclique-width and on well-quasi-orderability by the induced subgraph relation\nfor hereditary graph classes. \n\n"}
{"id": "1901.01484", "contents": "Title: LanczosNet: Multi-Scale Deep Graph Convolutional Networks Abstract: We propose the Lanczos network (LanczosNet), which uses the Lanczos algorithm\nto construct low rank approximations of the graph Laplacian for graph\nconvolution. Relying on the tridiagonal decomposition of the Lanczos algorithm,\nwe not only efficiently exploit multi-scale information via fast approximated\ncomputation of matrix power but also design learnable spectral filters. Being\nfully differentiable, LanczosNet facilitates both graph kernel learning as well\nas learning node embeddings. We show the connection between our LanczosNet and\ngraph based manifold learning methods, especially the diffusion maps. We\nbenchmark our model against several recent deep graph networks on citation\nnetworks and QM8 quantum chemistry dataset. Experimental results show that our\nmodel achieves the state-of-the-art performance in most tasks. Code is released\nat: \\url{https://github.com/lrjconan/LanczosNetwork}. \n\n"}
{"id": "1901.02671", "contents": "Title: Is it Time to Swish? Comparing Deep Learning Activation Functions Across\n  NLP tasks Abstract: Activation functions play a crucial role in neural networks because they are\nthe nonlinearities which have been attributed to the success story of deep\nlearning. One of the currently most popular activation functions is ReLU, but\nseveral competitors have recently been proposed or 'discovered', including\nLReLU functions and swish. While most works compare newly proposed activation\nfunctions on few tasks (usually from image classification) and against few\ncompetitors (usually ReLU), we perform the first large-scale comparison of 21\nactivation functions across eight different NLP tasks. We find that a largely\nunknown activation function performs most stably across all tasks, the\nso-called penalized tanh function. We also show that it can successfully\nreplace the sigmoid and tanh gates in LSTM cells, leading to a 2 percentage\npoint (pp) improvement over the standard choices on a challenging NLP task. \n\n"}
{"id": "1901.02757", "contents": "Title: How Compact?: Assessing Compactness of Representations through\n  Layer-Wise Pruning Abstract: Various forms of representations may arise in the many layers embedded in\ndeep neural networks (DNNs). Of these, where can we find the most compact\nrepresentation? We propose to use a pruning framework to answer this question:\nHow compact can each layer be compressed, without losing performance? Most of\nthe existing DNN compression methods do not consider the relative\ncompressibility of the individual layers. They uniformly apply a single target\nsparsity to all layers or adapt layer sparsity using heuristics and additional\ntraining. We propose a principled method that automatically determines the\nsparsity of individual layers derived from the importance of each layer. To do\nthis, we consider a metric to measure the importance of each layer based on the\nlayer-wise capacity. Given the trained model and the total target sparsity, we\nfirst evaluate the importance of each layer from the model. From the evaluated\nimportance, we compute the layer-wise sparsity of each layer. The proposed\nmethod can be applied to any DNN architecture and can be combined with any\npruning method that takes the total target sparsity as a parameter. To validate\nthe proposed method, we carried out an image classification task with two types\nof DNN architectures on two benchmark datasets and used three pruning methods\nfor compression. In case of VGG-16 model with weight pruning on the ImageNet\ndataset, we achieved up to 75% (17.5% on average) better top-5 accuracy than\nthe baseline under the same total target sparsity. Furthermore, we analyzed\nwhere the maximum compression can occur in the network. This kind of analysis\ncan help us identify the most compact representation within a deep neural\nnetwork. \n\n"}
{"id": "1901.02871", "contents": "Title: The Lingering of Gradients: Theory and Applications Abstract: Classically, the time complexity of a first-order method is estimated by its\nnumber of gradient computations. In this paper, we study a more refined\ncomplexity by taking into account the `lingering' of gradients: once a gradient\nis computed at $x_k$, the additional time to compute gradients at\n$x_{k+1},x_{k+2},\\dots$ may be reduced.\n  We show how this improves the running time of several first-order methods.\nFor instance, if the `additional time' scales linearly with respect to the\ntraveled distance, then the `convergence rate' of gradient descent can be\nimproved from $1/T$ to $\\exp(-T^{1/3})$. On the application side, we solve a\nhypothetical revenue management problem on the Yahoo! Front Page Today Module\nwith 4.6m users to $10^{-6}$ error using only 6 passes of the dataset; and\nsolve a real-life support vector machine problem to an accuracy that is two\norders of magnitude better comparing to the state-of-the-art algorithm. \n\n"}
{"id": "1901.02928", "contents": "Title: Beyond the EM Algorithm: Constrained Optimization Methods for Latent\n  Class Model Abstract: Latent class model (LCM), which is a finite mixture of different categorical\ndistributions, is one of the most widely used models in statistics and machine\nlearning fields. Because of its non-continuous nature and the flexibility in\nshape, researchers in practice areas such as marketing and social sciences also\nfrequently use LCM to gain insights from their data. One likelihood-based\nmethod, the Expectation-Maximization (EM) algorithm, is often used to obtain\nthe model estimators. However, the EM algorithm is well-known for its\nnotoriously slow convergence. In this research, we explore alternative\nlikelihood-based methods that can potential remedy the slow convergence of the\nEM algorithm. More specifically, we regard likelihood-based approach as a\nconstrained nonlinear optimization problem, and apply quasi-Newton type methods\nto solve them. We examine two different constrained optimization methods to\nmaximize the log likelihood function. We present simulation study results to\nshow that the proposed methods not only converge in less iterations than the EM\nalgorithm but also produce more accurate model estimators. \n\n"}
{"id": "1901.03357", "contents": "Title: No-Regret Bayesian Optimization with Unknown Hyperparameters Abstract: Bayesian optimization (BO) based on Gaussian process models is a powerful\nparadigm to optimize black-box functions that are expensive to evaluate. While\nseveral BO algorithms provably converge to the global optimum of the unknown\nfunction, they assume that the hyperparameters of the kernel are known in\nadvance. This is not the case in practice and misspecification often causes\nthese algorithms to converge to poor local optima. In this paper, we present\nthe first BO algorithm that is provably no-regret and converges to the optimum\nwithout knowledge of the hyperparameters. During optimization we slowly adapt\nthe hyperparameters of stationary kernels and thereby expand the associated\nfunction class over time, so that the BO algorithm considers more complex\nfunction candidates. Based on the theoretical insights, we propose several\npractical algorithms that achieve the empirical sample efficiency of BO with\nonline hyperparameter estimation, but retain theoretical convergence\nguarantees. We evaluate our method on several benchmark problems. \n\n"}
{"id": "1901.03719", "contents": "Title: Non-Parametric Inference Adaptive to Intrinsic Dimension Abstract: We consider non-parametric estimation and inference of conditional moment\nmodels in high dimensions. We show that even when the dimension $D$ of the\nconditioning variable is larger than the sample size $n$, estimation and\ninference is feasible as long as the distribution of the conditioning variable\nhas small intrinsic dimension $d$, as measured by locally low doubling\nmeasures. Our estimation is based on a sub-sampled ensemble of the $k$-nearest\nneighbors ($k$-NN) $Z$-estimator. We show that if the intrinsic dimension of\nthe covariate distribution is equal to $d$, then the finite sample estimation\nerror of our estimator is of order $n^{-1/(d+2)}$ and our estimate is\n$n^{1/(d+2)}$-asymptotically normal, irrespective of $D$. The sub-sampling size\nrequired for achieving these results depends on the unknown intrinsic dimension\n$d$. We propose an adaptive data-driven approach for choosing this parameter\nand prove that it achieves the desired rates. We discuss extensions and\napplications to heterogeneous treatment effect estimation. \n\n"}
{"id": "1901.03919", "contents": "Title: Semi-Supervised Regression using Cluster Ensemble and Low-Rank\n  Co-Association Matrix Decomposition under Uncertainties Abstract: In this paper, we solve a semi-supervised regression problem. Due to the lack\nof knowledge about the data structure and the presence of random noise, the\nconsidered data model is uncertain. We propose a method which combines graph\nLaplacian regularization and cluster ensemble methodologies. The co-association\nmatrix of the ensemble is calculated on both labeled and unlabeled data; this\nmatrix is used as a similarity matrix in the regularization framework to derive\nthe predicted outputs. We use the low-rank decomposition of the co-association\nmatrix to significantly speedup calculations and reduce memory. Numerical\nexperiments using the Monte Carlo approach demonstrate robustness, efficiency,\nand scalability of the proposed method. \n\n"}
{"id": "1901.04169", "contents": "Title: Towards Testing of Deep Learning Systems with Training Set Reduction Abstract: Testing the implementation of deep learning systems and their training\nroutines is crucial to maintain a reliable code base. Modern software\ndevelopment employs processes, such as Continuous Integration, in which changes\nto the software are frequently integrated and tested. However, testing the\ntraining routines requires running them and fully training a deep learning\nmodel can be resource-intensive, when using the full data set. Using only a\nsubset of the training data can improve test run time, but can also reduce its\neffectiveness. We evaluate different ways for training set reduction and their\nability to mimic the characteristics of model training with the original full\ndata set. Our results underline the usefulness of training set reduction,\nespecially in resource-constrained environments. \n\n"}
{"id": "1901.04436", "contents": "Title: Bayesian Learning of Neural Network Architectures Abstract: In this paper we propose a Bayesian method for estimating architectural\nparameters of neural networks, namely layer size and network depth. We do this\nby learning concrete distributions over these parameters. Our results show that\nregular networks with a learnt structure can generalise better on small\ndatasets, while fully stochastic networks can be more robust to parameter\ninitialisation. The proposed method relies on standard neural variational\nlearning and, unlike randomised architecture search, does not require a\nretraining of the model, thus keeping the computational overhead at minimum. \n\n"}
{"id": "1901.04878", "contents": "Title: Conditional deep surrogate models for stochastic, high-dimensional, and\n  multi-fidelity systems Abstract: We present a probabilistic deep learning methodology that enables the\nconstruction of predictive data-driven surrogates for stochastic systems.\nLeveraging recent advances in variational inference with implicit\ndistributions, we put forth a statistical inference framework that enables the\nend-to-end training of surrogate models on paired input-output observations\nthat may be stochastic in nature, originate from different information sources\nof variable fidelity, or be corrupted by complex noise processes. The resulting\nsurrogates can accommodate high-dimensional inputs and outputs and are able to\nreturn predictions with quantified uncertainty. The effectiveness our approach\nis demonstrated through a series of canonical studies, including the regression\nof noisy data, multi-fidelity modeling of stochastic processes, and uncertainty\npropagation in high-dimensional dynamical systems. \n\n"}
{"id": "1901.04909", "contents": "Title: Efficient Search for Diverse Coherent Explanations Abstract: This paper proposes new search algorithms for counterfactual explanations\nbased upon mixed integer programming. We are concerned with complex data in\nwhich variables may take any value from a contiguous range or an additional set\nof discrete states. We propose a novel set of constraints that we refer to as a\n\"mixed polytope\" and show how this can be used with an integer programming\nsolver to efficiently find coherent counterfactual explanations i.e. solutions\nthat are guaranteed to map back onto the underlying data structure, while\navoiding the need for brute-force enumeration. We also look at the problem of\ndiverse explanations and show how these can be generated within our framework. \n\n"}
{"id": "1901.05028", "contents": "Title: The Bayesian Prophet: A Low-Regret Framework for Online Decision Making Abstract: We develop a new framework for designing online policies given access to an\noracle providing statistical information about an offline benchmark. Having\naccess to such prediction oracles enables simple and natural Bayesian selection\npolicies, and raises the question as to how these policies perform in different\nsettings.\n  Our work makes two important contributions towards this question: First, we\ndevelop a general technique we call *compensated coupling* which can be used to\nderive bounds on the expected regret (i.e., additive loss with respect to a\nbenchmark) for any online policy and offline benchmark. Second, using this\ntechnique, we show that a natural greedy policy, which we call *the Bayes\nSelector*, has constant expected regret (i.e., independent of the number of\narrivals and resource levels) for a large class of problems we refer to as\nOnline Allocation with finite types, which includes widely-studied Online\nPacking and Online Matching problems. Our results generalize and simplify\nseveral existing results for Online Packing and Online Matching, and suggest a\npromising pathway for obtaining oracle-driven policies for other online\ndecision-making settings. \n\n"}
{"id": "1901.05534", "contents": "Title: Lagging Inference Networks and Posterior Collapse in Variational\n  Autoencoders Abstract: The variational autoencoder (VAE) is a popular combination of deep latent\nvariable model and accompanying variational learning technique. By using a\nneural inference network to approximate the model's posterior on latent\nvariables, VAEs efficiently parameterize a lower bound on marginal data\nlikelihood that can be optimized directly via gradient methods. In practice,\nhowever, VAE training often results in a degenerate local optimum known as\n\"posterior collapse\" where the model learns to ignore the latent variable and\nthe approximate posterior mimics the prior. In this paper, we investigate\nposterior collapse from the perspective of training dynamics. We find that\nduring the initial stages of training the inference network fails to\napproximate the model's true posterior, which is a moving target. As a result,\nthe model is encouraged to ignore the latent encoding and posterior collapse\noccurs. Based on this observation, we propose an extremely simple modification\nto VAE training to reduce inference lag: depending on the model's current\nmutual information between latent variable and observation, we aggressively\noptimize the inference network before performing each model update. Despite\nintroducing neither new model components nor significant complexity over basic\nVAE, our approach is able to avoid the problem of collapse that has plagued a\nlarge amount of previous work. Empirically, our approach outperforms strong\nautoregressive baselines on text and image benchmarks in terms of held-out\nlikelihood, and is competitive with more complex techniques for avoiding\ncollapse while being substantially faster. \n\n"}
{"id": "1901.05560", "contents": "Title: Off-Policy Evaluation of Probabilistic Identity Data in Lookalike\n  Modeling Abstract: We evaluate the impact of probabilistically-constructed digital identity data\ncollected from Sep. to Dec. 2017 (approx.), in the context of\nLookalike-targeted campaigns. The backbone of this study is a large set of\nprobabilistically-constructed \"identities\", represented as small bags of\ncookies and mobile ad identifiers with associated metadata, that are likely all\nowned by the same underlying user. The identity data allows to generate\n\"identity-based\", rather than \"identifier-based\", user models, giving a fuller\npicture of the interests of the users underlying the identifiers. We employ\noff-policy techniques to evaluate the potential of identity-powered lookalike\nmodels without incurring the risk of allowing untested models to direct large\namounts of ad spend or the large cost of performing A/B tests. We add to\nhistorical work on off-policy evaluation by noting a significant type of\n\"finite-sample bias\" that occurs for studies combining modestly-sized datasets\nand evaluation metrics involving rare events (e.g., conversions). We illustrate\nthis bias using a simulation study that later informs the handling of inverse\npropensity weights in our analyses on real data. We demonstrate significant\nlift in identity-powered lookalikes versus an identity-ignorant baseline: on\naverage ~70% lift in conversion rate. This rises to factors of ~(4-32)x for\nidentifiers having little data themselves, but that can be inferred to belong\nto users with substantial data to aggregate across identifiers. This implies\nthat identity-powered user modeling is especially important in the context of\nidentifiers having very short lifespans (i.e., frequently churned cookies). Our\nwork motivates and informs the use of probabilistically-constructed identities\nin marketing. It also deepens the canon of examples in which off-policy\nlearning has been employed to evaluate the complex systems of the internet\neconomy. \n\n"}
{"id": "1901.05704", "contents": "Title: Evolving embodied intelligence from materials to machines Abstract: Natural lifeforms specialise to their environmental niches across many\nlevels; from low-level features such as DNA and proteins, through to\nhigher-level artefacts including eyes, limbs, and overarching body plans. We\npropose Multi-Level Evolution (MLE), a bottom-up automatic process that designs\nrobots across multiple levels and niches them to tasks and environmental\nconditions. MLE concurrently explores constituent molecular and material\n'building blocks', as well as their possible assemblies into specialised\nmorphological and sensorimotor configurations. MLE provides a route to fully\nharness a recent explosion in available candidate materials and ongoing\nadvances in rapid manufacturing processes. We outline a feasible MLE\narchitecture that realises this vision, highlight the main roadblocks and how\nthey may be overcome, and show robotic applications to which MLE is\nparticularly suited. By forming a research agenda to stimulate discussion\nbetween researchers in related fields, we hope to inspire the pursuit of\nmulti-level robotic design all the way from material to machine. \n\n"}
{"id": "1901.06003", "contents": "Title: Gromov-Wasserstein Learning for Graph Matching and Node Embedding Abstract: A novel Gromov-Wasserstein learning framework is proposed to jointly match\n(align) graphs and learn embedding vectors for the associated graph nodes.\nUsing Gromov-Wasserstein discrepancy, we measure the dissimilarity between two\ngraphs and find their correspondence, according to the learned optimal\ntransport. The node embeddings associated with the two graphs are learned under\nthe guidance of the optimal transport, the distance of which not only reflects\nthe topological structure of each graph but also yields the correspondence\nacross the graphs. These two learning steps are mutually-beneficial, and are\nunified here by minimizing the Gromov-Wasserstein discrepancy with structural\nregularizers. This framework leads to an optimization problem that is solved by\na proximal point method. We apply the proposed method to matching problems in\nreal-world networks, and demonstrate its superior performance compared to\nalternative approaches. \n\n"}
{"id": "1901.06033", "contents": "Title: Continuous Hierarchical Representations with Poincar\\'e Variational\n  Auto-Encoders Abstract: The variational auto-encoder (VAE) is a popular method for learning a\ngenerative model and embeddings of the data. Many real datasets are\nhierarchically structured. However, traditional VAEs map data in a Euclidean\nlatent space which cannot efficiently embed tree-like structures. Hyperbolic\nspaces with negative curvature can. We therefore endow VAEs with a Poincar\\'e\nball model of hyperbolic geometry as a latent space and rigorously derive the\nnecessary methods to work with two main Gaussian generalisations on that space.\nWe empirically show better generalisation to unseen data than the Euclidean\ncounterpart, and can qualitatively and quantitatively better recover\nhierarchical structures. \n\n"}
{"id": "1901.07361", "contents": "Title: Lower bounds for testing graphical models: colorings and\n  antiferromagnetic Ising models Abstract: We study the identity testing problem in the context of spin systems or\nundirected graphical models, where it takes the following form: given the\nparameter specification of the model $M$ and a sampling oracle for the\ndistribution $\\mu_{\\hat{M}}$ of an unknown model $\\hat{M}$, can we efficiently\ndetermine if the two models $M$ and $\\hat{M}$ are the same? We consider\nidentity testing for both soft-constraint and hard-constraint systems. In\nparticular, we prove hardness results in two prototypical cases, the Ising\nmodel and proper colorings, and explore whether identity testing is any easier\nthan structure learning.\n  For the ferromagnetic (attractive) Ising model, Daskalakis et al. (2018)\npresented a polynomial time algorithm for identity testing. We prove hardness\nresults in the antiferromagnetic (repulsive) setting in the same regime of\nparameters where structure learning is known to require a super-polynomial\nnumber of samples. In particular, for $n$-vertex graphs of maximum degree $d$,\nwe prove that if $|\\beta| d = \\omega(\\log{n})$ (where $\\beta$ is the inverse\ntemperature parameter), then there is no polynomial running time identity\ntesting algorithm unless $RP=NP$. We also establish computational lower bounds\nfor a broader set of parameters under the (randomized) exponential time\nhypothesis. Our proofs utilize insights into the design of gadgets using random\ngraphs in recent works concerning the hardness of approximate counting by Sly\n(2010). In the hard-constraint setting, we present hardness results for\nidentity testing for proper colorings. Our results are based on the presumed\nhardness of #BIS, the problem of (approximately) counting independent sets in\nbipartite graphs. In particular, we prove that identity testing is hard in the\nsame range of parameters where structure learning is known to be hard. \n\n"}
{"id": "1901.07777", "contents": "Title: Stochastic Gradient Trees Abstract: We present an algorithm for learning decision trees using stochastic gradient\ninformation as the source of supervision. In contrast to previous approaches to\ngradient-based tree learning, our method operates in the incremental learning\nsetting rather than the batch learning setting, and does not make use of soft\nsplits or require the construction of a new tree for every update. We\ndemonstrate how one can apply these decision trees to different problems by\nchanging only the loss function, using classification, regression, and\nmulti-instance learning as example applications. In the experimental\nevaluation, our method performs similarly to standard incremental\nclassification trees, outperforms state of the art incremental regression\ntrees, and achieves comparable performance with batch multi-instance learning\nmethods. \n\n"}
{"id": "1901.07878", "contents": "Title: \"Is this an example image?\" -- Predicting the Relative Abstractness\n  Level of Image and Text Abstract: Successful multimodal search and retrieval requires the automatic\nunderstanding of semantic cross-modal relations, which, however, is still an\nopen research problem. Previous work has suggested the metrics cross-modal\nmutual information and semantic correlation to model and predict cross-modal\nsemantic relations of image and text. In this paper, we present an approach to\npredict the (cross-modal) relative abstractness level of a given image-text\npair, that is whether the image is an abstraction of the text or vice versa.\nFor this purpose, we introduce a new metric that captures this specific\nrelationship between image and text at the Abstractness Level (ABS). We present\na deep learning approach to predict this metric, which relies on an autoencoder\narchitecture that allows us to significantly reduce the required amount of\nlabeled training data. A comprehensive set of publicly available scientific\ndocuments has been gathered. Experimental results on a challenging test set\ndemonstrate the feasibility of the approach. \n\n"}
{"id": "1901.07947", "contents": "Title: Machine Learning for Wireless Communications in the Internet of Things:\n  A Comprehensive Survey Abstract: The Internet of Things (IoT) is expected to require more effective and\nefficient wireless communications than ever before. For this reason, techniques\nsuch as spectrum sharing, dynamic spectrum access, extraction of signal\nintelligence and optimized routing will soon become essential components of the\nIoT wireless communication paradigm. Given that the majority of the IoT will be\ncomposed of tiny, mobile, and energy-constrained devices, traditional\ntechniques based on a priori network optimization may not be suitable, since\n(i) an accurate model of the environment may not be readily available in\npractical scenarios; (ii) the computational requirements of traditional\noptimization techniques may prove unbearable for IoT devices. To address the\nabove challenges, much research has been devoted to exploring the use of\nmachine learning to address problems in the IoT wireless communications domain.\n  This work provides a comprehensive survey of the state of the art in the\napplication of machine learning techniques to address key problems in IoT\nwireless communications with an emphasis on its ad hoc networking aspect.\nFirst, we present extensive background notions of machine learning techniques.\nThen, by adopting a bottom-up approach, we examine existing work on machine\nlearning for the IoT at the physical, data-link and network layer of the\nprotocol stack. Thereafter, we discuss directions taken by the community\ntowards hardware implementation to ensure the feasibility of these techniques.\nAdditionally, before concluding, we also provide a brief discussion of the\napplication of machine learning in IoT beyond wireless communication. Finally,\neach of these discussions is accompanied by a detailed analysis of the related\nopen problems and challenges. \n\n"}
{"id": "1901.08275", "contents": "Title: Multi-fidelity Bayesian Optimization with Max-value Entropy Search and\n  its parallelization Abstract: In a standard setting of Bayesian optimization (BO), the objective function\nevaluation is assumed to be highly expensive. Multi-fidelity Bayesian\noptimization (MFBO) accelerates BO by incorporating lower fidelity observations\navailable with a lower sampling cost. In this paper, we focus on the\ninformation-based approach, which is a popular and empirically successful\napproach in BO. For MFBO, however, existing information-based methods are\nplagued by difficulty in estimating the information gain. We propose an\napproach based on max-value entropy search (MES), which greatly facilitates\ncomputations by considering the entropy of the optimal function value instead\nof the optimal input point. We show that, in our multi-fidelity MES (MF-MES),\nmost of additional computations, compared with usual MES, is reduced to\nanalytical computations. Although an additional numerical integration is\nnecessary for the information across different fidelities, this is only in one\ndimensional space, which can be performed efficiently and accurately. Further,\nwe also propose parallelization of MF-MES. Since there exist a variety of\ndifferent sampling costs, queries typically occur asynchronously in MFBO. We\nshow that similar simple computations can be derived for asynchronous parallel\nMFBO. We demonstrate effectiveness of our approach by using benchmark datasets\nand a real-world application to materials science data. \n\n"}
{"id": "1901.08386", "contents": "Title: PAC Identification of Many Good Arms in Stochastic Multi-Armed Bandits Abstract: We consider the problem of identifying any $k$ out of the best $m$ arms in an\n$n$-armed stochastic multi-armed bandit. Framed in the PAC setting, this\nparticular problem generalises both the problem of `best subset selection' and\nthat of selecting `one out of the best m' arms [arcsk 2017]. In applications\nsuch as crowd-sourcing and drug-designing, identifying a single good solution\nis often not sufficient. Moreover, finding the best subset might be hard due to\nthe presence of many indistinguishably close solutions. Our generalisation of\nidentifying exactly $k$ arms out of the best $m$, where $1 \\leq k \\leq m$,\nserves as a more effective alternative. We present a lower bound on the\nworst-case sample complexity for general $k$, and a fully sequential PAC\nalgorithm, \\GLUCB, which is more sample-efficient on easy instances. Also,\nextending our analysis to infinite-armed bandits, we present a PAC algorithm\nthat is independent of $n$, which identifies an arm from the best $\\rho$\nfraction of arms using at most an additive poly-log number of samples than\ncompared to the lower bound, thereby improving over [arcsk 2017] and\n[Aziz+AKA:2018]. The problem of identifying $k > 1$ distinct arms from the best\n$\\rho$ fraction is not always well-defined; for a special class of this\nproblem, we present lower and upper bounds. Finally, through a reduction, we\nestablish a relation between upper bounds for the `one out of the best $\\rho$'\nproblem for infinite instances and the `one out of the best $m$' problem for\nfinite instances. We conjecture that it is more efficient to solve `small'\nfinite instances using the latter formulation, rather than going through the\nformer. \n\n"}
{"id": "1901.08518", "contents": "Title: Learning from Multiple Cities: A Meta-Learning Approach for\n  Spatial-Temporal Prediction Abstract: Spatial-temporal prediction is a fundamental problem for constructing smart\ncity, which is useful for tasks such as traffic control, taxi dispatching, and\nenvironmental policy making. Due to data collection mechanism, it is common to\nsee data collection with unbalanced spatial distributions. For example, some\ncities may release taxi data for multiple years while others only release a few\ndays of data; some regions may have constant water quality data monitored by\nsensors whereas some regions only have a small collection of water samples. In\nthis paper, we tackle the problem of spatial-temporal prediction for the cities\nwith only a short period of data collection. We aim to utilize the long-period\ndata from other cities via transfer learning. Different from previous studies\nthat transfer knowledge from one single source city to a target city, we are\nthe first to leverage information from multiple cities to increase the\nstability of transfer. Specifically, our proposed model is designed as a\nspatial-temporal network with a meta-learning paradigm. The meta-learning\nparadigm learns a well-generalized initialization of the spatial-temporal\nnetwork, which can be effectively adapted to target cities. In addition, a\npattern-based spatial-temporal memory is designed to distill long-term temporal\ninformation (i.e., periodicity). We conduct extensive experiments on two tasks:\ntraffic (taxi and bike) prediction and water quality prediction. The\nexperiments demonstrate the effectiveness of our proposed model over several\ncompetitive baseline models. \n\n"}
{"id": "1901.08560", "contents": "Title: Semi-Unsupervised Learning: Clustering and Classifying using\n  Ultra-Sparse Labels Abstract: In semi-supervised learning for classification, it is assumed that every\nground truth class of data is present in the small labelled dataset. Many\nreal-world sparsely-labelled datasets are plausibly not of this type. It could\neasily be the case that some classes of data are found only in the unlabelled\ndataset -- perhaps the labelling process was biased -- so we do not have any\nlabelled examples to train on for some classes. We call this learning regime\n$\\textit{semi-unsupervised learning}$, an extreme case of semi-supervised\nlearning, where some classes have no labelled exemplars in the training set.\nFirst, we outline the pitfalls associated with trying to apply deep generative\nmodel (DGM)-based semi-supervised learning algorithms to datasets of this type.\nWe then show how a combination of clustering and semi-supervised learning,\nusing DGMs, can be brought to bear on this problem. We study several different\ndatasets, showing how one can still learn effectively when half of the ground\ntruth classes are entirely unlabelled and the other half are sparsely labelled. \n\n"}
{"id": "1901.08628", "contents": "Title: Fair k-Center Clustering for Data Summarization Abstract: In data summarization we want to choose $k$ prototypes in order to summarize\na data set. We study a setting where the data set comprises several demographic\ngroups and we are restricted to choose $k_i$ prototypes belonging to group $i$.\nA common approach to the problem without the fairness constraint is to optimize\na centroid-based clustering objective such as $k$-center. A natural extension\nthen is to incorporate the fairness constraint into the clustering problem.\nExisting algorithms for doing so run in time super-quadratic in the size of the\ndata set, which is in contrast to the standard $k$-center problem being\napproximable in linear time. In this paper, we resolve this gap by providing a\nsimple approximation algorithm for the $k$-center problem under the fairness\nconstraint with running time linear in the size of the data set and $k$. If the\nnumber of demographic groups is small, the approximation guarantee of our\nalgorithm only incurs a constant-factor overhead. \n\n"}
{"id": "1901.08925", "contents": "Title: Combinational Q-Learning for Dou Di Zhu Abstract: Deep reinforcement learning (DRL) has gained a lot of attention in recent\nyears, and has been proven to be able to play Atari games and Go at or above\nhuman levels. However, those games are assumed to have a small fixed number of\nactions and could be trained with a simple CNN network. In this paper, we study\na special class of Asian popular card games called Dou Di Zhu, in which two\nadversarial groups of agents must consider numerous card combinations at each\ntime step, leading to huge number of actions. We propose a novel method to\nhandle combinatorial actions, which we call combinational Q-learning (CQL). We\nemploy a two-stage network to reduce action space and also leverage\norder-invariant max-pooling operations to extract relationships between\nprimitive actions. Results show that our method prevails over state-of-the art\nmethods like naive Q-learning and A3C. We develop an easy-to-use card game\nenvironments and train all agents adversarially from sractch, with only\nknowledge of game rules and verify that our agents are comparative to humans.\nOur code to reproduce all reported results will be available online. \n\n"}
{"id": "1901.09270", "contents": "Title: Challenges in Designing Datasets and Validation for Autonomous Driving Abstract: Autonomous driving is getting a lot of attention in the last decade and will\nbe the hot topic at least until the first successful certification of a car\nwith Level 5 autonomy. There are many public datasets in the academic\ncommunity. However, they are far away from what a robust industrial production\nsystem needs. There is a large gap between academic and industrial setting and\na substantial way from a research prototype, built on public datasets, to a\ndeployable solution which is a challenging task. In this paper, we focus on bad\npractices that often happen in the autonomous driving from an industrial\ndeployment perspective. Data design deserves at least the same amount of\nattention as the model design. There is very little attention paid to these\nissues in the scientific community, and we hope this paper encourages better\nformalization of dataset design. More specifically, we focus on the datasets\ndesign and validation scheme for autonomous driving, where we would like to\nhighlight the common problems, wrong assumptions, and steps towards avoiding\nthem, as well as some open problems. \n\n"}
{"id": "1901.09321", "contents": "Title: Fixup Initialization: Residual Learning Without Normalization Abstract: Normalization layers are a staple in state-of-the-art deep neural network\narchitectures. They are widely believed to stabilize training, enable higher\nlearning rate, accelerate convergence and improve generalization, though the\nreason for their effectiveness is still an active research topic. In this work,\nwe challenge the commonly-held beliefs by showing that none of the perceived\nbenefits is unique to normalization. Specifically, we propose fixed-update\ninitialization (Fixup), an initialization motivated by solving the exploding\nand vanishing gradient problem at the beginning of training via properly\nrescaling a standard initialization. We find training residual networks with\nFixup to be as stable as training with normalization -- even for networks with\n10,000 layers. Furthermore, with proper regularization, Fixup enables residual\nnetworks without normalization to achieve state-of-the-art performance in image\nclassification and machine translation. \n\n"}
{"id": "1901.09330", "contents": "Title: Reward Shaping via Meta-Learning Abstract: Reward shaping is one of the most effective methods to tackle the crucial yet\nchallenging problem of credit assignment in Reinforcement Learning (RL).\nHowever, designing shaping functions usually requires much expert knowledge and\nhand-engineering, and the difficulties are further exacerbated given multiple\nsimilar tasks to solve. In this paper, we consider reward shaping on a\ndistribution of tasks, and propose a general meta-learning framework to\nautomatically learn the efficient reward shaping on newly sampled tasks,\nassuming only shared state space but not necessarily action space. We first\nderive the theoretically optimal reward shaping in terms of credit assignment\nin model-free RL. We then propose a value-based meta-learning algorithm to\nextract an effective prior over the optimal reward shaping. The prior can be\napplied directly to new tasks, or provably adapted to the task-posterior while\nsolving the task within few gradient updates. We demonstrate the effectiveness\nof our shaping through significantly improved learning efficiency and\ninterpretable visualizations across various settings, including notably a\nsuccessful transfer from DQN to DDPG. \n\n"}
{"id": "1901.09387", "contents": "Title: Imitation Learning from Imperfect Demonstration Abstract: Imitation learning (IL) aims to learn an optimal policy from demonstrations.\nHowever, such demonstrations are often imperfect since collecting optimal ones\nis costly. To effectively learn from imperfect demonstrations, we propose a\nnovel approach that utilizes confidence scores, which describe the quality of\ndemonstrations. More specifically, we propose two confidence-based IL methods,\nnamely two-step importance weighting IL (2IWIL) and generative adversarial IL\nwith imperfect demonstration and confidence (IC-GAIL). We show that confidence\nscores given only to a small portion of sub-optimal demonstrations\nsignificantly improve the performance of IL both theoretically and empirically. \n\n"}
{"id": "1901.09491", "contents": "Title: Stiffness: A New Perspective on Generalization in Neural Networks Abstract: In this paper we develop a new perspective on generalization of neural\nnetworks by proposing and investigating the concept of a neural network\nstiffness. We measure how stiff a network is by looking at how a small gradient\nstep in the network's parameters on one example affects the loss on another\nexample. Higher stiffness suggests that a network is learning features that\ngeneralize. In particular, we study how stiffness depends on 1) class\nmembership, 2) distance between data points in the input space, 3) training\niteration, and 4) learning rate. We present experiments on MNIST, FASHION\nMNIST, and CIFAR-10/100 using fully-connected and convolutional neural\nnetworks, as well as on a transformer-based NLP model. We demonstrate the\nconnection between stiffness and generalization, and observe its dependence on\nlearning rate. When training on CIFAR-100, the stiffness matrix exhibits a\ncoarse-grained behavior indicative of the model's awareness of super-class\nmembership. In addition, we measure how stiffness between two data points\ndepends on their mutual input-space distance, and establish the concept of a\ndynamical critical length -- a distance below which a parameter update based on\na data point influences its neighbors. \n\n"}
{"id": "1901.09565", "contents": "Title: Fairness in representation: quantifying stereotyping as a\n  representational harm Abstract: While harms of allocation have been increasingly studied as part of the\nsubfield of algorithmic fairness, harms of representation have received\nconsiderably less attention. In this paper, we formalize two notions of\nstereotyping and show how they manifest in later allocative harms within the\nmachine learning pipeline. We also propose mitigation strategies and\ndemonstrate their effectiveness on synthetic datasets. \n\n"}
{"id": "1901.09613", "contents": "Title: Hybrid Machine Learning Approach to Popularity Prediction of Newly\n  Released Contents for Online Video Streaming Service Abstract: In the industry of video content providers such as VOD and IPTV, predicting\nthe popularity of video contents in advance is critical not only from a\nmarketing perspective but also from a network optimization perspective. By\npredicting whether the content will be successful or not in advance, the\ncontent file, which is large, is efficiently deployed in the proper service\nproviding server, leading to network cost optimization. Many previous studies\nhave done view count prediction research to do this. However, the studies have\nbeen making predictions based on historical view count data from users. In this\ncase, the contents had been published to the users and already deployed on a\nservice server. These approaches make possible to efficiently deploy a content\nalready published but are impossible to use for a content that is not be\npublished. To address the problems, this research proposes a hybrid machine\nlearning approach to the classification model for the popularity prediction of\nnewly video contents which is not published. In this paper, we create a new\nvariable based on the related content of the specific content and divide entire\ndataset by the characteristics of the contents. Next, the prediction is\nperformed using XGBoosting and deep neural net based model according to the\ndata characteristics of the cluster. Our model uses metadata for contents for\nprediction, so we use categorical embedding techniques to solve the sparsity of\ncategorical variables and make them learn efficiently for the deep neural net\nmodel. As well, we use the FTRL-proximal algorithm to solve the problem of the\nview-count volatility of video content. We achieve overall better performance\nthan the previous standalone method with a dataset from one of the top\nstreaming service company. \n\n"}
{"id": "1901.09749", "contents": "Title: Fairwashing: the risk of rationalization Abstract: Black-box explanation is the problem of explaining how a machine learning\nmodel -- whose internal logic is hidden to the auditor and generally complex --\nproduces its outcomes. Current approaches for solving this problem include\nmodel explanation, outcome explanation as well as model inspection. While these\ntechniques can be beneficial by providing interpretability, they can be used in\na negative manner to perform fairwashing, which we define as promoting the\nfalse perception that a machine learning model respects some ethical values. In\nparticular, we demonstrate that it is possible to systematically rationalize\ndecisions taken by an unfair black-box model using the model explanation as\nwell as the outcome explanation approaches with a given fairness metric. Our\nsolution, LaundryML, is based on a regularized rule list enumeration algorithm\nwhose objective is to search for fair rule lists approximating an unfair\nblack-box model. We empirically evaluate our rationalization technique on\nblack-box models trained on real-world datasets and show that one can obtain\nrule lists with high fidelity to the black-box model while being considerably\nless unfair at the same time. \n\n"}
{"id": "1901.09919", "contents": "Title: Inferring Heterogeneous Causal Effects in Presence of Spatial\n  Confounding Abstract: We address the problem of inferring the causal effect of an exposure on an\noutcome across space, using observational data. The data is possibly subject to\nunmeasured confounding variables which, in a standard approach, must be\nadjusted for by estimating a nuisance function. Here we develop a method that\neliminates the nuisance function, while mitigating the resulting\nerrors-in-variables. The result is a robust and accurate inference method for\nspatially varying heterogeneous causal effects. The properties of the method\nare demonstrated on synthetic as well as real data from Germany and the US. \n\n"}
{"id": "1901.09972", "contents": "Title: Heartbeat Anomaly Detection using Adversarial Oversampling Abstract: Cardiovascular diseases are one of the most common causes of death in the\nworld. Prevention, knowledge of previous cases in the family, and early\ndetection is the best strategy to reduce this fact. Different machine learning\napproaches to automatic diagnostic are being proposed to this task. As in most\nhealth problems, the imbalance between examples and classes is predominant in\nthis problem and affects the performance of the automated solution. In this\npaper, we address the classification of heartbeats images in different\ncardiovascular diseases. We propose a two-dimensional Convolutional Neural\nNetwork for classification after using a InfoGAN architecture for generating\nsynthetic images to unbalanced classes. We call this proposal Adversarial\nOversampling and compare it with the classical oversampling methods as SMOTE,\nADASYN, and RandomOversampling. The results show that the proposed approach\nimproves the classifier performance for the minority classes without harming\nthe performance in the balanced classes. \n\n"}
{"id": "1901.10024", "contents": "Title: Cross-Domain Image Manipulation by Demonstration Abstract: In this work we propose a model that can manipulate individual visual\nattributes of objects in a real scene using examples of how respective\nattribute manipulations affect the output of a simulation. As an example, we\ntrain our model to manipulate the expression of a human face using\nnonphotorealistic 3D renders of a face with varied expression. Our model\nmanages to preserve all other visual attributes of a real face, such as head\norientation, even though this and other attributes are not labeled in either\nreal or synthetic domain. Since our model learns to manipulate a specific\nproperty in isolation using only \"synthetic demonstrations\" of such\nmanipulations without explicitly provided labels, it can be applied to shape,\ntexture, lighting, and other properties that are difficult to measure or\nrepresent as real-valued vectors. We measure the degree to which our model\npreserves other attributes of a real image when a single specific attribute is\nmanipulated. We use digit datasets to analyze how discrepancy in attribute\ndistributions affects the performance of our model, and demonstrate results in\na far more difficult setting: learning to manipulate real human faces using\nnonphotorealistic 3D renders. \n\n"}
{"id": "1901.10026", "contents": "Title: Heterogeneous Network Motifs Abstract: Many real-world applications give rise to large heterogeneous networks where\nnodes and edges can be of any arbitrary type (e.g., user, web page, location).\nSpecial cases of such heterogeneous graphs include homogeneous graphs,\nbipartite, k-partite, signed, labeled graphs, among many others. In this work,\nwe generalize the notion of network motifs to heterogeneous networks. In\nparticular, small induced typed subgraphs called typed graphlets (heterogeneous\nnetwork motifs) are introduced and shown to be the fundamental building blocks\nof complex heterogeneous networks. Typed graphlets are a powerful\ngeneralization of the notion of graphlet (network motif) to heterogeneous\nnetworks as they capture both the induced subgraph of interest and the types\nassociated with the nodes in the induced subgraph. To address this problem, we\npropose a fast, parallel, and space-efficient framework for counting typed\ngraphlets in large networks. We discover the existence of non-trivial\ncombinatorial relationships between lower-order ($k-1$)-node typed graphlets\nand leverage them for deriving many of the $k$-node typed graphlets in $o(1)$\nconstant time. Thus, we avoid explicit enumeration of those typed graphlets.\nNotably, the time complexity matches the best untyped graphlet counting\nalgorithm. The experiments demonstrate the effectiveness of the proposed\nframework in terms of runtime, space-efficiency, parallel speedup, and\nscalability as it is able to handle large-scale networks. \n\n"}
{"id": "1901.10055", "contents": "Title: Self-Attention Networks for Connectionist Temporal Classification in\n  Speech Recognition Abstract: The success of self-attention in NLP has led to recent applications in\nend-to-end encoder-decoder architectures for speech recognition. Separately,\nconnectionist temporal classification (CTC) has matured as an alignment-free,\nnon-autoregressive approach to sequence transduction, either by itself or in\nvarious multitask and decoding frameworks. We propose SAN-CTC, a deep, fully\nself-attentional network for CTC, and show it is tractable and competitive for\nend-to-end speech recognition. SAN-CTC trains quickly and outperforms existing\nCTC models and most encoder-decoder models, with character error rates (CERs)\nof 4.7% in 1 day on WSJ eval92 and 2.8% in 1 week on LibriSpeech test-clean,\nwith a fixed architecture and one GPU. Similar improvements hold for WERs after\nLM decoding. We motivate the architecture for speech, evaluate position and\ndownsampling approaches, and explore how label alphabets (character, phoneme,\nsubword) affect attention heads and performance. \n\n"}
{"id": "1901.10082", "contents": "Title: Variational Characterizations of Local Entropy and Heat Regularization\n  in Deep Learning Abstract: The aim of this paper is to provide new theoretical and computational\nunderstanding on two loss regularizations employed in deep learning, known as\nlocal entropy and heat regularization. For both regularized losses we introduce\nvariational characterizations that naturally suggest a two-step scheme for\ntheir optimization, based on the iterative shift of a probability density and\nthe calculation of a best Gaussian approximation in Kullback-Leibler\ndivergence. Under this unified light, the optimization schemes for local\nentropy and heat regularized loss differ only over which argument of the\nKullback-Leibler divergence is used to find the best Gaussian approximation.\nLocal entropy corresponds to minimizing over the second argument, and the\nsolution is given by moment matching. This allows to replace traditional\nback-propagation calculation of gradients by sampling algorithms, opening an\navenue for gradient-free, parallelizable training of neural networks. \n\n"}
{"id": "1901.10084", "contents": "Title: A Parallel Projection Method for Metric Constrained Optimization Abstract: Many clustering applications in machine learning and data mining rely on\nsolving metric-constrained optimization problems. These problems are\ncharacterized by $O(n^3)$ constraints that enforce triangle inequalities on\ndistance variables associated with $n$ objects in a large dataset. Despite its\nusefulness, metric-constrained optimization is challenging in practice due to\nthe cubic number of constraints and the high-memory requirements of standard\noptimization software. Recent work has shown that iterative projection methods\nare able to solve metric-constrained optimization problems on a much larger\nscale than was previously possible, thanks to their comparatively low memory\nrequirement. However, the major limitation of projection methods is their slow\nconvergence rate. In this paper we present a parallel projection method for\nmetric-constrained optimization which allows us to speed up the convergence\nrate in practice. The key to our approach is a new parallel execution schedule\nthat allows us to perform projections at multiple metric constraints\nsimultaneously without any conflicts or locking of variables. We illustrate the\neffectiveness of this execution schedule by implementing and testing a parallel\nprojection method for solving the metric-constrained linear programming\nrelaxation of correlation clustering. We show numerous experimental results on\nproblems involving up to 2.9 trillion constraints. \n\n"}
{"id": "1901.10113", "contents": "Title: Self-organization of action hierarchy and compositionality by\n  reinforcement learning with recurrent neural networks Abstract: Recurrent neural networks (RNNs) for reinforcement learning (RL) have shown\ndistinct advantages, e.g., solving memory-dependent tasks and meta-learning.\nHowever, little effort has been spent on improving RNN architectures and on\nunderstanding the underlying neural mechanisms for performance gain. In this\npaper, we propose a novel, multiple-timescale, stochastic RNN for RL. Empirical\nresults show that the network can autonomously learn to abstract sub-goals and\ncan self-develop an action hierarchy using internal dynamics in a challenging\ncontinuous control task. Furthermore, we show that the self-developed\ncompositionality of the network enhances faster re-learning when adapting to a\nnew task that is a re-composition of previously learned sub-goals, than when\nstarting from scratch. We also found that improved performance can be achieved\nwhen neural activities are subject to stochastic rather than deterministic\ndynamics. \n\n"}
{"id": "1901.10230", "contents": "Title: Partially Exchangeable Networks and Architectures for Learning Summary\n  Statistics in Approximate Bayesian Computation Abstract: We present a novel family of deep neural architectures, named partially\nexchangeable networks (PENs) that leverage probabilistic symmetries. By design,\nPENs are invariant to block-switch transformations, which characterize the\npartial exchangeability properties of conditionally Markovian processes.\nMoreover, we show that any block-switch invariant function has a PEN-like\nrepresentation. The DeepSets architecture is a special case of PEN and we can\ntherefore also target fully exchangeable data. We employ PENs to learn summary\nstatistics in approximate Bayesian computation (ABC). When comparing PENs to\nprevious deep learning methods for learning summary statistics, our results are\nhighly competitive, both considering time series and static models. Indeed,\nPENs provide more reliable posterior samples even when using less training\ndata. \n\n"}
{"id": "1901.10503", "contents": "Title: Time-Space tradeoff in deep learning models for crop classification on\n  satellite multi-spectral image time series Abstract: In this article, we investigate several structured deep learning models for\ncrop type classification on multi-spectral time series. In particular, our aim\nis to assess the respective importance of spatial and temporal structures in\nsuch data. With this objective, we consider several designs of convolutional,\nrecurrent, and hybrid neural networks, and assess their performance on a large\ndataset of freely available Sentinel-2 imagery. We find that the\nbest-performing approaches are hybrid configurations for which most of the\nparameters (up to 90%) are allocated to modeling the temporal structure of the\ndata. Our results thus constitute a set of guidelines for the design of bespoke\ndeep learning models for crop type classification. \n\n"}
{"id": "1901.10609", "contents": "Title: Deep Active Learning for Efficient Training of a LiDAR 3D Object\n  Detector Abstract: Training a deep object detector for autonomous driving requires a huge amount\nof labeled data. While recording data via on-board sensors such as camera or\nLiDAR is relatively easy, annotating data is very tedious and time-consuming,\nespecially when dealing with 3D LiDAR points or radar data. Active learning has\nthe potential to minimize human annotation efforts while maximizing the object\ndetector's performance. In this work, we propose an active learning method to\ntrain a LiDAR 3D object detector with the least amount of labeled training data\nnecessary. The detector leverages 2D region proposals generated from the RGB\nimages to reduce the search space of objects and speed up the learning process.\nExperiments show that our proposed method works under different uncertainty\nestimations and query functions, and can save up to 60% of the labeling efforts\nwhile reaching the same network performance. \n\n"}
{"id": "1901.10653", "contents": "Title: Evaluating Bregman Divergences for Probability Learning from Crowd Abstract: The crowdsourcing scenarios are a good example of having a probability\ndistribution over some categories showing what the people in a global\nperspective thinks. Learn a predictive model of this probability distribution\ncan be of much more valuable that learn only a discriminative model that gives\nthe most likely category of the data. Here we present differents models that\nadapts having probability distribution as target to train a machine learning\nmodel. We focus on the Bregman divergences framework to used as objective\nfunction to minimize. The results show that special care must be taken when\nbuild a objective function and consider a equal optimization on neural network\nin Keras framework. \n\n"}
{"id": "1901.11261", "contents": "Title: Higher-order Count Sketch: Dimensionality Reduction That Retains\n  Efficient Tensor Operations Abstract: Sketching is a randomized dimensionality-reduction method that aims to\npreserve relevant information in large-scale datasets. Count sketch is a simple\npopular sketch which uses a randomized hash function to achieve compression. In\nthis paper, we propose a novel extension known as Higher-order Count Sketch\n(HCS). While count sketch uses a single hash function, HCS uses multiple\n(smaller) hash functions for sketching. HCS reshapes the input (vector) data\ninto a higher-order tensor and employs a tensor product of the random hash\nfunctions to compute the sketch. This results in an exponential saving (with\nrespect to the order of the tensor) in the memory requirements of the hash\nfunctions, under certain conditions on the input data. Furthermore, when the\ninput data itself has an underlying structure in the form of various tensor\nrepresentations such as the Tucker decomposition, we obtain significant\nadvantages. We derive efficient (approximate) computation of various tensor\noperations such as tensor products and tensor contractions directly on the\nsketched data. Thus, HCS is the first sketch to fully exploit the\nmulti-dimensional nature of higher-order tensors. We apply HCS to tensorized\nneural networks where we replace fully connected layers with sketched tensor\noperations. We achieve nearly state of the art accuracy with significant\ncompression on the image classification benchmark. \n\n"}
{"id": "1901.11300", "contents": "Title: Robust Inference via Generative Classifiers for Handling Noisy Labels Abstract: Large-scale datasets may contain significant proportions of noisy (incorrect)\nclass labels, and it is well-known that modern deep neural networks (DNNs)\npoorly generalize from such noisy training datasets. To mitigate the issue, we\npropose a novel inference method, termed Robust Generative classifier (RoG),\napplicable to any discriminative (e.g., softmax) neural classifier pre-trained\non noisy datasets. In particular, we induce a generative classifier on top of\nhidden feature spaces of the pre-trained DNNs, for obtaining a more robust\ndecision boundary. By estimating the parameters of generative classifier using\nthe minimum covariance determinant estimator, we significantly improve the\nclassification accuracy with neither re-training of the deep model nor changing\nits architectures. With the assumption of Gaussian distribution for features,\nwe prove that RoG generalizes better than baselines under noisy labels.\nFinally, we propose the ensemble version of RoG to improve its performance by\ninvestigating the layer-wise characteristics of DNNs. Our extensive\nexperimental results demonstrate the superiority of RoG given different\nlearning models optimized by several training techniques to handle diverse\nscenarios of noisy labels. \n\n"}
{"id": "1901.11528", "contents": "Title: Shaping the Narrative Arc: An Information-Theoretic Approach to\n  Collaborative Dialogue Abstract: We consider the problem of designing an artificial agent capable of\ninteracting with humans in collaborative dialogue to produce creative, engaging\nnarratives. In this task, the goal is to establish universe details, and to\ncollaborate on an interesting story in that universe, through a series of\nnatural dialogue exchanges. Our model can augment any probabilistic\nconversational agent by allowing it to reason about universe information\nestablished and what potential next utterances might reveal. Ideally, with each\nutterance, agents would reveal just enough information to add specificity and\nreduce ambiguity without limiting the conversation. We empirically show that\nour model allows control over the rate at which the agent reveals information\nand that doing so significantly improves accuracy in predicting the next line\nof dialogues from movies. We close with a case-study with four professional\ntheatre performers, who preferred interactions with our model-augmented agent\nover an unaugmented agent. \n\n"}
{"id": "cs/0106019", "contents": "Title: Playing Games with Algorithms: Algorithmic Combinatorial Game Theory Abstract: Combinatorial games lead to several interesting, clean problems in algorithms\nand complexity theory, many of which remain open. The purpose of this paper is\nto provide an overview of the area to encourage further research. In\nparticular, we begin with general background in Combinatorial Game Theory,\nwhich analyzes ideal play in perfect-information games, and Constraint Logic,\nwhich provides a framework for showing hardness. Then we survey results about\nthe complexity of determining ideal play in these games, and the related\nproblems of solving puzzles, in terms of both polynomial-time algorithms and\ncomputational intractability results. Our review of background and survey of\nalgorithmic results are by no means complete, but should serve as a useful\nprimer. \n\n"}
{"id": "cs/0301030", "contents": "Title: Bounds on the Number of Longest Common Subsequences Abstract: This paper performs the analysis necessary to bound the running time of\nknown, efficient algorithms for generating all longest common subsequences.\nThat is, we bound the running time as a function of input size for algorithms\nwith time essentially proportional to the output size. This paper considers\nboth the case of computing all distinct LCSs and the case of computing all LCS\nembeddings. Also included is an analysis of how much better the efficient\nalgorithms are than the standard method of generating LCS embeddings. A full\nanalysis is carried out with running times measured as a function of the total\nnumber of input characters, and much of the analysis is also provided for cases\nin which the two input sequences are of the same specified length or of two\nindependently specified lengths. \n\n"}
{"id": "math-ph/0701043", "contents": "Title: Strong Spatial Mixing and Rapid Mixing with Five Colours for the Kagome\n  Lattice Abstract: We consider proper 5-colourings of the kagome lattice. Proper q-colourings\ncorrespond to configurations in the zero-temperature q-state anti-ferromagnetic\nPotts model. Salas and Sokal have given a computer assisted proof of strong\nspatial mixing on the kagome lattice for q>=6 under any temperature, including\nzero temperature. It is believed that there is strong spatial mixing for q>=4.\nHere we give a computer assisted proof of strong spatial mixing for q=5 and\nzero temperature. It is commonly known that strong spatial mixing implies that\nthere is a unique infinite-volume Gibbs measure and that the Glauber dynamics\nis rapidly mixing. We give a proof of rapid mixing of the Glauber dynamics on\nany finite subset of the vertices of the kagome lattice, provided that the\nboundary is free (not coloured). The Glauber dynamics is not necessarily\nirreducible if the boundary is chosen arbitrarily for q=5 colours. The Glauber\ndynamics can be used to uniformly sample proper 5-colourings. Thus, a\nconsequence of rapidly mixing Glauber dynamics is that there is fully\npolynomial randomised approximation scheme for counting the number of proper\n5-colourings. \n\n"}
